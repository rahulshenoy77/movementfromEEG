{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from __future__ import absolute_import\n",
    "from __future__ import division\n",
    "from __future__ import print_function\n",
    "\n",
    "import tensorflow as tf\n",
    "import numpy as np\n",
    "import time\n",
    "import os\n",
    "from datetime import datetime\n",
    "\n",
    "from model_final_2 import Model\n",
    "from configs_final_2 import config\n",
    "from tensorflow.core.protobuf import rewriter_config_pb2\n",
    "from sklearn.model_selection import train_test_split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def data_loader_gan():\n",
    "    time_bin = 700\n",
    "    X_test = np.load(\"X_test.npy\")\n",
    "    X_test = X_test[:,0:22,0:time_bin]\n",
    "    y_test = np.load(\"y_test.npy\")\n",
    "    person_test = np.load(\"person_test.npy\")\n",
    "\n",
    "    X_train_valid = np.load(\"X_train_valid.npy\")\n",
    "    X_train_valid = X_train_valid[:,0:22,0:time_bin]\n",
    "    y_train_valid = np.load(\"y_train_valid.npy\")\n",
    "    person_train_valid = np.load(\"person_train_valid.npy\")\n",
    "    \n",
    "    X_train_gan = np.load(\"X_train_gan4.npy\")\n",
    "    X_train_gan = X_train_gan[:,0:22,0:time_bin,:]\n",
    "    shp = X_train_gan.shape\n",
    "    X_train_gan = np.reshape(X_train_gan,(shp[0],shp[1],shp[2]))\n",
    "    y_train_gan = np.load(\"y_train_gan4.npy\")\n",
    "    \n",
    "    N_train = X_train_valid.shape[0]\n",
    "    idx_train_valid = np.arange(N_train,dtype='int')\n",
    "\n",
    "    _, X_val, _ , idx_val = train_test_split(X_train_valid, idx_train_valid, test_size=0.2, random_state=21)\n",
    "\n",
    "    y_val = y_train_valid[idx_val]\n",
    "    person_val = person_train_valid[idx_val]\n",
    "    \n",
    "    idx11 = np.arange(0,X_test.shape[2],2,dtype=int)\n",
    "    idx21 = np.arange(1,X_test.shape[2],2,dtype=int)\n",
    "    X_test_ss1 = np.take(X_test,idx11,axis=2)\n",
    "    X_test_ss2 = np.take(X_test,idx21,axis=2)\n",
    "    X_test = np.concatenate((X_test_ss1,X_test_ss2),axis=0)\n",
    "    y_test = np.concatenate((y_test,y_test),axis=0)\n",
    "    person_test = np.concatenate((person_test,person_test),axis=0)\n",
    "    \n",
    "    idx12 = np.arange(0,X_train_gan.shape[2],2,dtype=int)\n",
    "    idx22 = np.arange(1,X_train_gan.shape[2],2,dtype=int)\n",
    "    X_train_ss1 = np.take(X_train_gan,idx12,axis=2)\n",
    "    X_train_ss2 = np.take(X_train_gan,idx22,axis=2)\n",
    "    X_train_gan = np.concatenate((X_train_ss1,X_train_ss2),axis=0)\n",
    "    y_train_gan = np.concatenate((y_train_gan,y_train_gan),axis=0)\n",
    "    \n",
    "    idx13 = np.arange(0,X_val.shape[2],2,dtype=int)\n",
    "    idx23 = np.arange(1,X_val.shape[2],2,dtype=int)\n",
    "    X_val_ss1 = np.take(X_val,idx13,axis=2)\n",
    "    X_val_ss2 = np.take(X_val,idx23,axis=2)\n",
    "    X_val = np.concatenate((X_val_ss1,X_val_ss2),axis=0)\n",
    "    y_val = np.concatenate((y_val,y_val),axis=0)\n",
    "    person_val = np.concatenate((person_val,person_val),axis=0)\n",
    "\n",
    "    tl = X_train_gan.shape[2]\n",
    "    X_test = np.reshape(X_test,(-1,22,tl,1))\n",
    "    X_train_gan = np.reshape(X_train_gan,(-1,22,tl,1))\n",
    "    X_val = np.reshape(X_val,(-1,22,tl,1))\n",
    "\n",
    "    label0 = 769\n",
    "    new_label0 = 0\n",
    "    for i in range(4):\n",
    "        m1 = (y_test==label0)\n",
    "        m3 = (y_val==label0)\n",
    "        np.place(y_test,m1,new_label0)\n",
    "        np.place(y_val,m3,new_label0)\n",
    "        label0 += 1\n",
    "        new_label0 += 1\n",
    "\n",
    "    labelNames = [0,1,2,3]\n",
    "    train_set = {'data': X_train_gan, 'labels': y_train_gan}\n",
    "    test_set = {'data': X_test, 'labels': y_test}\n",
    "    val_set = {'data': X_val, 'labels': y_val}\n",
    "    return train_set, test_set, val_set, labelNames\n",
    "\n",
    "def sample_batch(dataset, batch_size):\n",
    "    N = dataset['data'].shape[0]\n",
    "    indices = np.random.randint(N, size=batch_size)\n",
    "    return {key: dataset[key][indices] for key in dataset}\n",
    "\n",
    "def train_model_gan(target_dir,start,stop,step,time_bin,fsz,use_batchnorm,use_dropout,use_l2loss,num_class,max_step,log_frequency,batch_size,model_saving_freq):\n",
    "    # load data\n",
    "    print(\"Loading datasets...\")\n",
    "    trainSet, testSet, valSet, labelNames = data_loader_gan()\n",
    "    print(\"Dataset loading completes.\")\n",
    "    \n",
    "    best_val_acc = 0\n",
    "    best_val_path = target_dir\n",
    "    \n",
    "\n",
    "\n",
    "    # reset default graph\n",
    "    tf.reset_default_graph()\n",
    "\n",
    "    global_step = tf.train.get_or_create_global_step()\n",
    "    \n",
    "    model = Model(config, labelNames,start,stop,step,time_bin,fsz,use_batchnorm,use_dropout,use_l2loss)\n",
    "\n",
    "    # training setups\n",
    "    saver = tf.train.Saver(max_to_keep=100)\n",
    "\n",
    "    # Build an initialization operation to run below.\n",
    "    init = tf.global_variables_initializer()\n",
    "    \n",
    "    config_proto = tf.ConfigProto()\n",
    "\n",
    "    off = rewriter_config_pb2.RewriterConfig.OFF\n",
    "    config_proto.graph_options.rewrite_options.arithmetic_optimization = off\n",
    "    \n",
    "    sess = tf.Session(config=config_proto)\n",
    "\n",
    "    sess.run(init)\n",
    "\n",
    "    # main loop\n",
    "    for step in range(max_step):\n",
    "        start_time = time.time()\n",
    "\n",
    "        # prepare data\n",
    "        train_batch = sample_batch(trainSet, batch_size)\n",
    "        # feed dict\n",
    "        feed_dict = {\n",
    "            model.input: train_batch['data'],\n",
    "            model.fine_labels: train_batch['labels'],\n",
    "            model.is_training: True,\n",
    "            model.drprob: 0.7\n",
    "        }\n",
    "        \n",
    "        fetch_list = [model.optimizer_op, model.loss, model.global_step]\n",
    "        _, loss_value, global_step_value = sess.run(fetch_list, feed_dict=feed_dict)\n",
    "        duration = time.time() - start_time\n",
    "        assert not np.isnan(loss_value), 'Model diverged with loss = NaN'\n",
    "\n",
    "        # log\n",
    "        if step % log_frequency == 0:\n",
    "            num_examples_per_step = batch_size\n",
    "            examples_per_sec = num_examples_per_step / duration\n",
    "            sec_per_batch = duration\n",
    "            format_str = (\n",
    "                '%s: step %d, examples %d, loss = %.9f (%.3f examples/sec; %.3f sec/batch)'\n",
    "            )\n",
    "            print(\n",
    "                format_str % (\n",
    "                    datetime.now(), step, batch_size * step,\n",
    "                    loss_value,\n",
    "                    examples_per_sec, sec_per_batch\n",
    "                )\n",
    "            )\n",
    "\n",
    "        # Save the model checkpoint periodically.\n",
    "        if step % model_saving_freq == 0 or (step + 1) == max_step:\n",
    "            fetch_list = [model.accuracy,model.top_2_accuracy]\n",
    "            feed_dict = {\n",
    "                model.input: valSet['data'],\n",
    "                model.fine_labels: valSet['labels'],\n",
    "                model.is_training: False,\n",
    "            }\n",
    "            val_acc_1, val_acc_2 =  sess.run(fetch_list, feed_dict=feed_dict)\n",
    "            checkpoint_path = os.path.join(target_dir, 'model.ckpt')\n",
    "            saver.save(sess, checkpoint_path, global_step=int(global_step_value))\n",
    "            print('Top 1 validation accuracy: {} and top 2 validation accuracy: {}'.format(val_acc_1,val_acc_2))\n",
    "            print('Model Saved!')\n",
    "            if val_acc_1>best_val_acc:\n",
    "                best_val_acc = val_acc_1\n",
    "                best_val_path = checkpoint_path+'-'+str(int(global_step_value))\n",
    "    return best_val_acc,best_val_path\n",
    "\n",
    "\n",
    "def test_model_gan(model_dir,start,stop,step,time_bin,fsz,use_batchnorm,use_dropout,use_l2loss):\n",
    "    print(\"Loading datasets...\")\n",
    "    trainSet, testSet, valSet, labelNames = data_loader_gan()\n",
    "    print(\"Dataset loading completes.\")\n",
    "    \n",
    "    # reset default graph\n",
    "    tf.reset_default_graph()\n",
    "    \n",
    "    # create model\n",
    "    \n",
    "    model = Model(config, labelNames,start,stop,step,time_bin,fsz,use_batchnorm,use_dropout,use_l2loss)\n",
    "    # training setups\n",
    "    saver = tf.train.Saver(max_to_keep=100)\n",
    "    test_accuracy = [0, 0]\n",
    "    \n",
    "    config_proto = tf.ConfigProto()\n",
    "\n",
    "    off = rewriter_config_pb2.RewriterConfig.OFF\n",
    "    config_proto.graph_options.rewrite_options.arithmetic_optimization = off\n",
    "\n",
    "    with tf.Session(config=config_proto) as session:\n",
    "        session.run(tf.global_variables_initializer())\n",
    "        saver.restore(session, model_dir)\n",
    "        # test model\n",
    "        exp_results = run_single_step(session, model, testSet, mode='test')\n",
    "        test_accuracy[0] = exp_results['top_1_accuracy']\n",
    "        test_accuracy[1] = exp_results['top_2_accuracy']\n",
    "        print('top_1_accuracy_test = ', test_accuracy[0], 'top_2_accuracy_test = ', test_accuracy[1])\n",
    "        \n",
    "    top1_acc = test_accuracy[0]\n",
    "    top2_acc = test_accuracy[1]\n",
    "    return top1_acc,top2_acc\n",
    "\n",
    "\n",
    "def run_single_step(\n",
    "        session,\n",
    "        model,\n",
    "        batch,\n",
    "        mode='test',\n",
    "        log=True,\n",
    "):\n",
    "    # construct feed dict\n",
    "    feed_dict = {\n",
    "        model.input: batch['data'],\n",
    "        # model.coarse_labels: batch['coarse_labels'],\n",
    "        model.fine_labels: batch['labels'],\n",
    "        # model.label_mapping: label_mapping,\n",
    "        model.is_training: mode == 'train'\n",
    "    }\n",
    "    \n",
    "    # select proper summary op\n",
    "    if mode == 'train':\n",
    "        summary_op = model.train_summary_op\n",
    "    elif mode == 'val':\n",
    "        summary_op = model.val_summary_op\n",
    "    else:\n",
    "        summary_op = model.test_summary_op\n",
    "    \n",
    "    # construct fetch list\n",
    "    fetch_list = [model.global_step, summary_op, model.loss, model.accuracy, model.top_2_accuracy]\n",
    "\n",
    "    # run single step\n",
    "    _start_time = time.time()\n",
    "    _step, _summary, _loss, _top_1, _top_2 = session.run(fetch_list, feed_dict=feed_dict)[:5]\n",
    "    _end_time = time.time()\n",
    "    \n",
    "    # collect step statistics\n",
    "    step_time = _end_time - _start_time\n",
    "    batch_size = batch['data'].shape[0]\n",
    "    \n",
    "    # log in console\n",
    "    if log:\n",
    "        print(('[{:5s} step {:4d}] loss: {:.5f}; top_1_accuracy: {:.5f}; top_5_accuracy: {:5f} ' +\n",
    "              '({:.3f} sec/batch; {:.3f} instances/sec)'\n",
    "              ).format(mode, _step, _loss, _top_1, _top_2, \n",
    "                       step_time, batch_size / step_time))\n",
    "    \n",
    "    # log results to file and return statistics\n",
    "    if mode == 'test':\n",
    "        test_fetch_list = [model.per_class_accuracy,\n",
    "                model.top_2_per_class_accuracy,\n",
    "                model.confusion_matrix, \n",
    "                model.pred, model.probs]\n",
    "        _top_1_c,  _top_2_c, _cm, _pred, _probs = \\\n",
    "                session.run(test_fetch_list, feed_dict=feed_dict)\n",
    "        \n",
    "        \n",
    "        # Log detailed test results in pickle format\n",
    "        stats = {\n",
    "            \"loss\": _loss,\n",
    "            \"top_1_accuracy\": _top_1,\n",
    "            \"top_2_accuracy\": _top_2,\n",
    "            \"top_1_perclass_accuracy\": _top_1_c,\n",
    "            \"top_2_perclass_accuracy\": _top_2_c,\n",
    "            \"confusion_matrix\": _cm,\n",
    "            \"pred\": _pred,\n",
    "            \"probs\": _probs\n",
    "        }\n",
    "    else:\n",
    "        stats = {\n",
    "            \"step\": _step,\n",
    "            \"loss\": _loss,\n",
    "            \"top_1_accuracy\": _top_1,\n",
    "            \"top_2_accuracy\": _top_2\n",
    "        }\n",
    "        \n",
    "    return stats\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "best_val_gan = {}\n",
    "num_cls = 4\n",
    "mstp = 500\n",
    "lfrq = 10\n",
    "bsz = 50\n",
    "msf = 50\n",
    "tr = './trained_model_final/DCNN_GAN4'\n",
    "if not os.path.exists(tr):\n",
    "    os.mkdir(tr)\n",
    "start = 0\n",
    "stop = 250\n",
    "step = 10\n",
    "time_bin = 350\n",
    "fsz = 3\n",
    "use_batchnorm = True\n",
    "use_dropout = True\n",
    "use_l2loss = True\n",
    "acc = 'Accuracy_gan'\n",
    "path = 'Path_gan'\n",
    "\n",
    "best_val_gan[acc],best_val_gan[path] = train_model_gan(tr,start,stop,step,time_bin,fsz,use_batchnorm,use_dropout,use_l2loss,num_cls,mstp,lfrq,bsz,msf)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Test model accuracy\n",
    "start = 0\n",
    "stop = 250\n",
    "step = 10\n",
    "time_bin = 350\n",
    "#Nb = BATCH_SIZE\n",
    "fsz = 3\n",
    "use_batchnorm = True\n",
    "use_dropout = True\n",
    "use_l2loss = True\n",
    "path = 'Path_gan' \n",
    "model_dir = best_val_gan[path]\n",
    "print('Test Accuracy for all subjects:')\n",
    "top_1_acc_test, top_2_acc_test = test_model_gan(model_dir,start,stop,step,time_bin,fsz,use_batchnorm,use_dropout,use_l2loss)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "def data_loader_gan2():\n",
    "    time_bin = 700\n",
    "    X_test = np.load(\"X_test.npy\")\n",
    "    X_test = X_test[:,0:22,0:time_bin]\n",
    "    y_test = np.load(\"y_test.npy\")\n",
    "    person_test = np.load(\"person_test.npy\")\n",
    "\n",
    "    X_train_valid = np.load(\"X_train_valid.npy\")\n",
    "    X_train_valid = X_train_valid[:,0:22,0:time_bin]\n",
    "    y_train_valid = np.load(\"y_train_valid.npy\")\n",
    "    person_train_valid = np.load(\"person_train_valid.npy\")\n",
    "    \n",
    "    X_train_gan = np.load(\"X_train_gan4.npy\")\n",
    "    X_train_gan = X_train_gan[:,0:22,0:time_bin,:]\n",
    "    shp = X_train_gan.shape\n",
    "    X_train_gan = np.reshape(X_train_gan,(shp[0],shp[1],shp[2]))\n",
    "    y_train_gan = np.load(\"y_train_gan4.npy\")\n",
    "    \n",
    "    N_train = X_train_valid.shape[0]\n",
    "    idx_train_valid = np.arange(N_train,dtype='int')\n",
    "    \n",
    "    N_train_gan = X_train_gan.shape[0]\n",
    "    idx_train_gan = np.arange(N_train_gan,dtype='int')\n",
    "\n",
    "    X_train_2, _, idx_train_2 , _ = train_test_split(X_train_gan, idx_train_gan, test_size=0.7, random_state=15)\n",
    "    X_train_1, X_val, idx_train_1 , idx_val = train_test_split(X_train_valid, idx_train_valid, test_size=0.1, random_state=21)\n",
    "\n",
    "    y_val = y_train_valid[idx_val]\n",
    "    person_val = person_train_valid[idx_val]\n",
    "    \n",
    "    y_train_1 = y_train_valid[idx_train_1]\n",
    "    y_train_2 = y_train_gan[idx_train_2]\n",
    "    \n",
    "    X_train = np.concatenate((X_train_1,X_train_2),axis=0)\n",
    "    y_train = np.concatenate((y_train_1,y_train_2),axis=0)\n",
    "    \n",
    "    idx11 = np.arange(0,X_test.shape[2],2,dtype=int)\n",
    "    idx21 = np.arange(1,X_test.shape[2],2,dtype=int)\n",
    "    X_test_ss1 = np.take(X_test,idx11,axis=2)\n",
    "    X_test_ss2 = np.take(X_test,idx21,axis=2)\n",
    "    X_test = np.concatenate((X_test_ss1,X_test_ss2),axis=0)\n",
    "    y_test = np.concatenate((y_test,y_test),axis=0)\n",
    "    person_test = np.concatenate((person_test,person_test),axis=0)\n",
    "    \n",
    "    idx12 = np.arange(0,X_train.shape[2],2,dtype=int)\n",
    "    idx22 = np.arange(1,X_train.shape[2],2,dtype=int)\n",
    "    X_train_ss1 = np.take(X_train,idx12,axis=2)\n",
    "    X_train_ss2 = np.take(X_train,idx22,axis=2)\n",
    "    X_train = np.concatenate((X_train_ss1,X_train_ss2),axis=0)\n",
    "    y_train = np.concatenate((y_train,y_train),axis=0)\n",
    "    \n",
    "    idx13 = np.arange(0,X_val.shape[2],2,dtype=int)\n",
    "    idx23 = np.arange(1,X_val.shape[2],2,dtype=int)\n",
    "    X_val_ss1 = np.take(X_val,idx13,axis=2)\n",
    "    X_val_ss2 = np.take(X_val,idx23,axis=2)\n",
    "    X_val = np.concatenate((X_val_ss1,X_val_ss2),axis=0)\n",
    "    y_val = np.concatenate((y_val,y_val),axis=0)\n",
    "    person_val = np.concatenate((person_val,person_val),axis=0)\n",
    "\n",
    "    tl = X_train.shape[2]\n",
    "    X_test = np.reshape(X_test,(-1,22,tl,1))\n",
    "    X_train = np.reshape(X_train,(-1,22,tl,1))\n",
    "    X_val = np.reshape(X_val,(-1,22,tl,1))\n",
    "\n",
    "    label0 = 769\n",
    "    new_label0 = 0\n",
    "    for i in range(4):\n",
    "        m1 = (y_test==label0)\n",
    "        m2 = (y_train==label0)\n",
    "        m3 = (y_val==label0)\n",
    "        np.place(y_test,m1,new_label0)\n",
    "        np.place(y_train,m2,new_label0)\n",
    "        np.place(y_val,m3,new_label0)\n",
    "        label0 += 1\n",
    "        new_label0 += 1\n",
    "\n",
    "    labelNames = [0,1,2,3]\n",
    "    train_set = {'data': X_train, 'labels': y_train}\n",
    "    test_set = {'data': X_test, 'labels': y_test}\n",
    "    val_set = {'data': X_val, 'labels': y_val}\n",
    "    return train_set, test_set, val_set, labelNames\n",
    "\n",
    "def sample_batch(dataset, batch_size):\n",
    "    N = dataset['data'].shape[0]\n",
    "    indices = np.random.randint(N, size=batch_size)\n",
    "    return {key: dataset[key][indices] for key in dataset}\n",
    "\n",
    "def train_model_gan2(target_dir,start,stop,step,time_bin,fsz,use_batchnorm,use_dropout,use_l2loss,num_class,max_step,log_frequency,batch_size,model_saving_freq):\n",
    "    # load data\n",
    "    print(\"Loading datasets...\")\n",
    "    trainSet, testSet, valSet, labelNames = data_loader_gan2()\n",
    "    print(\"Dataset loading completes.\")\n",
    "    \n",
    "    best_val_acc = 0\n",
    "    best_val_path = target_dir\n",
    "    \n",
    "\n",
    "\n",
    "    # reset default graph\n",
    "    tf.reset_default_graph()\n",
    "\n",
    "    global_step = tf.train.get_or_create_global_step()\n",
    "    \n",
    "    model = Model(config, labelNames,start,stop,step,time_bin,fsz,use_batchnorm,use_dropout,use_l2loss)\n",
    "\n",
    "    # training setups\n",
    "    saver = tf.train.Saver(max_to_keep=100)\n",
    "\n",
    "    # Build an initialization operation to run below.\n",
    "    init = tf.global_variables_initializer()\n",
    "    \n",
    "    config_proto = tf.ConfigProto()\n",
    "\n",
    "    off = rewriter_config_pb2.RewriterConfig.OFF\n",
    "    config_proto.graph_options.rewrite_options.arithmetic_optimization = off\n",
    "    \n",
    "    sess = tf.Session(config=config_proto)\n",
    "\n",
    "    sess.run(init)\n",
    "\n",
    "    # main loop\n",
    "    for step in range(max_step):\n",
    "        start_time = time.time()\n",
    "\n",
    "        # prepare data\n",
    "        train_batch = sample_batch(trainSet, batch_size)\n",
    "        # feed dict\n",
    "        feed_dict = {\n",
    "            model.input: train_batch['data'],\n",
    "            model.fine_labels: train_batch['labels'],\n",
    "            model.is_training: True,\n",
    "            model.drprob: 0.7\n",
    "        }\n",
    "        \n",
    "        fetch_list = [model.optimizer_op, model.loss, model.global_step]\n",
    "        _, loss_value, global_step_value = sess.run(fetch_list, feed_dict=feed_dict)\n",
    "        duration = time.time() - start_time\n",
    "        assert not np.isnan(loss_value), 'Model diverged with loss = NaN'\n",
    "\n",
    "        # log\n",
    "        if step % log_frequency == 0:\n",
    "            num_examples_per_step = batch_size\n",
    "            examples_per_sec = num_examples_per_step / duration\n",
    "            sec_per_batch = duration\n",
    "            format_str = (\n",
    "                '%s: step %d, examples %d, loss = %.9f (%.3f examples/sec; %.3f sec/batch)'\n",
    "            )\n",
    "            print(\n",
    "                format_str % (\n",
    "                    datetime.now(), step, batch_size * step,\n",
    "                    loss_value,\n",
    "                    examples_per_sec, sec_per_batch\n",
    "                )\n",
    "            )\n",
    "\n",
    "        # Save the model checkpoint periodically.\n",
    "        if step % model_saving_freq == 0 or (step + 1) == max_step:\n",
    "            fetch_list = [model.accuracy,model.top_2_accuracy]\n",
    "            feed_dict = {\n",
    "                model.input: valSet['data'],\n",
    "                model.fine_labels: valSet['labels'],\n",
    "                model.is_training: False,\n",
    "            }\n",
    "            val_acc_1, val_acc_2 =  sess.run(fetch_list, feed_dict=feed_dict)\n",
    "            checkpoint_path = os.path.join(target_dir, 'model.ckpt')\n",
    "            saver.save(sess, checkpoint_path, global_step=int(global_step_value))\n",
    "            print('Top 1 validation accuracy: {} and top 2 validation accuracy: {}'.format(val_acc_1,val_acc_2))\n",
    "            print('Model Saved!')\n",
    "            if val_acc_1>best_val_acc:\n",
    "                best_val_acc = val_acc_1\n",
    "                best_val_path = checkpoint_path+'-'+str(int(global_step_value))\n",
    "    return best_val_acc,best_val_path\n",
    "\n",
    "\n",
    "def test_model_gan2(model_dir,start,stop,step,time_bin,fsz,use_batchnorm,use_dropout,use_l2loss):\n",
    "    print(\"Loading datasets...\")\n",
    "    trainSet, testSet, valSet, labelNames = data_loader_gan2()\n",
    "    print(\"Dataset loading completes.\")\n",
    "    \n",
    "    # reset default graph\n",
    "    tf.reset_default_graph()\n",
    "    \n",
    "    # create model\n",
    "    \n",
    "    model = Model(config, labelNames,start,stop,step,time_bin,fsz,use_batchnorm,use_dropout,use_l2loss)\n",
    "    # training setups\n",
    "    saver = tf.train.Saver(max_to_keep=100)\n",
    "    test_accuracy = [0, 0]\n",
    "    \n",
    "    config_proto = tf.ConfigProto()\n",
    "\n",
    "    off = rewriter_config_pb2.RewriterConfig.OFF\n",
    "    config_proto.graph_options.rewrite_options.arithmetic_optimization = off\n",
    "\n",
    "    with tf.Session(config=config_proto) as session:\n",
    "        session.run(tf.global_variables_initializer())\n",
    "        saver.restore(session, model_dir)\n",
    "        # test model\n",
    "        exp_results = run_single_step(session, model, testSet, mode='test')\n",
    "        test_accuracy[0] = exp_results['top_1_accuracy']\n",
    "        test_accuracy[1] = exp_results['top_2_accuracy']\n",
    "        print('top_1_accuracy_test = ', test_accuracy[0], 'top_2_accuracy_test = ', test_accuracy[1])\n",
    "        \n",
    "    top1_acc = test_accuracy[0]\n",
    "    top2_acc = test_accuracy[1]\n",
    "    return top1_acc,top2_acc\n",
    "\n",
    "\n",
    "def run_single_step(\n",
    "        session,\n",
    "        model,\n",
    "        batch,\n",
    "        mode='test',\n",
    "        log=True,\n",
    "):\n",
    "    # construct feed dict\n",
    "    feed_dict = {\n",
    "        model.input: batch['data'],\n",
    "        # model.coarse_labels: batch['coarse_labels'],\n",
    "        model.fine_labels: batch['labels'],\n",
    "        # model.label_mapping: label_mapping,\n",
    "        model.is_training: mode == 'train'\n",
    "    }\n",
    "    \n",
    "    # select proper summary op\n",
    "    if mode == 'train':\n",
    "        summary_op = model.train_summary_op\n",
    "    elif mode == 'val':\n",
    "        summary_op = model.val_summary_op\n",
    "    else:\n",
    "        summary_op = model.test_summary_op\n",
    "    \n",
    "    # construct fetch list\n",
    "    fetch_list = [model.global_step, summary_op, model.loss, model.accuracy, model.top_2_accuracy]\n",
    "\n",
    "    # run single step\n",
    "    _start_time = time.time()\n",
    "    _step, _summary, _loss, _top_1, _top_2 = session.run(fetch_list, feed_dict=feed_dict)[:5]\n",
    "    _end_time = time.time()\n",
    "    \n",
    "    # collect step statistics\n",
    "    step_time = _end_time - _start_time\n",
    "    batch_size = batch['data'].shape[0]\n",
    "    \n",
    "    # log in console\n",
    "    if log:\n",
    "        print(('[{:5s} step {:4d}] loss: {:.5f}; top_1_accuracy: {:.5f}; top_5_accuracy: {:5f} ' +\n",
    "              '({:.3f} sec/batch; {:.3f} instances/sec)'\n",
    "              ).format(mode, _step, _loss, _top_1, _top_2, \n",
    "                       step_time, batch_size / step_time))\n",
    "    \n",
    "    # log results to file and return statistics\n",
    "    if mode == 'test':\n",
    "        test_fetch_list = [model.per_class_accuracy,\n",
    "                model.top_2_per_class_accuracy,\n",
    "                model.confusion_matrix, \n",
    "                model.pred, model.probs]\n",
    "        _top_1_c,  _top_2_c, _cm, _pred, _probs = \\\n",
    "                session.run(test_fetch_list, feed_dict=feed_dict)\n",
    "        \n",
    "        \n",
    "        # Log detailed test results in pickle format\n",
    "        stats = {\n",
    "            \"loss\": _loss,\n",
    "            \"top_1_accuracy\": _top_1,\n",
    "            \"top_2_accuracy\": _top_2,\n",
    "            \"top_1_perclass_accuracy\": _top_1_c,\n",
    "            \"top_2_perclass_accuracy\": _top_2_c,\n",
    "            \"confusion_matrix\": _cm,\n",
    "            \"pred\": _pred,\n",
    "            \"probs\": _probs\n",
    "        }\n",
    "    else:\n",
    "        stats = {\n",
    "            \"step\": _step,\n",
    "            \"loss\": _loss,\n",
    "            \"top_1_accuracy\": _top_1,\n",
    "            \"top_2_accuracy\": _top_2\n",
    "        }\n",
    "        \n",
    "    return stats\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading datasets...\n",
      "Dataset loading completes.\n",
      "2019-03-19 00:23:15.886005: step 0, examples 0, loss = 1.420910001 (30.224 examples/sec; 1.654 sec/batch)\n",
      "Top 1 validation accuracy: 0.24528302252292633 and top 2 validation accuracy: 0.5094339847564697\n",
      "Model Saved!\n",
      "2019-03-19 00:23:34.147170: step 10, examples 500, loss = 1.413841844 (35.108 examples/sec; 1.424 sec/batch)\n",
      "2019-03-19 00:23:47.606177: step 20, examples 1000, loss = 1.416572094 (37.330 examples/sec; 1.339 sec/batch)\n",
      "2019-03-19 00:24:01.245702: step 30, examples 1500, loss = 1.370634913 (36.621 examples/sec; 1.365 sec/batch)\n",
      "2019-03-19 00:24:14.839348: step 40, examples 2000, loss = 1.469452024 (36.917 examples/sec; 1.354 sec/batch)\n",
      "2019-03-19 00:24:28.398089: step 50, examples 2500, loss = 1.386072159 (36.621 examples/sec; 1.365 sec/batch)\n",
      "2019-03-19 00:24:42.068530: step 60, examples 3000, loss = 1.402094603 (36.594 examples/sec; 1.366 sec/batch)\n",
      "2019-03-19 00:24:55.486647: step 70, examples 3500, loss = 1.403366804 (36.972 examples/sec; 1.352 sec/batch)\n",
      "2019-03-19 00:25:09.052368: step 80, examples 4000, loss = 1.373702049 (36.145 examples/sec; 1.383 sec/batch)\n",
      "2019-03-19 00:25:22.508384: step 90, examples 4500, loss = 1.406017661 (36.917 examples/sec; 1.354 sec/batch)\n",
      "2019-03-19 00:25:35.958415: step 100, examples 5000, loss = 1.382342219 (37.164 examples/sec; 1.345 sec/batch)\n",
      "Top 1 validation accuracy: 0.39150944352149963 and top 2 validation accuracy: 0.6367924809455872\n",
      "Model Saved!\n",
      "2019-03-19 00:25:54.168715: step 110, examples 5500, loss = 1.343684912 (36.863 examples/sec; 1.356 sec/batch)\n",
      "2019-03-19 00:26:07.647670: step 120, examples 6000, loss = 1.342714548 (36.172 examples/sec; 1.382 sec/batch)\n",
      "2019-03-19 00:26:21.108671: step 130, examples 6500, loss = 1.305652380 (36.890 examples/sec; 1.355 sec/batch)\n",
      "2019-03-19 00:26:34.572665: step 140, examples 7000, loss = 1.364289522 (37.610 examples/sec; 1.329 sec/batch)\n",
      "2019-03-19 00:26:47.878083: step 150, examples 7500, loss = 1.334026217 (37.980 examples/sec; 1.316 sec/batch)\n",
      "2019-03-19 00:27:01.399922: step 160, examples 8000, loss = 1.346998334 (35.430 examples/sec; 1.411 sec/batch)\n",
      "2019-03-19 00:27:14.845963: step 170, examples 8500, loss = 1.362766147 (37.054 examples/sec; 1.349 sec/batch)\n",
      "2019-03-19 00:27:28.513414: step 180, examples 9000, loss = 1.287458420 (37.330 examples/sec; 1.339 sec/batch)\n",
      "2019-03-19 00:27:41.995359: step 190, examples 9500, loss = 1.324242592 (37.413 examples/sec; 1.336 sec/batch)\n",
      "2019-03-19 00:27:55.540138: step 200, examples 10000, loss = 1.353699923 (36.809 examples/sec; 1.358 sec/batch)\n",
      "Top 1 validation accuracy: 0.4245283007621765 and top 2 validation accuracy: 0.6415094137191772\n",
      "Model Saved!\n",
      "2019-03-19 00:28:14.032683: step 210, examples 10500, loss = 1.347866416 (35.455 examples/sec; 1.410 sec/batch)\n",
      "2019-03-19 00:28:27.585440: step 220, examples 11000, loss = 1.364591956 (38.241 examples/sec; 1.308 sec/batch)\n",
      "2019-03-19 00:28:40.853955: step 230, examples 11500, loss = 1.366813898 (38.154 examples/sec; 1.310 sec/batch)\n",
      "2019-03-19 00:28:54.160371: step 240, examples 12000, loss = 1.372943044 (35.505 examples/sec; 1.408 sec/batch)\n",
      "2019-03-19 00:29:07.591453: step 250, examples 12500, loss = 1.312946677 (37.553 examples/sec; 1.331 sec/batch)\n",
      "2019-03-19 00:29:20.947734: step 260, examples 13000, loss = 1.320404530 (37.219 examples/sec; 1.343 sec/batch)\n",
      "2019-03-19 00:29:34.410731: step 270, examples 13500, loss = 1.246741414 (36.945 examples/sec; 1.353 sec/batch)\n",
      "2019-03-19 00:29:47.857770: step 280, examples 14000, loss = 1.321923733 (37.666 examples/sec; 1.327 sec/batch)\n",
      "2019-03-19 00:30:01.251950: step 290, examples 14500, loss = 1.334355831 (37.054 examples/sec; 1.349 sec/batch)\n",
      "2019-03-19 00:30:14.640147: step 300, examples 15000, loss = 1.243875623 (35.887 examples/sec; 1.393 sec/batch)\n",
      "Top 1 validation accuracy: 0.43396225571632385 and top 2 validation accuracy: 0.6839622855186462\n",
      "Model Saved!\n",
      "2019-03-19 00:30:32.744730: step 310, examples 15500, loss = 1.299739599 (37.553 examples/sec; 1.331 sec/batch)\n",
      "2019-03-19 00:30:46.048154: step 320, examples 16000, loss = 1.310237885 (36.224 examples/sec; 1.380 sec/batch)\n",
      "2019-03-19 00:30:59.419396: step 330, examples 16500, loss = 1.205093861 (38.743 examples/sec; 1.291 sec/batch)\n",
      "2019-03-19 00:31:12.786648: step 340, examples 17000, loss = 1.421812773 (36.890 examples/sec; 1.355 sec/batch)\n",
      "2019-03-19 00:31:26.147916: step 350, examples 17500, loss = 1.335094333 (37.666 examples/sec; 1.327 sec/batch)\n",
      "2019-03-19 00:31:39.549078: step 360, examples 18000, loss = 1.249837637 (37.553 examples/sec; 1.331 sec/batch)\n",
      "2019-03-19 00:31:52.916331: step 370, examples 18500, loss = 1.163877964 (37.581 examples/sec; 1.330 sec/batch)\n",
      "2019-03-19 00:32:06.372346: step 380, examples 19000, loss = 1.241861224 (35.912 examples/sec; 1.392 sec/batch)\n",
      "2019-03-19 00:32:19.731619: step 390, examples 19500, loss = 1.396020055 (37.780 examples/sec; 1.323 sec/batch)\n",
      "2019-03-19 00:32:33.042025: step 400, examples 20000, loss = 1.196708202 (37.923 examples/sec; 1.318 sec/batch)\n",
      "Top 1 validation accuracy: 0.4386792480945587 and top 2 validation accuracy: 0.6627358198165894\n",
      "Model Saved!\n",
      "2019-03-19 00:32:51.039893: step 410, examples 20500, loss = 1.302042007 (37.808 examples/sec; 1.322 sec/batch)\n",
      "2019-03-19 00:33:04.676426: step 420, examples 21000, loss = 1.362793326 (35.861 examples/sec; 1.394 sec/batch)\n",
      "2019-03-19 00:33:18.052654: step 430, examples 21500, loss = 1.267957568 (37.330 examples/sec; 1.339 sec/batch)\n",
      "2019-03-19 00:33:31.633336: step 440, examples 22000, loss = 1.257671475 (36.461 examples/sec; 1.371 sec/batch)\n",
      "2019-03-19 00:33:45.375585: step 450, examples 22500, loss = 1.185251951 (37.469 examples/sec; 1.334 sec/batch)\n",
      "2019-03-19 00:33:59.207594: step 460, examples 23000, loss = 1.295171857 (35.887 examples/sec; 1.393 sec/batch)\n",
      "2019-03-19 00:34:12.885020: step 470, examples 23500, loss = 1.278870702 (37.054 examples/sec; 1.349 sec/batch)\n",
      "2019-03-19 00:34:26.575406: step 480, examples 24000, loss = 1.258446693 (37.385 examples/sec; 1.337 sec/batch)\n",
      "2019-03-19 00:34:40.441325: step 490, examples 24500, loss = 1.127201319 (35.108 examples/sec; 1.424 sec/batch)\n",
      "2019-03-19 00:34:54.756043: step 500, examples 25000, loss = 1.213785768 (35.938 examples/sec; 1.391 sec/batch)\n",
      "Top 1 validation accuracy: 0.4528301954269409 and top 2 validation accuracy: 0.7476415038108826\n",
      "Model Saved!\n",
      "2019-03-19 00:35:13.682429: step 510, examples 25500, loss = 1.177134037 (37.246 examples/sec; 1.342 sec/batch)\n",
      "2019-03-19 00:35:27.252141: step 520, examples 26000, loss = 1.273590922 (35.887 examples/sec; 1.393 sec/batch)\n",
      "2019-03-19 00:35:41.133019: step 530, examples 26500, loss = 1.147342563 (36.042 examples/sec; 1.387 sec/batch)\n",
      "2019-03-19 00:35:55.225333: step 540, examples 27000, loss = 1.312210083 (35.355 examples/sec; 1.414 sec/batch)\n",
      "2019-03-19 00:36:09.146106: step 550, examples 27500, loss = 1.225734353 (36.728 examples/sec; 1.361 sec/batch)\n",
      "2019-03-19 00:36:23.050920: step 560, examples 28000, loss = 1.260080576 (36.408 examples/sec; 1.373 sec/batch)\n",
      "2019-03-19 00:36:36.861985: step 570, examples 28500, loss = 1.145901561 (35.556 examples/sec; 1.406 sec/batch)\n",
      "2019-03-19 00:36:50.490539: step 580, examples 29000, loss = 1.069915771 (36.863 examples/sec; 1.356 sec/batch)\n",
      "2019-03-19 00:37:04.208853: step 590, examples 29500, loss = 1.198684573 (37.751 examples/sec; 1.324 sec/batch)\n",
      "2019-03-19 00:37:17.840399: step 600, examples 30000, loss = 1.072130203 (35.912 examples/sec; 1.392 sec/batch)\n",
      "Top 1 validation accuracy: 0.5 and top 2 validation accuracy: 0.7712264060974121\n",
      "Model Saved!\n",
      "2019-03-19 00:37:36.612198: step 610, examples 30500, loss = 1.253327489 (36.647 examples/sec; 1.364 sec/batch)\n",
      "2019-03-19 00:37:50.409300: step 620, examples 31000, loss = 1.365226269 (37.136 examples/sec; 1.346 sec/batch)\n",
      "2019-03-19 00:38:04.137587: step 630, examples 31500, loss = 1.127530456 (37.525 examples/sec; 1.332 sec/batch)\n",
      "2019-03-19 00:38:17.740211: step 640, examples 32000, loss = 1.040032864 (36.782 examples/sec; 1.359 sec/batch)\n",
      "2019-03-19 00:38:31.215175: step 650, examples 32500, loss = 1.149137378 (35.581 examples/sec; 1.405 sec/batch)\n",
      "2019-03-19 00:38:44.954433: step 660, examples 33000, loss = 1.221522331 (35.990 examples/sec; 1.389 sec/batch)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2019-03-19 00:38:58.693691: step 670, examples 33500, loss = 1.221694946 (37.385 examples/sec; 1.337 sec/batch)\n",
      "2019-03-19 00:39:12.264399: step 680, examples 34000, loss = 1.100214124 (37.695 examples/sec; 1.326 sec/batch)\n",
      "2019-03-19 00:39:25.380323: step 690, examples 34500, loss = 1.153830647 (37.274 examples/sec; 1.341 sec/batch)\n",
      "2019-03-19 00:39:38.561075: step 700, examples 35000, loss = 1.227276683 (38.505 examples/sec; 1.299 sec/batch)\n",
      "Top 1 validation accuracy: 0.5400943160057068 and top 2 validation accuracy: 0.7547169923782349\n",
      "Model Saved!\n",
      "2019-03-19 00:39:56.279399: step 710, examples 35500, loss = 1.021826982 (37.865 examples/sec; 1.320 sec/batch)\n",
      "2019-03-19 00:40:09.867063: step 720, examples 36000, loss = 1.297267437 (33.289 examples/sec; 1.502 sec/batch)\n",
      "2019-03-19 00:40:24.176795: step 730, examples 36500, loss = 1.245475769 (35.682 examples/sec; 1.401 sec/batch)\n",
      "2019-03-19 00:40:37.715588: step 740, examples 37000, loss = 1.194679737 (37.357 examples/sec; 1.338 sec/batch)\n",
      "2019-03-19 00:40:51.017017: step 750, examples 37500, loss = 1.106726050 (38.476 examples/sec; 1.300 sec/batch)\n",
      "2019-03-19 00:41:04.554813: step 760, examples 38000, loss = 1.185417652 (36.224 examples/sec; 1.380 sec/batch)\n",
      "2019-03-19 00:41:17.864220: step 770, examples 38500, loss = 1.260339499 (37.780 examples/sec; 1.323 sec/batch)\n",
      "2019-03-19 00:41:31.252417: step 780, examples 39000, loss = 1.229348660 (37.751 examples/sec; 1.324 sec/batch)\n",
      "2019-03-19 00:41:44.621664: step 790, examples 39500, loss = 1.178083539 (37.666 examples/sec; 1.327 sec/batch)\n",
      "2019-03-19 00:41:57.958996: step 800, examples 40000, loss = 1.283012271 (36.461 examples/sec; 1.371 sec/batch)\n",
      "Top 1 validation accuracy: 0.4929245412349701 and top 2 validation accuracy: 0.7452830076217651\n",
      "Model Saved!\n",
      "2019-03-19 00:42:15.982818: step 810, examples 40500, loss = 1.100621819 (37.109 examples/sec; 1.347 sec/batch)\n",
      "2019-03-19 00:42:29.348076: step 820, examples 41000, loss = 1.133527160 (37.026 examples/sec; 1.350 sec/batch)\n",
      "2019-03-19 00:42:42.731286: step 830, examples 41500, loss = 1.121978045 (36.917 examples/sec; 1.354 sec/batch)\n",
      "2019-03-19 00:42:56.140426: step 840, examples 42000, loss = 1.132323623 (37.385 examples/sec; 1.337 sec/batch)\n",
      "2019-03-19 00:43:09.590457: step 850, examples 42500, loss = 1.195772171 (38.212 examples/sec; 1.309 sec/batch)\n",
      "2019-03-19 00:43:22.987629: step 860, examples 43000, loss = 1.156308651 (38.038 examples/sec; 1.314 sec/batch)\n",
      "2019-03-19 00:43:36.348898: step 870, examples 43500, loss = 1.126414537 (37.219 examples/sec; 1.343 sec/batch)\n",
      "2019-03-19 00:43:49.699197: step 880, examples 44000, loss = 1.143742681 (37.553 examples/sec; 1.331 sec/batch)\n",
      "2019-03-19 00:44:03.042513: step 890, examples 44500, loss = 1.141464353 (37.666 examples/sec; 1.327 sec/batch)\n",
      "2019-03-19 00:44:16.439685: step 900, examples 45000, loss = 1.169508457 (37.780 examples/sec; 1.323 sec/batch)\n",
      "Top 1 validation accuracy: 0.5400943160057068 and top 2 validation accuracy: 0.7924528121948242\n",
      "Model Saved!\n",
      "2019-03-19 00:44:34.377713: step 910, examples 45500, loss = 0.908047497 (37.469 examples/sec; 1.334 sec/batch)\n",
      "2019-03-19 00:44:47.919499: step 920, examples 46000, loss = 1.047980070 (38.564 examples/sec; 1.297 sec/batch)\n",
      "2019-03-19 00:45:01.127178: step 930, examples 46500, loss = 1.350793242 (37.441 examples/sec; 1.335 sec/batch)\n",
      "2019-03-19 00:45:14.626079: step 940, examples 47000, loss = 1.054460526 (37.191 examples/sec; 1.344 sec/batch)\n",
      "2019-03-19 00:45:28.016270: step 950, examples 47500, loss = 1.159317613 (37.695 examples/sec; 1.326 sec/batch)\n",
      "2019-03-19 00:45:41.425411: step 960, examples 48000, loss = 1.203393102 (36.329 examples/sec; 1.376 sec/batch)\n",
      "2019-03-19 00:45:54.989139: step 970, examples 48500, loss = 1.085714579 (37.330 examples/sec; 1.339 sec/batch)\n",
      "2019-03-19 00:46:08.325473: step 980, examples 49000, loss = 1.178535819 (38.038 examples/sec; 1.314 sec/batch)\n",
      "2019-03-19 00:46:21.844320: step 990, examples 49500, loss = 1.176138401 (37.219 examples/sec; 1.343 sec/batch)\n",
      "2019-03-19 00:46:35.041029: step 1000, examples 50000, loss = 1.180877209 (37.638 examples/sec; 1.328 sec/batch)\n",
      "Top 1 validation accuracy: 0.5660377144813538 and top 2 validation accuracy: 0.7853773832321167\n",
      "Model Saved!\n",
      "2019-03-19 00:46:53.213431: step 1010, examples 50500, loss = 1.148675799 (36.917 examples/sec; 1.354 sec/batch)\n",
      "2019-03-19 00:47:06.664459: step 1020, examples 51000, loss = 1.078541517 (37.219 examples/sec; 1.343 sec/batch)\n",
      "2019-03-19 00:47:20.255113: step 1030, examples 51500, loss = 1.025868893 (36.647 examples/sec; 1.364 sec/batch)\n",
      "2019-03-19 00:47:34.109066: step 1040, examples 52000, loss = 1.118265271 (34.839 examples/sec; 1.435 sec/batch)\n",
      "2019-03-19 00:47:47.524190: step 1050, examples 52500, loss = 1.093155026 (37.441 examples/sec; 1.335 sec/batch)\n",
      "2019-03-19 00:48:00.955272: step 1060, examples 53000, loss = 1.017601848 (36.782 examples/sec; 1.359 sec/batch)\n",
      "2019-03-19 00:48:14.700513: step 1070, examples 53500, loss = 1.044622540 (38.505 examples/sec; 1.299 sec/batch)\n",
      "2019-03-19 00:48:27.782528: step 1080, examples 54000, loss = 1.165289640 (37.951 examples/sec; 1.317 sec/batch)\n",
      "2019-03-19 00:48:40.996192: step 1090, examples 54500, loss = 1.055122614 (38.299 examples/sec; 1.306 sec/batch)\n",
      "2019-03-19 00:48:54.191903: step 1100, examples 55000, loss = 1.033792377 (37.525 examples/sec; 1.332 sec/batch)\n",
      "Top 1 validation accuracy: 0.5471698045730591 and top 2 validation accuracy: 0.7476415038108826\n",
      "Model Saved!\n",
      "2019-03-19 00:49:11.791836: step 1110, examples 55500, loss = 1.027373791 (38.654 examples/sec; 1.294 sec/batch)\n",
      "2019-03-19 00:49:24.990539: step 1120, examples 56000, loss = 0.969296098 (38.270 examples/sec; 1.307 sec/batch)\n",
      "2019-03-19 00:49:38.684916: step 1130, examples 56500, loss = 1.090721488 (34.815 examples/sec; 1.436 sec/batch)\n",
      "2019-03-19 00:49:52.222713: step 1140, examples 57000, loss = 1.112948298 (37.638 examples/sec; 1.328 sec/batch)\n",
      "2019-03-19 00:50:05.578995: step 1150, examples 57500, loss = 0.905384243 (37.638 examples/sec; 1.328 sec/batch)\n",
      "2019-03-19 00:50:19.069917: step 1160, examples 58000, loss = 1.106851935 (36.621 examples/sec; 1.365 sec/batch)\n",
      "2019-03-19 00:50:32.523937: step 1170, examples 58500, loss = 0.976532519 (37.385 examples/sec; 1.337 sec/batch)\n",
      "2019-03-19 00:50:45.990922: step 1180, examples 59000, loss = 1.249364495 (35.034 examples/sec; 1.427 sec/batch)\n",
      "2019-03-19 00:50:59.276394: step 1190, examples 59500, loss = 1.092001677 (36.728 examples/sec; 1.361 sec/batch)\n",
      "2019-03-19 00:51:12.696505: step 1200, examples 60000, loss = 1.126089215 (36.917 examples/sec; 1.354 sec/batch)\n",
      "Top 1 validation accuracy: 0.5801886916160583 and top 2 validation accuracy: 0.7900943160057068\n",
      "Model Saved!\n",
      "2019-03-19 00:51:30.702353: step 1210, examples 60500, loss = 1.081401944 (37.081 examples/sec; 1.348 sec/batch)\n",
      "2019-03-19 00:51:44.124458: step 1220, examples 61000, loss = 1.064601779 (37.246 examples/sec; 1.342 sec/batch)\n",
      "2019-03-19 00:51:57.546565: step 1230, examples 61500, loss = 1.126917601 (37.219 examples/sec; 1.343 sec/batch)\n",
      "2019-03-19 00:52:10.983630: step 1240, examples 62000, loss = 1.005069852 (36.701 examples/sec; 1.362 sec/batch)\n",
      "2019-03-19 00:52:24.251149: step 1250, examples 62500, loss = 1.018994689 (38.387 examples/sec; 1.303 sec/batch)\n",
      "2019-03-19 00:52:37.532632: step 1260, examples 63000, loss = 1.086389661 (36.621 examples/sec; 1.365 sec/batch)\n",
      "2019-03-19 00:52:50.957728: step 1270, examples 63500, loss = 1.062942266 (37.582 examples/sec; 1.330 sec/batch)\n",
      "2019-03-19 00:53:04.292069: step 1280, examples 64000, loss = 1.125869155 (37.525 examples/sec; 1.332 sec/batch)\n",
      "2019-03-19 00:53:17.667301: step 1290, examples 64500, loss = 1.156332850 (37.357 examples/sec; 1.338 sec/batch)\n",
      "2019-03-19 00:53:31.094393: step 1300, examples 65000, loss = 1.095659733 (37.413 examples/sec; 1.336 sec/batch)\n",
      "Top 1 validation accuracy: 0.5825471878051758 and top 2 validation accuracy: 0.8042452931404114\n",
      "Model Saved!\n",
      "2019-03-19 00:53:49.659744: step 1310, examples 65500, loss = 1.000397205 (32.597 examples/sec; 1.534 sec/batch)\n",
      "2019-03-19 00:54:04.334500: step 1320, examples 66000, loss = 0.946799994 (36.621 examples/sec; 1.365 sec/batch)\n",
      "2019-03-19 00:54:17.702750: step 1330, examples 66500, loss = 1.205532193 (38.009 examples/sec; 1.315 sec/batch)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2019-03-19 00:54:31.094936: step 1340, examples 67000, loss = 1.069013953 (37.469 examples/sec; 1.334 sec/batch)\n",
      "2019-03-19 00:54:44.369435: step 1350, examples 67500, loss = 1.197281718 (37.951 examples/sec; 1.317 sec/batch)\n",
      "2019-03-19 00:54:57.779574: step 1360, examples 68000, loss = 1.107256055 (37.553 examples/sec; 1.331 sec/batch)\n",
      "2019-03-19 00:55:11.200682: step 1370, examples 68500, loss = 0.986317098 (37.638 examples/sec; 1.328 sec/batch)\n",
      "2019-03-19 00:55:24.665674: step 1380, examples 69000, loss = 1.175650239 (36.999 examples/sec; 1.351 sec/batch)\n",
      "2019-03-19 00:55:38.215438: step 1390, examples 69500, loss = 0.874410272 (37.865 examples/sec; 1.320 sec/batch)\n",
      "2019-03-19 00:55:51.632557: step 1400, examples 70000, loss = 1.228473067 (36.972 examples/sec; 1.352 sec/batch)\n",
      "Top 1 validation accuracy: 0.5754716992378235 and top 2 validation accuracy: 0.775943398475647\n",
      "Model Saved!\n",
      "2019-03-19 00:56:09.949573: step 1410, examples 70500, loss = 1.194548011 (36.917 examples/sec; 1.354 sec/batch)\n",
      "2019-03-19 00:56:23.409577: step 1420, examples 71000, loss = 1.048454046 (37.413 examples/sec; 1.336 sec/batch)\n",
      "2019-03-19 00:56:36.797774: step 1430, examples 71500, loss = 1.011354089 (37.136 examples/sec; 1.346 sec/batch)\n",
      "2019-03-19 00:56:50.257777: step 1440, examples 72000, loss = 1.102900386 (37.581 examples/sec; 1.330 sec/batch)\n",
      "2019-03-19 00:57:03.640988: step 1450, examples 72500, loss = 1.231288075 (37.581 examples/sec; 1.330 sec/batch)\n",
      "2019-03-19 00:57:17.196736: step 1460, examples 73000, loss = 0.979856670 (37.610 examples/sec; 1.329 sec/batch)\n",
      "2019-03-19 00:57:31.163387: step 1470, examples 73500, loss = 1.035435200 (33.579 examples/sec; 1.489 sec/batch)\n",
      "2019-03-19 00:57:44.903640: step 1480, examples 74000, loss = 0.928622186 (34.623 examples/sec; 1.444 sec/batch)\n",
      "2019-03-19 00:57:58.665836: step 1490, examples 74500, loss = 1.123727918 (36.145 examples/sec; 1.383 sec/batch)\n",
      "2019-03-19 00:58:12.006161: step 1500, examples 75000, loss = 1.110185862 (37.469 examples/sec; 1.334 sec/batch)\n",
      "Top 1 validation accuracy: 0.6179245114326477 and top 2 validation accuracy: 0.7995283007621765\n",
      "Model Saved!\n",
      "2019-03-19 00:58:30.317193: step 1510, examples 75500, loss = 1.211479545 (36.041 examples/sec; 1.387 sec/batch)\n",
      "2019-03-19 00:58:43.711374: step 1520, examples 76000, loss = 1.051333070 (37.666 examples/sec; 1.327 sec/batch)\n",
      "2019-03-19 00:58:57.191324: step 1530, examples 76500, loss = 1.111417890 (38.009 examples/sec; 1.315 sec/batch)\n",
      "2019-03-19 00:59:10.451862: step 1540, examples 77000, loss = 1.284187436 (38.505 examples/sec; 1.299 sec/batch)\n",
      "2019-03-19 00:59:23.946773: step 1550, examples 77500, loss = 1.017984867 (36.701 examples/sec; 1.362 sec/batch)\n",
      "2019-03-19 00:59:37.488560: step 1560, examples 78000, loss = 1.036087871 (37.026 examples/sec; 1.350 sec/batch)\n",
      "2019-03-19 00:59:51.853146: step 1570, examples 78500, loss = 1.004018784 (32.533 examples/sec; 1.537 sec/batch)\n",
      "2019-03-19 01:00:06.538871: step 1580, examples 79000, loss = 0.977215827 (31.831 examples/sec; 1.571 sec/batch)\n",
      "2019-03-19 01:00:21.747466: step 1590, examples 79500, loss = 1.148980856 (32.034 examples/sec; 1.561 sec/batch)\n",
      "2019-03-19 01:00:37.688939: step 1600, examples 80000, loss = 0.959179282 (31.373 examples/sec; 1.594 sec/batch)\n",
      "Top 1 validation accuracy: 0.6297169923782349 and top 2 validation accuracy: 0.8160377144813538\n",
      "Model Saved!\n",
      "2019-03-19 01:00:57.761924: step 1610, examples 80500, loss = 1.022843122 (33.573 examples/sec; 1.489 sec/batch)\n",
      "2019-03-19 01:01:13.820773: step 1620, examples 81000, loss = 1.142035961 (31.192 examples/sec; 1.603 sec/batch)\n",
      "2019-03-19 01:01:30.524759: step 1630, examples 81500, loss = 1.125097990 (30.569 examples/sec; 1.636 sec/batch)\n",
      "2019-03-19 01:01:47.016371: step 1640, examples 82000, loss = 0.987311900 (29.236 examples/sec; 1.710 sec/batch)\n",
      "2019-03-19 01:02:02.574451: step 1650, examples 82500, loss = 1.069431663 (31.991 examples/sec; 1.563 sec/batch)\n",
      "2019-03-19 01:02:17.293229: step 1660, examples 83000, loss = 0.942774177 (34.328 examples/sec; 1.457 sec/batch)\n",
      "2019-03-19 01:02:32.270517: step 1670, examples 83500, loss = 1.072222233 (36.317 examples/sec; 1.377 sec/batch)\n",
      "2019-03-19 01:02:46.421113: step 1680, examples 84000, loss = 1.079923749 (33.217 examples/sec; 1.505 sec/batch)\n",
      "2019-03-19 01:03:00.561601: step 1690, examples 84500, loss = 1.066533923 (34.292 examples/sec; 1.458 sec/batch)\n",
      "2019-03-19 01:03:14.608182: step 1700, examples 85000, loss = 0.970856071 (35.014 examples/sec; 1.428 sec/batch)\n",
      "Top 1 validation accuracy: 0.6297169923782349 and top 2 validation accuracy: 0.8207547068595886\n",
      "Model Saved!\n",
      "2019-03-19 01:03:33.658685: step 1710, examples 85500, loss = 0.889374316 (34.306 examples/sec; 1.457 sec/batch)\n",
      "2019-03-19 01:03:47.637243: step 1720, examples 86000, loss = 1.241811872 (35.771 examples/sec; 1.398 sec/batch)\n",
      "2019-03-19 01:04:01.722305: step 1730, examples 86500, loss = 0.998677790 (34.586 examples/sec; 1.446 sec/batch)\n",
      "2019-03-19 01:04:15.813635: step 1740, examples 87000, loss = 1.005352855 (38.051 examples/sec; 1.314 sec/batch)\n",
      "2019-03-19 01:04:29.170264: step 1750, examples 87500, loss = 0.951183259 (38.263 examples/sec; 1.307 sec/batch)\n",
      "2019-03-19 01:04:42.311613: step 1760, examples 88000, loss = 1.093968272 (39.036 examples/sec; 1.281 sec/batch)\n",
      "2019-03-19 01:04:55.497360: step 1770, examples 88500, loss = 0.853853464 (38.186 examples/sec; 1.309 sec/batch)\n",
      "2019-03-19 01:05:08.371850: step 1780, examples 89000, loss = 0.937315404 (38.854 examples/sec; 1.287 sec/batch)\n",
      "2019-03-19 01:05:21.526035: step 1790, examples 89500, loss = 0.892388880 (38.065 examples/sec; 1.314 sec/batch)\n",
      "2019-03-19 01:05:34.490981: step 1800, examples 90000, loss = 1.138238430 (38.087 examples/sec; 1.313 sec/batch)\n",
      "Top 1 validation accuracy: 0.6037735939025879 and top 2 validation accuracy: 0.8207547068595886\n",
      "Model Saved!\n",
      "2019-03-19 01:05:53.441148: step 1810, examples 90500, loss = 0.856354773 (35.764 examples/sec; 1.398 sec/batch)\n",
      "2019-03-19 01:06:07.637377: step 1820, examples 91000, loss = 1.058489203 (35.124 examples/sec; 1.424 sec/batch)\n",
      "2019-03-19 01:06:21.687468: step 1830, examples 91500, loss = 1.050687313 (36.145 examples/sec; 1.383 sec/batch)\n",
      "2019-03-19 01:06:35.746142: step 1840, examples 92000, loss = 1.010603786 (35.329 examples/sec; 1.415 sec/batch)\n",
      "2019-03-19 01:06:49.819134: step 1850, examples 92500, loss = 0.961153388 (35.307 examples/sec; 1.416 sec/batch)\n",
      "2019-03-19 01:07:03.958651: step 1860, examples 93000, loss = 1.033852935 (35.207 examples/sec; 1.420 sec/batch)\n",
      "2019-03-19 01:07:17.993940: step 1870, examples 93500, loss = 0.923485339 (34.392 examples/sec; 1.454 sec/batch)\n",
      "2019-03-19 01:07:32.002342: step 1880, examples 94000, loss = 1.108089566 (36.544 examples/sec; 1.368 sec/batch)\n",
      "2019-03-19 01:07:46.028460: step 1890, examples 94500, loss = 1.216537952 (35.415 examples/sec; 1.412 sec/batch)\n",
      "2019-03-19 01:07:59.968504: step 1900, examples 95000, loss = 0.985597551 (36.144 examples/sec; 1.383 sec/batch)\n",
      "Top 1 validation accuracy: 0.6179245114326477 and top 2 validation accuracy: 0.8207547068595886\n",
      "Model Saved!\n",
      "2019-03-19 01:08:19.325490: step 1910, examples 95500, loss = 0.976571441 (35.061 examples/sec; 1.426 sec/batch)\n",
      "2019-03-19 01:08:33.923929: step 1920, examples 96000, loss = 1.170944691 (34.003 examples/sec; 1.470 sec/batch)\n",
      "2019-03-19 01:08:48.646022: step 1930, examples 96500, loss = 1.057050467 (33.954 examples/sec; 1.473 sec/batch)\n",
      "2019-03-19 01:09:03.278312: step 1940, examples 97000, loss = 0.893833518 (33.644 examples/sec; 1.486 sec/batch)\n",
      "2019-03-19 01:09:17.766354: step 1950, examples 97500, loss = 1.046512127 (35.568 examples/sec; 1.406 sec/batch)\n",
      "2019-03-19 01:09:32.458249: step 1960, examples 98000, loss = 0.814573348 (34.444 examples/sec; 1.452 sec/batch)\n",
      "2019-03-19 01:09:47.096829: step 1970, examples 98500, loss = 0.972046316 (34.598 examples/sec; 1.445 sec/batch)\n",
      "2019-03-19 01:10:01.754482: step 1980, examples 99000, loss = 1.124070644 (34.833 examples/sec; 1.435 sec/batch)\n",
      "2019-03-19 01:10:16.414892: step 1990, examples 99500, loss = 0.892829716 (34.149 examples/sec; 1.464 sec/batch)\n",
      "2019-03-19 01:10:30.994748: step 2000, examples 100000, loss = 0.972432554 (33.833 examples/sec; 1.478 sec/batch)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Top 1 validation accuracy: 0.6084905862808228 and top 2 validation accuracy: 0.7995283007621765\n",
      "Model Saved!\n",
      "2019-03-19 01:10:50.811579: step 2010, examples 100500, loss = 1.095290899 (34.432 examples/sec; 1.452 sec/batch)\n",
      "2019-03-19 01:11:05.417368: step 2020, examples 101000, loss = 1.180123448 (33.307 examples/sec; 1.501 sec/batch)\n",
      "2019-03-19 01:11:20.138054: step 2030, examples 101500, loss = 0.960664749 (33.531 examples/sec; 1.491 sec/batch)\n",
      "2019-03-19 01:11:34.808930: step 2040, examples 102000, loss = 1.021329641 (33.736 examples/sec; 1.482 sec/batch)\n",
      "2019-03-19 01:11:49.103398: step 2050, examples 102500, loss = 1.090866566 (35.194 examples/sec; 1.421 sec/batch)\n",
      "2019-03-19 01:12:03.372631: step 2060, examples 103000, loss = 1.017120838 (32.622 examples/sec; 1.533 sec/batch)\n",
      "2019-03-19 01:12:18.583178: step 2070, examples 103500, loss = 1.002319455 (33.828 examples/sec; 1.478 sec/batch)\n",
      "2019-03-19 01:12:35.327384: step 2080, examples 104000, loss = 1.031033993 (31.421 examples/sec; 1.591 sec/batch)\n",
      "2019-03-19 01:12:50.472399: step 2090, examples 104500, loss = 1.025750041 (33.223 examples/sec; 1.505 sec/batch)\n",
      "2019-03-19 01:13:05.128874: step 2100, examples 105000, loss = 0.839601338 (33.404 examples/sec; 1.497 sec/batch)\n",
      "Top 1 validation accuracy: 0.599056601524353 and top 2 validation accuracy: 0.8207547068595886\n",
      "Model Saved!\n",
      "2019-03-19 01:13:26.300744: step 2110, examples 105500, loss = 0.861015737 (31.667 examples/sec; 1.579 sec/batch)\n",
      "2019-03-19 01:13:41.687142: step 2120, examples 106000, loss = 1.179277420 (31.370 examples/sec; 1.594 sec/batch)\n",
      "2019-03-19 01:13:56.969292: step 2130, examples 106500, loss = 0.981937468 (31.972 examples/sec; 1.564 sec/batch)\n",
      "2019-03-19 01:14:12.089643: step 2140, examples 107000, loss = 0.960166395 (33.724 examples/sec; 1.483 sec/batch)\n",
      "2019-03-19 01:14:27.112236: step 2150, examples 107500, loss = 0.976476073 (33.680 examples/sec; 1.485 sec/batch)\n",
      "2019-03-19 01:14:42.175700: step 2160, examples 108000, loss = 0.897757292 (33.919 examples/sec; 1.474 sec/batch)\n",
      "2019-03-19 01:14:56.900391: step 2170, examples 108500, loss = 0.964612603 (35.058 examples/sec; 1.426 sec/batch)\n",
      "2019-03-19 01:15:11.858794: step 2180, examples 109000, loss = 1.072507620 (34.155 examples/sec; 1.464 sec/batch)\n",
      "2019-03-19 01:15:26.566635: step 2190, examples 109500, loss = 0.969299734 (32.402 examples/sec; 1.543 sec/batch)\n",
      "2019-03-19 01:15:42.068150: step 2200, examples 110000, loss = 0.929674506 (32.597 examples/sec; 1.534 sec/batch)\n",
      "Top 1 validation accuracy: 0.5825471878051758 and top 2 validation accuracy: 0.8089622855186462\n",
      "Model Saved!\n",
      "2019-03-19 01:16:02.068509: step 2210, examples 110500, loss = 0.922552168 (35.231 examples/sec; 1.419 sec/batch)\n",
      "2019-03-19 01:16:16.916801: step 2220, examples 111000, loss = 0.947691679 (32.703 examples/sec; 1.529 sec/batch)\n",
      "2019-03-19 01:16:31.810970: step 2230, examples 111500, loss = 1.102583766 (34.221 examples/sec; 1.461 sec/batch)\n",
      "2019-03-19 01:16:46.216446: step 2240, examples 112000, loss = 0.950025320 (33.378 examples/sec; 1.498 sec/batch)\n",
      "2019-03-19 01:17:01.395852: step 2250, examples 112500, loss = 0.897372663 (33.989 examples/sec; 1.471 sec/batch)\n",
      "2019-03-19 01:17:15.800331: step 2260, examples 113000, loss = 0.944247246 (34.151 examples/sec; 1.464 sec/batch)\n",
      "2019-03-19 01:17:30.305540: step 2270, examples 113500, loss = 0.986138284 (33.760 examples/sec; 1.481 sec/batch)\n",
      "2019-03-19 01:17:45.075043: step 2280, examples 114000, loss = 1.054676175 (34.743 examples/sec; 1.439 sec/batch)\n",
      "2019-03-19 01:18:00.228519: step 2290, examples 114500, loss = 1.014593005 (29.788 examples/sec; 1.679 sec/batch)\n",
      "2019-03-19 01:18:15.695480: step 2300, examples 115000, loss = 1.019309163 (34.268 examples/sec; 1.459 sec/batch)\n",
      "Top 1 validation accuracy: 0.6367924809455872 and top 2 validation accuracy: 0.8113207817077637\n",
      "Model Saved!\n",
      "2019-03-19 01:18:35.152537: step 2310, examples 115500, loss = 0.920317471 (34.815 examples/sec; 1.436 sec/batch)\n",
      "2019-03-19 01:18:49.603891: step 2320, examples 116000, loss = 0.900257468 (34.527 examples/sec; 1.448 sec/batch)\n",
      "2019-03-19 01:19:03.908635: step 2330, examples 116500, loss = 1.047148585 (35.784 examples/sec; 1.397 sec/batch)\n",
      "2019-03-19 01:19:18.338048: step 2340, examples 117000, loss = 1.166116595 (33.557 examples/sec; 1.490 sec/batch)\n",
      "2019-03-19 01:19:32.668724: step 2350, examples 117500, loss = 0.906423628 (35.059 examples/sec; 1.426 sec/batch)\n",
      "2019-03-19 01:19:47.017351: step 2360, examples 118000, loss = 0.924893558 (35.964 examples/sec; 1.390 sec/batch)\n",
      "2019-03-19 01:20:01.340049: step 2370, examples 118500, loss = 1.057217360 (34.671 examples/sec; 1.442 sec/batch)\n",
      "2019-03-19 01:20:16.329962: step 2380, examples 119000, loss = 0.955138564 (33.989 examples/sec; 1.471 sec/batch)\n",
      "2019-03-19 01:20:31.028654: step 2390, examples 119500, loss = 0.956312180 (35.059 examples/sec; 1.426 sec/batch)\n",
      "2019-03-19 01:20:45.593703: step 2400, examples 120000, loss = 1.114535928 (34.912 examples/sec; 1.432 sec/batch)\n",
      "Top 1 validation accuracy: 0.6108490824699402 and top 2 validation accuracy: 0.849056601524353\n",
      "Model Saved!\n",
      "2019-03-19 01:21:05.583245: step 2410, examples 120500, loss = 0.955766439 (33.512 examples/sec; 1.492 sec/batch)\n",
      "2019-03-19 01:21:20.397628: step 2420, examples 121000, loss = 0.974037349 (32.918 examples/sec; 1.519 sec/batch)\n",
      "2019-03-19 01:21:35.886208: step 2430, examples 121500, loss = 1.053504109 (28.469 examples/sec; 1.756 sec/batch)\n",
      "2019-03-19 01:21:51.386122: step 2440, examples 122000, loss = 0.956415951 (28.228 examples/sec; 1.771 sec/batch)\n",
      "2019-03-19 01:22:06.313199: step 2450, examples 122500, loss = 0.902682245 (34.815 examples/sec; 1.436 sec/batch)\n",
      "2019-03-19 01:22:22.100017: step 2460, examples 123000, loss = 0.934116542 (32.533 examples/sec; 1.537 sec/batch)\n",
      "2019-03-19 01:22:35.137517: step 2470, examples 123500, loss = 0.861740470 (39.075 examples/sec; 1.280 sec/batch)\n",
      "2019-03-19 01:22:47.916448: step 2480, examples 124000, loss = 0.975025237 (40.709 examples/sec; 1.228 sec/batch)\n",
      "2019-03-19 01:23:00.699324: step 2490, examples 124500, loss = 0.943370461 (38.845 examples/sec; 1.287 sec/batch)\n",
      "2019-03-19 01:23:13.583335: step 2500, examples 125000, loss = 1.126785398 (39.044 examples/sec; 1.281 sec/batch)\n",
      "Top 1 validation accuracy: 0.6155660152435303 and top 2 validation accuracy: 0.8301886916160583\n",
      "Model Saved!\n",
      "2019-03-19 01:23:30.788366: step 2510, examples 125500, loss = 1.167176485 (38.786 examples/sec; 1.289 sec/batch)\n",
      "2019-03-19 01:23:43.628379: step 2520, examples 126000, loss = 0.982727051 (38.665 examples/sec; 1.293 sec/batch)\n",
      "2019-03-19 01:23:56.529692: step 2530, examples 126500, loss = 0.794811428 (38.466 examples/sec; 1.300 sec/batch)\n",
      "2019-03-19 01:24:09.281607: step 2540, examples 127000, loss = 0.948628664 (39.034 examples/sec; 1.281 sec/batch)\n",
      "2019-03-19 01:24:22.073973: step 2550, examples 127500, loss = 0.936891794 (37.511 examples/sec; 1.333 sec/batch)\n",
      "2019-03-19 01:24:34.835721: step 2560, examples 128000, loss = 0.936533213 (38.694 examples/sec; 1.292 sec/batch)\n",
      "2019-03-19 01:24:47.617990: step 2570, examples 128500, loss = 0.918353617 (38.332 examples/sec; 1.304 sec/batch)\n",
      "2019-03-19 01:25:00.420509: step 2580, examples 129000, loss = 1.029818654 (38.782 examples/sec; 1.289 sec/batch)\n",
      "2019-03-19 01:25:13.209146: step 2590, examples 129500, loss = 1.011665821 (41.303 examples/sec; 1.211 sec/batch)\n",
      "2019-03-19 01:25:25.927588: step 2600, examples 130000, loss = 1.044258595 (37.502 examples/sec; 1.333 sec/batch)\n",
      "Top 1 validation accuracy: 0.5919811129570007 and top 2 validation accuracy: 0.8301886916160583\n",
      "Model Saved!\n",
      "2019-03-19 01:25:43.177943: step 2610, examples 130500, loss = 0.985807240 (39.552 examples/sec; 1.264 sec/batch)\n",
      "2019-03-19 01:25:55.954110: step 2620, examples 131000, loss = 0.883049190 (40.525 examples/sec; 1.234 sec/batch)\n",
      "2019-03-19 01:26:08.668985: step 2630, examples 131500, loss = 0.944133759 (39.318 examples/sec; 1.272 sec/batch)\n",
      "2019-03-19 01:26:21.396670: step 2640, examples 132000, loss = 1.005269170 (39.120 examples/sec; 1.278 sec/batch)\n",
      "2019-03-19 01:26:34.205752: step 2650, examples 132500, loss = 0.846664071 (38.103 examples/sec; 1.312 sec/batch)\n",
      "2019-03-19 01:26:47.175505: step 2660, examples 133000, loss = 0.940888226 (39.237 examples/sec; 1.274 sec/batch)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2019-03-19 01:26:59.895481: step 2670, examples 133500, loss = 0.986196876 (38.949 examples/sec; 1.284 sec/batch)\n",
      "2019-03-19 01:27:12.714234: step 2680, examples 134000, loss = 0.879651070 (38.767 examples/sec; 1.290 sec/batch)\n",
      "2019-03-19 01:27:25.758889: step 2690, examples 134500, loss = 1.057764888 (37.598 examples/sec; 1.330 sec/batch)\n",
      "2019-03-19 01:27:38.648621: step 2700, examples 135000, loss = 0.821721673 (39.395 examples/sec; 1.269 sec/batch)\n",
      "Top 1 validation accuracy: 0.625 and top 2 validation accuracy: 0.8349056839942932\n",
      "Model Saved!\n",
      "2019-03-19 01:27:57.424478: step 2710, examples 135500, loss = 0.951138556 (37.558 examples/sec; 1.331 sec/batch)\n",
      "2019-03-19 01:28:10.305757: step 2720, examples 136000, loss = 0.946308196 (40.005 examples/sec; 1.250 sec/batch)\n",
      "2019-03-19 01:28:23.310826: step 2730, examples 136500, loss = 0.942223310 (39.259 examples/sec; 1.274 sec/batch)\n",
      "2019-03-19 01:28:36.244983: step 2740, examples 137000, loss = 0.938438833 (38.426 examples/sec; 1.301 sec/batch)\n",
      "2019-03-19 01:28:49.290047: step 2750, examples 137500, loss = 1.015668392 (38.931 examples/sec; 1.284 sec/batch)\n",
      "2019-03-19 01:29:02.369321: step 2760, examples 138000, loss = 0.941997707 (38.885 examples/sec; 1.286 sec/batch)\n",
      "2019-03-19 01:29:15.322815: step 2770, examples 138500, loss = 0.816079319 (38.080 examples/sec; 1.313 sec/batch)\n",
      "2019-03-19 01:29:28.322330: step 2780, examples 139000, loss = 0.871949553 (39.014 examples/sec; 1.282 sec/batch)\n",
      "2019-03-19 01:29:41.305493: step 2790, examples 139500, loss = 0.927266061 (38.503 examples/sec; 1.299 sec/batch)\n",
      "2019-03-19 01:29:54.315414: step 2800, examples 140000, loss = 0.942212284 (38.787 examples/sec; 1.289 sec/batch)\n",
      "Top 1 validation accuracy: 0.6391509175300598 and top 2 validation accuracy: 0.8278301954269409\n",
      "Model Saved!\n",
      "2019-03-19 01:30:12.024662: step 2810, examples 140500, loss = 0.822111309 (38.930 examples/sec; 1.284 sec/batch)\n",
      "2019-03-19 01:30:25.174755: step 2820, examples 141000, loss = 0.815537453 (37.799 examples/sec; 1.323 sec/batch)\n",
      "2019-03-19 01:30:38.227662: step 2830, examples 141500, loss = 0.865339220 (39.051 examples/sec; 1.280 sec/batch)\n",
      "2019-03-19 01:30:51.093427: step 2840, examples 142000, loss = 0.904445410 (40.053 examples/sec; 1.248 sec/batch)\n",
      "2019-03-19 01:31:04.271562: step 2850, examples 142500, loss = 0.906937838 (37.461 examples/sec; 1.335 sec/batch)\n",
      "2019-03-19 01:31:17.313077: step 2860, examples 143000, loss = 0.999604642 (38.979 examples/sec; 1.283 sec/batch)\n",
      "2019-03-19 01:31:30.442777: step 2870, examples 143500, loss = 0.804602444 (37.804 examples/sec; 1.323 sec/batch)\n",
      "2019-03-19 01:31:43.445173: step 2880, examples 144000, loss = 1.094787598 (38.724 examples/sec; 1.291 sec/batch)\n",
      "2019-03-19 01:31:56.672761: step 2890, examples 144500, loss = 0.971499681 (36.832 examples/sec; 1.358 sec/batch)\n",
      "2019-03-19 01:32:09.537869: step 2900, examples 145000, loss = 1.035610318 (38.422 examples/sec; 1.301 sec/batch)\n",
      "Top 1 validation accuracy: 0.6320754885673523 and top 2 validation accuracy: 0.8066037893295288\n",
      "Model Saved!\n",
      "2019-03-19 01:32:27.230770: step 2910, examples 145500, loss = 1.062373638 (38.612 examples/sec; 1.295 sec/batch)\n",
      "2019-03-19 01:32:40.330532: step 2920, examples 146000, loss = 0.940712690 (38.187 examples/sec; 1.309 sec/batch)\n",
      "2019-03-19 01:32:53.230347: step 2930, examples 146500, loss = 0.890881538 (38.097 examples/sec; 1.312 sec/batch)\n",
      "2019-03-19 01:33:06.208974: step 2940, examples 147000, loss = 0.724560320 (39.004 examples/sec; 1.282 sec/batch)\n",
      "2019-03-19 01:33:19.230903: step 2950, examples 147500, loss = 0.838766873 (38.513 examples/sec; 1.298 sec/batch)\n",
      "2019-03-19 01:33:32.380886: step 2960, examples 148000, loss = 0.850396216 (39.641 examples/sec; 1.261 sec/batch)\n",
      "2019-03-19 01:33:45.327064: step 2970, examples 148500, loss = 0.819426775 (38.798 examples/sec; 1.289 sec/batch)\n",
      "2019-03-19 01:33:58.436806: step 2980, examples 149000, loss = 0.817036211 (37.518 examples/sec; 1.333 sec/batch)\n",
      "2019-03-19 01:34:11.526784: step 2990, examples 149500, loss = 0.830244601 (37.634 examples/sec; 1.329 sec/batch)\n",
      "2019-03-19 01:34:24.588343: step 3000, examples 150000, loss = 0.904120028 (39.069 examples/sec; 1.280 sec/batch)\n",
      "Top 1 validation accuracy: 0.6061320900917053 and top 2 validation accuracy: 0.8136792182922363\n",
      "Model Saved!\n",
      "2019-03-19 01:34:42.521428: step 3010, examples 150500, loss = 0.876160860 (36.855 examples/sec; 1.357 sec/batch)\n",
      "2019-03-19 01:34:55.586975: step 3020, examples 151000, loss = 0.927003443 (38.596 examples/sec; 1.295 sec/batch)\n",
      "2019-03-19 01:35:08.540063: step 3030, examples 151500, loss = 0.789948046 (38.157 examples/sec; 1.310 sec/batch)\n",
      "2019-03-19 01:35:21.443362: step 3040, examples 152000, loss = 0.849662721 (39.515 examples/sec; 1.265 sec/batch)\n",
      "2019-03-19 01:35:34.568599: step 3050, examples 152500, loss = 0.712070286 (37.220 examples/sec; 1.343 sec/batch)\n",
      "2019-03-19 01:35:47.514837: step 3060, examples 153000, loss = 0.798738062 (38.899 examples/sec; 1.285 sec/batch)\n",
      "2019-03-19 01:36:00.719181: step 3070, examples 153500, loss = 0.809297919 (37.457 examples/sec; 1.335 sec/batch)\n",
      "2019-03-19 01:36:13.829623: step 3080, examples 154000, loss = 0.799473703 (38.439 examples/sec; 1.301 sec/batch)\n",
      "2019-03-19 01:36:26.899606: step 3090, examples 154500, loss = 0.984429181 (37.924 examples/sec; 1.318 sec/batch)\n",
      "2019-03-19 01:36:40.042428: step 3100, examples 155000, loss = 0.745685160 (39.866 examples/sec; 1.254 sec/batch)\n",
      "Top 1 validation accuracy: 0.6415094137191772 and top 2 validation accuracy: 0.823113203048706\n",
      "Model Saved!\n",
      "2019-03-19 01:36:57.429344: step 3110, examples 155500, loss = 0.786731720 (39.471 examples/sec; 1.267 sec/batch)\n",
      "2019-03-19 01:37:10.506162: step 3120, examples 156000, loss = 0.720665872 (37.257 examples/sec; 1.342 sec/batch)\n",
      "2019-03-19 01:37:23.478752: step 3130, examples 156500, loss = 0.750922918 (37.990 examples/sec; 1.316 sec/batch)\n",
      "2019-03-19 01:37:36.584215: step 3140, examples 157000, loss = 0.652962744 (38.867 examples/sec; 1.286 sec/batch)\n",
      "2019-03-19 01:37:49.571384: step 3150, examples 157500, loss = 0.779065311 (39.069 examples/sec; 1.280 sec/batch)\n",
      "2019-03-19 01:38:02.519874: step 3160, examples 158000, loss = 0.687456250 (36.688 examples/sec; 1.363 sec/batch)\n",
      "2019-03-19 01:38:15.672757: step 3170, examples 158500, loss = 0.741551220 (38.357 examples/sec; 1.304 sec/batch)\n",
      "2019-03-19 01:38:28.570423: step 3180, examples 159000, loss = 0.724706769 (38.624 examples/sec; 1.295 sec/batch)\n",
      "2019-03-19 01:38:41.662874: step 3190, examples 159500, loss = 0.621869326 (38.683 examples/sec; 1.293 sec/batch)\n",
      "2019-03-19 01:38:54.708776: step 3200, examples 160000, loss = 0.706696570 (39.068 examples/sec; 1.280 sec/batch)\n",
      "Top 1 validation accuracy: 0.6344339847564697 and top 2 validation accuracy: 0.8325471878051758\n",
      "Model Saved!\n",
      "2019-03-19 01:39:12.360970: step 3210, examples 160500, loss = 0.827932596 (38.978 examples/sec; 1.283 sec/batch)\n",
      "2019-03-19 01:39:25.503614: step 3220, examples 161000, loss = 0.840990245 (36.985 examples/sec; 1.352 sec/batch)\n",
      "2019-03-19 01:39:38.666756: step 3230, examples 161500, loss = 0.736834109 (38.422 examples/sec; 1.301 sec/batch)\n",
      "2019-03-19 01:39:51.641135: step 3240, examples 162000, loss = 0.719584703 (38.250 examples/sec; 1.307 sec/batch)\n",
      "2019-03-19 01:40:04.992738: step 3250, examples 162500, loss = 0.614540160 (36.620 examples/sec; 1.365 sec/batch)\n",
      "2019-03-19 01:40:18.116435: step 3260, examples 163000, loss = 0.738763750 (38.066 examples/sec; 1.314 sec/batch)\n",
      "2019-03-19 01:40:31.168111: step 3270, examples 163500, loss = 0.856895208 (37.906 examples/sec; 1.319 sec/batch)\n",
      "2019-03-19 01:40:44.531090: step 3280, examples 164000, loss = 0.576255560 (36.708 examples/sec; 1.362 sec/batch)\n",
      "2019-03-19 01:40:57.857478: step 3290, examples 164500, loss = 0.704382956 (39.104 examples/sec; 1.279 sec/batch)\n",
      "2019-03-19 01:41:10.982652: step 3300, examples 165000, loss = 0.696543813 (38.290 examples/sec; 1.306 sec/batch)\n",
      "Top 1 validation accuracy: 0.6273584961891174 and top 2 validation accuracy: 0.8443396091461182\n",
      "Model Saved!\n",
      "2019-03-19 01:41:28.728211: step 3310, examples 165500, loss = 0.641113937 (38.608 examples/sec; 1.295 sec/batch)\n",
      "2019-03-19 01:41:41.738145: step 3320, examples 166000, loss = 0.731495321 (37.440 examples/sec; 1.335 sec/batch)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2019-03-19 01:41:54.834005: step 3330, examples 166500, loss = 0.619890273 (38.431 examples/sec; 1.301 sec/batch)\n",
      "2019-03-19 01:42:07.880419: step 3340, examples 167000, loss = 0.649988234 (39.095 examples/sec; 1.279 sec/batch)\n",
      "2019-03-19 01:42:22.662330: step 3350, examples 167500, loss = 0.682064295 (33.223 examples/sec; 1.505 sec/batch)\n",
      "2019-03-19 01:42:36.586238: step 3360, examples 168000, loss = 0.829471231 (38.956 examples/sec; 1.284 sec/batch)\n",
      "2019-03-19 01:42:50.591303: step 3370, examples 168500, loss = 0.758712590 (35.811 examples/sec; 1.396 sec/batch)\n",
      "2019-03-19 01:43:06.282114: step 3380, examples 169000, loss = 0.642302752 (29.301 examples/sec; 1.706 sec/batch)\n",
      "2019-03-19 01:43:23.151577: step 3390, examples 169500, loss = 0.812564909 (32.122 examples/sec; 1.557 sec/batch)\n",
      "2019-03-19 01:43:37.640701: step 3400, examples 170000, loss = 0.691053629 (35.429 examples/sec; 1.411 sec/batch)\n",
      "Top 1 validation accuracy: 0.6132075190544128 and top 2 validation accuracy: 0.8301886916160583\n",
      "Model Saved!\n",
      "2019-03-19 01:43:56.798143: step 3410, examples 170500, loss = 0.769139469 (35.616 examples/sec; 1.404 sec/batch)\n",
      "2019-03-19 01:44:10.905407: step 3420, examples 171000, loss = 0.672674417 (35.820 examples/sec; 1.396 sec/batch)\n",
      "2019-03-19 01:44:25.026495: step 3430, examples 171500, loss = 0.863754988 (35.731 examples/sec; 1.399 sec/batch)\n",
      "2019-03-19 01:44:39.173164: step 3440, examples 172000, loss = 0.682312250 (35.065 examples/sec; 1.426 sec/batch)\n",
      "2019-03-19 01:44:53.234123: step 3450, examples 172500, loss = 0.779557765 (35.344 examples/sec; 1.415 sec/batch)\n",
      "2019-03-19 01:45:07.293361: step 3460, examples 173000, loss = 0.569858134 (35.535 examples/sec; 1.407 sec/batch)\n",
      "2019-03-19 01:45:21.415412: step 3470, examples 173500, loss = 0.692399681 (34.800 examples/sec; 1.437 sec/batch)\n",
      "2019-03-19 01:45:35.507626: step 3480, examples 174000, loss = 0.703173697 (36.054 examples/sec; 1.387 sec/batch)\n",
      "2019-03-19 01:45:49.730649: step 3490, examples 174500, loss = 0.507638574 (35.404 examples/sec; 1.412 sec/batch)\n",
      "2019-03-19 01:46:03.800134: step 3500, examples 175000, loss = 0.695545256 (35.626 examples/sec; 1.403 sec/batch)\n",
      "Top 1 validation accuracy: 0.6132075190544128 and top 2 validation accuracy: 0.8113207817077637\n",
      "Model Saved!\n",
      "2019-03-19 01:46:22.640504: step 3510, examples 175500, loss = 0.653670728 (36.059 examples/sec; 1.387 sec/batch)\n",
      "2019-03-19 01:46:36.624705: step 3520, examples 176000, loss = 0.633434355 (35.666 examples/sec; 1.402 sec/batch)\n",
      "2019-03-19 01:46:50.681501: step 3530, examples 176500, loss = 0.768889368 (35.684 examples/sec; 1.401 sec/batch)\n",
      "2019-03-19 01:47:04.906526: step 3540, examples 177000, loss = 0.796117961 (35.624 examples/sec; 1.404 sec/batch)\n",
      "2019-03-19 01:47:19.165184: step 3550, examples 177500, loss = 0.680490792 (33.980 examples/sec; 1.471 sec/batch)\n",
      "2019-03-19 01:47:33.245019: step 3560, examples 178000, loss = 0.637569547 (34.780 examples/sec; 1.438 sec/batch)\n",
      "2019-03-19 01:47:47.233088: step 3570, examples 178500, loss = 0.568042576 (36.236 examples/sec; 1.380 sec/batch)\n",
      "2019-03-19 01:48:01.419705: step 3580, examples 179000, loss = 0.718207002 (34.070 examples/sec; 1.468 sec/batch)\n",
      "2019-03-19 01:48:15.523361: step 3590, examples 179500, loss = 0.830753684 (36.132 examples/sec; 1.384 sec/batch)\n",
      "2019-03-19 01:48:29.580252: step 3600, examples 180000, loss = 0.636106968 (36.251 examples/sec; 1.379 sec/batch)\n",
      "Top 1 validation accuracy: 0.6155660152435303 and top 2 validation accuracy: 0.823113203048706\n",
      "Model Saved!\n",
      "2019-03-19 01:48:48.551956: step 3610, examples 180500, loss = 0.793501258 (36.792 examples/sec; 1.359 sec/batch)\n",
      "2019-03-19 01:49:02.578379: step 3620, examples 181000, loss = 0.585494399 (35.746 examples/sec; 1.399 sec/batch)\n",
      "2019-03-19 01:49:16.647888: step 3630, examples 181500, loss = 0.819772899 (36.119 examples/sec; 1.384 sec/batch)\n",
      "2019-03-19 01:49:30.648688: step 3640, examples 182000, loss = 0.554677486 (35.656 examples/sec; 1.402 sec/batch)\n",
      "2019-03-19 01:49:44.637498: step 3650, examples 182500, loss = 0.580038488 (36.798 examples/sec; 1.359 sec/batch)\n",
      "2019-03-19 01:49:58.744557: step 3660, examples 183000, loss = 0.589764774 (34.643 examples/sec; 1.443 sec/batch)\n",
      "2019-03-19 01:50:12.516863: step 3670, examples 183500, loss = 0.671301425 (36.301 examples/sec; 1.377 sec/batch)\n",
      "2019-03-19 01:50:26.648011: step 3680, examples 184000, loss = 0.788859189 (34.439 examples/sec; 1.452 sec/batch)\n",
      "2019-03-19 01:50:40.682457: step 3690, examples 184500, loss = 0.633225620 (35.806 examples/sec; 1.396 sec/batch)\n",
      "2019-03-19 01:50:54.899344: step 3700, examples 185000, loss = 0.729053438 (35.479 examples/sec; 1.409 sec/batch)\n",
      "Top 1 validation accuracy: 0.5801886916160583 and top 2 validation accuracy: 0.8160377144813538\n",
      "Model Saved!\n",
      "2019-03-19 01:51:13.832015: step 3710, examples 185500, loss = 0.680397928 (34.230 examples/sec; 1.461 sec/batch)\n",
      "2019-03-19 01:51:27.893465: step 3720, examples 186000, loss = 0.683853745 (35.700 examples/sec; 1.401 sec/batch)\n",
      "2019-03-19 01:51:41.992121: step 3730, examples 186500, loss = 0.573711574 (35.964 examples/sec; 1.390 sec/batch)\n",
      "2019-03-19 01:51:55.980409: step 3740, examples 187000, loss = 0.590538204 (36.755 examples/sec; 1.360 sec/batch)\n",
      "2019-03-19 01:52:10.120242: step 3750, examples 187500, loss = 0.621054232 (35.694 examples/sec; 1.401 sec/batch)\n",
      "2019-03-19 01:52:24.123400: step 3760, examples 188000, loss = 0.714449704 (36.276 examples/sec; 1.378 sec/batch)\n",
      "2019-03-19 01:52:38.213552: step 3770, examples 188500, loss = 0.636911929 (34.406 examples/sec; 1.453 sec/batch)\n",
      "2019-03-19 01:52:52.201274: step 3780, examples 189000, loss = 0.648571014 (36.255 examples/sec; 1.379 sec/batch)\n",
      "2019-03-19 01:53:06.224073: step 3790, examples 189500, loss = 0.626087785 (35.975 examples/sec; 1.390 sec/batch)\n",
      "2019-03-19 01:53:20.313882: step 3800, examples 190000, loss = 0.805406749 (35.707 examples/sec; 1.400 sec/batch)\n",
      "Top 1 validation accuracy: 0.6202830076217651 and top 2 validation accuracy: 0.8207547068595886\n",
      "Model Saved!\n",
      "2019-03-19 01:53:39.230807: step 3810, examples 190500, loss = 0.671275377 (36.119 examples/sec; 1.384 sec/batch)\n",
      "2019-03-19 01:53:53.441028: step 3820, examples 191000, loss = 0.678730905 (34.323 examples/sec; 1.457 sec/batch)\n",
      "2019-03-19 01:54:07.639329: step 3830, examples 191500, loss = 0.601113796 (35.606 examples/sec; 1.404 sec/batch)\n",
      "2019-03-19 01:54:21.727828: step 3840, examples 192000, loss = 0.688130498 (35.430 examples/sec; 1.411 sec/batch)\n",
      "2019-03-19 01:54:35.902600: step 3850, examples 192500, loss = 0.592532218 (37.969 examples/sec; 1.317 sec/batch)\n",
      "2019-03-19 01:54:49.040090: step 3860, examples 193000, loss = 0.896427095 (38.181 examples/sec; 1.310 sec/batch)\n",
      "2019-03-19 01:55:02.326537: step 3870, examples 193500, loss = 0.596441925 (35.213 examples/sec; 1.420 sec/batch)\n",
      "2019-03-19 01:55:16.138400: step 3880, examples 194000, loss = 0.633175194 (36.621 examples/sec; 1.365 sec/batch)\n",
      "2019-03-19 01:55:30.736362: step 3890, examples 194500, loss = 0.749469936 (33.422 examples/sec; 1.496 sec/batch)\n",
      "2019-03-19 01:55:45.263512: step 3900, examples 195000, loss = 0.611790895 (37.164 examples/sec; 1.345 sec/batch)\n",
      "Top 1 validation accuracy: 0.5754716992378235 and top 2 validation accuracy: 0.8183962106704712\n",
      "Model Saved!\n",
      "2019-03-19 01:56:03.447882: step 3910, examples 195500, loss = 0.670526505 (37.666 examples/sec; 1.327 sec/batch)\n",
      "2019-03-19 01:56:16.813139: step 3920, examples 196000, loss = 0.701339304 (37.581 examples/sec; 1.330 sec/batch)\n",
      "2019-03-19 01:56:30.200338: step 3930, examples 196500, loss = 0.615099132 (37.246 examples/sec; 1.342 sec/batch)\n",
      "2019-03-19 01:56:43.572577: step 3940, examples 197000, loss = 0.654734194 (36.945 examples/sec; 1.353 sec/batch)\n",
      "2019-03-19 01:56:57.500274: step 3950, examples 197500, loss = 0.686438024 (35.055 examples/sec; 1.426 sec/batch)\n",
      "2019-03-19 01:57:10.885367: step 3960, examples 198000, loss = 0.662297964 (36.497 examples/sec; 1.370 sec/batch)\n",
      "2019-03-19 01:57:24.155112: step 3970, examples 198500, loss = 0.661194861 (36.416 examples/sec; 1.373 sec/batch)\n",
      "2019-03-19 01:57:37.996726: step 3980, examples 199000, loss = 0.549748361 (37.909 examples/sec; 1.319 sec/batch)\n",
      "2019-03-19 01:57:51.351159: step 3990, examples 199500, loss = 0.458329499 (38.638 examples/sec; 1.294 sec/batch)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2019-03-19 01:58:04.508968: step 4000, examples 200000, loss = 0.581089735 (37.575 examples/sec; 1.331 sec/batch)\n",
      "Top 1 validation accuracy: 0.6391509175300598 and top 2 validation accuracy: 0.8349056839942932\n",
      "Model Saved!\n",
      "2019-03-19 01:58:22.291182: step 4010, examples 200500, loss = 0.717105210 (38.565 examples/sec; 1.297 sec/batch)\n",
      "2019-03-19 01:58:35.407517: step 4020, examples 201000, loss = 0.582926333 (38.267 examples/sec; 1.307 sec/batch)\n",
      "2019-03-19 01:58:48.486406: step 4030, examples 201500, loss = 0.758684099 (38.671 examples/sec; 1.293 sec/batch)\n",
      "2019-03-19 01:59:01.669483: step 4040, examples 202000, loss = 0.629420817 (36.478 examples/sec; 1.371 sec/batch)\n",
      "2019-03-19 01:59:14.818870: step 4050, examples 202500, loss = 0.751155436 (39.743 examples/sec; 1.258 sec/batch)\n",
      "2019-03-19 01:59:27.819203: step 4060, examples 203000, loss = 0.546702325 (38.742 examples/sec; 1.291 sec/batch)\n",
      "2019-03-19 01:59:41.036253: step 4070, examples 203500, loss = 0.623867452 (38.229 examples/sec; 1.308 sec/batch)\n",
      "2019-03-19 01:59:54.093468: step 4080, examples 204000, loss = 0.474092960 (39.222 examples/sec; 1.275 sec/batch)\n",
      "2019-03-19 02:00:07.177943: step 4090, examples 204500, loss = 0.633169413 (38.031 examples/sec; 1.315 sec/batch)\n",
      "2019-03-19 02:00:20.239460: step 4100, examples 205000, loss = 0.823499680 (38.812 examples/sec; 1.288 sec/batch)\n",
      "Top 1 validation accuracy: 0.5683962106704712 and top 2 validation accuracy: 0.8160377144813538\n",
      "Model Saved!\n",
      "2019-03-19 02:00:37.936330: step 4110, examples 205500, loss = 0.712277472 (37.636 examples/sec; 1.329 sec/batch)\n",
      "2019-03-19 02:00:50.869962: step 4120, examples 206000, loss = 0.717882693 (39.334 examples/sec; 1.271 sec/batch)\n",
      "2019-03-19 02:01:03.990725: step 4130, examples 206500, loss = 0.636380136 (37.415 examples/sec; 1.336 sec/batch)\n",
      "2019-03-19 02:01:17.256208: step 4140, examples 207000, loss = 0.613646388 (38.326 examples/sec; 1.305 sec/batch)\n",
      "2019-03-19 02:01:30.252994: step 4150, examples 207500, loss = 0.590340555 (38.456 examples/sec; 1.300 sec/batch)\n",
      "2019-03-19 02:01:43.435483: step 4160, examples 208000, loss = 0.631992996 (37.662 examples/sec; 1.328 sec/batch)\n",
      "2019-03-19 02:01:56.603742: step 4170, examples 208500, loss = 0.594377577 (38.627 examples/sec; 1.294 sec/batch)\n",
      "2019-03-19 02:02:09.685514: step 4180, examples 209000, loss = 0.510766268 (37.859 examples/sec; 1.321 sec/batch)\n",
      "2019-03-19 02:02:22.751639: step 4190, examples 209500, loss = 0.618352056 (38.189 examples/sec; 1.309 sec/batch)\n",
      "2019-03-19 02:02:35.741107: step 4200, examples 210000, loss = 0.840603828 (37.940 examples/sec; 1.318 sec/batch)\n",
      "Top 1 validation accuracy: 0.6367924809455872 and top 2 validation accuracy: 0.8396226167678833\n",
      "Model Saved!\n",
      "2019-03-19 02:02:53.839262: step 4210, examples 210500, loss = 0.563530326 (37.964 examples/sec; 1.317 sec/batch)\n",
      "2019-03-19 02:03:06.733653: step 4220, examples 211000, loss = 0.563828230 (37.302 examples/sec; 1.340 sec/batch)\n",
      "2019-03-19 02:03:19.751820: step 4230, examples 211500, loss = 0.534139574 (40.253 examples/sec; 1.242 sec/batch)\n",
      "2019-03-19 02:03:32.689184: step 4240, examples 212000, loss = 0.787798285 (39.215 examples/sec; 1.275 sec/batch)\n",
      "2019-03-19 02:03:45.621899: step 4250, examples 212500, loss = 0.706469119 (38.152 examples/sec; 1.311 sec/batch)\n",
      "2019-03-19 02:03:58.616697: step 4260, examples 213000, loss = 0.619733095 (37.954 examples/sec; 1.317 sec/batch)\n",
      "2019-03-19 02:04:11.601535: step 4270, examples 213500, loss = 0.638917148 (39.416 examples/sec; 1.269 sec/batch)\n",
      "2019-03-19 02:04:24.555426: step 4280, examples 214000, loss = 0.752899945 (39.089 examples/sec; 1.279 sec/batch)\n",
      "2019-03-19 02:04:37.355507: step 4290, examples 214500, loss = 0.455195308 (37.393 examples/sec; 1.337 sec/batch)\n",
      "2019-03-19 02:04:50.509144: step 4300, examples 215000, loss = 0.536587000 (38.046 examples/sec; 1.314 sec/batch)\n",
      "Top 1 validation accuracy: 0.6415094137191772 and top 2 validation accuracy: 0.8443396091461182\n",
      "Model Saved!\n",
      "2019-03-19 02:05:09.905912: step 4310, examples 215500, loss = 0.710143626 (34.128 examples/sec; 1.465 sec/batch)\n",
      "2019-03-19 02:05:24.947018: step 4320, examples 216000, loss = 0.533261716 (34.623 examples/sec; 1.444 sec/batch)\n",
      "2019-03-19 02:05:39.193806: step 4330, examples 216500, loss = 0.588555872 (35.201 examples/sec; 1.420 sec/batch)\n",
      "2019-03-19 02:05:53.379916: step 4340, examples 217000, loss = 0.472221017 (35.551 examples/sec; 1.406 sec/batch)\n",
      "2019-03-19 02:06:07.583625: step 4350, examples 217500, loss = 0.553806722 (35.185 examples/sec; 1.421 sec/batch)\n",
      "2019-03-19 02:06:21.875068: step 4360, examples 218000, loss = 0.456622034 (35.492 examples/sec; 1.409 sec/batch)\n",
      "2019-03-19 02:06:36.384430: step 4370, examples 218500, loss = 0.541746140 (34.279 examples/sec; 1.459 sec/batch)\n",
      "2019-03-19 02:06:50.591072: step 4380, examples 219000, loss = 0.563100398 (36.089 examples/sec; 1.385 sec/batch)\n",
      "2019-03-19 02:07:04.941081: step 4390, examples 219500, loss = 0.535230815 (34.922 examples/sec; 1.432 sec/batch)\n",
      "2019-03-19 02:07:19.030192: step 4400, examples 220000, loss = 0.538930118 (33.782 examples/sec; 1.480 sec/batch)\n",
      "Top 1 validation accuracy: 0.6367924809455872 and top 2 validation accuracy: 0.8301886916160583\n",
      "Model Saved!\n",
      "2019-03-19 02:07:38.341342: step 4410, examples 220500, loss = 0.621084750 (34.872 examples/sec; 1.434 sec/batch)\n",
      "2019-03-19 02:07:52.437003: step 4420, examples 221000, loss = 0.587557912 (35.809 examples/sec; 1.396 sec/batch)\n",
      "2019-03-19 02:08:06.628433: step 4430, examples 221500, loss = 0.522411108 (32.435 examples/sec; 1.542 sec/batch)\n",
      "2019-03-19 02:08:20.827441: step 4440, examples 222000, loss = 0.636490405 (35.291 examples/sec; 1.417 sec/batch)\n",
      "2019-03-19 02:08:35.066515: step 4450, examples 222500, loss = 0.540156782 (34.964 examples/sec; 1.430 sec/batch)\n",
      "2019-03-19 02:08:49.423091: step 4460, examples 223000, loss = 0.512989938 (34.008 examples/sec; 1.470 sec/batch)\n",
      "2019-03-19 02:09:03.595441: step 4470, examples 223500, loss = 0.651108027 (35.467 examples/sec; 1.410 sec/batch)\n",
      "2019-03-19 02:09:17.922154: step 4480, examples 224000, loss = 0.503634691 (34.829 examples/sec; 1.436 sec/batch)\n",
      "2019-03-19 02:09:32.230867: step 4490, examples 224500, loss = 0.628412962 (34.773 examples/sec; 1.438 sec/batch)\n",
      "2019-03-19 02:09:46.444616: step 4500, examples 225000, loss = 0.648307800 (34.969 examples/sec; 1.430 sec/batch)\n",
      "Top 1 validation accuracy: 0.6297169923782349 and top 2 validation accuracy: 0.8301886916160583\n",
      "Model Saved!\n",
      "2019-03-19 02:10:06.183632: step 4510, examples 225500, loss = 0.607757509 (34.948 examples/sec; 1.431 sec/batch)\n",
      "2019-03-19 02:10:20.945866: step 4520, examples 226000, loss = 0.598347425 (33.896 examples/sec; 1.475 sec/batch)\n",
      "2019-03-19 02:10:35.643224: step 4530, examples 226500, loss = 0.592836320 (34.249 examples/sec; 1.460 sec/batch)\n",
      "2019-03-19 02:10:50.418690: step 4540, examples 227000, loss = 0.647844613 (33.744 examples/sec; 1.482 sec/batch)\n",
      "2019-03-19 02:11:05.300562: step 4550, examples 227500, loss = 0.433322251 (32.318 examples/sec; 1.547 sec/batch)\n",
      "2019-03-19 02:11:20.005133: step 4560, examples 228000, loss = 0.569249392 (34.302 examples/sec; 1.458 sec/batch)\n",
      "2019-03-19 02:11:34.644509: step 4570, examples 228500, loss = 0.717480719 (33.146 examples/sec; 1.508 sec/batch)\n",
      "2019-03-19 02:11:49.526985: step 4580, examples 229000, loss = 0.645754099 (32.466 examples/sec; 1.540 sec/batch)\n",
      "2019-03-19 02:12:04.159477: step 4590, examples 229500, loss = 0.646192968 (34.686 examples/sec; 1.442 sec/batch)\n",
      "2019-03-19 02:12:18.788401: step 4600, examples 230000, loss = 0.537176788 (34.936 examples/sec; 1.431 sec/batch)\n",
      "Top 1 validation accuracy: 0.5849056839942932 and top 2 validation accuracy: 0.8443396091461182\n",
      "Model Saved!\n",
      "2019-03-19 02:12:38.731355: step 4610, examples 230500, loss = 0.472897917 (32.885 examples/sec; 1.520 sec/batch)\n",
      "2019-03-19 02:12:53.479553: step 4620, examples 231000, loss = 0.532913446 (33.444 examples/sec; 1.495 sec/batch)\n",
      "2019-03-19 02:13:08.182859: step 4630, examples 231500, loss = 0.598506331 (34.548 examples/sec; 1.447 sec/batch)\n",
      "2019-03-19 02:13:22.718005: step 4640, examples 232000, loss = 0.610934913 (35.480 examples/sec; 1.409 sec/batch)\n",
      "2019-03-19 02:13:37.651268: step 4650, examples 232500, loss = 0.530583918 (33.989 examples/sec; 1.471 sec/batch)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2019-03-19 02:13:52.398462: step 4660, examples 233000, loss = 0.572956502 (34.583 examples/sec; 1.446 sec/batch)\n",
      "2019-03-19 02:14:07.042555: step 4670, examples 233500, loss = 0.534530997 (34.634 examples/sec; 1.444 sec/batch)\n",
      "2019-03-19 02:14:21.695974: step 4680, examples 234000, loss = 0.732063234 (34.618 examples/sec; 1.444 sec/batch)\n",
      "2019-03-19 02:14:36.789676: step 4690, examples 234500, loss = 0.600407362 (28.789 examples/sec; 1.737 sec/batch)\n",
      "2019-03-19 02:14:54.040891: step 4700, examples 235000, loss = 0.473254591 (28.991 examples/sec; 1.725 sec/batch)\n",
      "Top 1 validation accuracy: 0.6297169923782349 and top 2 validation accuracy: 0.8349056839942932\n",
      "Model Saved!\n",
      "2019-03-19 02:15:18.200281: step 4710, examples 235500, loss = 0.655471861 (28.812 examples/sec; 1.735 sec/batch)\n",
      "2019-03-19 02:15:35.087882: step 4720, examples 236000, loss = 0.544600487 (26.207 examples/sec; 1.908 sec/batch)\n",
      "2019-03-19 02:15:51.928088: step 4730, examples 236500, loss = 0.451531321 (30.283 examples/sec; 1.651 sec/batch)\n",
      "2019-03-19 02:16:07.046618: step 4740, examples 237000, loss = 0.573785245 (33.245 examples/sec; 1.504 sec/batch)\n",
      "2019-03-19 02:16:21.953752: step 4750, examples 237500, loss = 0.476098925 (33.223 examples/sec; 1.505 sec/batch)\n",
      "2019-03-19 02:16:36.615543: step 4760, examples 238000, loss = 0.530102491 (33.715 examples/sec; 1.483 sec/batch)\n",
      "2019-03-19 02:16:52.350586: step 4770, examples 238500, loss = 0.713866770 (33.376 examples/sec; 1.498 sec/batch)\n",
      "2019-03-19 02:17:08.812564: step 4780, examples 239000, loss = 0.611135244 (31.128 examples/sec; 1.606 sec/batch)\n",
      "2019-03-19 02:17:24.929746: step 4790, examples 239500, loss = 0.624182403 (29.480 examples/sec; 1.696 sec/batch)\n",
      "2019-03-19 02:17:41.998483: step 4800, examples 240000, loss = 0.573049963 (28.181 examples/sec; 1.774 sec/batch)\n",
      "Top 1 validation accuracy: 0.6438679099082947 and top 2 validation accuracy: 0.8207547068595886\n",
      "Model Saved!\n",
      "2019-03-19 02:18:05.002066: step 4810, examples 240500, loss = 0.468151569 (27.980 examples/sec; 1.787 sec/batch)\n",
      "2019-03-19 02:18:22.456119: step 4820, examples 241000, loss = 0.571829379 (30.028 examples/sec; 1.665 sec/batch)\n",
      "2019-03-19 02:18:38.936529: step 4830, examples 241500, loss = 0.573545158 (31.452 examples/sec; 1.590 sec/batch)\n",
      "2019-03-19 02:18:55.241254: step 4840, examples 242000, loss = 0.482576191 (31.892 examples/sec; 1.568 sec/batch)\n",
      "2019-03-19 02:19:10.834488: step 4850, examples 242500, loss = 0.556051493 (32.661 examples/sec; 1.531 sec/batch)\n",
      "2019-03-19 02:19:26.432499: step 4860, examples 243000, loss = 0.689496934 (31.906 examples/sec; 1.567 sec/batch)\n",
      "2019-03-19 02:19:41.968383: step 4870, examples 243500, loss = 0.517235041 (33.233 examples/sec; 1.505 sec/batch)\n",
      "2019-03-19 02:19:57.211572: step 4880, examples 244000, loss = 0.532454908 (32.639 examples/sec; 1.532 sec/batch)\n",
      "2019-03-19 02:20:12.619314: step 4890, examples 244500, loss = 0.558966875 (31.542 examples/sec; 1.585 sec/batch)\n",
      "2019-03-19 02:20:28.053591: step 4900, examples 245000, loss = 0.636593103 (32.944 examples/sec; 1.518 sec/batch)\n",
      "Top 1 validation accuracy: 0.6344339847564697 and top 2 validation accuracy: 0.8561320900917053\n",
      "Model Saved!\n",
      "2019-03-19 02:20:48.491773: step 4910, examples 245500, loss = 0.616889536 (33.299 examples/sec; 1.502 sec/batch)\n",
      "2019-03-19 02:21:03.725694: step 4920, examples 246000, loss = 0.595039904 (33.116 examples/sec; 1.510 sec/batch)\n",
      "2019-03-19 02:21:19.195261: step 4930, examples 246500, loss = 0.497722715 (32.399 examples/sec; 1.543 sec/batch)\n",
      "2019-03-19 02:21:34.546847: step 4940, examples 247000, loss = 0.683316529 (32.864 examples/sec; 1.521 sec/batch)\n",
      "2019-03-19 02:21:49.805854: step 4950, examples 247500, loss = 0.760911882 (33.048 examples/sec; 1.513 sec/batch)\n",
      "2019-03-19 02:22:05.097911: step 4960, examples 248000, loss = 0.622781932 (32.452 examples/sec; 1.541 sec/batch)\n",
      "2019-03-19 02:22:20.259075: step 4970, examples 248500, loss = 0.465596497 (32.858 examples/sec; 1.522 sec/batch)\n",
      "2019-03-19 02:22:35.472329: step 4980, examples 249000, loss = 0.577557385 (33.524 examples/sec; 1.491 sec/batch)\n",
      "2019-03-19 02:22:50.636540: step 4990, examples 249500, loss = 0.602578342 (33.938 examples/sec; 1.473 sec/batch)\n",
      "Top 1 validation accuracy: 0.6202830076217651 and top 2 validation accuracy: 0.8207547068595886\n",
      "Model Saved!\n"
     ]
    }
   ],
   "source": [
    "best_val_gan2 = {}\n",
    "num_cls = 4\n",
    "mstp = 5000\n",
    "lfrq = 10\n",
    "bsz = 50\n",
    "msf = 100\n",
    "tr = './trained_model_final/DCNN_GAN5'\n",
    "if not os.path.exists(tr):\n",
    "    os.mkdir(tr)\n",
    "start = 0\n",
    "stop = 250\n",
    "step = 10\n",
    "time_bin = 350\n",
    "fsz = 3\n",
    "use_batchnorm = True\n",
    "use_dropout = True\n",
    "use_l2loss = True\n",
    "acc = 'Accuracy_gan4'\n",
    "path = 'Path_gan4'\n",
    "\n",
    "best_val_gan2[acc],best_val_gan2[path] = train_model_gan2(tr,start,stop,step,time_bin,fsz,use_batchnorm,use_dropout,use_l2loss,num_cls,mstp,lfrq,bsz,msf)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test Accuracy for all subjects:\n",
      "Loading datasets...\n",
      "Dataset loading completes.\n",
      "INFO:tensorflow:Restoring parameters from ./trained_model_final/DCNN_GAN5\\model.ckpt-4801\n",
      "[test  step 4801] loss: 1.23245; top_1_accuracy: 0.63431; top_5_accuracy: 0.828442 (7.926 sec/batch; 111.791 instances/sec)\n",
      "top_1_accuracy_test =  0.6343115 top_2_accuracy_test =  0.82844245\n"
     ]
    }
   ],
   "source": [
    "# Test model accuracy\n",
    "start = 0\n",
    "stop = 250\n",
    "step = 10\n",
    "time_bin = 350\n",
    "#Nb = BATCH_SIZE\n",
    "fsz = 3\n",
    "use_batchnorm = True\n",
    "use_dropout = True\n",
    "use_l2loss = True\n",
    "path = 'Path_gan4' \n",
    "model_dir = best_val_gan2[path]\n",
    "print('Test Accuracy for all subjects:')\n",
    "top_1_acc_test, top_2_acc_test = test_model_gan2(model_dir,start,stop,step,time_bin,fsz,use_batchnorm,use_dropout,use_l2loss)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
