{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from __future__ import absolute_import\n",
    "from __future__ import division\n",
    "from __future__ import print_function\n",
    "\n",
    "import tensorflow as tf\n",
    "import numpy as np\n",
    "import time\n",
    "import os\n",
    "from datetime import datetime\n",
    "\n",
    "from model_final import Model\n",
    "from configs_final import config\n",
    "from tensorflow.core.protobuf import rewriter_config_pb2\n",
    "from sklearn.model_selection import train_test_split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading datasets...\n",
      "Dataset loading completes.\n",
      "2019-03-15 19:03:03.584374: step 0, examples 0, loss = 1.402904868 (90.105 examples/sec; 0.555 sec/batch)\n",
      "Top 1 validation accuracy: 0.24528302252292633 and top 2 validation accuracy: 0.4716981053352356\n",
      "Model Saved!\n",
      "2019-03-15 19:03:08.861117: step 10, examples 500, loss = 1.399699807 (125.609 examples/sec; 0.398 sec/batch)\n",
      "2019-03-15 19:03:12.880040: step 20, examples 1000, loss = 1.266509414 (126.967 examples/sec; 0.394 sec/batch)\n",
      "2019-03-15 19:03:16.878071: step 30, examples 1500, loss = 1.260570168 (127.698 examples/sec; 0.392 sec/batch)\n",
      "2019-03-15 19:03:20.877470: step 40, examples 2000, loss = 1.254686236 (123.123 examples/sec; 0.406 sec/batch)\n",
      "2019-03-15 19:03:24.869723: step 50, examples 2500, loss = 1.077540159 (125.505 examples/sec; 0.398 sec/batch)\n",
      "2019-03-15 19:03:29.031716: step 60, examples 3000, loss = 1.024056911 (127.986 examples/sec; 0.391 sec/batch)\n",
      "2019-03-15 19:03:33.097981: step 70, examples 3500, loss = 1.062388897 (122.398 examples/sec; 0.409 sec/batch)\n",
      "2019-03-15 19:03:37.122321: step 80, examples 4000, loss = 0.794503272 (124.611 examples/sec; 0.401 sec/batch)\n",
      "2019-03-15 19:03:41.141993: step 90, examples 4500, loss = 0.843891501 (123.066 examples/sec; 0.406 sec/batch)\n",
      "2019-03-15 19:03:45.424831: step 100, examples 5000, loss = 0.888632298 (109.899 examples/sec; 0.455 sec/batch)\n",
      "Top 1 validation accuracy: 0.43396225571632385 and top 2 validation accuracy: 0.6839622855186462\n",
      "Model Saved!\n",
      "2019-03-15 19:03:50.816459: step 110, examples 5500, loss = 0.803818643 (122.662 examples/sec; 0.408 sec/batch)\n",
      "2019-03-15 19:03:54.985083: step 120, examples 6000, loss = 0.805733502 (123.074 examples/sec; 0.406 sec/batch)\n",
      "2019-03-15 19:03:59.141886: step 130, examples 6500, loss = 0.796850502 (123.068 examples/sec; 0.406 sec/batch)\n",
      "2019-03-15 19:04:03.284921: step 140, examples 7000, loss = 0.514683843 (122.383 examples/sec; 0.409 sec/batch)\n",
      "2019-03-15 19:04:07.330048: step 150, examples 7500, loss = 0.516468287 (125.869 examples/sec; 0.397 sec/batch)\n",
      "2019-03-15 19:04:11.424666: step 160, examples 8000, loss = 0.384903818 (122.524 examples/sec; 0.408 sec/batch)\n",
      "2019-03-15 19:04:15.502020: step 170, examples 8500, loss = 0.243424013 (126.625 examples/sec; 0.395 sec/batch)\n",
      "2019-03-15 19:04:19.641058: step 180, examples 9000, loss = 0.400598526 (119.410 examples/sec; 0.419 sec/batch)\n",
      "2019-03-15 19:04:23.724822: step 190, examples 9500, loss = 0.310582459 (118.743 examples/sec; 0.421 sec/batch)\n",
      "2019-03-15 19:04:27.899387: step 200, examples 10000, loss = 0.504663765 (125.822 examples/sec; 0.397 sec/batch)\n",
      "Top 1 validation accuracy: 0.5094339847564697 and top 2 validation accuracy: 0.7641509175300598\n",
      "Model Saved!\n",
      "2019-03-15 19:04:33.235786: step 210, examples 10500, loss = 0.153484866 (127.925 examples/sec; 0.391 sec/batch)\n",
      "2019-03-15 19:04:37.359864: step 220, examples 11000, loss = 0.282951564 (120.886 examples/sec; 0.414 sec/batch)\n",
      "2019-03-15 19:04:41.440636: step 230, examples 11500, loss = 0.367227137 (122.305 examples/sec; 0.409 sec/batch)\n",
      "2019-03-15 19:04:45.517667: step 240, examples 12000, loss = 0.229853034 (122.091 examples/sec; 0.410 sec/batch)\n",
      "2019-03-15 19:04:49.625904: step 250, examples 12500, loss = 0.108697630 (122.165 examples/sec; 0.409 sec/batch)\n",
      "2019-03-15 19:04:53.690512: step 260, examples 13000, loss = 0.092284925 (122.615 examples/sec; 0.408 sec/batch)\n",
      "2019-03-15 19:04:57.781700: step 270, examples 13500, loss = 0.089179888 (123.738 examples/sec; 0.404 sec/batch)\n",
      "2019-03-15 19:05:01.844375: step 280, examples 14000, loss = 0.057742216 (124.821 examples/sec; 0.401 sec/batch)\n",
      "2019-03-15 19:05:05.953985: step 290, examples 14500, loss = 0.047177736 (126.642 examples/sec; 0.395 sec/batch)\n",
      "2019-03-15 19:05:10.016800: step 300, examples 15000, loss = 0.019910067 (123.055 examples/sec; 0.406 sec/batch)\n",
      "Top 1 validation accuracy: 0.4811320900917053 and top 2 validation accuracy: 0.7169811129570007\n",
      "Model Saved!\n",
      "2019-03-15 19:05:15.356499: step 310, examples 15500, loss = 0.017023332 (119.445 examples/sec; 0.419 sec/batch)\n",
      "2019-03-15 19:05:19.492371: step 320, examples 16000, loss = 0.013320912 (112.340 examples/sec; 0.445 sec/batch)\n",
      "2019-03-15 19:05:23.688503: step 330, examples 16500, loss = 0.026591290 (125.103 examples/sec; 0.400 sec/batch)\n",
      "2019-03-15 19:05:27.781882: step 340, examples 17000, loss = 0.009607586 (123.718 examples/sec; 0.404 sec/batch)\n",
      "2019-03-15 19:05:31.888919: step 350, examples 17500, loss = 0.015776975 (119.614 examples/sec; 0.418 sec/batch)\n",
      "2019-03-15 19:05:36.001161: step 360, examples 18000, loss = 0.005640442 (114.273 examples/sec; 0.438 sec/batch)\n",
      "2019-03-15 19:05:40.107039: step 370, examples 18500, loss = 0.004194963 (119.473 examples/sec; 0.419 sec/batch)\n",
      "2019-03-15 19:05:44.188457: step 380, examples 19000, loss = 0.005877903 (124.428 examples/sec; 0.402 sec/batch)\n",
      "2019-03-15 19:05:48.319624: step 390, examples 19500, loss = 0.009547004 (122.743 examples/sec; 0.407 sec/batch)\n",
      "2019-03-15 19:05:52.518388: step 400, examples 20000, loss = 0.005742854 (121.855 examples/sec; 0.410 sec/batch)\n",
      "Top 1 validation accuracy: 0.49056604504585266 and top 2 validation accuracy: 0.75\n",
      "Model Saved!\n",
      "2019-03-15 19:05:57.814084: step 410, examples 20500, loss = 0.002957675 (123.768 examples/sec; 0.404 sec/batch)\n",
      "2019-03-15 19:06:01.892622: step 420, examples 21000, loss = 0.001614977 (123.097 examples/sec; 0.406 sec/batch)\n",
      "2019-03-15 19:06:05.969542: step 430, examples 21500, loss = 0.001943679 (123.063 examples/sec; 0.406 sec/batch)\n",
      "2019-03-15 19:06:10.101326: step 440, examples 22000, loss = 0.002371063 (121.418 examples/sec; 0.412 sec/batch)\n",
      "2019-03-15 19:06:14.172798: step 450, examples 22500, loss = 0.001799991 (123.053 examples/sec; 0.406 sec/batch)\n",
      "2019-03-15 19:06:18.362346: step 460, examples 23000, loss = 0.001043304 (122.377 examples/sec; 0.409 sec/batch)\n",
      "2019-03-15 19:06:22.446683: step 470, examples 23500, loss = 0.000731036 (120.498 examples/sec; 0.415 sec/batch)\n",
      "2019-03-15 19:06:26.594252: step 480, examples 24000, loss = 0.000481574 (122.497 examples/sec; 0.408 sec/batch)\n",
      "2019-03-15 19:06:30.672441: step 490, examples 24500, loss = 0.000558571 (123.764 examples/sec; 0.404 sec/batch)\n",
      "2019-03-15 19:06:34.757578: step 500, examples 25000, loss = 0.001257694 (124.021 examples/sec; 0.403 sec/batch)\n",
      "Top 1 validation accuracy: 0.5141509175300598 and top 2 validation accuracy: 0.7641509175300598\n",
      "Model Saved!\n",
      "2019-03-15 19:06:40.254749: step 510, examples 25500, loss = 0.000315268 (113.876 examples/sec; 0.439 sec/batch)\n",
      "2019-03-15 19:06:44.355525: step 520, examples 26000, loss = 0.000556729 (120.926 examples/sec; 0.413 sec/batch)\n",
      "2019-03-15 19:06:48.470651: step 530, examples 26500, loss = 0.001143142 (118.284 examples/sec; 0.423 sec/batch)\n",
      "2019-03-15 19:06:52.541827: step 540, examples 27000, loss = 0.000605491 (120.407 examples/sec; 0.415 sec/batch)\n",
      "2019-03-15 19:06:56.658731: step 550, examples 27500, loss = 0.000656240 (114.012 examples/sec; 0.439 sec/batch)\n",
      "2019-03-15 19:07:00.734681: step 560, examples 28000, loss = 0.000302659 (123.991 examples/sec; 0.403 sec/batch)\n",
      "2019-03-15 19:07:04.797617: step 570, examples 28500, loss = 0.000309790 (123.624 examples/sec; 0.404 sec/batch)\n",
      "2019-03-15 19:07:08.878468: step 580, examples 29000, loss = 0.000442927 (122.629 examples/sec; 0.408 sec/batch)\n",
      "2019-03-15 19:07:13.016770: step 590, examples 29500, loss = 0.000223209 (123.064 examples/sec; 0.406 sec/batch)\n",
      "2019-03-15 19:07:17.096463: step 600, examples 30000, loss = 0.000574379 (122.415 examples/sec; 0.408 sec/batch)\n",
      "Top 1 validation accuracy: 0.5235849022865295 and top 2 validation accuracy: 0.75\n",
      "Model Saved!\n",
      "2019-03-15 19:07:22.393888: step 610, examples 30500, loss = 0.000369129 (122.225 examples/sec; 0.409 sec/batch)\n",
      "2019-03-15 19:07:26.471276: step 620, examples 31000, loss = 0.000311465 (122.579 examples/sec; 0.408 sec/batch)\n",
      "2019-03-15 19:07:30.688349: step 630, examples 31500, loss = 0.000226951 (109.992 examples/sec; 0.455 sec/batch)\n",
      "2019-03-15 19:07:34.751518: step 640, examples 32000, loss = 0.000252721 (126.139 examples/sec; 0.396 sec/batch)\n",
      "2019-03-15 19:07:38.830199: step 650, examples 32500, loss = 0.000203794 (118.836 examples/sec; 0.421 sec/batch)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2019-03-15 19:07:42.909110: step 660, examples 33000, loss = 0.000351356 (122.771 examples/sec; 0.407 sec/batch)\n",
      "2019-03-15 19:07:47.120058: step 670, examples 33500, loss = 0.000244107 (120.223 examples/sec; 0.416 sec/batch)\n",
      "2019-03-15 19:07:51.189097: step 680, examples 34000, loss = 0.000255331 (122.915 examples/sec; 0.407 sec/batch)\n",
      "2019-03-15 19:07:55.251528: step 690, examples 34500, loss = 0.000268399 (122.738 examples/sec; 0.407 sec/batch)\n",
      "2019-03-15 19:07:59.319860: step 700, examples 35000, loss = 0.000209941 (125.823 examples/sec; 0.397 sec/batch)\n",
      "Top 1 validation accuracy: 0.5094339847564697 and top 2 validation accuracy: 0.75\n",
      "Model Saved!\n",
      "2019-03-15 19:08:04.859868: step 710, examples 35500, loss = 0.000192922 (119.184 examples/sec; 0.420 sec/batch)\n",
      "2019-03-15 19:08:09.185992: step 720, examples 36000, loss = 0.000202350 (115.477 examples/sec; 0.433 sec/batch)\n",
      "2019-03-15 19:08:13.426671: step 730, examples 36500, loss = 0.000141824 (113.162 examples/sec; 0.442 sec/batch)\n",
      "2019-03-15 19:08:17.758250: step 740, examples 37000, loss = 0.000260051 (116.712 examples/sec; 0.428 sec/batch)\n",
      "2019-03-15 19:08:22.000913: step 750, examples 37500, loss = 0.000199302 (118.506 examples/sec; 0.422 sec/batch)\n",
      "2019-03-15 19:08:26.262294: step 760, examples 38000, loss = 0.000182666 (115.335 examples/sec; 0.434 sec/batch)\n",
      "2019-03-15 19:08:30.517376: step 770, examples 38500, loss = 0.000182537 (119.057 examples/sec; 0.420 sec/batch)\n",
      "2019-03-15 19:08:34.782578: step 780, examples 39000, loss = 0.000153303 (118.792 examples/sec; 0.421 sec/batch)\n",
      "2019-03-15 19:08:39.016286: step 790, examples 39500, loss = 0.000171604 (118.515 examples/sec; 0.422 sec/batch)\n",
      "2019-03-15 19:08:43.268992: step 800, examples 40000, loss = 0.000165980 (122.124 examples/sec; 0.409 sec/batch)\n",
      "Top 1 validation accuracy: 0.49528300762176514 and top 2 validation accuracy: 0.75\n",
      "Model Saved!\n",
      "2019-03-15 19:08:48.814496: step 810, examples 40500, loss = 0.000160341 (118.662 examples/sec; 0.421 sec/batch)\n",
      "2019-03-15 19:08:53.063371: step 820, examples 41000, loss = 0.000199952 (118.506 examples/sec; 0.422 sec/batch)\n",
      "2019-03-15 19:08:57.288476: step 830, examples 41500, loss = 0.000145014 (119.207 examples/sec; 0.419 sec/batch)\n",
      "2019-03-15 19:09:01.664210: step 840, examples 42000, loss = 0.000143549 (105.287 examples/sec; 0.475 sec/batch)\n",
      "2019-03-15 19:09:06.047115: step 850, examples 42500, loss = 0.000114457 (114.280 examples/sec; 0.438 sec/batch)\n",
      "2019-03-15 19:09:10.643825: step 860, examples 43000, loss = 0.000129981 (103.459 examples/sec; 0.483 sec/batch)\n",
      "2019-03-15 19:09:15.342149: step 870, examples 43500, loss = 0.000177636 (105.525 examples/sec; 0.474 sec/batch)\n",
      "2019-03-15 19:09:19.672543: step 880, examples 44000, loss = 0.000102409 (111.206 examples/sec; 0.450 sec/batch)\n",
      "2019-03-15 19:09:23.945542: step 890, examples 44500, loss = 0.000131958 (117.009 examples/sec; 0.427 sec/batch)\n",
      "2019-03-15 19:09:28.216740: step 900, examples 45000, loss = 0.000082384 (120.708 examples/sec; 0.414 sec/batch)\n",
      "Top 1 validation accuracy: 0.49056604504585266 and top 2 validation accuracy: 0.7452830076217651\n",
      "Model Saved!\n",
      "2019-03-15 19:09:33.783377: step 910, examples 45500, loss = 0.000145004 (118.643 examples/sec; 0.421 sec/batch)\n",
      "2019-03-15 19:09:38.103063: step 920, examples 46000, loss = 0.000093384 (114.919 examples/sec; 0.435 sec/batch)\n",
      "2019-03-15 19:09:42.362516: step 930, examples 46500, loss = 0.000128948 (118.952 examples/sec; 0.420 sec/batch)\n",
      "2019-03-15 19:09:46.656486: step 940, examples 47000, loss = 0.000127919 (115.760 examples/sec; 0.432 sec/batch)\n",
      "2019-03-15 19:09:50.886693: step 950, examples 47500, loss = 0.000119384 (120.262 examples/sec; 0.416 sec/batch)\n",
      "2019-03-15 19:09:55.157557: step 960, examples 48000, loss = 0.000151869 (118.211 examples/sec; 0.423 sec/batch)\n",
      "2019-03-15 19:09:59.393056: step 970, examples 48500, loss = 0.000102291 (122.548 examples/sec; 0.408 sec/batch)\n",
      "2019-03-15 19:10:03.641239: step 980, examples 49000, loss = 0.000139672 (118.673 examples/sec; 0.421 sec/batch)\n",
      "2019-03-15 19:10:08.151687: step 990, examples 49500, loss = 0.000131985 (104.543 examples/sec; 0.478 sec/batch)\n",
      "Top 1 validation accuracy: 0.49056604504585266 and top 2 validation accuracy: 0.7452830076217651\n",
      "Model Saved!\n"
     ]
    }
   ],
   "source": [
    "# First train the network without any regularization like batch norm, dropout and L2 loss\n",
    "NUM_CLASS = 4\n",
    "MAX_STEP = 1000\n",
    "LOG_FREQUENCY = 10\n",
    "BATCH_SIZE = 50\n",
    "MODEL_SAVING_FREQUENCY = 100\n",
    "TARGET_DIR = './trained_model_final/DCNN'\n",
    "\n",
    "def data_loader():\n",
    "    X_test = np.load(\"X_test.npy\")\n",
    "    X_test = X_test[:,0:22,:]\n",
    "    y_test = np.load(\"y_test.npy\")\n",
    "    person_test = np.load(\"person_test.npy\")\n",
    "\n",
    "    X_train_valid = np.load(\"X_train_valid.npy\")\n",
    "    X_train_valid = X_train_valid[:,0:22,:]\n",
    "    y_train_valid = np.load(\"y_train_valid.npy\")\n",
    "    person_train_valid = np.load(\"person_train_valid.npy\")\n",
    "    N_train = X_train_valid.shape[0]\n",
    "    idx_train_valid = np.arange(N_train,dtype='int')\n",
    "\n",
    "    X_train, X_val, idx_train, idx_val = train_test_split(X_train_valid, idx_train_valid, test_size=0.1, random_state=21)\n",
    "\n",
    "    y_train = y_train_valid[idx_train]\n",
    "    person_train = person_train_valid[idx_train]\n",
    "    y_val = y_train_valid[idx_val]\n",
    "    person_val = person_train_valid[idx_val]\n",
    "\n",
    "    tl = X_train.shape[2]\n",
    "    X_test = np.reshape(X_test,(-1,22,tl,1))\n",
    "    X_train = np.reshape(X_train,(-1,22,tl,1))\n",
    "    X_val = np.reshape(X_val,(-1,22,tl,1))\n",
    "\n",
    "    label0 = 769\n",
    "    new_label0 = 0\n",
    "    for i in range(4):\n",
    "        m1 = (y_test==label0)\n",
    "        m2 = (y_train==label0)\n",
    "        m3 = (y_val==label0)\n",
    "        np.place(y_test,m1,new_label0)\n",
    "        np.place(y_train,m2,new_label0)\n",
    "        np.place(y_val,m3,new_label0)\n",
    "        label0 += 1\n",
    "        new_label0 += 1\n",
    "\n",
    "    labelNames = [0,1,2,3]\n",
    "    train_set = {'data': X_train, 'labels': y_train, 'person': person_train}\n",
    "    test_set = {'data': X_test, 'labels': y_test, 'person': person_test}\n",
    "    val_set = {'data': X_val, 'labels': y_val, 'person': person_val}\n",
    "    return train_set, test_set, val_set, labelNames\n",
    "\n",
    "\n",
    "def sample_batch(dataset, batch_size):\n",
    "    N = dataset['data'].shape[0]\n",
    "    indices = np.random.randint(N, size=batch_size)\n",
    "    return {key: dataset[key][indices] for key in dataset}\n",
    "\n",
    "\n",
    "def main():\n",
    "    # load data\n",
    "    print(\"Loading datasets...\")\n",
    "    trainSet, testSet, valSet, labelNames = data_loader()\n",
    "    print(\"Dataset loading completes.\")\n",
    "\n",
    "    # reset default graph\n",
    "    tf.reset_default_graph()\n",
    "\n",
    "    global_step = tf.train.get_or_create_global_step()\n",
    "    \n",
    "    start = 0\n",
    "    stop = 1000\n",
    "    step = 100\n",
    "    time_length = 1000\n",
    "    #Nb = BATCH_SIZE\n",
    "    fsz = 10\n",
    "    \n",
    "    model = Model(config, labelNames,start,stop,step,time_length,fsz,False,False,False)\n",
    "\n",
    "    # training setups\n",
    "    saver = tf.train.Saver(max_to_keep=100)\n",
    "\n",
    "    # Build an initialization operation to run below.\n",
    "    init = tf.global_variables_initializer()\n",
    "    \n",
    "    config_proto = tf.ConfigProto()\n",
    "\n",
    "    off = rewriter_config_pb2.RewriterConfig.OFF\n",
    "    config_proto.graph_options.rewrite_options.arithmetic_optimization = off\n",
    "    \n",
    "    sess = tf.Session(config=config_proto)\n",
    "\n",
    "    sess.run(init)\n",
    "\n",
    "    # main loop\n",
    "    for step in range(MAX_STEP):\n",
    "        start_time = time.time()\n",
    "\n",
    "        # prepare data\n",
    "        train_batch = sample_batch(trainSet, BATCH_SIZE)\n",
    "        # feed dict\n",
    "        feed_dict = {\n",
    "            model.input: train_batch['data'],\n",
    "            model.fine_labels: train_batch['labels'],\n",
    "            model.is_training: True,\n",
    "        }\n",
    "        \n",
    "        fetch_list = [model.optimizer_op, model.loss, model.global_step]\n",
    "        _, loss_value, global_step_value = sess.run(fetch_list, feed_dict=feed_dict)\n",
    "        duration = time.time() - start_time\n",
    "        assert not np.isnan(loss_value), 'Model diverged with loss = NaN'\n",
    "\n",
    "        # log\n",
    "        if step % LOG_FREQUENCY == 0:\n",
    "            num_examples_per_step = BATCH_SIZE\n",
    "            examples_per_sec = num_examples_per_step / duration\n",
    "            sec_per_batch = duration\n",
    "            format_str = (\n",
    "                '%s: step %d, examples %d, loss = %.9f (%.3f examples/sec; %.3f sec/batch)'\n",
    "            )\n",
    "            print(\n",
    "                format_str % (\n",
    "                    datetime.now(), step, BATCH_SIZE * step,\n",
    "                    loss_value,\n",
    "                    examples_per_sec, sec_per_batch\n",
    "                )\n",
    "            )\n",
    "\n",
    "        # Save the model checkpoint periodically.\n",
    "        if step % MODEL_SAVING_FREQUENCY == 0 or (step + 1) == MAX_STEP:\n",
    "            fetch_list = [model.accuracy,model.top_2_accuracy]\n",
    "            feed_dict = {\n",
    "                model.input: valSet['data'],\n",
    "                model.fine_labels: valSet['labels'],\n",
    "                model.is_training: False,\n",
    "            }\n",
    "            val_acc_1, val_acc_2 =  sess.run(fetch_list, feed_dict=feed_dict)\n",
    "            checkpoint_path = os.path.join(TARGET_DIR, 'model.ckpt')\n",
    "            saver.save(sess, checkpoint_path, global_step=int(global_step_value))\n",
    "            print('Top 1 validation accuracy: {} and top 2 validation accuracy: {}'.format(val_acc_1,val_acc_2))\n",
    "            print('Model Saved!')\n",
    "\n",
    "\n",
    "if __name__ == '__main__':\n",
    "    main()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "#best model is 601\n",
    "\n",
    "def test_model(model_dir,start,stop,step,time_length,fsz,use_batchnorm,use_dropout,use_l2loss):\n",
    "    print(\"Loading datasets...\")\n",
    "    trainSet, testSet, valSet, labelNames = data_loader()\n",
    "    print(\"Dataset loading completes.\")\n",
    "    \n",
    "    # reset default graph\n",
    "    tf.reset_default_graph()\n",
    "    \n",
    "    # create model\n",
    "    \n",
    "    model = Model(config, labelNames,start,stop,step,time_length,fsz,use_batchnorm,use_dropout,use_l2loss)\n",
    "    # training setups\n",
    "    saver = tf.train.Saver(max_to_keep=100)\n",
    "    test_accuracy = [0, 0]\n",
    "    \n",
    "    config_proto = tf.ConfigProto()\n",
    "\n",
    "    off = rewriter_config_pb2.RewriterConfig.OFF\n",
    "    config_proto.graph_options.rewrite_options.arithmetic_optimization = off\n",
    "\n",
    "    with tf.Session(config=config_proto) as session:\n",
    "        session.run(tf.global_variables_initializer())\n",
    "        saver.restore(session, model_dir)\n",
    "        # test model\n",
    "        exp_results = run_single_step(session, model, testSet, mode='test')\n",
    "        test_accuracy[0] = exp_results['top_1_accuracy']\n",
    "        test_accuracy[1] = exp_results['top_2_accuracy']\n",
    "        print('top_1_accuracy_test = ', test_accuracy[0], 'top_2_accuracy_test = ', test_accuracy[1])\n",
    "        \n",
    "    top1_acc = test_accuracy[0]\n",
    "    top2_acc = test_accuracy[1]\n",
    "    return top1_acc,top2_acc\n",
    "\n",
    "\n",
    "def run_single_step(\n",
    "        session,\n",
    "        model,\n",
    "        batch,\n",
    "        mode='test',\n",
    "        log=True,\n",
    "):\n",
    "    # construct feed dict\n",
    "    feed_dict = {\n",
    "        model.input: batch['data'],\n",
    "        # model.coarse_labels: batch['coarse_labels'],\n",
    "        model.fine_labels: batch['labels'],\n",
    "        # model.label_mapping: label_mapping,\n",
    "        model.is_training: mode == 'train'\n",
    "    }\n",
    "    \n",
    "    # select proper summary op\n",
    "    if mode == 'train':\n",
    "        summary_op = model.train_summary_op\n",
    "    elif mode == 'val':\n",
    "        summary_op = model.val_summary_op\n",
    "    else:\n",
    "        summary_op = model.test_summary_op\n",
    "    \n",
    "    # construct fetch list\n",
    "    fetch_list = [model.global_step, summary_op, model.loss, model.accuracy, model.top_2_accuracy]\n",
    "\n",
    "    # run single step\n",
    "    _start_time = time.time()\n",
    "    _step, _summary, _loss, _top_1, _top_2 = session.run(fetch_list, feed_dict=feed_dict)[:5]\n",
    "    _end_time = time.time()\n",
    "    \n",
    "    # collect step statistics\n",
    "    step_time = _end_time - _start_time\n",
    "    batch_size = batch['data'].shape[0]\n",
    "    \n",
    "    # log in console\n",
    "    if log:\n",
    "        print(('[{:5s} step {:4d}] loss: {:.5f}; top_1_accuracy: {:.5f}; top_5_accuracy: {:5f} ' +\n",
    "              '({:.3f} sec/batch; {:.3f} instances/sec)'\n",
    "              ).format(mode, _step, _loss, _top_1, _top_2, \n",
    "                       step_time, batch_size / step_time))\n",
    "    \n",
    "    # log results to file and return statistics\n",
    "    if mode == 'test':\n",
    "        test_fetch_list = [model.per_class_accuracy,\n",
    "                model.top_2_per_class_accuracy,\n",
    "                model.confusion_matrix, \n",
    "                model.pred, model.probs]\n",
    "        _top_1_c,  _top_2_c, _cm, _pred, _probs = \\\n",
    "                session.run(test_fetch_list, feed_dict=feed_dict)\n",
    "        \n",
    "        \n",
    "        # Log detailed test results in pickle format\n",
    "        stats = {\n",
    "            \"loss\": _loss,\n",
    "            \"top_1_accuracy\": _top_1,\n",
    "            \"top_2_accuracy\": _top_2,\n",
    "            \"top_1_perclass_accuracy\": _top_1_c,\n",
    "            \"top_2_perclass_accuracy\": _top_2_c,\n",
    "            \"confusion_matrix\": _cm,\n",
    "            \"pred\": _pred,\n",
    "            \"probs\": _probs\n",
    "        }\n",
    "    else:\n",
    "        stats = {\n",
    "            \"step\": _step,\n",
    "            \"loss\": _loss,\n",
    "            \"top_1_accuracy\": _top_1,\n",
    "            \"top_2_accuracy\": _top_2\n",
    "        }\n",
    "        \n",
    "    return stats"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading datasets...\n",
      "Dataset loading completes.\n",
      "INFO:tensorflow:Restoring parameters from ./trained_model_final/DCNN/model.ckpt-601\n",
      "[test  step  601] loss: 2.56059; top_1_accuracy: 0.50339; top_5_accuracy: 0.742664 (1.309 sec/batch; 338.319 instances/sec)\n",
      "top_1_accuracy_test =  0.503386 top_2_accuracy_test =  0.7426637\n"
     ]
    }
   ],
   "source": [
    "# Accuracy for testSet 601\n",
    "model_dir = \"./trained_model_final/DCNN/model.ckpt-601\"\n",
    "start = 0\n",
    "stop = 1000\n",
    "step = 100\n",
    "time_length = 1000\n",
    "#Nb = BATCH_SIZE\n",
    "fsz = 10\n",
    "use_batchnorm = False\n",
    "use_dropout = False\n",
    "use_l2loss = False\n",
    "top_1_acc_org, top_2_acc_org = test_model(model_dir,start,stop,step,time_length,fsz,use_batchnorm,use_dropout,use_l2loss)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Now train the network with regularization like batch norm, dropout and L2 loss\n",
    "\n",
    "def train_model(target_dir,start,stop,step,time_length,fsz,use_batchnorm,use_dropout,use_l2loss,num_class,max_step,log_frequency,batch_size,model_saving_freq):\n",
    "    # load data\n",
    "    print(\"Loading datasets...\")\n",
    "    trainSet, testSet, valSet, labelNames = data_loader()\n",
    "    print(\"Dataset loading completes.\")\n",
    "\n",
    "    # reset default graph\n",
    "    tf.reset_default_graph()\n",
    "\n",
    "    global_step = tf.train.get_or_create_global_step()\n",
    "    \n",
    "    model = Model(config, labelNames,start,stop,step,time_length,fsz,use_batchnorm,use_dropout,use_l2loss)\n",
    "\n",
    "    # training setups\n",
    "    saver = tf.train.Saver(max_to_keep=100)\n",
    "\n",
    "    # Build an initialization operation to run below.\n",
    "    init = tf.global_variables_initializer()\n",
    "    \n",
    "    config_proto = tf.ConfigProto()\n",
    "\n",
    "    off = rewriter_config_pb2.RewriterConfig.OFF\n",
    "    config_proto.graph_options.rewrite_options.arithmetic_optimization = off\n",
    "    \n",
    "    sess = tf.Session(config=config_proto)\n",
    "\n",
    "    sess.run(init)\n",
    "\n",
    "    # main loop\n",
    "    for step in range(max_step):\n",
    "        start_time = time.time()\n",
    "\n",
    "        # prepare data\n",
    "        train_batch = sample_batch(trainSet, batch_size)\n",
    "        # feed dict\n",
    "        feed_dict = {\n",
    "            model.input: train_batch['data'],\n",
    "            model.fine_labels: train_batch['labels'],\n",
    "            model.is_training: True,\n",
    "        }\n",
    "        \n",
    "        fetch_list = [model.optimizer_op, model.loss, model.global_step]\n",
    "        _, loss_value, global_step_value = sess.run(fetch_list, feed_dict=feed_dict)\n",
    "        duration = time.time() - start_time\n",
    "        assert not np.isnan(loss_value), 'Model diverged with loss = NaN'\n",
    "\n",
    "        # log\n",
    "        if step % log_frequency == 0:\n",
    "            num_examples_per_step = batch_size\n",
    "            examples_per_sec = num_examples_per_step / duration\n",
    "            sec_per_batch = duration\n",
    "            format_str = (\n",
    "                '%s: step %d, examples %d, loss = %.9f (%.3f examples/sec; %.3f sec/batch)'\n",
    "            )\n",
    "            print(\n",
    "                format_str % (\n",
    "                    datetime.now(), step, batch_size * step,\n",
    "                    loss_value,\n",
    "                    examples_per_sec, sec_per_batch\n",
    "                )\n",
    "            )\n",
    "\n",
    "        # Save the model checkpoint periodically.\n",
    "        if step % model_saving_freq == 0 or (step + 1) == max_step:\n",
    "            fetch_list = [model.accuracy,model.top_2_accuracy]\n",
    "            feed_dict = {\n",
    "                model.input: valSet['data'],\n",
    "                model.fine_labels: valSet['labels'],\n",
    "                model.is_training: False,\n",
    "            }\n",
    "            val_acc_1, val_acc_2 =  sess.run(fetch_list, feed_dict=feed_dict)\n",
    "            checkpoint_path = os.path.join(target_dir, 'model.ckpt')\n",
    "            saver.save(sess, checkpoint_path, global_step=int(global_step_value))\n",
    "            print('Top 1 validation accuracy: {} and top 2 validation accuracy: {}'.format(val_acc_1,val_acc_2))\n",
    "            print('Model Saved!')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading datasets...\n",
      "Dataset loading completes.\n",
      "2019-03-15 19:36:07.429616: step 0, examples 0, loss = 1.481527090 (54.813 examples/sec; 0.912 sec/batch)\n",
      "Top 1 validation accuracy: 0.25471699237823486 and top 2 validation accuracy: 0.5235849022865295\n",
      "Model Saved!\n",
      "2019-03-15 19:36:15.043898: step 10, examples 500, loss = 1.477544785 (85.081 examples/sec; 0.588 sec/batch)\n",
      "2019-03-15 19:36:20.684522: step 20, examples 1000, loss = 1.462527990 (89.579 examples/sec; 0.558 sec/batch)\n",
      "2019-03-15 19:36:26.170413: step 30, examples 1500, loss = 1.493336678 (89.194 examples/sec; 0.561 sec/batch)\n",
      "2019-03-15 19:36:31.706731: step 40, examples 2000, loss = 1.439875841 (91.459 examples/sec; 0.547 sec/batch)\n",
      "2019-03-15 19:36:37.218895: step 50, examples 2500, loss = 1.430225611 (87.385 examples/sec; 0.572 sec/batch)\n",
      "2019-03-15 19:36:42.769315: step 60, examples 3000, loss = 1.317382336 (88.507 examples/sec; 0.565 sec/batch)\n",
      "2019-03-15 19:36:48.289031: step 70, examples 3500, loss = 1.422132969 (86.902 examples/sec; 0.575 sec/batch)\n",
      "2019-03-15 19:36:53.940854: step 80, examples 4000, loss = 1.438593864 (81.693 examples/sec; 0.612 sec/batch)\n",
      "2019-03-15 19:36:59.546487: step 90, examples 4500, loss = 1.272730827 (80.034 examples/sec; 0.625 sec/batch)\n",
      "2019-03-15 19:37:05.225687: step 100, examples 5000, loss = 1.320084095 (90.194 examples/sec; 0.554 sec/batch)\n",
      "Top 1 validation accuracy: 0.4150943458080292 and top 2 validation accuracy: 0.6650943160057068\n",
      "Model Saved!\n",
      "2019-03-15 19:37:13.244560: step 110, examples 5500, loss = 1.311977148 (76.898 examples/sec; 0.650 sec/batch)\n",
      "2019-03-15 19:37:19.048339: step 120, examples 6000, loss = 1.522525430 (86.648 examples/sec; 0.577 sec/batch)\n",
      "2019-03-15 19:37:24.916448: step 130, examples 6500, loss = 1.294333696 (87.486 examples/sec; 0.572 sec/batch)\n",
      "2019-03-15 19:37:30.608584: step 140, examples 7000, loss = 1.399281144 (82.561 examples/sec; 0.606 sec/batch)\n",
      "2019-03-15 19:37:37.124096: step 150, examples 7500, loss = 1.304385781 (61.187 examples/sec; 0.817 sec/batch)\n",
      "2019-03-15 19:37:44.553318: step 160, examples 8000, loss = 1.201700449 (85.320 examples/sec; 0.586 sec/batch)\n",
      "2019-03-15 19:37:50.766598: step 170, examples 8500, loss = 1.190568805 (89.827 examples/sec; 0.557 sec/batch)\n",
      "2019-03-15 19:37:56.463020: step 180, examples 9000, loss = 1.383886099 (90.794 examples/sec; 0.551 sec/batch)\n",
      "2019-03-15 19:38:02.528355: step 190, examples 9500, loss = 1.322177172 (87.477 examples/sec; 0.572 sec/batch)\n",
      "2019-03-15 19:38:08.733555: step 200, examples 10000, loss = 1.171877384 (64.939 examples/sec; 0.770 sec/batch)\n",
      "Top 1 validation accuracy: 0.5377358198165894 and top 2 validation accuracy: 0.7452830076217651\n",
      "Model Saved!\n",
      "2019-03-15 19:38:16.768493: step 210, examples 10500, loss = 1.064245462 (88.728 examples/sec; 0.564 sec/batch)\n",
      "2019-03-15 19:38:22.408909: step 220, examples 11000, loss = 1.200673819 (91.024 examples/sec; 0.549 sec/batch)\n",
      "2019-03-15 19:38:28.141547: step 230, examples 11500, loss = 1.015813828 (91.422 examples/sec; 0.547 sec/batch)\n",
      "2019-03-15 19:38:33.845895: step 240, examples 12000, loss = 0.989004076 (91.369 examples/sec; 0.547 sec/batch)\n",
      "2019-03-15 19:38:39.803339: step 250, examples 12500, loss = 0.987134278 (83.996 examples/sec; 0.595 sec/batch)\n",
      "2019-03-15 19:38:46.235959: step 260, examples 13000, loss = 0.895497143 (90.013 examples/sec; 0.555 sec/batch)\n",
      "2019-03-15 19:38:52.100556: step 270, examples 13500, loss = 1.138566017 (88.573 examples/sec; 0.565 sec/batch)\n",
      "2019-03-15 19:38:58.099386: step 280, examples 14000, loss = 1.097148895 (82.174 examples/sec; 0.608 sec/batch)\n",
      "2019-03-15 19:39:04.077288: step 290, examples 14500, loss = 1.101477742 (89.859 examples/sec; 0.556 sec/batch)\n",
      "2019-03-15 19:39:09.753883: step 300, examples 15000, loss = 1.154088020 (90.579 examples/sec; 0.552 sec/batch)\n",
      "Top 1 validation accuracy: 0.5235849022865295 and top 2 validation accuracy: 0.7547169923782349\n",
      "Model Saved!\n",
      "2019-03-15 19:39:17.320036: step 310, examples 15500, loss = 1.217301488 (93.978 examples/sec; 0.532 sec/batch)\n",
      "2019-03-15 19:39:23.022835: step 320, examples 16000, loss = 0.876946032 (90.684 examples/sec; 0.551 sec/batch)\n",
      "2019-03-15 19:39:28.680118: step 330, examples 16500, loss = 1.079560041 (85.776 examples/sec; 0.583 sec/batch)\n",
      "2019-03-15 19:39:34.322000: step 340, examples 17000, loss = 1.203710318 (91.533 examples/sec; 0.546 sec/batch)\n",
      "2019-03-15 19:39:40.001320: step 350, examples 17500, loss = 0.894211471 (90.303 examples/sec; 0.554 sec/batch)\n",
      "2019-03-15 19:39:45.765880: step 360, examples 18000, loss = 0.777244091 (87.358 examples/sec; 0.572 sec/batch)\n",
      "2019-03-15 19:39:51.750307: step 370, examples 18500, loss = 0.953322113 (83.876 examples/sec; 0.596 sec/batch)\n",
      "2019-03-15 19:39:57.688959: step 380, examples 19000, loss = 0.795476556 (89.231 examples/sec; 0.560 sec/batch)\n",
      "2019-03-15 19:40:03.448915: step 390, examples 19500, loss = 0.782192409 (83.149 examples/sec; 0.601 sec/batch)\n",
      "2019-03-15 19:40:09.048143: step 400, examples 20000, loss = 0.818689585 (91.776 examples/sec; 0.545 sec/batch)\n",
      "Top 1 validation accuracy: 0.4858490526676178 and top 2 validation accuracy: 0.7311320900917053\n",
      "Model Saved!\n",
      "2019-03-15 19:40:16.667914: step 410, examples 20500, loss = 0.759071350 (89.240 examples/sec; 0.560 sec/batch)\n",
      "2019-03-15 19:40:22.319836: step 420, examples 21000, loss = 0.600093365 (91.485 examples/sec; 0.547 sec/batch)\n",
      "2019-03-15 19:40:27.985645: step 430, examples 21500, loss = 0.851292372 (92.117 examples/sec; 0.543 sec/batch)\n",
      "2019-03-15 19:40:33.669801: step 440, examples 22000, loss = 0.784362912 (88.994 examples/sec; 0.562 sec/batch)\n",
      "2019-03-15 19:40:39.378065: step 450, examples 22500, loss = 0.656909406 (84.931 examples/sec; 0.589 sec/batch)\n",
      "2019-03-15 19:40:45.013767: step 460, examples 23000, loss = 0.816480100 (89.883 examples/sec; 0.556 sec/batch)\n",
      "2019-03-15 19:40:50.675291: step 470, examples 23500, loss = 0.817798018 (87.674 examples/sec; 0.570 sec/batch)\n",
      "2019-03-15 19:40:56.286309: step 480, examples 24000, loss = 0.801528811 (93.419 examples/sec; 0.535 sec/batch)\n",
      "2019-03-15 19:41:01.902612: step 490, examples 24500, loss = 0.623065293 (85.756 examples/sec; 0.583 sec/batch)\n",
      "2019-03-15 19:41:07.713018: step 500, examples 25000, loss = 0.822169602 (91.079 examples/sec; 0.549 sec/batch)\n",
      "Top 1 validation accuracy: 0.551886796951294 and top 2 validation accuracy: 0.7547169923782349\n",
      "Model Saved!\n",
      "2019-03-15 19:41:15.094087: step 510, examples 25500, loss = 0.998826742 (87.374 examples/sec; 0.572 sec/batch)\n",
      "2019-03-15 19:41:20.765551: step 520, examples 26000, loss = 0.943828523 (81.910 examples/sec; 0.610 sec/batch)\n",
      "2019-03-15 19:41:26.414880: step 530, examples 26500, loss = 0.755379438 (88.621 examples/sec; 0.564 sec/batch)\n",
      "2019-03-15 19:41:32.065496: step 540, examples 27000, loss = 0.695829690 (86.519 examples/sec; 0.578 sec/batch)\n",
      "2019-03-15 19:41:37.723431: step 550, examples 27500, loss = 0.635981858 (87.833 examples/sec; 0.569 sec/batch)\n",
      "2019-03-15 19:41:43.452250: step 560, examples 28000, loss = 0.617226601 (79.087 examples/sec; 0.632 sec/batch)\n",
      "2019-03-15 19:41:49.027113: step 570, examples 28500, loss = 0.841079772 (90.018 examples/sec; 0.555 sec/batch)\n",
      "2019-03-15 19:41:54.768358: step 580, examples 29000, loss = 0.666246057 (88.752 examples/sec; 0.563 sec/batch)\n",
      "2019-03-15 19:42:00.362695: step 590, examples 29500, loss = 0.545693278 (92.071 examples/sec; 0.543 sec/batch)\n",
      "2019-03-15 19:42:05.931893: step 600, examples 30000, loss = 0.664334416 (88.581 examples/sec; 0.564 sec/batch)\n",
      "Top 1 validation accuracy: 0.5424528121948242 and top 2 validation accuracy: 0.7735849022865295\n",
      "Model Saved!\n",
      "2019-03-15 19:42:13.705048: step 610, examples 30500, loss = 0.716468930 (83.802 examples/sec; 0.597 sec/batch)\n",
      "2019-03-15 19:42:19.663377: step 620, examples 31000, loss = 0.517258704 (83.376 examples/sec; 0.600 sec/batch)\n",
      "2019-03-15 19:42:25.640942: step 630, examples 31500, loss = 0.570534706 (83.282 examples/sec; 0.600 sec/batch)\n",
      "2019-03-15 19:42:31.535952: step 640, examples 32000, loss = 0.638679743 (82.248 examples/sec; 0.608 sec/batch)\n",
      "2019-03-15 19:42:37.365752: step 650, examples 32500, loss = 0.618216574 (86.728 examples/sec; 0.577 sec/batch)\n",
      "2019-03-15 19:42:43.305697: step 660, examples 33000, loss = 0.602765322 (85.175 examples/sec; 0.587 sec/batch)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2019-03-15 19:42:49.202727: step 670, examples 33500, loss = 0.805280328 (86.687 examples/sec; 0.577 sec/batch)\n",
      "2019-03-15 19:42:55.064397: step 680, examples 34000, loss = 0.844516695 (84.299 examples/sec; 0.593 sec/batch)\n",
      "2019-03-15 19:43:01.042173: step 690, examples 34500, loss = 0.708914340 (84.777 examples/sec; 0.590 sec/batch)\n",
      "2019-03-15 19:43:06.877369: step 700, examples 35000, loss = 0.760557890 (86.675 examples/sec; 0.577 sec/batch)\n",
      "Top 1 validation accuracy: 0.5801886916160583 and top 2 validation accuracy: 0.7877358198165894\n",
      "Model Saved!\n",
      "2019-03-15 19:43:14.703428: step 710, examples 35500, loss = 0.615862072 (83.993 examples/sec; 0.595 sec/batch)\n",
      "2019-03-15 19:43:20.578438: step 720, examples 36000, loss = 0.644081771 (84.260 examples/sec; 0.593 sec/batch)\n",
      "2019-03-15 19:43:26.473737: step 730, examples 36500, loss = 0.639435589 (83.843 examples/sec; 0.596 sec/batch)\n",
      "2019-03-15 19:43:32.324773: step 740, examples 37000, loss = 0.626901567 (88.301 examples/sec; 0.566 sec/batch)\n",
      "2019-03-15 19:43:38.193840: step 750, examples 37500, loss = 0.685872436 (84.814 examples/sec; 0.590 sec/batch)\n",
      "2019-03-15 19:43:44.181810: step 760, examples 38000, loss = 0.483463675 (79.105 examples/sec; 0.632 sec/batch)\n",
      "2019-03-15 19:43:49.987591: step 770, examples 38500, loss = 0.771955907 (89.641 examples/sec; 0.558 sec/batch)\n",
      "2019-03-15 19:43:55.832513: step 780, examples 39000, loss = 0.407058895 (81.222 examples/sec; 0.616 sec/batch)\n",
      "2019-03-15 19:44:01.777474: step 790, examples 39500, loss = 0.571024954 (76.813 examples/sec; 0.651 sec/batch)\n",
      "2019-03-15 19:44:07.735531: step 800, examples 40000, loss = 0.602878928 (84.239 examples/sec; 0.594 sec/batch)\n",
      "Top 1 validation accuracy: 0.5707547068595886 and top 2 validation accuracy: 0.801886796951294\n",
      "Model Saved!\n",
      "2019-03-15 19:44:15.729595: step 810, examples 40500, loss = 0.357745171 (80.427 examples/sec; 0.622 sec/batch)\n",
      "2019-03-15 19:44:21.724386: step 820, examples 41000, loss = 0.382725209 (85.354 examples/sec; 0.586 sec/batch)\n",
      "2019-03-15 19:44:27.641023: step 830, examples 41500, loss = 0.444621086 (89.099 examples/sec; 0.561 sec/batch)\n",
      "2019-03-15 19:44:33.646594: step 840, examples 42000, loss = 0.522026539 (86.557 examples/sec; 0.578 sec/batch)\n",
      "2019-03-15 19:44:40.294441: step 850, examples 42500, loss = 0.754013598 (67.297 examples/sec; 0.743 sec/batch)\n",
      "2019-03-15 19:44:47.432422: step 860, examples 43000, loss = 0.342482865 (71.648 examples/sec; 0.698 sec/batch)\n",
      "2019-03-15 19:44:54.018937: step 870, examples 43500, loss = 0.602490544 (83.529 examples/sec; 0.599 sec/batch)\n",
      "2019-03-15 19:44:59.936672: step 880, examples 44000, loss = 0.520555913 (84.377 examples/sec; 0.593 sec/batch)\n",
      "2019-03-15 19:45:05.952701: step 890, examples 44500, loss = 0.612472534 (83.950 examples/sec; 0.596 sec/batch)\n",
      "2019-03-15 19:45:11.908507: step 900, examples 45000, loss = 0.476154953 (82.289 examples/sec; 0.608 sec/batch)\n",
      "Top 1 validation accuracy: 0.5047169923782349 and top 2 validation accuracy: 0.7688679099082947\n",
      "Model Saved!\n",
      "2019-03-15 19:45:20.061185: step 910, examples 45500, loss = 0.690677404 (77.796 examples/sec; 0.643 sec/batch)\n",
      "2019-03-15 19:45:26.247829: step 920, examples 46000, loss = 0.585820556 (80.296 examples/sec; 0.623 sec/batch)\n",
      "2019-03-15 19:45:32.486394: step 930, examples 46500, loss = 0.437408656 (81.312 examples/sec; 0.615 sec/batch)\n",
      "2019-03-15 19:45:38.486291: step 940, examples 47000, loss = 0.536178887 (87.390 examples/sec; 0.572 sec/batch)\n",
      "2019-03-15 19:45:44.377804: step 950, examples 47500, loss = 0.756139517 (81.801 examples/sec; 0.611 sec/batch)\n",
      "2019-03-15 19:45:50.235669: step 960, examples 48000, loss = 0.637648582 (86.428 examples/sec; 0.579 sec/batch)\n",
      "2019-03-15 19:45:56.253663: step 970, examples 48500, loss = 0.435884535 (85.267 examples/sec; 0.586 sec/batch)\n",
      "2019-03-15 19:46:02.157696: step 980, examples 49000, loss = 0.563950777 (84.055 examples/sec; 0.595 sec/batch)\n",
      "2019-03-15 19:46:08.395298: step 990, examples 49500, loss = 0.485944331 (81.544 examples/sec; 0.613 sec/batch)\n",
      "Top 1 validation accuracy: 0.5283018946647644 and top 2 validation accuracy: 0.8396226167678833\n",
      "Model Saved!\n"
     ]
    }
   ],
   "source": [
    "num_cls = 4\n",
    "mstp = 1000\n",
    "lfrq = 10\n",
    "bsz = 50\n",
    "msf = 100\n",
    "tr = './trained_model_final/DCNN_reg'\n",
    "start = 0\n",
    "stop = 1000\n",
    "step = 100\n",
    "time_length = 1000\n",
    "#Nb = BATCH_SIZE\n",
    "fsz = 10\n",
    "use_batchnorm = True\n",
    "use_dropout = True\n",
    "use_l2loss = True\n",
    "\n",
    "train_model(tr,start,stop,step,time_length,fsz,use_batchnorm,use_dropout,use_l2loss,num_cls,mstp,lfrq,bsz,msf)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading datasets...\n",
      "Dataset loading completes.\n",
      "INFO:tensorflow:Restoring parameters from ./trained_model_final/DCNN_reg/model.ckpt-701\n",
      "[test  step  701] loss: 1.49420; top_1_accuracy: 0.56433; top_5_accuracy: 0.821670 (1.523 sec/batch; 290.838 instances/sec)\n",
      "top_1_accuracy_test =  0.5643341 top_2_accuracy_test =  0.8216704\n"
     ]
    }
   ],
   "source": [
    "# Accuracy for testSet 701 (best)\n",
    "model_dir = \"./trained_model_final/DCNN_reg/model.ckpt-701\"\n",
    "start = 0\n",
    "stop = 1000\n",
    "step = 100\n",
    "time_length = 1000\n",
    "#Nb = BATCH_SIZE\n",
    "fsz = 10\n",
    "use_batchnorm = True\n",
    "use_dropout = True\n",
    "use_l2loss = True\n",
    "top_1_acc_org, top_2_acc_org = test_model(model_dir,start,stop,step,time_length,fsz,use_batchnorm,use_dropout,use_l2loss)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading datasets...\n",
      "Dataset loading completes.\n",
      "2019-03-15 19:51:37.806159: step 0, examples 0, loss = 1.487277269 (78.597 examples/sec; 0.636 sec/batch)\n",
      "Top 1 validation accuracy: 0.21226415038108826 and top 2 validation accuracy: 0.49528300762176514\n",
      "Model Saved!\n",
      "2019-03-15 19:51:43.366185: step 10, examples 500, loss = 1.483107328 (113.203 examples/sec; 0.442 sec/batch)\n",
      "2019-03-15 19:51:47.489193: step 20, examples 1000, loss = 1.461261034 (120.840 examples/sec; 0.414 sec/batch)\n",
      "2019-03-15 19:51:51.564133: step 30, examples 1500, loss = 1.452936292 (122.075 examples/sec; 0.410 sec/batch)\n",
      "2019-03-15 19:51:55.659489: step 40, examples 2000, loss = 1.500891209 (117.816 examples/sec; 0.424 sec/batch)\n",
      "2019-03-15 19:51:59.791915: step 50, examples 2500, loss = 1.391779542 (118.295 examples/sec; 0.423 sec/batch)\n",
      "2019-03-15 19:52:03.904646: step 60, examples 3000, loss = 1.565071821 (124.353 examples/sec; 0.402 sec/batch)\n",
      "2019-03-15 19:52:08.000272: step 70, examples 3500, loss = 1.323044777 (118.567 examples/sec; 0.422 sec/batch)\n",
      "2019-03-15 19:52:12.116179: step 80, examples 4000, loss = 1.472566724 (119.993 examples/sec; 0.417 sec/batch)\n",
      "2019-03-15 19:52:16.251220: step 90, examples 4500, loss = 1.119960904 (111.181 examples/sec; 0.450 sec/batch)\n",
      "2019-03-15 19:52:20.335197: step 100, examples 5000, loss = 1.291595817 (124.074 examples/sec; 0.403 sec/batch)\n",
      "Top 1 validation accuracy: 0.3962264060974121 and top 2 validation accuracy: 0.6462264060974121\n",
      "Model Saved!\n",
      "2019-03-15 19:52:25.962269: step 110, examples 5500, loss = 1.551341891 (117.680 examples/sec; 0.425 sec/batch)\n",
      "2019-03-15 19:52:30.154244: step 120, examples 6000, loss = 1.334965110 (123.159 examples/sec; 0.406 sec/batch)\n",
      "2019-03-15 19:52:34.443113: step 130, examples 6500, loss = 1.381377459 (117.398 examples/sec; 0.426 sec/batch)\n",
      "2019-03-15 19:52:38.594326: step 140, examples 7000, loss = 1.340944290 (123.280 examples/sec; 0.406 sec/batch)\n",
      "2019-03-15 19:52:42.797399: step 150, examples 7500, loss = 1.141336441 (119.100 examples/sec; 0.420 sec/batch)\n",
      "2019-03-15 19:52:46.957405: step 160, examples 8000, loss = 1.233089566 (120.736 examples/sec; 0.414 sec/batch)\n",
      "2019-03-15 19:52:51.158114: step 170, examples 8500, loss = 1.060300827 (118.780 examples/sec; 0.421 sec/batch)\n",
      "2019-03-15 19:52:55.393335: step 180, examples 9000, loss = 1.226859093 (117.514 examples/sec; 0.425 sec/batch)\n",
      "2019-03-15 19:52:59.563806: step 190, examples 9500, loss = 1.119864941 (122.318 examples/sec; 0.409 sec/batch)\n",
      "2019-03-15 19:53:03.755236: step 200, examples 10000, loss = 1.144318223 (117.309 examples/sec; 0.426 sec/batch)\n",
      "Top 1 validation accuracy: 0.46226415038108826 and top 2 validation accuracy: 0.7122641801834106\n",
      "Model Saved!\n",
      "2019-03-15 19:53:09.362694: step 210, examples 10500, loss = 1.204556465 (115.988 examples/sec; 0.431 sec/batch)\n",
      "2019-03-15 19:53:13.517750: step 220, examples 11000, loss = 1.305614948 (122.035 examples/sec; 0.410 sec/batch)\n",
      "2019-03-15 19:53:17.672445: step 230, examples 11500, loss = 1.043283582 (118.681 examples/sec; 0.421 sec/batch)\n",
      "2019-03-15 19:53:21.881953: step 240, examples 12000, loss = 0.978893697 (121.616 examples/sec; 0.411 sec/batch)\n",
      "2019-03-15 19:53:26.031740: step 250, examples 12500, loss = 1.198123097 (118.506 examples/sec; 0.422 sec/batch)\n",
      "2019-03-15 19:53:30.172903: step 260, examples 13000, loss = 0.846317410 (117.044 examples/sec; 0.427 sec/batch)\n",
      "2019-03-15 19:53:34.319434: step 270, examples 13500, loss = 1.158576846 (118.926 examples/sec; 0.420 sec/batch)\n",
      "2019-03-15 19:53:38.517549: step 280, examples 14000, loss = 1.123865247 (122.014 examples/sec; 0.410 sec/batch)\n",
      "2019-03-15 19:53:42.657186: step 290, examples 14500, loss = 0.977685511 (123.566 examples/sec; 0.405 sec/batch)\n",
      "2019-03-15 19:53:46.860086: step 300, examples 15000, loss = 0.931946278 (119.911 examples/sec; 0.417 sec/batch)\n",
      "Top 1 validation accuracy: 0.5188679099082947 and top 2 validation accuracy: 0.75\n",
      "Model Saved!\n",
      "2019-03-15 19:53:52.674303: step 310, examples 15500, loss = 0.826270938 (113.319 examples/sec; 0.441 sec/batch)\n",
      "2019-03-15 19:53:57.016775: step 320, examples 16000, loss = 0.949714303 (114.265 examples/sec; 0.438 sec/batch)\n",
      "2019-03-15 19:54:01.377403: step 330, examples 16500, loss = 1.088073134 (114.122 examples/sec; 0.438 sec/batch)\n",
      "2019-03-15 19:54:05.732796: step 340, examples 17000, loss = 0.904220462 (116.838 examples/sec; 0.428 sec/batch)\n",
      "2019-03-15 19:54:10.123682: step 350, examples 17500, loss = 0.995690346 (115.874 examples/sec; 0.432 sec/batch)\n",
      "2019-03-15 19:54:14.469456: step 360, examples 18000, loss = 0.892005503 (114.415 examples/sec; 0.437 sec/batch)\n",
      "2019-03-15 19:54:18.820110: step 370, examples 18500, loss = 1.006075859 (113.164 examples/sec; 0.442 sec/batch)\n",
      "2019-03-15 19:54:23.157906: step 380, examples 19000, loss = 1.027398467 (114.012 examples/sec; 0.439 sec/batch)\n",
      "2019-03-15 19:54:27.517934: step 390, examples 19500, loss = 1.030656219 (113.901 examples/sec; 0.439 sec/batch)\n",
      "2019-03-15 19:54:31.829532: step 400, examples 20000, loss = 1.027275920 (118.906 examples/sec; 0.421 sec/batch)\n",
      "Top 1 validation accuracy: 0.4433962404727936 and top 2 validation accuracy: 0.7830188870429993\n",
      "Model Saved!\n",
      "2019-03-15 19:54:37.719534: step 410, examples 20500, loss = 0.789751172 (115.156 examples/sec; 0.434 sec/batch)\n",
      "2019-03-15 19:54:42.107910: step 420, examples 21000, loss = 0.751166880 (113.344 examples/sec; 0.441 sec/batch)\n",
      "2019-03-15 19:54:46.486443: step 430, examples 21500, loss = 0.723356187 (114.014 examples/sec; 0.439 sec/batch)\n",
      "2019-03-15 19:54:50.823369: step 440, examples 22000, loss = 0.770045519 (112.197 examples/sec; 0.446 sec/batch)\n",
      "2019-03-15 19:54:55.172887: step 450, examples 22500, loss = 0.955929697 (114.263 examples/sec; 0.438 sec/batch)\n",
      "2019-03-15 19:54:59.578816: step 460, examples 23000, loss = 0.709008574 (116.537 examples/sec; 0.429 sec/batch)\n",
      "2019-03-15 19:55:04.220124: step 470, examples 23500, loss = 0.633988976 (114.342 examples/sec; 0.437 sec/batch)\n",
      "2019-03-15 19:55:08.753591: step 480, examples 24000, loss = 0.628948689 (113.671 examples/sec; 0.440 sec/batch)\n",
      "2019-03-15 19:55:13.190482: step 490, examples 24500, loss = 0.574767292 (113.544 examples/sec; 0.440 sec/batch)\n",
      "2019-03-15 19:55:17.541911: step 500, examples 25000, loss = 0.854460955 (114.454 examples/sec; 0.437 sec/batch)\n",
      "Top 1 validation accuracy: 0.49056604504585266 and top 2 validation accuracy: 0.7877358198165894\n",
      "Model Saved!\n",
      "2019-03-15 19:55:23.378348: step 510, examples 25500, loss = 0.907318234 (114.039 examples/sec; 0.438 sec/batch)\n",
      "2019-03-15 19:55:27.723166: step 520, examples 26000, loss = 0.675240576 (114.089 examples/sec; 0.438 sec/batch)\n",
      "2019-03-15 19:55:32.078947: step 530, examples 26500, loss = 0.752859235 (114.281 examples/sec; 0.438 sec/batch)\n",
      "2019-03-15 19:55:36.393216: step 540, examples 27000, loss = 0.741272569 (113.254 examples/sec; 0.441 sec/batch)\n",
      "2019-03-15 19:55:40.721256: step 550, examples 27500, loss = 0.758645773 (117.310 examples/sec; 0.426 sec/batch)\n",
      "2019-03-15 19:55:45.120202: step 560, examples 28000, loss = 0.660455644 (108.504 examples/sec; 0.461 sec/batch)\n",
      "2019-03-15 19:55:49.424986: step 570, examples 28500, loss = 0.678186059 (117.710 examples/sec; 0.425 sec/batch)\n",
      "2019-03-15 19:55:53.765420: step 580, examples 29000, loss = 0.543814242 (114.422 examples/sec; 0.437 sec/batch)\n",
      "2019-03-15 19:55:58.122723: step 590, examples 29500, loss = 0.792477250 (111.067 examples/sec; 0.450 sec/batch)\n",
      "2019-03-15 19:56:02.518376: step 600, examples 30000, loss = 0.608401597 (113.643 examples/sec; 0.440 sec/batch)\n",
      "Top 1 validation accuracy: 0.5094339847564697 and top 2 validation accuracy: 0.7547169923782349\n",
      "Model Saved!\n",
      "2019-03-15 19:56:08.378197: step 610, examples 30500, loss = 0.736303270 (113.524 examples/sec; 0.440 sec/batch)\n",
      "2019-03-15 19:56:12.703801: step 620, examples 31000, loss = 0.663946509 (115.088 examples/sec; 0.434 sec/batch)\n",
      "2019-03-15 19:56:17.114323: step 630, examples 31500, loss = 0.650043607 (109.236 examples/sec; 0.458 sec/batch)\n",
      "2019-03-15 19:56:21.486676: step 640, examples 32000, loss = 0.744313061 (113.934 examples/sec; 0.439 sec/batch)\n",
      "2019-03-15 19:56:25.828951: step 650, examples 32500, loss = 0.637538552 (114.700 examples/sec; 0.436 sec/batch)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2019-03-15 19:56:30.217126: step 660, examples 33000, loss = 0.493227005 (109.913 examples/sec; 0.455 sec/batch)\n",
      "2019-03-15 19:56:34.641083: step 670, examples 33500, loss = 0.557910204 (114.547 examples/sec; 0.437 sec/batch)\n",
      "2019-03-15 19:56:38.940073: step 680, examples 34000, loss = 0.682563126 (118.506 examples/sec; 0.422 sec/batch)\n",
      "2019-03-15 19:56:43.299240: step 690, examples 34500, loss = 0.549979508 (113.831 examples/sec; 0.439 sec/batch)\n",
      "2019-03-15 19:56:47.675686: step 700, examples 35000, loss = 0.484500051 (111.325 examples/sec; 0.449 sec/batch)\n",
      "Top 1 validation accuracy: 0.5660377144813538 and top 2 validation accuracy: 0.7735849022865295\n",
      "Model Saved!\n",
      "2019-03-15 19:56:53.657416: step 710, examples 35500, loss = 0.626695752 (109.765 examples/sec; 0.456 sec/batch)\n",
      "2019-03-15 19:56:58.001059: step 720, examples 36000, loss = 0.615614533 (114.274 examples/sec; 0.438 sec/batch)\n",
      "2019-03-15 19:57:02.356982: step 730, examples 36500, loss = 0.835541368 (115.120 examples/sec; 0.434 sec/batch)\n",
      "2019-03-15 19:57:06.739774: step 740, examples 37000, loss = 0.526268482 (114.227 examples/sec; 0.438 sec/batch)\n",
      "2019-03-15 19:57:11.063196: step 750, examples 37500, loss = 0.510826945 (114.273 examples/sec; 0.438 sec/batch)\n",
      "2019-03-15 19:57:15.408688: step 760, examples 38000, loss = 0.612834513 (112.055 examples/sec; 0.446 sec/batch)\n",
      "2019-03-15 19:57:19.782657: step 770, examples 38500, loss = 0.650625825 (111.837 examples/sec; 0.447 sec/batch)\n",
      "2019-03-15 19:57:24.232369: step 780, examples 39000, loss = 0.726443470 (102.636 examples/sec; 0.487 sec/batch)\n",
      "2019-03-15 19:57:28.714299: step 790, examples 39500, loss = 0.442206591 (108.091 examples/sec; 0.463 sec/batch)\n",
      "2019-03-15 19:57:33.063017: step 800, examples 40000, loss = 0.505298853 (114.265 examples/sec; 0.438 sec/batch)\n",
      "Top 1 validation accuracy: 0.5424528121948242 and top 2 validation accuracy: 0.8254716992378235\n",
      "Model Saved!\n",
      "2019-03-15 19:57:38.711493: step 810, examples 40500, loss = 0.612565756 (122.877 examples/sec; 0.407 sec/batch)\n",
      "2019-03-15 19:57:42.860522: step 820, examples 41000, loss = 0.441800416 (121.606 examples/sec; 0.411 sec/batch)\n",
      "2019-03-15 19:57:47.033689: step 830, examples 41500, loss = 0.550449431 (123.064 examples/sec; 0.406 sec/batch)\n",
      "2019-03-15 19:57:51.173333: step 840, examples 42000, loss = 0.606772184 (119.033 examples/sec; 0.420 sec/batch)\n",
      "2019-03-15 19:57:55.393940: step 850, examples 42500, loss = 0.520834684 (122.240 examples/sec; 0.409 sec/batch)\n",
      "2019-03-15 19:57:59.578776: step 860, examples 43000, loss = 0.851262510 (113.676 examples/sec; 0.440 sec/batch)\n",
      "2019-03-15 19:58:03.820522: step 870, examples 43500, loss = 0.555524111 (121.515 examples/sec; 0.411 sec/batch)\n",
      "2019-03-15 19:58:07.972723: step 880, examples 44000, loss = 0.558114648 (115.632 examples/sec; 0.432 sec/batch)\n",
      "2019-03-15 19:58:12.116623: step 890, examples 44500, loss = 0.407218397 (116.963 examples/sec; 0.427 sec/batch)\n",
      "2019-03-15 19:58:16.288884: step 900, examples 45000, loss = 0.659549296 (119.067 examples/sec; 0.420 sec/batch)\n",
      "Top 1 validation accuracy: 0.5943396091461182 and top 2 validation accuracy: 0.7830188870429993\n",
      "Model Saved!\n",
      "2019-03-15 19:58:21.962637: step 910, examples 45500, loss = 0.468544126 (119.616 examples/sec; 0.418 sec/batch)\n",
      "2019-03-15 19:58:26.356587: step 920, examples 46000, loss = 0.505058646 (111.127 examples/sec; 0.450 sec/batch)\n",
      "2019-03-15 19:58:30.663092: step 930, examples 46500, loss = 0.286380798 (115.851 examples/sec; 0.432 sec/batch)\n",
      "2019-03-15 19:58:34.984798: step 940, examples 47000, loss = 0.624301672 (118.498 examples/sec; 0.422 sec/batch)\n",
      "2019-03-15 19:58:39.282929: step 950, examples 47500, loss = 0.650714755 (115.378 examples/sec; 0.433 sec/batch)\n",
      "2019-03-15 19:58:43.688617: step 960, examples 48000, loss = 0.528078914 (117.707 examples/sec; 0.425 sec/batch)\n",
      "2019-03-15 19:58:48.016228: step 970, examples 48500, loss = 0.415028244 (114.273 examples/sec; 0.438 sec/batch)\n",
      "2019-03-15 19:58:52.355866: step 980, examples 49000, loss = 0.632465720 (113.824 examples/sec; 0.439 sec/batch)\n",
      "2019-03-15 19:58:56.740560: step 990, examples 49500, loss = 0.496495187 (113.170 examples/sec; 0.442 sec/batch)\n",
      "Top 1 validation accuracy: 0.5613207817077637 and top 2 validation accuracy: 0.8160377144813538\n",
      "Model Saved!\n"
     ]
    }
   ],
   "source": [
    "# Train only with dropout and l2loss\n",
    "\n",
    "num_cls = 4\n",
    "mstp = 1000\n",
    "lfrq = 10\n",
    "bsz = 50\n",
    "msf = 100\n",
    "tr = './trained_model_final/DCNN_reg2'\n",
    "start = 0\n",
    "stop = 1000\n",
    "step = 100\n",
    "time_length = 1000\n",
    "#Nb = BATCH_SIZE\n",
    "fsz = 10\n",
    "use_batchnorm = False\n",
    "use_dropout = True\n",
    "use_l2loss = True\n",
    "\n",
    "train_model(tr,start,stop,step,time_length,fsz,use_batchnorm,use_dropout,use_l2loss,num_cls,mstp,lfrq,bsz,msf)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading datasets...\n",
      "Dataset loading completes.\n",
      "INFO:tensorflow:Restoring parameters from ./trained_model_final/DCNN_reg2/model.ckpt-901\n",
      "[test  step  901] loss: 1.70193; top_1_accuracy: 0.54402; top_5_accuracy: 0.830700 (1.343 sec/batch; 329.870 instances/sec)\n",
      "top_1_accuracy_test =  0.54401803 top_2_accuracy_test =  0.8306998\n"
     ]
    }
   ],
   "source": [
    "# Accuracy for testSet 901 (best)\n",
    "model_dir = \"./trained_model_final/DCNN_reg2/model.ckpt-901\"\n",
    "start = 0\n",
    "stop = 1000\n",
    "step = 100\n",
    "time_length = 1000\n",
    "#Nb = BATCH_SIZE\n",
    "fsz = 10\n",
    "use_batchnorm = False\n",
    "use_dropout = True\n",
    "use_l2loss = True\n",
    "top_1_acc_org, top_2_acc_org = test_model(model_dir,start,stop,step,time_length,fsz,use_batchnorm,use_dropout,use_l2loss)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Batch Norm or No Batch Norm\n",
    "Adding batch normalization gave 2% better result on the test dataset, even though the validation accuracy without batch norm was higher. Which weakly implies that the model with batch norm is more generalizable"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "def data_loader_tb(time_bin):\n",
    "    X_test = np.load(\"X_test.npy\")\n",
    "    X_test = X_test[:,0:22,0:time_bin]\n",
    "    y_test = np.load(\"y_test.npy\")\n",
    "    person_test = np.load(\"person_test.npy\")\n",
    "\n",
    "    X_train_valid = np.load(\"X_train_valid.npy\")\n",
    "    X_train_valid = X_train_valid[:,0:22,0:time_bin]\n",
    "    y_train_valid = np.load(\"y_train_valid.npy\")\n",
    "    person_train_valid = np.load(\"person_train_valid.npy\")\n",
    "    \n",
    "    N_train = X_train_valid.shape[0]\n",
    "    idx_train_valid = np.arange(N_train,dtype='int')\n",
    "\n",
    "    X_train, X_val, idx_train, idx_val = train_test_split(X_train_valid, idx_train_valid, test_size=0.1, random_state=21)\n",
    "\n",
    "    y_train = y_train_valid[idx_train]\n",
    "    person_train = person_train_valid[idx_train]\n",
    "    y_val = y_train_valid[idx_val]\n",
    "    person_val = person_train_valid[idx_val]\n",
    "\n",
    "    tl = X_train.shape[2]\n",
    "    X_test = np.reshape(X_test,(-1,22,tl,1))\n",
    "    X_train = np.reshape(X_train,(-1,22,tl,1))\n",
    "    X_val = np.reshape(X_val,(-1,22,tl,1))\n",
    "\n",
    "    label0 = 769\n",
    "    new_label0 = 0\n",
    "    for i in range(4):\n",
    "        m1 = (y_test==label0)\n",
    "        m2 = (y_train==label0)\n",
    "        m3 = (y_val==label0)\n",
    "        np.place(y_test,m1,new_label0)\n",
    "        np.place(y_train,m2,new_label0)\n",
    "        np.place(y_val,m3,new_label0)\n",
    "        label0 += 1\n",
    "        new_label0 += 1\n",
    "\n",
    "    labelNames = [0,1,2,3]\n",
    "    train_set = {'data': X_train, 'labels': y_train, 'person': person_train}\n",
    "    test_set = {'data': X_test, 'labels': y_test, 'person': person_test}\n",
    "    val_set = {'data': X_val, 'labels': y_val, 'person': person_val}\n",
    "    return train_set, test_set, val_set, labelNames\n",
    "\n",
    "\n",
    "def sample_batch(dataset, batch_size):\n",
    "    N = dataset['data'].shape[0]\n",
    "    indices = np.random.randint(N, size=batch_size)\n",
    "    return {key: dataset[key][indices] for key in dataset}\n",
    "\n",
    "def train_model_tb(target_dir,start,stop,step,time_length,fsz,use_batchnorm,use_dropout,use_l2loss,num_class,max_step,log_frequency,batch_size,model_saving_freq):\n",
    "    # load data\n",
    "    print(\"Loading datasets...\")\n",
    "    trainSet, testSet, valSet, labelNames = data_loader_tb(time_length)\n",
    "    print(\"Dataset loading completes.\")\n",
    "    \n",
    "    best_val_acc = 0\n",
    "    best_val_path = target_dir\n",
    "\n",
    "    # reset default graph\n",
    "    tf.reset_default_graph()\n",
    "\n",
    "    global_step = tf.train.get_or_create_global_step()\n",
    "    \n",
    "    model = Model(config, labelNames,start,stop,step,time_length,fsz,use_batchnorm,use_dropout,use_l2loss)\n",
    "\n",
    "    # training setups\n",
    "    saver = tf.train.Saver(max_to_keep=100)\n",
    "\n",
    "    # Build an initialization operation to run below.\n",
    "    init = tf.global_variables_initializer()\n",
    "    \n",
    "    config_proto = tf.ConfigProto()\n",
    "\n",
    "    off = rewriter_config_pb2.RewriterConfig.OFF\n",
    "    config_proto.graph_options.rewrite_options.arithmetic_optimization = off\n",
    "    \n",
    "    sess = tf.Session(config=config_proto)\n",
    "\n",
    "    sess.run(init)\n",
    "\n",
    "    # main loop\n",
    "    for step in range(max_step):\n",
    "        start_time = time.time()\n",
    "\n",
    "        # prepare data\n",
    "        train_batch = sample_batch(trainSet, batch_size)\n",
    "        # feed dict\n",
    "        feed_dict = {\n",
    "            model.input: train_batch['data'],\n",
    "            model.fine_labels: train_batch['labels'],\n",
    "            model.is_training: True,\n",
    "        }\n",
    "        \n",
    "        fetch_list = [model.optimizer_op, model.loss, model.global_step]\n",
    "        _, loss_value, global_step_value = sess.run(fetch_list, feed_dict=feed_dict)\n",
    "        duration = time.time() - start_time\n",
    "        assert not np.isnan(loss_value), 'Model diverged with loss = NaN'\n",
    "\n",
    "        # log\n",
    "        if step % log_frequency == 0:\n",
    "            num_examples_per_step = batch_size\n",
    "            examples_per_sec = num_examples_per_step / duration\n",
    "            sec_per_batch = duration\n",
    "            format_str = (\n",
    "                '%s: step %d, examples %d, loss = %.9f (%.3f examples/sec; %.3f sec/batch)'\n",
    "            )\n",
    "            print(\n",
    "                format_str % (\n",
    "                    datetime.now(), step, batch_size * step,\n",
    "                    loss_value,\n",
    "                    examples_per_sec, sec_per_batch\n",
    "                )\n",
    "            )\n",
    "\n",
    "        # Save the model checkpoint periodically.\n",
    "        if step % model_saving_freq == 0 or (step + 1) == max_step:\n",
    "            fetch_list = [model.accuracy,model.top_2_accuracy]\n",
    "            feed_dict = {\n",
    "                model.input: valSet['data'],\n",
    "                model.fine_labels: valSet['labels'],\n",
    "                model.is_training: False,\n",
    "            }\n",
    "            val_acc_1, val_acc_2 =  sess.run(fetch_list, feed_dict=feed_dict)\n",
    "            checkpoint_path = os.path.join(target_dir, 'model.ckpt')\n",
    "            saver.save(sess, checkpoint_path, global_step=int(global_step_value))\n",
    "            print('Top 1 validation accuracy: {} and top 2 validation accuracy: {}'.format(val_acc_1,val_acc_2))\n",
    "            print('Model Saved!')\n",
    "            if val_acc_1>best_val_acc:\n",
    "                best_val_acc = val_acc_1\n",
    "                best_val_path = checkpoint_path+'-'+str(int(global_step_value))\n",
    "    return best_val_acc,best_val_path\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading datasets...\n",
      "Dataset loading completes.\n",
      "2019-03-15 21:52:58.930062: step 0, examples 0, loss = 1.475036025 (82.492 examples/sec; 0.606 sec/batch)\n",
      "Top 1 validation accuracy: 0.2358490526676178 and top 2 validation accuracy: 0.4858490526676178\n",
      "Model Saved!\n",
      "2019-03-15 21:53:03.216090: step 10, examples 500, loss = 1.491670966 (184.279 examples/sec; 0.271 sec/batch)\n",
      "2019-03-15 21:53:05.907360: step 20, examples 1000, loss = 1.548984766 (188.215 examples/sec; 0.266 sec/batch)\n",
      "2019-03-15 21:53:08.538250: step 30, examples 1500, loss = 1.437868714 (184.191 examples/sec; 0.271 sec/batch)\n",
      "2019-03-15 21:53:11.200766: step 40, examples 2000, loss = 1.451322913 (183.810 examples/sec; 0.272 sec/batch)\n",
      "2019-03-15 21:53:13.829003: step 50, examples 2500, loss = 1.292630792 (188.215 examples/sec; 0.266 sec/batch)\n",
      "2019-03-15 21:53:16.471125: step 60, examples 3000, loss = 1.257043123 (194.109 examples/sec; 0.258 sec/batch)\n",
      "2019-03-15 21:53:19.173365: step 70, examples 3500, loss = 1.464167833 (187.471 examples/sec; 0.267 sec/batch)\n",
      "2019-03-15 21:53:21.906909: step 80, examples 4000, loss = 1.302419782 (188.215 examples/sec; 0.266 sec/batch)\n",
      "2019-03-15 21:53:24.562708: step 90, examples 4500, loss = 1.301165581 (182.341 examples/sec; 0.274 sec/batch)\n",
      "2019-03-15 21:53:27.229063: step 100, examples 5000, loss = 1.241057992 (188.032 examples/sec; 0.266 sec/batch)\n",
      "Top 1 validation accuracy: 0.4150943458080292 and top 2 validation accuracy: 0.6745283007621765\n",
      "Model Saved!\n",
      "2019-03-15 21:53:31.440409: step 110, examples 5500, loss = 1.134322405 (184.176 examples/sec; 0.271 sec/batch)\n",
      "2019-03-15 21:53:34.117570: step 120, examples 6000, loss = 1.322398186 (182.992 examples/sec; 0.273 sec/batch)\n",
      "2019-03-15 21:53:36.948133: step 130, examples 6500, loss = 1.238286972 (188.215 examples/sec; 0.266 sec/batch)\n",
      "2019-03-15 21:53:39.732707: step 140, examples 7000, loss = 1.200197577 (169.041 examples/sec; 0.296 sec/batch)\n",
      "2019-03-15 21:53:42.761204: step 150, examples 7500, loss = 1.352585077 (192.049 examples/sec; 0.260 sec/batch)\n",
      "2019-03-15 21:53:45.471174: step 160, examples 8000, loss = 1.147120357 (174.442 examples/sec; 0.287 sec/batch)\n",
      "2019-03-15 21:53:48.562863: step 170, examples 8500, loss = 1.119812012 (178.101 examples/sec; 0.281 sec/batch)\n",
      "2019-03-15 21:53:51.949869: step 180, examples 9000, loss = 1.172655702 (157.310 examples/sec; 0.318 sec/batch)\n",
      "2019-03-15 21:53:55.014905: step 190, examples 9500, loss = 1.357635498 (167.830 examples/sec; 0.298 sec/batch)\n",
      "2019-03-15 21:53:57.943289: step 200, examples 10000, loss = 1.220502853 (165.413 examples/sec; 0.302 sec/batch)\n",
      "Top 1 validation accuracy: 0.5188679099082947 and top 2 validation accuracy: 0.7405660152435303\n",
      "Model Saved!\n",
      "2019-03-15 21:54:02.288359: step 210, examples 10500, loss = 1.014989257 (184.354 examples/sec; 0.271 sec/batch)\n",
      "2019-03-15 21:54:05.338351: step 220, examples 11000, loss = 0.934938550 (181.897 examples/sec; 0.275 sec/batch)\n",
      "2019-03-15 21:54:08.750287: step 230, examples 11500, loss = 1.044684529 (161.382 examples/sec; 0.310 sec/batch)\n",
      "2019-03-15 21:54:11.757793: step 240, examples 12000, loss = 1.209871888 (171.955 examples/sec; 0.291 sec/batch)\n",
      "2019-03-15 21:54:14.681568: step 250, examples 12500, loss = 1.022062063 (162.433 examples/sec; 0.308 sec/batch)\n",
      "2019-03-15 21:54:17.494008: step 260, examples 13000, loss = 0.972014129 (176.863 examples/sec; 0.283 sec/batch)\n",
      "2019-03-15 21:54:20.392484: step 270, examples 13500, loss = 1.171009183 (172.587 examples/sec; 0.290 sec/batch)\n",
      "2019-03-15 21:54:23.338869: step 280, examples 14000, loss = 1.339112401 (185.875 examples/sec; 0.269 sec/batch)\n",
      "2019-03-15 21:54:26.103647: step 290, examples 14500, loss = 0.931743920 (178.892 examples/sec; 0.279 sec/batch)\n",
      "2019-03-15 21:54:28.815320: step 300, examples 15000, loss = 1.271222234 (194.614 examples/sec; 0.257 sec/batch)\n",
      "Top 1 validation accuracy: 0.49056604504585266 and top 2 validation accuracy: 0.7405660152435303\n",
      "Model Saved!\n",
      "2019-03-15 21:54:33.085796: step 310, examples 15500, loss = 1.342435122 (155.349 examples/sec; 0.322 sec/batch)\n",
      "2019-03-15 21:54:36.319619: step 320, examples 16000, loss = 0.937440515 (168.912 examples/sec; 0.296 sec/batch)\n",
      "2019-03-15 21:54:39.137933: step 330, examples 16500, loss = 0.934444547 (174.879 examples/sec; 0.286 sec/batch)\n",
      "2019-03-15 21:54:41.913936: step 340, examples 17000, loss = 0.805849910 (188.215 examples/sec; 0.266 sec/batch)\n",
      "2019-03-15 21:54:44.674133: step 350, examples 17500, loss = 0.805129349 (176.580 examples/sec; 0.283 sec/batch)\n",
      "2019-03-15 21:54:47.378259: step 360, examples 18000, loss = 0.733610988 (185.639 examples/sec; 0.269 sec/batch)\n",
      "2019-03-15 21:54:50.114019: step 370, examples 18500, loss = 1.002882123 (179.685 examples/sec; 0.278 sec/batch)\n",
      "2019-03-15 21:54:52.788884: step 380, examples 19000, loss = 0.849404573 (184.303 examples/sec; 0.271 sec/batch)\n",
      "2019-03-15 21:54:55.610523: step 390, examples 19500, loss = 0.844033241 (189.045 examples/sec; 0.264 sec/batch)\n",
      "2019-03-15 21:54:58.393436: step 400, examples 20000, loss = 0.907261610 (178.861 examples/sec; 0.280 sec/batch)\n",
      "Top 1 validation accuracy: 0.5707547068595886 and top 2 validation accuracy: 0.7641509175300598\n",
      "Model Saved!\n",
      "2019-03-15 21:55:03.032329: step 410, examples 20500, loss = 0.752695203 (168.401 examples/sec; 0.297 sec/batch)\n",
      "2019-03-15 21:55:06.061304: step 420, examples 21000, loss = 0.973924339 (168.403 examples/sec; 0.297 sec/batch)\n",
      "2019-03-15 21:55:09.130615: step 430, examples 21500, loss = 0.793067992 (152.499 examples/sec; 0.328 sec/batch)\n",
      "2019-03-15 21:55:12.105909: step 440, examples 22000, loss = 0.974755645 (166.224 examples/sec; 0.301 sec/batch)\n",
      "2019-03-15 21:55:15.031689: step 450, examples 22500, loss = 0.867040813 (178.097 examples/sec; 0.281 sec/batch)\n",
      "2019-03-15 21:55:17.917864: step 460, examples 23000, loss = 0.701656759 (170.778 examples/sec; 0.293 sec/batch)\n",
      "2019-03-15 21:55:20.817585: step 470, examples 23500, loss = 0.855125368 (173.451 examples/sec; 0.288 sec/batch)\n",
      "2019-03-15 21:55:23.779317: step 480, examples 24000, loss = 0.961359024 (168.051 examples/sec; 0.298 sec/batch)\n",
      "2019-03-15 21:55:26.674149: step 490, examples 24500, loss = 0.922357738 (178.127 examples/sec; 0.281 sec/batch)\n",
      "2019-03-15 21:55:29.545960: step 500, examples 25000, loss = 0.804021537 (181.310 examples/sec; 0.276 sec/batch)\n",
      "Top 1 validation accuracy: 0.5424528121948242 and top 2 validation accuracy: 0.8066037893295288\n",
      "Model Saved!\n",
      "2019-03-15 21:55:33.989134: step 510, examples 25500, loss = 0.714540303 (177.758 examples/sec; 0.281 sec/batch)\n",
      "2019-03-15 21:55:36.787804: step 520, examples 26000, loss = 0.971275449 (175.254 examples/sec; 0.285 sec/batch)\n",
      "2019-03-15 21:55:39.610304: step 530, examples 26500, loss = 1.166802287 (183.759 examples/sec; 0.272 sec/batch)\n",
      "2019-03-15 21:55:42.411527: step 540, examples 27000, loss = 0.908685982 (185.809 examples/sec; 0.269 sec/batch)\n",
      "2019-03-15 21:55:45.319772: step 550, examples 27500, loss = 0.825984776 (168.421 examples/sec; 0.297 sec/batch)\n",
      "2019-03-15 21:55:48.346844: step 560, examples 28000, loss = 0.813142061 (165.710 examples/sec; 0.302 sec/batch)\n",
      "2019-03-15 21:55:51.277555: step 570, examples 28500, loss = 0.672082126 (180.503 examples/sec; 0.277 sec/batch)\n",
      "2019-03-15 21:55:54.142277: step 580, examples 29000, loss = 0.638600767 (185.945 examples/sec; 0.269 sec/batch)\n",
      "2019-03-15 21:55:56.969177: step 590, examples 29500, loss = 0.607032239 (177.759 examples/sec; 0.281 sec/batch)\n",
      "2019-03-15 21:55:59.766508: step 600, examples 30000, loss = 0.712177157 (169.381 examples/sec; 0.295 sec/batch)\n",
      "Top 1 validation accuracy: 0.5613207817077637 and top 2 validation accuracy: 0.7971698045730591\n",
      "Model Saved!\n",
      "2019-03-15 21:56:04.113277: step 610, examples 30500, loss = 0.783310354 (149.659 examples/sec; 0.334 sec/batch)\n",
      "2019-03-15 21:56:06.909281: step 620, examples 31000, loss = 0.619449556 (177.759 examples/sec; 0.281 sec/batch)\n",
      "2019-03-15 21:56:09.756240: step 630, examples 31500, loss = 0.633940220 (163.721 examples/sec; 0.305 sec/batch)\n",
      "2019-03-15 21:56:12.735633: step 640, examples 32000, loss = 0.556822121 (185.393 examples/sec; 0.270 sec/batch)\n",
      "2019-03-15 21:56:15.578624: step 650, examples 32500, loss = 0.563851237 (181.939 examples/sec; 0.275 sec/batch)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2019-03-15 21:56:18.463414: step 660, examples 33000, loss = 0.659628868 (169.726 examples/sec; 0.295 sec/batch)\n",
      "2019-03-15 21:56:21.362489: step 670, examples 33500, loss = 0.604616165 (178.569 examples/sec; 0.280 sec/batch)\n",
      "2019-03-15 21:56:24.204267: step 680, examples 34000, loss = 0.510358334 (178.731 examples/sec; 0.280 sec/batch)\n",
      "2019-03-15 21:56:27.283217: step 690, examples 34500, loss = 0.519466817 (144.962 examples/sec; 0.345 sec/batch)\n",
      "2019-03-15 21:56:30.658595: step 700, examples 35000, loss = 0.618541837 (147.974 examples/sec; 0.338 sec/batch)\n",
      "Top 1 validation accuracy: 0.5754716992378235 and top 2 validation accuracy: 0.7971698045730591\n",
      "Model Saved!\n",
      "2019-03-15 21:56:35.199590: step 710, examples 35500, loss = 0.488366753 (178.240 examples/sec; 0.281 sec/batch)\n",
      "2019-03-15 21:56:38.021206: step 720, examples 36000, loss = 0.672968268 (177.759 examples/sec; 0.281 sec/batch)\n",
      "2019-03-15 21:56:40.834429: step 730, examples 36500, loss = 0.644783795 (178.739 examples/sec; 0.280 sec/batch)\n",
      "2019-03-15 21:56:43.656518: step 740, examples 37000, loss = 0.613822937 (179.171 examples/sec; 0.279 sec/batch)\n",
      "2019-03-15 21:56:46.502033: step 750, examples 37500, loss = 0.526956499 (173.650 examples/sec; 0.288 sec/batch)\n",
      "2019-03-15 21:56:49.393291: step 760, examples 38000, loss = 0.577269316 (184.678 examples/sec; 0.271 sec/batch)\n",
      "2019-03-15 21:56:52.228718: step 770, examples 38500, loss = 0.492638886 (182.568 examples/sec; 0.274 sec/batch)\n",
      "2019-03-15 21:56:55.033747: step 780, examples 39000, loss = 0.865474343 (177.758 examples/sec; 0.281 sec/batch)\n",
      "2019-03-15 21:56:57.844685: step 790, examples 39500, loss = 0.612772942 (177.758 examples/sec; 0.281 sec/batch)\n",
      "2019-03-15 21:57:00.760520: step 800, examples 40000, loss = 0.647724509 (186.261 examples/sec; 0.268 sec/batch)\n",
      "Top 1 validation accuracy: 0.599056601524353 and top 2 validation accuracy: 0.7877358198165894\n",
      "Model Saved!\n",
      "2019-03-15 21:57:05.141186: step 810, examples 40500, loss = 0.565341532 (178.026 examples/sec; 0.281 sec/batch)\n",
      "2019-03-15 21:57:07.959648: step 820, examples 41000, loss = 0.718906105 (177.758 examples/sec; 0.281 sec/batch)\n",
      "2019-03-15 21:57:10.750743: step 830, examples 41500, loss = 0.545301676 (178.796 examples/sec; 0.280 sec/batch)\n",
      "2019-03-15 21:57:13.552713: step 840, examples 42000, loss = 0.595965385 (174.931 examples/sec; 0.286 sec/batch)\n",
      "2019-03-15 21:57:16.355459: step 850, examples 42500, loss = 0.576249242 (179.429 examples/sec; 0.279 sec/batch)\n",
      "2019-03-15 21:57:19.237831: step 860, examples 43000, loss = 0.553371191 (187.301 examples/sec; 0.267 sec/batch)\n",
      "2019-03-15 21:57:22.545830: step 870, examples 43500, loss = 0.491937339 (142.477 examples/sec; 0.351 sec/batch)\n",
      "2019-03-15 21:57:25.486857: step 880, examples 44000, loss = 0.448299438 (183.028 examples/sec; 0.273 sec/batch)\n",
      "2019-03-15 21:57:28.319983: step 890, examples 44500, loss = 0.431054294 (178.086 examples/sec; 0.281 sec/batch)\n",
      "2019-03-15 21:57:31.137603: step 900, examples 45000, loss = 0.580723763 (180.215 examples/sec; 0.277 sec/batch)\n",
      "Top 1 validation accuracy: 0.5896226167678833 and top 2 validation accuracy: 0.7924528121948242\n",
      "Model Saved!\n",
      "2019-03-15 21:57:35.610447: step 910, examples 45500, loss = 0.492766619 (163.504 examples/sec; 0.306 sec/batch)\n",
      "2019-03-15 21:57:38.486359: step 920, examples 46000, loss = 0.386978596 (177.273 examples/sec; 0.282 sec/batch)\n",
      "2019-03-15 21:57:41.360764: step 930, examples 46500, loss = 0.529767692 (169.370 examples/sec; 0.295 sec/batch)\n",
      "2019-03-15 21:57:44.270702: step 940, examples 47000, loss = 0.465816677 (175.307 examples/sec; 0.285 sec/batch)\n",
      "2019-03-15 21:57:47.126440: step 950, examples 47500, loss = 0.387101829 (177.062 examples/sec; 0.282 sec/batch)\n",
      "2019-03-15 21:57:49.954196: step 960, examples 48000, loss = 0.689881563 (188.216 examples/sec; 0.266 sec/batch)\n",
      "2019-03-15 21:57:52.840247: step 970, examples 48500, loss = 0.457249671 (178.682 examples/sec; 0.280 sec/batch)\n",
      "2019-03-15 21:57:55.656809: step 980, examples 49000, loss = 0.574084699 (179.036 examples/sec; 0.279 sec/batch)\n",
      "2019-03-15 21:57:58.527307: step 990, examples 49500, loss = 0.481184155 (188.012 examples/sec; 0.266 sec/batch)\n",
      "Top 1 validation accuracy: 0.5566037893295288 and top 2 validation accuracy: 0.7830188870429993\n",
      "Model Saved!\n",
      "Loading datasets...\n",
      "Dataset loading completes.\n",
      "2019-03-15 21:58:05.486480: step 0, examples 0, loss = 1.476857901 (74.469 examples/sec; 0.671 sec/batch)\n",
      "Top 1 validation accuracy: 0.27358490228652954 and top 2 validation accuracy: 0.5283018946647644\n",
      "Model Saved!\n",
      "2019-03-15 21:58:10.671531: step 10, examples 500, loss = 1.413959146 (142.090 examples/sec; 0.352 sec/batch)\n",
      "2019-03-15 21:58:14.064483: step 20, examples 1000, loss = 1.419600248 (152.365 examples/sec; 0.328 sec/batch)\n",
      "2019-03-15 21:58:17.448565: step 30, examples 1500, loss = 1.483649373 (146.952 examples/sec; 0.340 sec/batch)\n",
      "2019-03-15 21:58:20.874298: step 40, examples 2000, loss = 1.355737925 (131.808 examples/sec; 0.379 sec/batch)\n",
      "2019-03-15 21:58:24.495361: step 50, examples 2500, loss = 1.341111183 (129.708 examples/sec; 0.385 sec/batch)\n",
      "2019-03-15 21:58:28.022976: step 60, examples 3000, loss = 1.384595513 (142.647 examples/sec; 0.351 sec/batch)\n",
      "2019-03-15 21:58:31.455772: step 70, examples 3500, loss = 1.403736591 (149.888 examples/sec; 0.334 sec/batch)\n",
      "2019-03-15 21:58:34.886750: step 80, examples 4000, loss = 1.182771325 (154.794 examples/sec; 0.323 sec/batch)\n",
      "2019-03-15 21:58:38.284237: step 90, examples 4500, loss = 1.294669628 (154.324 examples/sec; 0.324 sec/batch)\n",
      "2019-03-15 21:58:42.015287: step 100, examples 5000, loss = 1.253719687 (146.653 examples/sec; 0.341 sec/batch)\n",
      "Top 1 validation accuracy: 0.4433962404727936 and top 2 validation accuracy: 0.6933962106704712\n",
      "Model Saved!\n",
      "2019-03-15 21:58:47.055929: step 110, examples 5500, loss = 1.309253097 (152.364 examples/sec; 0.328 sec/batch)\n",
      "2019-03-15 21:58:50.442274: step 120, examples 6000, loss = 1.221059561 (146.037 examples/sec; 0.342 sec/batch)\n",
      "2019-03-15 21:58:53.845866: step 130, examples 6500, loss = 1.248684883 (152.478 examples/sec; 0.328 sec/batch)\n",
      "2019-03-15 21:58:57.313830: step 140, examples 7000, loss = 0.971804023 (152.018 examples/sec; 0.329 sec/batch)\n",
      "2019-03-15 21:59:00.766761: step 150, examples 7500, loss = 1.141402245 (146.755 examples/sec; 0.341 sec/batch)\n",
      "2019-03-15 21:59:04.170788: step 160, examples 8000, loss = 1.317148685 (149.218 examples/sec; 0.335 sec/batch)\n",
      "2019-03-15 21:59:07.547769: step 170, examples 8500, loss = 1.153269649 (145.470 examples/sec; 0.344 sec/batch)\n",
      "2019-03-15 21:59:10.922174: step 180, examples 9000, loss = 1.161833048 (152.365 examples/sec; 0.328 sec/batch)\n",
      "2019-03-15 21:59:14.332889: step 190, examples 9500, loss = 1.093805075 (150.694 examples/sec; 0.332 sec/batch)\n",
      "2019-03-15 21:59:17.704408: step 200, examples 10000, loss = 1.084424973 (152.965 examples/sec; 0.327 sec/batch)\n",
      "Top 1 validation accuracy: 0.4858490526676178 and top 2 validation accuracy: 0.7122641801834106\n",
      "Model Saved!\n",
      "2019-03-15 21:59:22.773192: step 210, examples 10500, loss = 1.152679920 (143.413 examples/sec; 0.349 sec/batch)\n",
      "2019-03-15 21:59:26.181931: step 220, examples 11000, loss = 0.948934793 (142.503 examples/sec; 0.351 sec/batch)\n",
      "2019-03-15 21:59:29.606604: step 230, examples 11500, loss = 0.964252174 (150.042 examples/sec; 0.333 sec/batch)\n",
      "2019-03-15 21:59:33.000409: step 240, examples 12000, loss = 1.099223733 (152.366 examples/sec; 0.328 sec/batch)\n",
      "2019-03-15 21:59:36.426003: step 250, examples 12500, loss = 1.154629230 (151.319 examples/sec; 0.330 sec/batch)\n",
      "2019-03-15 21:59:39.815151: step 260, examples 13000, loss = 1.091986656 (145.118 examples/sec; 0.345 sec/batch)\n",
      "2019-03-15 21:59:43.244469: step 270, examples 13500, loss = 1.028889418 (136.182 examples/sec; 0.367 sec/batch)\n",
      "2019-03-15 21:59:46.737753: step 280, examples 14000, loss = 0.939860106 (133.620 examples/sec; 0.374 sec/batch)\n",
      "2019-03-15 21:59:50.218266: step 290, examples 14500, loss = 1.089771152 (145.947 examples/sec; 0.343 sec/batch)\n",
      "2019-03-15 21:59:53.610392: step 300, examples 15000, loss = 0.899869382 (148.131 examples/sec; 0.338 sec/batch)\n",
      "Top 1 validation accuracy: 0.5424528121948242 and top 2 validation accuracy: 0.7452830076217651\n",
      "Model Saved!\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2019-03-15 21:59:58.643291: step 310, examples 15500, loss = 0.960688233 (139.802 examples/sec; 0.358 sec/batch)\n",
      "2019-03-15 22:00:02.017183: step 320, examples 16000, loss = 0.938169897 (159.983 examples/sec; 0.313 sec/batch)\n",
      "2019-03-15 22:00:05.409517: step 330, examples 16500, loss = 0.900954366 (157.094 examples/sec; 0.318 sec/batch)\n",
      "2019-03-15 22:00:08.766698: step 340, examples 17000, loss = 1.204232574 (149.306 examples/sec; 0.335 sec/batch)\n",
      "2019-03-15 22:00:12.155567: step 350, examples 17500, loss = 1.036954045 (153.317 examples/sec; 0.326 sec/batch)\n",
      "2019-03-15 22:00:15.502543: step 360, examples 18000, loss = 1.007626653 (151.803 examples/sec; 0.329 sec/batch)\n",
      "2019-03-15 22:00:18.951640: step 370, examples 18500, loss = 0.922007024 (145.439 examples/sec; 0.344 sec/batch)\n",
      "2019-03-15 22:00:22.393287: step 380, examples 19000, loss = 1.065659761 (155.200 examples/sec; 0.322 sec/batch)\n",
      "2019-03-15 22:00:25.769527: step 390, examples 19500, loss = 0.835670173 (153.917 examples/sec; 0.325 sec/batch)\n",
      "2019-03-15 22:00:29.184321: step 400, examples 20000, loss = 0.851414800 (146.961 examples/sec; 0.340 sec/batch)\n",
      "Top 1 validation accuracy: 0.5613207817077637 and top 2 validation accuracy: 0.801886796951294\n",
      "Model Saved!\n",
      "2019-03-15 22:00:34.167691: step 410, examples 20500, loss = 0.883707345 (151.055 examples/sec; 0.331 sec/batch)\n",
      "2019-03-15 22:00:37.610449: step 420, examples 21000, loss = 0.874714792 (147.348 examples/sec; 0.339 sec/batch)\n",
      "2019-03-15 22:00:40.999968: step 430, examples 21500, loss = 0.948838949 (152.365 examples/sec; 0.328 sec/batch)\n",
      "2019-03-15 22:00:44.378149: step 440, examples 22000, loss = 0.905119002 (151.983 examples/sec; 0.329 sec/batch)\n",
      "2019-03-15 22:00:47.778858: step 450, examples 22500, loss = 1.037897825 (141.097 examples/sec; 0.354 sec/batch)\n",
      "2019-03-15 22:00:51.190111: step 460, examples 23000, loss = 1.029128551 (151.307 examples/sec; 0.330 sec/batch)\n",
      "2019-03-15 22:00:54.606613: step 470, examples 23500, loss = 0.805582583 (145.938 examples/sec; 0.343 sec/batch)\n",
      "2019-03-15 22:00:57.987393: step 480, examples 24000, loss = 0.948714495 (145.439 examples/sec; 0.344 sec/batch)\n",
      "2019-03-15 22:01:01.362152: step 490, examples 24500, loss = 0.703865588 (154.492 examples/sec; 0.324 sec/batch)\n",
      "2019-03-15 22:01:04.797857: step 500, examples 25000, loss = 0.872739136 (151.632 examples/sec; 0.330 sec/batch)\n",
      "Top 1 validation accuracy: 0.551886796951294 and top 2 validation accuracy: 0.8113207817077637\n",
      "Model Saved!\n",
      "2019-03-15 22:01:09.782203: step 510, examples 25500, loss = 0.799231827 (154.923 examples/sec; 0.323 sec/batch)\n",
      "2019-03-15 22:01:13.158395: step 520, examples 26000, loss = 0.788317919 (146.038 examples/sec; 0.342 sec/batch)\n",
      "2019-03-15 22:01:16.564377: step 530, examples 26500, loss = 0.676090598 (141.541 examples/sec; 0.353 sec/batch)\n",
      "2019-03-15 22:01:20.027018: step 540, examples 27000, loss = 0.575014949 (135.108 examples/sec; 0.370 sec/batch)\n",
      "2019-03-15 22:01:23.470762: step 550, examples 27500, loss = 0.779325485 (151.859 examples/sec; 0.329 sec/batch)\n",
      "2019-03-15 22:01:26.852151: step 560, examples 28000, loss = 0.523273945 (149.834 examples/sec; 0.334 sec/batch)\n",
      "2019-03-15 22:01:30.229125: step 570, examples 28500, loss = 0.493846238 (154.986 examples/sec; 0.323 sec/batch)\n",
      "2019-03-15 22:01:33.605391: step 580, examples 29000, loss = 0.641466796 (150.216 examples/sec; 0.333 sec/batch)\n",
      "2019-03-15 22:01:37.029192: step 590, examples 29500, loss = 0.722946763 (152.364 examples/sec; 0.328 sec/batch)\n",
      "2019-03-15 22:01:40.393141: step 600, examples 30000, loss = 1.003701687 (150.232 examples/sec; 0.333 sec/batch)\n",
      "Top 1 validation accuracy: 0.551886796951294 and top 2 validation accuracy: 0.7971698045730591\n",
      "Model Saved!\n",
      "2019-03-15 22:01:45.361805: step 610, examples 30500, loss = 0.634168863 (132.548 examples/sec; 0.377 sec/batch)\n",
      "2019-03-15 22:01:48.743151: step 620, examples 31000, loss = 0.486282259 (142.995 examples/sec; 0.350 sec/batch)\n",
      "2019-03-15 22:01:52.141738: step 630, examples 31500, loss = 0.690364599 (145.368 examples/sec; 0.344 sec/batch)\n",
      "2019-03-15 22:01:55.578603: step 640, examples 32000, loss = 0.677260220 (144.414 examples/sec; 0.346 sec/batch)\n",
      "2019-03-15 22:01:59.219364: step 650, examples 32500, loss = 0.610828042 (140.471 examples/sec; 0.356 sec/batch)\n",
      "2019-03-15 22:02:02.643019: step 660, examples 33000, loss = 0.674827993 (147.526 examples/sec; 0.339 sec/batch)\n",
      "2019-03-15 22:02:06.048078: step 670, examples 33500, loss = 0.852558255 (145.439 examples/sec; 0.344 sec/batch)\n",
      "2019-03-15 22:02:09.441348: step 680, examples 34000, loss = 0.648147821 (146.821 examples/sec; 0.341 sec/batch)\n",
      "2019-03-15 22:02:12.797164: step 690, examples 34500, loss = 0.651275992 (149.594 examples/sec; 0.334 sec/batch)\n",
      "2019-03-15 22:02:16.190546: step 700, examples 35000, loss = 0.747437239 (148.932 examples/sec; 0.336 sec/batch)\n",
      "Top 1 validation accuracy: 0.6084905862808228 and top 2 validation accuracy: 0.8113207817077637\n",
      "Model Saved!\n",
      "2019-03-15 22:02:21.247489: step 710, examples 35500, loss = 0.420812607 (147.300 examples/sec; 0.339 sec/batch)\n",
      "2019-03-15 22:02:24.656622: step 720, examples 36000, loss = 0.829252779 (148.420 examples/sec; 0.337 sec/batch)\n",
      "2019-03-15 22:02:28.047940: step 730, examples 36500, loss = 0.663301110 (145.439 examples/sec; 0.344 sec/batch)\n",
      "2019-03-15 22:02:31.408827: step 740, examples 37000, loss = 0.517574489 (146.852 examples/sec; 0.340 sec/batch)\n",
      "2019-03-15 22:02:34.782420: step 750, examples 37500, loss = 0.562609017 (156.691 examples/sec; 0.319 sec/batch)\n",
      "2019-03-15 22:02:38.442498: step 760, examples 38000, loss = 0.649887860 (131.229 examples/sec; 0.381 sec/batch)\n",
      "2019-03-15 22:02:42.393151: step 770, examples 38500, loss = 0.565710843 (124.048 examples/sec; 0.403 sec/batch)\n",
      "2019-03-15 22:02:45.890840: step 780, examples 39000, loss = 0.520814061 (146.948 examples/sec; 0.340 sec/batch)\n",
      "2019-03-15 22:02:49.378383: step 790, examples 39500, loss = 0.530333817 (142.427 examples/sec; 0.351 sec/batch)\n",
      "2019-03-15 22:02:52.766189: step 800, examples 40000, loss = 0.530761003 (146.400 examples/sec; 0.342 sec/batch)\n",
      "Top 1 validation accuracy: 0.5188679099082947 and top 2 validation accuracy: 0.7688679099082947\n",
      "Model Saved!\n",
      "2019-03-15 22:02:57.902919: step 810, examples 40500, loss = 0.423059881 (144.804 examples/sec; 0.345 sec/batch)\n",
      "2019-03-15 22:03:01.220559: step 820, examples 41000, loss = 0.503303289 (151.827 examples/sec; 0.329 sec/batch)\n",
      "2019-03-15 22:03:04.606714: step 830, examples 41500, loss = 0.566028476 (153.981 examples/sec; 0.325 sec/batch)\n",
      "2019-03-15 22:03:08.032271: step 840, examples 42000, loss = 0.610710144 (152.380 examples/sec; 0.328 sec/batch)\n",
      "2019-03-15 22:03:11.702058: step 850, examples 42500, loss = 0.558236718 (106.554 examples/sec; 0.469 sec/batch)\n",
      "2019-03-15 22:03:15.272791: step 860, examples 43000, loss = 0.690283954 (155.165 examples/sec; 0.322 sec/batch)\n",
      "2019-03-15 22:03:18.683552: step 870, examples 43500, loss = 0.523497105 (154.014 examples/sec; 0.325 sec/batch)\n",
      "2019-03-15 22:03:22.142379: step 880, examples 44000, loss = 0.657147765 (144.928 examples/sec; 0.345 sec/batch)\n",
      "2019-03-15 22:03:25.533167: step 890, examples 44500, loss = 0.574288845 (142.449 examples/sec; 0.351 sec/batch)\n",
      "2019-03-15 22:03:28.981812: step 900, examples 45000, loss = 0.446204007 (145.440 examples/sec; 0.344 sec/batch)\n",
      "Top 1 validation accuracy: 0.5 and top 2 validation accuracy: 0.7358490824699402\n",
      "Model Saved!\n",
      "2019-03-15 22:03:34.065741: step 910, examples 45500, loss = 0.575480759 (145.439 examples/sec; 0.344 sec/batch)\n",
      "2019-03-15 22:03:37.462343: step 920, examples 46000, loss = 0.480096519 (148.834 examples/sec; 0.336 sec/batch)\n",
      "2019-03-15 22:03:40.816669: step 930, examples 46500, loss = 0.790306509 (144.460 examples/sec; 0.346 sec/batch)\n",
      "2019-03-15 22:03:44.319407: step 940, examples 47000, loss = 0.534325957 (128.053 examples/sec; 0.390 sec/batch)\n",
      "2019-03-15 22:03:47.976033: step 950, examples 47500, loss = 0.374407768 (136.787 examples/sec; 0.366 sec/batch)\n",
      "2019-03-15 22:03:51.377868: step 960, examples 48000, loss = 0.554771006 (151.426 examples/sec; 0.330 sec/batch)\n",
      "2019-03-15 22:03:54.815502: step 970, examples 48500, loss = 0.662423730 (145.211 examples/sec; 0.344 sec/batch)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2019-03-15 22:03:58.220443: step 980, examples 49000, loss = 0.456899583 (152.029 examples/sec; 0.329 sec/batch)\n",
      "2019-03-15 22:04:01.645290: step 990, examples 49500, loss = 0.551029921 (146.505 examples/sec; 0.341 sec/batch)\n",
      "Top 1 validation accuracy: 0.599056601524353 and top 2 validation accuracy: 0.8113207817077637\n",
      "Model Saved!\n",
      "Loading datasets...\n",
      "Dataset loading completes.\n",
      "2019-03-15 22:04:09.173694: step 0, examples 0, loss = 1.457754254 (66.741 examples/sec; 0.749 sec/batch)\n",
      "Top 1 validation accuracy: 0.25 and top 2 validation accuracy: 0.5094339847564697\n",
      "Model Saved!\n",
      "2019-03-15 22:04:15.015896: step 10, examples 500, loss = 1.435146809 (123.064 examples/sec; 0.406 sec/batch)\n",
      "2019-03-15 22:04:19.124772: step 20, examples 1000, loss = 1.479582429 (123.989 examples/sec; 0.403 sec/batch)\n",
      "2019-03-15 22:04:23.188870: step 30, examples 1500, loss = 1.428952456 (118.824 examples/sec; 0.421 sec/batch)\n",
      "2019-03-15 22:04:27.420458: step 40, examples 2000, loss = 1.454817295 (118.982 examples/sec; 0.420 sec/batch)\n",
      "2019-03-15 22:04:32.228638: step 50, examples 2500, loss = 1.338528872 (116.089 examples/sec; 0.431 sec/batch)\n",
      "2019-03-15 22:04:36.288140: step 60, examples 3000, loss = 1.370473146 (121.756 examples/sec; 0.411 sec/batch)\n",
      "2019-03-15 22:04:40.362343: step 70, examples 3500, loss = 1.336784601 (127.134 examples/sec; 0.393 sec/batch)\n",
      "2019-03-15 22:04:44.377637: step 80, examples 4000, loss = 1.377886534 (127.276 examples/sec; 0.393 sec/batch)\n",
      "2019-03-15 22:04:48.471498: step 90, examples 4500, loss = 1.303643584 (122.524 examples/sec; 0.408 sec/batch)\n",
      "2019-03-15 22:04:53.027141: step 100, examples 5000, loss = 1.476740837 (98.942 examples/sec; 0.505 sec/batch)\n",
      "Top 1 validation accuracy: 0.4433962404727936 and top 2 validation accuracy: 0.6839622855186462\n",
      "Model Saved!\n",
      "2019-03-15 22:04:59.356284: step 110, examples 5500, loss = 1.385517478 (124.914 examples/sec; 0.400 sec/batch)\n",
      "2019-03-15 22:05:03.467069: step 120, examples 6000, loss = 1.315146565 (113.857 examples/sec; 0.439 sec/batch)\n",
      "2019-03-15 22:05:07.546069: step 130, examples 6500, loss = 1.075820088 (123.602 examples/sec; 0.405 sec/batch)\n",
      "2019-03-15 22:05:11.578741: step 140, examples 7000, loss = 1.300436497 (127.629 examples/sec; 0.392 sec/batch)\n",
      "2019-03-15 22:05:15.609796: step 150, examples 7500, loss = 1.329114079 (131.251 examples/sec; 0.381 sec/batch)\n",
      "2019-03-15 22:05:19.677302: step 160, examples 8000, loss = 1.144422293 (117.439 examples/sec; 0.426 sec/batch)\n",
      "2019-03-15 22:05:23.828397: step 170, examples 8500, loss = 1.138079405 (119.197 examples/sec; 0.419 sec/batch)\n",
      "2019-03-15 22:05:28.047216: step 180, examples 9000, loss = 1.363343120 (118.506 examples/sec; 0.422 sec/batch)\n",
      "2019-03-15 22:05:32.139853: step 190, examples 9500, loss = 1.154150367 (122.749 examples/sec; 0.407 sec/batch)\n",
      "2019-03-15 22:05:36.233838: step 200, examples 10000, loss = 1.216637373 (115.273 examples/sec; 0.434 sec/batch)\n",
      "Top 1 validation accuracy: 0.4575471580028534 and top 2 validation accuracy: 0.6745283007621765\n",
      "Model Saved!\n",
      "2019-03-15 22:05:41.969759: step 210, examples 10500, loss = 1.102651238 (123.063 examples/sec; 0.406 sec/batch)\n",
      "2019-03-15 22:05:46.075951: step 220, examples 11000, loss = 0.993045866 (123.088 examples/sec; 0.406 sec/batch)\n",
      "2019-03-15 22:05:50.124315: step 230, examples 11500, loss = 1.020340204 (127.650 examples/sec; 0.392 sec/batch)\n",
      "2019-03-15 22:05:54.263488: step 240, examples 12000, loss = 1.233426094 (119.449 examples/sec; 0.419 sec/batch)\n",
      "2019-03-15 22:05:58.378040: step 250, examples 12500, loss = 1.090499401 (127.101 examples/sec; 0.393 sec/batch)\n",
      "2019-03-15 22:06:02.408943: step 260, examples 13000, loss = 1.139214873 (127.202 examples/sec; 0.393 sec/batch)\n",
      "2019-03-15 22:06:06.463961: step 270, examples 13500, loss = 1.231244922 (115.730 examples/sec; 0.432 sec/batch)\n",
      "2019-03-15 22:06:10.546411: step 280, examples 14000, loss = 1.282783508 (117.961 examples/sec; 0.424 sec/batch)\n",
      "2019-03-15 22:06:14.593999: step 290, examples 14500, loss = 0.920097470 (123.437 examples/sec; 0.405 sec/batch)\n",
      "2019-03-15 22:06:18.625906: step 300, examples 15000, loss = 1.010733008 (123.909 examples/sec; 0.404 sec/batch)\n",
      "Top 1 validation accuracy: 0.4858490526676178 and top 2 validation accuracy: 0.7264150977134705\n",
      "Model Saved!\n",
      "2019-03-15 22:06:24.454067: step 310, examples 15500, loss = 1.251060724 (118.571 examples/sec; 0.422 sec/batch)\n",
      "2019-03-15 22:06:28.540231: step 320, examples 16000, loss = 0.899274766 (115.504 examples/sec; 0.433 sec/batch)\n",
      "2019-03-15 22:06:32.561811: step 330, examples 16500, loss = 0.937350392 (119.193 examples/sec; 0.419 sec/batch)\n",
      "2019-03-15 22:06:36.609574: step 340, examples 17000, loss = 0.822883070 (124.167 examples/sec; 0.403 sec/batch)\n",
      "2019-03-15 22:06:40.734922: step 350, examples 17500, loss = 0.917284667 (120.401 examples/sec; 0.415 sec/batch)\n",
      "2019-03-15 22:06:44.813252: step 360, examples 18000, loss = 0.961652815 (123.585 examples/sec; 0.405 sec/batch)\n",
      "2019-03-15 22:06:48.890664: step 370, examples 18500, loss = 1.122988224 (119.226 examples/sec; 0.419 sec/batch)\n",
      "2019-03-15 22:06:52.922159: step 380, examples 19000, loss = 1.015436888 (123.681 examples/sec; 0.404 sec/batch)\n",
      "2019-03-15 22:06:57.029295: step 390, examples 19500, loss = 0.991825104 (123.064 examples/sec; 0.406 sec/batch)\n",
      "2019-03-15 22:07:01.094430: step 400, examples 20000, loss = 0.883366883 (122.119 examples/sec; 0.409 sec/batch)\n",
      "Top 1 validation accuracy: 0.5188679099082947 and top 2 validation accuracy: 0.7594339847564697\n",
      "Model Saved!\n",
      "2019-03-15 22:07:06.894270: step 410, examples 20500, loss = 0.892986357 (127.529 examples/sec; 0.392 sec/batch)\n",
      "2019-03-15 22:07:10.953687: step 420, examples 21000, loss = 0.942295969 (127.986 examples/sec; 0.391 sec/batch)\n",
      "2019-03-15 22:07:15.078529: step 430, examples 21500, loss = 0.835628211 (123.064 examples/sec; 0.406 sec/batch)\n",
      "2019-03-15 22:07:19.157736: step 440, examples 22000, loss = 0.586115479 (127.840 examples/sec; 0.391 sec/batch)\n",
      "2019-03-15 22:07:23.229677: step 450, examples 22500, loss = 0.720053315 (120.711 examples/sec; 0.414 sec/batch)\n",
      "2019-03-15 22:07:27.270067: step 460, examples 23000, loss = 0.687273026 (121.113 examples/sec; 0.413 sec/batch)\n",
      "2019-03-15 22:07:31.409164: step 470, examples 23500, loss = 0.737438858 (122.278 examples/sec; 0.409 sec/batch)\n",
      "2019-03-15 22:07:35.486714: step 480, examples 24000, loss = 0.707263231 (127.442 examples/sec; 0.392 sec/batch)\n",
      "2019-03-15 22:07:39.543442: step 490, examples 24500, loss = 0.803717852 (119.062 examples/sec; 0.420 sec/batch)\n",
      "2019-03-15 22:07:43.609797: step 500, examples 25000, loss = 0.990534067 (122.807 examples/sec; 0.407 sec/batch)\n",
      "Top 1 validation accuracy: 0.5094339847564697 and top 2 validation accuracy: 0.7641509175300598\n",
      "Model Saved!\n",
      "2019-03-15 22:07:49.378277: step 510, examples 25500, loss = 0.784837723 (118.853 examples/sec; 0.421 sec/batch)\n",
      "2019-03-15 22:07:53.457760: step 520, examples 26000, loss = 0.784037888 (121.993 examples/sec; 0.410 sec/batch)\n",
      "2019-03-15 22:07:57.517630: step 530, examples 26500, loss = 0.980793238 (122.483 examples/sec; 0.408 sec/batch)\n",
      "2019-03-15 22:08:01.641403: step 540, examples 27000, loss = 0.600098729 (124.575 examples/sec; 0.401 sec/batch)\n",
      "2019-03-15 22:08:05.641161: step 550, examples 27500, loss = 0.631692529 (120.567 examples/sec; 0.415 sec/batch)\n",
      "2019-03-15 22:08:09.685240: step 560, examples 28000, loss = 0.736865461 (124.209 examples/sec; 0.403 sec/batch)\n",
      "2019-03-15 22:08:13.717912: step 570, examples 28500, loss = 0.704338312 (124.491 examples/sec; 0.402 sec/batch)\n",
      "2019-03-15 22:08:17.831050: step 580, examples 29000, loss = 0.832339048 (123.110 examples/sec; 0.406 sec/batch)\n",
      "2019-03-15 22:08:21.929141: step 590, examples 29500, loss = 0.834217787 (128.087 examples/sec; 0.390 sec/batch)\n",
      "2019-03-15 22:08:26.013518: step 600, examples 30000, loss = 0.697835743 (123.064 examples/sec; 0.406 sec/batch)\n",
      "Top 1 validation accuracy: 0.6037735939025879 and top 2 validation accuracy: 0.8254716992378235\n",
      "Model Saved!\n",
      "2019-03-15 22:08:31.912396: step 610, examples 30500, loss = 0.547301233 (117.483 examples/sec; 0.426 sec/batch)\n",
      "2019-03-15 22:08:36.000501: step 620, examples 31000, loss = 0.526096642 (123.064 examples/sec; 0.406 sec/batch)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2019-03-15 22:08:40.061385: step 630, examples 31500, loss = 0.812939823 (127.987 examples/sec; 0.391 sec/batch)\n",
      "2019-03-15 22:08:44.173870: step 640, examples 32000, loss = 0.541201711 (114.768 examples/sec; 0.436 sec/batch)\n",
      "2019-03-15 22:08:48.343328: step 650, examples 32500, loss = 0.511578560 (111.903 examples/sec; 0.447 sec/batch)\n",
      "2019-03-15 22:08:52.486368: step 660, examples 33000, loss = 0.583886147 (118.230 examples/sec; 0.423 sec/batch)\n",
      "2019-03-15 22:08:56.545020: step 670, examples 33500, loss = 0.701379061 (124.126 examples/sec; 0.403 sec/batch)\n",
      "2019-03-15 22:09:00.562676: step 680, examples 34000, loss = 0.653021753 (128.455 examples/sec; 0.389 sec/batch)\n",
      "2019-03-15 22:09:04.749982: step 690, examples 34500, loss = 0.590762079 (109.067 examples/sec; 0.458 sec/batch)\n",
      "2019-03-15 22:09:09.019854: step 700, examples 35000, loss = 0.469384104 (125.446 examples/sec; 0.399 sec/batch)\n",
      "Top 1 validation accuracy: 0.5707547068595886 and top 2 validation accuracy: 0.7877358198165894\n",
      "Model Saved!\n",
      "2019-03-15 22:09:14.864924: step 710, examples 35500, loss = 0.530464768 (116.644 examples/sec; 0.429 sec/batch)\n",
      "2019-03-15 22:09:18.955736: step 720, examples 36000, loss = 0.928399384 (119.980 examples/sec; 0.417 sec/batch)\n",
      "2019-03-15 22:09:23.013142: step 730, examples 36500, loss = 0.703916192 (127.976 examples/sec; 0.391 sec/batch)\n",
      "2019-03-15 22:09:27.049278: step 740, examples 37000, loss = 0.643710017 (123.064 examples/sec; 0.406 sec/batch)\n",
      "2019-03-15 22:09:31.153975: step 750, examples 37500, loss = 0.546091020 (116.842 examples/sec; 0.428 sec/batch)\n",
      "2019-03-15 22:09:35.220794: step 760, examples 38000, loss = 0.485093653 (127.401 examples/sec; 0.392 sec/batch)\n",
      "2019-03-15 22:09:39.298068: step 770, examples 38500, loss = 0.764913082 (123.814 examples/sec; 0.404 sec/batch)\n",
      "2019-03-15 22:09:43.397577: step 780, examples 39000, loss = 0.522457302 (116.698 examples/sec; 0.428 sec/batch)\n",
      "2019-03-15 22:09:47.570442: step 790, examples 39500, loss = 0.565937638 (121.041 examples/sec; 0.413 sec/batch)\n",
      "2019-03-15 22:09:51.656676: step 800, examples 40000, loss = 0.626184225 (116.934 examples/sec; 0.428 sec/batch)\n",
      "Top 1 validation accuracy: 0.5471698045730591 and top 2 validation accuracy: 0.7924528121948242\n",
      "Model Saved!\n",
      "2019-03-15 22:09:57.486223: step 810, examples 40500, loss = 0.627178073 (123.576 examples/sec; 0.405 sec/batch)\n",
      "2019-03-15 22:10:01.690489: step 820, examples 41000, loss = 0.493153572 (122.764 examples/sec; 0.407 sec/batch)\n",
      "2019-03-15 22:10:05.846507: step 830, examples 41500, loss = 0.500794232 (128.593 examples/sec; 0.389 sec/batch)\n",
      "2019-03-15 22:10:09.921405: step 840, examples 42000, loss = 0.585737348 (133.951 examples/sec; 0.373 sec/batch)\n",
      "2019-03-15 22:10:13.828301: step 850, examples 42500, loss = 0.587792516 (135.817 examples/sec; 0.368 sec/batch)\n",
      "2019-03-15 22:10:17.788243: step 860, examples 43000, loss = 0.478660285 (126.742 examples/sec; 0.395 sec/batch)\n",
      "2019-03-15 22:10:21.703463: step 870, examples 43500, loss = 0.476365596 (130.280 examples/sec; 0.384 sec/batch)\n",
      "2019-03-15 22:10:25.719645: step 880, examples 44000, loss = 0.552815676 (118.878 examples/sec; 0.421 sec/batch)\n",
      "2019-03-15 22:10:29.609780: step 890, examples 44500, loss = 0.669528544 (126.618 examples/sec; 0.395 sec/batch)\n",
      "2019-03-15 22:10:33.487035: step 900, examples 45000, loss = 0.588186383 (134.032 examples/sec; 0.373 sec/batch)\n",
      "Top 1 validation accuracy: 0.5801886916160583 and top 2 validation accuracy: 0.8349056839942932\n",
      "Model Saved!\n",
      "2019-03-15 22:10:38.924816: step 910, examples 45500, loss = 0.376688898 (132.509 examples/sec; 0.377 sec/batch)\n",
      "2019-03-15 22:10:42.847847: step 920, examples 46000, loss = 0.430943340 (132.654 examples/sec; 0.377 sec/batch)\n",
      "2019-03-15 22:10:46.799724: step 930, examples 46500, loss = 0.449335515 (127.921 examples/sec; 0.391 sec/batch)\n",
      "2019-03-15 22:10:50.722600: step 940, examples 47000, loss = 0.399096251 (133.411 examples/sec; 0.375 sec/batch)\n",
      "2019-03-15 22:10:54.626083: step 950, examples 47500, loss = 0.547489405 (134.835 examples/sec; 0.371 sec/batch)\n",
      "2019-03-15 22:10:58.596475: step 960, examples 48000, loss = 0.739928663 (120.870 examples/sec; 0.414 sec/batch)\n",
      "2019-03-15 22:11:02.486326: step 970, examples 48500, loss = 0.648547888 (130.654 examples/sec; 0.383 sec/batch)\n",
      "2019-03-15 22:11:06.362443: step 980, examples 49000, loss = 0.565568089 (128.278 examples/sec; 0.390 sec/batch)\n",
      "2019-03-15 22:11:10.197614: step 990, examples 49500, loss = 0.578503311 (129.935 examples/sec; 0.385 sec/batch)\n",
      "Top 1 validation accuracy: 0.6084905862808228 and top 2 validation accuracy: 0.8160377144813538\n",
      "Model Saved!\n",
      "Loading datasets...\n",
      "Dataset loading completes.\n",
      "2019-03-15 22:11:18.594555: step 0, examples 0, loss = 1.482170224 (60.838 examples/sec; 0.822 sec/batch)\n",
      "Top 1 validation accuracy: 0.2641509473323822 and top 2 validation accuracy: 0.49056604504585266\n",
      "Model Saved!\n",
      "2019-03-15 22:11:25.047465: step 10, examples 500, loss = 1.490627766 (110.333 examples/sec; 0.453 sec/batch)\n",
      "2019-03-15 22:11:29.703782: step 20, examples 1000, loss = 1.475206614 (109.933 examples/sec; 0.455 sec/batch)\n",
      "2019-03-15 22:11:34.304605: step 30, examples 1500, loss = 1.413310409 (110.668 examples/sec; 0.452 sec/batch)\n",
      "2019-03-15 22:11:38.828709: step 40, examples 2000, loss = 1.335770965 (111.031 examples/sec; 0.450 sec/batch)\n",
      "2019-03-15 22:11:43.424410: step 50, examples 2500, loss = 1.272242665 (105.355 examples/sec; 0.475 sec/batch)\n",
      "2019-03-15 22:11:47.984867: step 60, examples 3000, loss = 1.432707787 (117.647 examples/sec; 0.425 sec/batch)\n",
      "2019-03-15 22:11:52.578639: step 70, examples 3500, loss = 1.456038952 (109.604 examples/sec; 0.456 sec/batch)\n",
      "2019-03-15 22:11:57.171200: step 80, examples 4000, loss = 1.401853085 (113.938 examples/sec; 0.439 sec/batch)\n",
      "2019-03-15 22:12:01.755973: step 90, examples 4500, loss = 1.158787012 (109.162 examples/sec; 0.458 sec/batch)\n",
      "2019-03-15 22:12:06.377596: step 100, examples 5000, loss = 1.230472565 (106.712 examples/sec; 0.469 sec/batch)\n",
      "Top 1 validation accuracy: 0.47641509771347046 and top 2 validation accuracy: 0.6745283007621765\n",
      "Model Saved!\n",
      "2019-03-15 22:12:12.657003: step 110, examples 5500, loss = 1.308810234 (106.870 examples/sec; 0.468 sec/batch)\n",
      "2019-03-15 22:12:17.263120: step 120, examples 6000, loss = 1.160682917 (109.024 examples/sec; 0.459 sec/batch)\n",
      "2019-03-15 22:12:21.847237: step 130, examples 6500, loss = 1.108629704 (114.156 examples/sec; 0.438 sec/batch)\n",
      "2019-03-15 22:12:26.424318: step 140, examples 7000, loss = 1.328313351 (104.399 examples/sec; 0.479 sec/batch)\n",
      "2019-03-15 22:12:30.959353: step 150, examples 7500, loss = 1.165276647 (109.322 examples/sec; 0.457 sec/batch)\n",
      "2019-03-15 22:12:35.578516: step 160, examples 8000, loss = 1.296916842 (110.221 examples/sec; 0.454 sec/batch)\n",
      "2019-03-15 22:12:40.204983: step 170, examples 8500, loss = 1.025292516 (106.799 examples/sec; 0.468 sec/batch)\n",
      "2019-03-15 22:12:44.808158: step 180, examples 9000, loss = 1.173147321 (112.048 examples/sec; 0.446 sec/batch)\n",
      "2019-03-15 22:12:49.465589: step 190, examples 9500, loss = 1.085321069 (107.606 examples/sec; 0.465 sec/batch)\n",
      "2019-03-15 22:12:54.047690: step 200, examples 10000, loss = 1.108926535 (114.274 examples/sec; 0.438 sec/batch)\n",
      "Top 1 validation accuracy: 0.4811320900917053 and top 2 validation accuracy: 0.75\n",
      "Model Saved!\n",
      "2019-03-15 22:13:00.470107: step 210, examples 10500, loss = 1.171856403 (106.484 examples/sec; 0.470 sec/batch)\n",
      "2019-03-15 22:13:05.409533: step 220, examples 11000, loss = 1.215976119 (102.823 examples/sec; 0.486 sec/batch)\n",
      "2019-03-15 22:13:10.141730: step 230, examples 11500, loss = 1.142478228 (106.577 examples/sec; 0.469 sec/batch)\n",
      "2019-03-15 22:13:14.688344: step 240, examples 12000, loss = 1.144077420 (114.733 examples/sec; 0.436 sec/batch)\n",
      "2019-03-15 22:13:19.302805: step 250, examples 12500, loss = 0.947596848 (105.393 examples/sec; 0.474 sec/batch)\n",
      "2019-03-15 22:13:23.922768: step 260, examples 13000, loss = 1.170981646 (109.990 examples/sec; 0.455 sec/batch)\n",
      "2019-03-15 22:13:28.502241: step 270, examples 13500, loss = 1.125253081 (109.864 examples/sec; 0.455 sec/batch)\n",
      "2019-03-15 22:13:33.101720: step 280, examples 14000, loss = 1.160467148 (105.048 examples/sec; 0.476 sec/batch)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2019-03-15 22:13:37.781221: step 290, examples 14500, loss = 1.034456730 (113.460 examples/sec; 0.441 sec/batch)\n",
      "2019-03-15 22:13:42.378236: step 300, examples 15000, loss = 1.153218985 (109.835 examples/sec; 0.455 sec/batch)\n",
      "Top 1 validation accuracy: 0.5235849022865295 and top 2 validation accuracy: 0.7311320900917053\n",
      "Model Saved!\n",
      "2019-03-15 22:13:48.640868: step 310, examples 15500, loss = 0.950036705 (110.710 examples/sec; 0.452 sec/batch)\n",
      "2019-03-15 22:13:53.232592: step 320, examples 16000, loss = 1.031529307 (112.770 examples/sec; 0.443 sec/batch)\n",
      "2019-03-15 22:13:57.812841: step 330, examples 16500, loss = 1.183319926 (110.927 examples/sec; 0.451 sec/batch)\n",
      "2019-03-15 22:14:02.357236: step 340, examples 17000, loss = 1.121684432 (112.222 examples/sec; 0.446 sec/batch)\n",
      "2019-03-15 22:14:06.987679: step 350, examples 17500, loss = 1.265745997 (103.105 examples/sec; 0.485 sec/batch)\n",
      "2019-03-15 22:14:11.594551: step 360, examples 18000, loss = 0.892851532 (110.435 examples/sec; 0.453 sec/batch)\n",
      "2019-03-15 22:14:16.261927: step 370, examples 18500, loss = 1.092043042 (108.255 examples/sec; 0.462 sec/batch)\n",
      "2019-03-15 22:14:20.782789: step 380, examples 19000, loss = 1.102125883 (108.106 examples/sec; 0.463 sec/batch)\n",
      "2019-03-15 22:14:25.393492: step 390, examples 19500, loss = 0.773558676 (108.973 examples/sec; 0.459 sec/batch)\n",
      "2019-03-15 22:14:29.977684: step 400, examples 20000, loss = 0.708725333 (105.192 examples/sec; 0.475 sec/batch)\n",
      "Top 1 validation accuracy: 0.551886796951294 and top 2 validation accuracy: 0.7830188870429993\n",
      "Model Saved!\n",
      "2019-03-15 22:14:36.346751: step 410, examples 20500, loss = 0.793310404 (109.081 examples/sec; 0.458 sec/batch)\n",
      "2019-03-15 22:14:41.028110: step 420, examples 21000, loss = 0.707972229 (106.422 examples/sec; 0.470 sec/batch)\n",
      "2019-03-15 22:14:45.517702: step 430, examples 21500, loss = 0.622042835 (110.022 examples/sec; 0.454 sec/batch)\n",
      "2019-03-15 22:14:50.032028: step 440, examples 22000, loss = 0.838898361 (110.333 examples/sec; 0.453 sec/batch)\n",
      "2019-03-15 22:14:54.641205: step 450, examples 22500, loss = 0.657926977 (110.492 examples/sec; 0.453 sec/batch)\n",
      "2019-03-15 22:14:59.267097: step 460, examples 23000, loss = 0.810059845 (109.827 examples/sec; 0.455 sec/batch)\n",
      "2019-03-15 22:15:03.935514: step 470, examples 23500, loss = 0.817414641 (107.640 examples/sec; 0.465 sec/batch)\n",
      "2019-03-15 22:15:08.486417: step 480, examples 24000, loss = 0.552286148 (110.057 examples/sec; 0.454 sec/batch)\n",
      "2019-03-15 22:15:13.127620: step 490, examples 24500, loss = 0.724613428 (110.532 examples/sec; 0.452 sec/batch)\n",
      "2019-03-15 22:15:17.668636: step 500, examples 25000, loss = 0.843419552 (111.581 examples/sec; 0.448 sec/batch)\n",
      "Top 1 validation accuracy: 0.5330188870429993 and top 2 validation accuracy: 0.7971698045730591\n",
      "Model Saved!\n",
      "2019-03-15 22:15:23.947955: step 510, examples 25500, loss = 0.806321025 (112.193 examples/sec; 0.446 sec/batch)\n",
      "2019-03-15 22:15:28.563229: step 520, examples 26000, loss = 0.611726582 (107.207 examples/sec; 0.466 sec/batch)\n",
      "2019-03-15 22:15:33.157776: step 530, examples 26500, loss = 0.553175271 (106.867 examples/sec; 0.468 sec/batch)\n",
      "2019-03-15 22:15:37.735423: step 540, examples 27000, loss = 0.660011649 (110.437 examples/sec; 0.453 sec/batch)\n",
      "2019-03-15 22:15:42.283129: step 550, examples 27500, loss = 0.614049613 (104.983 examples/sec; 0.476 sec/batch)\n",
      "2019-03-15 22:15:46.922519: step 560, examples 28000, loss = 0.562423468 (115.568 examples/sec; 0.433 sec/batch)\n",
      "2019-03-15 22:15:51.502370: step 570, examples 28500, loss = 0.690755486 (109.849 examples/sec; 0.455 sec/batch)\n",
      "2019-03-15 22:15:55.987169: step 580, examples 29000, loss = 0.674975395 (114.559 examples/sec; 0.436 sec/batch)\n",
      "2019-03-15 22:16:00.685435: step 590, examples 29500, loss = 0.652096927 (105.920 examples/sec; 0.472 sec/batch)\n",
      "2019-03-15 22:16:05.267040: step 600, examples 30000, loss = 0.696288824 (110.386 examples/sec; 0.453 sec/batch)\n",
      "Top 1 validation accuracy: 0.599056601524353 and top 2 validation accuracy: 0.8396226167678833\n",
      "Model Saved!\n",
      "2019-03-15 22:16:11.682467: step 610, examples 30500, loss = 0.562098742 (108.508 examples/sec; 0.461 sec/batch)\n",
      "2019-03-15 22:16:16.353392: step 620, examples 31000, loss = 0.555241346 (102.112 examples/sec; 0.490 sec/batch)\n",
      "2019-03-15 22:16:20.940801: step 630, examples 31500, loss = 0.613205671 (110.187 examples/sec; 0.454 sec/batch)\n",
      "2019-03-15 22:16:25.502628: step 640, examples 32000, loss = 0.683615923 (109.966 examples/sec; 0.455 sec/batch)\n",
      "2019-03-15 22:16:30.122567: step 650, examples 32500, loss = 0.682444572 (110.308 examples/sec; 0.453 sec/batch)\n",
      "2019-03-15 22:16:34.768471: step 660, examples 33000, loss = 0.932789922 (109.991 examples/sec; 0.455 sec/batch)\n",
      "2019-03-15 22:16:39.378022: step 670, examples 33500, loss = 0.743540764 (107.753 examples/sec; 0.464 sec/batch)\n",
      "2019-03-15 22:16:43.970102: step 680, examples 34000, loss = 0.514180064 (110.577 examples/sec; 0.452 sec/batch)\n",
      "2019-03-15 22:16:48.502291: step 690, examples 34500, loss = 0.504240215 (106.212 examples/sec; 0.471 sec/batch)\n",
      "2019-03-15 22:16:53.116007: step 700, examples 35000, loss = 0.691527724 (105.404 examples/sec; 0.474 sec/batch)\n",
      "Top 1 validation accuracy: 0.5283018946647644 and top 2 validation accuracy: 0.7594339847564697\n",
      "Model Saved!\n",
      "2019-03-15 22:16:59.393842: step 710, examples 35500, loss = 0.807473361 (104.974 examples/sec; 0.476 sec/batch)\n",
      "2019-03-15 22:17:03.941678: step 720, examples 36000, loss = 0.620340943 (106.171 examples/sec; 0.471 sec/batch)\n",
      "2019-03-15 22:17:08.609809: step 730, examples 36500, loss = 0.569035769 (114.664 examples/sec; 0.436 sec/batch)\n",
      "2019-03-15 22:17:13.173119: step 740, examples 37000, loss = 0.859796226 (110.285 examples/sec; 0.453 sec/batch)\n",
      "2019-03-15 22:17:17.763273: step 750, examples 37500, loss = 0.619797707 (112.751 examples/sec; 0.443 sec/batch)\n",
      "2019-03-15 22:17:22.362624: step 760, examples 38000, loss = 0.455071926 (115.632 examples/sec; 0.432 sec/batch)\n",
      "2019-03-15 22:17:26.995258: step 770, examples 38500, loss = 0.578271925 (109.479 examples/sec; 0.457 sec/batch)\n",
      "2019-03-15 22:17:31.593955: step 780, examples 39000, loss = 0.749461889 (106.894 examples/sec; 0.468 sec/batch)\n",
      "2019-03-15 22:17:36.184385: step 790, examples 39500, loss = 0.797103643 (107.986 examples/sec; 0.463 sec/batch)\n",
      "2019-03-15 22:17:40.739529: step 800, examples 40000, loss = 0.569526911 (107.252 examples/sec; 0.466 sec/batch)\n",
      "Top 1 validation accuracy: 0.49528300762176514 and top 2 validation accuracy: 0.7783018946647644\n",
      "Model Saved!\n",
      "2019-03-15 22:17:47.115215: step 810, examples 40500, loss = 0.569988787 (105.399 examples/sec; 0.474 sec/batch)\n",
      "2019-03-15 22:17:51.672849: step 820, examples 41000, loss = 0.544179678 (105.907 examples/sec; 0.472 sec/batch)\n",
      "2019-03-15 22:17:56.362784: step 830, examples 41500, loss = 0.468102545 (106.649 examples/sec; 0.469 sec/batch)\n",
      "2019-03-15 22:18:00.992561: step 840, examples 42000, loss = 0.644245267 (114.145 examples/sec; 0.438 sec/batch)\n",
      "2019-03-15 22:18:05.594549: step 850, examples 42500, loss = 0.406430930 (110.038 examples/sec; 0.454 sec/batch)\n",
      "2019-03-15 22:18:10.224557: step 860, examples 43000, loss = 0.616846681 (111.260 examples/sec; 0.449 sec/batch)\n",
      "2019-03-15 22:18:14.779404: step 870, examples 43500, loss = 0.419635653 (107.423 examples/sec; 0.465 sec/batch)\n",
      "2019-03-15 22:18:19.377545: step 880, examples 44000, loss = 0.492528439 (109.234 examples/sec; 0.458 sec/batch)\n",
      "2019-03-15 22:18:24.036006: step 890, examples 44500, loss = 0.428216964 (99.843 examples/sec; 0.501 sec/batch)\n",
      "2019-03-15 22:18:28.609612: step 900, examples 45000, loss = 0.699046850 (106.937 examples/sec; 0.468 sec/batch)\n",
      "Top 1 validation accuracy: 0.5188679099082947 and top 2 validation accuracy: 0.7830188870429993\n",
      "Model Saved!\n",
      "2019-03-15 22:18:34.985384: step 910, examples 45500, loss = 0.469200343 (117.639 examples/sec; 0.425 sec/batch)\n",
      "2019-03-15 22:18:39.534431: step 920, examples 46000, loss = 0.563545227 (113.947 examples/sec; 0.439 sec/batch)\n",
      "2019-03-15 22:18:44.173126: step 930, examples 46500, loss = 0.463131189 (110.306 examples/sec; 0.453 sec/batch)\n",
      "2019-03-15 22:18:48.735151: step 940, examples 47000, loss = 0.622021437 (112.071 examples/sec; 0.446 sec/batch)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2019-03-15 22:18:53.378321: step 950, examples 47500, loss = 0.593931675 (109.886 examples/sec; 0.455 sec/batch)\n",
      "2019-03-15 22:18:58.032071: step 960, examples 48000, loss = 0.503998160 (106.192 examples/sec; 0.471 sec/batch)\n",
      "2019-03-15 22:19:02.656743: step 970, examples 48500, loss = 0.649743676 (103.570 examples/sec; 0.483 sec/batch)\n",
      "2019-03-15 22:19:07.213523: step 980, examples 49000, loss = 0.677944779 (108.547 examples/sec; 0.461 sec/batch)\n",
      "2019-03-15 22:19:11.844939: step 990, examples 49500, loss = 0.552101672 (103.522 examples/sec; 0.483 sec/batch)\n",
      "Top 1 validation accuracy: 0.5235849022865295 and top 2 validation accuracy: 0.7735849022865295\n",
      "Model Saved!\n",
      "Loading datasets...\n",
      "Dataset loading completes.\n",
      "2019-03-15 22:19:20.896782: step 0, examples 0, loss = 1.542200089 (55.802 examples/sec; 0.896 sec/batch)\n",
      "Top 1 validation accuracy: 0.24528302252292633 and top 2 validation accuracy: 0.47641509771347046\n",
      "Model Saved!\n",
      "2019-03-15 22:19:28.157799: step 10, examples 500, loss = 1.507521629 (86.399 examples/sec; 0.579 sec/batch)\n",
      "2019-03-15 22:19:33.377816: step 20, examples 1000, loss = 1.368328571 (96.496 examples/sec; 0.518 sec/batch)\n",
      "2019-03-15 22:19:38.622351: step 30, examples 1500, loss = 1.476536036 (89.684 examples/sec; 0.558 sec/batch)\n",
      "2019-03-15 22:19:43.907276: step 40, examples 2000, loss = 1.354195237 (84.564 examples/sec; 0.591 sec/batch)\n",
      "2019-03-15 22:19:49.188787: step 50, examples 2500, loss = 1.440549612 (100.377 examples/sec; 0.498 sec/batch)\n",
      "2019-03-15 22:19:54.407803: step 60, examples 3000, loss = 1.357343674 (93.996 examples/sec; 0.532 sec/batch)\n",
      "2019-03-15 22:19:59.737393: step 70, examples 3500, loss = 1.348263025 (88.581 examples/sec; 0.564 sec/batch)\n",
      "2019-03-15 22:20:05.047484: step 80, examples 4000, loss = 1.430936575 (100.906 examples/sec; 0.496 sec/batch)\n",
      "2019-03-15 22:20:10.288931: step 90, examples 4500, loss = 1.199298501 (92.951 examples/sec; 0.538 sec/batch)\n",
      "2019-03-15 22:20:15.486506: step 100, examples 5000, loss = 1.188126206 (96.946 examples/sec; 0.516 sec/batch)\n",
      "Top 1 validation accuracy: 0.3962264060974121 and top 2 validation accuracy: 0.6698113083839417\n",
      "Model Saved!\n",
      "2019-03-15 22:20:22.625385: step 110, examples 5500, loss = 1.301447749 (98.643 examples/sec; 0.507 sec/batch)\n",
      "2019-03-15 22:20:27.860220: step 120, examples 6000, loss = 1.253433824 (98.481 examples/sec; 0.508 sec/batch)\n",
      "2019-03-15 22:20:33.142534: step 130, examples 6500, loss = 1.208381176 (96.745 examples/sec; 0.517 sec/batch)\n",
      "2019-03-15 22:20:38.319650: step 140, examples 7000, loss = 1.018725634 (97.783 examples/sec; 0.511 sec/batch)\n",
      "2019-03-15 22:20:43.594184: step 150, examples 7500, loss = 1.010624886 (95.848 examples/sec; 0.522 sec/batch)\n",
      "2019-03-15 22:20:48.857206: step 160, examples 8000, loss = 1.293118834 (96.849 examples/sec; 0.516 sec/batch)\n",
      "2019-03-15 22:20:54.079209: step 170, examples 8500, loss = 1.542350411 (96.953 examples/sec; 0.516 sec/batch)\n",
      "2019-03-15 22:20:59.352663: step 180, examples 9000, loss = 1.164382696 (94.045 examples/sec; 0.532 sec/batch)\n",
      "2019-03-15 22:21:04.656900: step 190, examples 9500, loss = 1.155076027 (94.320 examples/sec; 0.530 sec/batch)\n",
      "2019-03-15 22:21:09.924106: step 200, examples 10000, loss = 1.035211563 (94.248 examples/sec; 0.531 sec/batch)\n",
      "Top 1 validation accuracy: 0.5 and top 2 validation accuracy: 0.75\n",
      "Model Saved!\n",
      "2019-03-15 22:21:17.290328: step 210, examples 10500, loss = 1.011631846 (92.336 examples/sec; 0.542 sec/batch)\n",
      "2019-03-15 22:21:22.674535: step 220, examples 11000, loss = 1.261290669 (92.031 examples/sec; 0.543 sec/batch)\n",
      "2019-03-15 22:21:27.981292: step 230, examples 11500, loss = 1.047870040 (98.051 examples/sec; 0.510 sec/batch)\n",
      "2019-03-15 22:21:33.200297: step 240, examples 12000, loss = 0.939709187 (97.929 examples/sec; 0.511 sec/batch)\n",
      "2019-03-15 22:21:38.470893: step 250, examples 12500, loss = 1.018074989 (95.046 examples/sec; 0.526 sec/batch)\n",
      "2019-03-15 22:21:43.752477: step 260, examples 13000, loss = 1.145086765 (83.485 examples/sec; 0.599 sec/batch)\n",
      "2019-03-15 22:21:49.032016: step 270, examples 13500, loss = 1.061613441 (97.314 examples/sec; 0.514 sec/batch)\n",
      "2019-03-15 22:21:54.393365: step 280, examples 14000, loss = 1.121160746 (93.822 examples/sec; 0.533 sec/batch)\n",
      "2019-03-15 22:21:59.641477: step 290, examples 14500, loss = 1.236656427 (94.172 examples/sec; 0.531 sec/batch)\n",
      "2019-03-15 22:22:04.847205: step 300, examples 15000, loss = 1.246244192 (94.762 examples/sec; 0.528 sec/batch)\n",
      "Top 1 validation accuracy: 0.49528300762176514 and top 2 validation accuracy: 0.7547169923782349\n",
      "Model Saved!\n",
      "2019-03-15 22:22:11.955660: step 310, examples 15500, loss = 1.007900238 (94.239 examples/sec; 0.531 sec/batch)\n",
      "2019-03-15 22:22:17.264695: step 320, examples 16000, loss = 1.420726657 (91.689 examples/sec; 0.545 sec/batch)\n",
      "2019-03-15 22:22:22.424740: step 330, examples 16500, loss = 0.872620106 (96.587 examples/sec; 0.518 sec/batch)\n",
      "2019-03-15 22:22:27.625285: step 340, examples 17000, loss = 0.760454893 (98.418 examples/sec; 0.508 sec/batch)\n",
      "2019-03-15 22:22:32.815428: step 350, examples 17500, loss = 1.072088003 (99.627 examples/sec; 0.502 sec/batch)\n",
      "2019-03-15 22:22:38.063232: step 360, examples 18000, loss = 0.708656907 (99.267 examples/sec; 0.504 sec/batch)\n",
      "2019-03-15 22:22:43.353320: step 370, examples 18500, loss = 0.996307671 (92.856 examples/sec; 0.538 sec/batch)\n",
      "2019-03-15 22:22:48.587123: step 380, examples 19000, loss = 0.909215748 (90.535 examples/sec; 0.552 sec/batch)\n",
      "2019-03-15 22:22:53.869190: step 390, examples 19500, loss = 0.964988410 (96.547 examples/sec; 0.518 sec/batch)\n",
      "2019-03-15 22:22:59.172834: step 400, examples 20000, loss = 0.914178431 (96.961 examples/sec; 0.516 sec/batch)\n",
      "Top 1 validation accuracy: 0.5188679099082947 and top 2 validation accuracy: 0.7735849022865295\n",
      "Model Saved!\n",
      "2019-03-15 22:23:06.173105: step 410, examples 20500, loss = 0.903448343 (91.409 examples/sec; 0.547 sec/batch)\n",
      "2019-03-15 22:23:11.377454: step 420, examples 21000, loss = 0.988219976 (96.099 examples/sec; 0.520 sec/batch)\n",
      "2019-03-15 22:23:16.706201: step 430, examples 21500, loss = 0.991379976 (91.241 examples/sec; 0.548 sec/batch)\n",
      "2019-03-15 22:23:21.924979: step 440, examples 22000, loss = 0.792541146 (94.069 examples/sec; 0.532 sec/batch)\n",
      "2019-03-15 22:23:27.157146: step 450, examples 22500, loss = 0.931758285 (94.092 examples/sec; 0.531 sec/batch)\n",
      "2019-03-15 22:23:32.470905: step 460, examples 23000, loss = 0.863418102 (91.138 examples/sec; 0.549 sec/batch)\n",
      "2019-03-15 22:23:37.672525: step 470, examples 23500, loss = 1.019669771 (94.198 examples/sec; 0.531 sec/batch)\n",
      "2019-03-15 22:23:42.922982: step 480, examples 24000, loss = 0.768027842 (94.472 examples/sec; 0.529 sec/batch)\n",
      "2019-03-15 22:23:48.341754: step 490, examples 24500, loss = 0.829274058 (91.827 examples/sec; 0.545 sec/batch)\n",
      "2019-03-15 22:23:53.641318: step 500, examples 25000, loss = 0.890928864 (96.341 examples/sec; 0.519 sec/batch)\n",
      "Top 1 validation accuracy: 0.5754716992378235 and top 2 validation accuracy: 0.7735849022865295\n",
      "Model Saved!\n",
      "2019-03-15 22:24:00.891523: step 510, examples 25500, loss = 0.800201237 (93.521 examples/sec; 0.535 sec/batch)\n",
      "2019-03-15 22:24:06.141611: step 520, examples 26000, loss = 0.996531963 (96.898 examples/sec; 0.516 sec/batch)\n",
      "2019-03-15 22:24:11.393548: step 530, examples 26500, loss = 0.719214678 (93.762 examples/sec; 0.533 sec/batch)\n",
      "2019-03-15 22:24:16.784012: step 540, examples 27000, loss = 0.740251720 (91.842 examples/sec; 0.544 sec/batch)\n",
      "2019-03-15 22:24:22.290991: step 550, examples 27500, loss = 0.730156481 (91.579 examples/sec; 0.546 sec/batch)\n",
      "2019-03-15 22:24:27.661382: step 560, examples 28000, loss = 0.457022011 (88.885 examples/sec; 0.563 sec/batch)\n",
      "2019-03-15 22:24:33.088822: step 570, examples 28500, loss = 0.735869050 (97.129 examples/sec; 0.515 sec/batch)\n",
      "2019-03-15 22:24:38.377604: step 580, examples 29000, loss = 0.871384978 (93.416 examples/sec; 0.535 sec/batch)\n",
      "2019-03-15 22:24:43.594093: step 590, examples 29500, loss = 0.829220712 (96.988 examples/sec; 0.516 sec/batch)\n",
      "2019-03-15 22:24:48.909296: step 600, examples 30000, loss = 0.810609281 (96.992 examples/sec; 0.516 sec/batch)\n",
      "Top 1 validation accuracy: 0.5754716992378235 and top 2 validation accuracy: 0.7971698045730591\n",
      "Model Saved!\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2019-03-15 22:24:56.102590: step 610, examples 30500, loss = 0.678909361 (92.681 examples/sec; 0.539 sec/batch)\n",
      "2019-03-15 22:25:01.330833: step 620, examples 31000, loss = 0.684697509 (96.758 examples/sec; 0.517 sec/batch)\n",
      "2019-03-15 22:25:06.641424: step 630, examples 31500, loss = 1.054907441 (95.699 examples/sec; 0.522 sec/batch)\n",
      "2019-03-15 22:25:11.893247: step 640, examples 32000, loss = 0.826445699 (91.662 examples/sec; 0.545 sec/batch)\n",
      "2019-03-15 22:25:17.141859: step 650, examples 32500, loss = 0.660133183 (96.956 examples/sec; 0.516 sec/batch)\n",
      "2019-03-15 22:25:22.378328: step 660, examples 33000, loss = 0.578632772 (95.224 examples/sec; 0.525 sec/batch)\n",
      "2019-03-15 22:25:27.640841: step 670, examples 33500, loss = 0.499891728 (94.309 examples/sec; 0.530 sec/batch)\n",
      "2019-03-15 22:25:32.812971: step 680, examples 34000, loss = 0.491972238 (94.347 examples/sec; 0.530 sec/batch)\n",
      "2019-03-15 22:25:38.057030: step 690, examples 34500, loss = 0.696641862 (98.628 examples/sec; 0.507 sec/batch)\n",
      "2019-03-15 22:25:43.424759: step 700, examples 35000, loss = 0.647055268 (91.066 examples/sec; 0.549 sec/batch)\n",
      "Top 1 validation accuracy: 0.5283018946647644 and top 2 validation accuracy: 0.7405660152435303\n",
      "Model Saved!\n",
      "2019-03-15 22:25:50.502240: step 710, examples 35500, loss = 0.778601646 (93.763 examples/sec; 0.533 sec/batch)\n",
      "2019-03-15 22:25:55.876768: step 720, examples 36000, loss = 0.556032062 (95.991 examples/sec; 0.521 sec/batch)\n",
      "2019-03-15 22:26:01.122518: step 730, examples 36500, loss = 0.565724134 (95.987 examples/sec; 0.521 sec/batch)\n",
      "2019-03-15 22:26:06.357216: step 740, examples 37000, loss = 0.441359460 (92.616 examples/sec; 0.540 sec/batch)\n",
      "2019-03-15 22:26:11.721751: step 750, examples 37500, loss = 0.545843840 (91.112 examples/sec; 0.549 sec/batch)\n",
      "2019-03-15 22:26:16.938380: step 760, examples 38000, loss = 0.739528298 (94.507 examples/sec; 0.529 sec/batch)\n",
      "2019-03-15 22:26:22.120520: step 770, examples 38500, loss = 0.523356020 (95.010 examples/sec; 0.526 sec/batch)\n",
      "2019-03-15 22:26:27.409011: step 780, examples 39000, loss = 0.477900565 (97.165 examples/sec; 0.515 sec/batch)\n",
      "2019-03-15 22:26:32.625295: step 790, examples 39500, loss = 0.771396339 (99.837 examples/sec; 0.501 sec/batch)\n",
      "2019-03-15 22:26:37.887042: step 800, examples 40000, loss = 0.572392464 (98.219 examples/sec; 0.509 sec/batch)\n",
      "Top 1 validation accuracy: 0.5188679099082947 and top 2 validation accuracy: 0.7641509175300598\n",
      "Model Saved!\n",
      "2019-03-15 22:26:45.079244: step 810, examples 40500, loss = 0.536724687 (96.953 examples/sec; 0.516 sec/batch)\n",
      "2019-03-15 22:26:50.313224: step 820, examples 41000, loss = 0.515715122 (97.259 examples/sec; 0.514 sec/batch)\n",
      "2019-03-15 22:26:55.542293: step 830, examples 41500, loss = 0.545698345 (97.927 examples/sec; 0.511 sec/batch)\n",
      "2019-03-15 22:27:00.846309: step 840, examples 42000, loss = 0.463126481 (99.338 examples/sec; 0.503 sec/batch)\n",
      "2019-03-15 22:27:06.110143: step 850, examples 42500, loss = 0.606061399 (94.177 examples/sec; 0.531 sec/batch)\n",
      "2019-03-15 22:27:11.358555: step 860, examples 43000, loss = 0.630781054 (97.279 examples/sec; 0.514 sec/batch)\n",
      "2019-03-15 22:27:16.603402: step 870, examples 43500, loss = 0.496437103 (92.552 examples/sec; 0.540 sec/batch)\n",
      "2019-03-15 22:27:21.839845: step 880, examples 44000, loss = 0.446985185 (100.140 examples/sec; 0.499 sec/batch)\n",
      "2019-03-15 22:27:27.075929: step 890, examples 44500, loss = 0.567348301 (92.729 examples/sec; 0.539 sec/batch)\n",
      "2019-03-15 22:27:32.342996: step 900, examples 45000, loss = 0.544833660 (91.707 examples/sec; 0.545 sec/batch)\n",
      "Top 1 validation accuracy: 0.551886796951294 and top 2 validation accuracy: 0.8066037893295288\n",
      "Model Saved!\n",
      "2019-03-15 22:27:39.377590: step 910, examples 45500, loss = 0.552164555 (99.148 examples/sec; 0.504 sec/batch)\n",
      "2019-03-15 22:27:44.847574: step 920, examples 46000, loss = 0.537929118 (93.593 examples/sec; 0.534 sec/batch)\n",
      "2019-03-15 22:27:50.157423: step 930, examples 46500, loss = 0.541078746 (91.410 examples/sec; 0.547 sec/batch)\n",
      "2019-03-15 22:27:55.393567: step 940, examples 47000, loss = 0.523388386 (96.646 examples/sec; 0.517 sec/batch)\n",
      "2019-03-15 22:28:00.656760: step 950, examples 47500, loss = 0.498152673 (89.219 examples/sec; 0.560 sec/batch)\n",
      "2019-03-15 22:28:05.991431: step 960, examples 48000, loss = 0.430862963 (96.037 examples/sec; 0.521 sec/batch)\n",
      "2019-03-15 22:28:11.288301: step 970, examples 48500, loss = 0.436071038 (95.309 examples/sec; 0.525 sec/batch)\n",
      "2019-03-15 22:28:16.610506: step 980, examples 49000, loss = 0.659271598 (89.319 examples/sec; 0.560 sec/batch)\n",
      "2019-03-15 22:28:22.044102: step 990, examples 49500, loss = 0.512059867 (93.297 examples/sec; 0.536 sec/batch)\n",
      "Top 1 validation accuracy: 0.5330188870429993 and top 2 validation accuracy: 0.7547169923782349\n",
      "Model Saved!\n",
      "Loading datasets...\n",
      "Dataset loading completes.\n",
      "2019-03-15 22:28:32.082678: step 0, examples 0, loss = 1.536239028 (50.810 examples/sec; 0.984 sec/batch)\n",
      "Top 1 validation accuracy: 0.25943395495414734 and top 2 validation accuracy: 0.4811320900917053\n",
      "Model Saved!\n",
      "2019-03-15 22:28:40.073111: step 10, examples 500, loss = 1.483351350 (85.236 examples/sec; 0.587 sec/batch)\n",
      "2019-03-15 22:28:45.887011: step 20, examples 1000, loss = 1.468741298 (83.587 examples/sec; 0.598 sec/batch)\n",
      "2019-03-15 22:28:51.783494: step 30, examples 1500, loss = 1.444014430 (86.327 examples/sec; 0.579 sec/batch)\n",
      "2019-03-15 22:28:57.622443: step 40, examples 2000, loss = 1.474410176 (82.906 examples/sec; 0.603 sec/batch)\n",
      "2019-03-15 22:29:03.362439: step 50, examples 2500, loss = 1.473124146 (82.940 examples/sec; 0.603 sec/batch)\n",
      "2019-03-15 22:29:09.267841: step 60, examples 3000, loss = 1.471310854 (86.277 examples/sec; 0.580 sec/batch)\n",
      "2019-03-15 22:29:15.082332: step 70, examples 3500, loss = 1.414364576 (88.632 examples/sec; 0.564 sec/batch)\n",
      "2019-03-15 22:29:20.934871: step 80, examples 4000, loss = 1.399970889 (86.909 examples/sec; 0.575 sec/batch)\n",
      "2019-03-15 22:29:26.721902: step 90, examples 4500, loss = 1.323260307 (86.203 examples/sec; 0.580 sec/batch)\n",
      "2019-03-15 22:29:32.562810: step 100, examples 5000, loss = 1.253627777 (77.211 examples/sec; 0.648 sec/batch)\n",
      "Top 1 validation accuracy: 0.38679245114326477 and top 2 validation accuracy: 0.6650943160057068\n",
      "Model Saved!\n",
      "2019-03-15 22:29:40.358302: step 110, examples 5500, loss = 1.221137404 (84.495 examples/sec; 0.592 sec/batch)\n",
      "2019-03-15 22:29:46.301461: step 120, examples 6000, loss = 1.362076521 (81.567 examples/sec; 0.613 sec/batch)\n",
      "2019-03-15 22:29:52.118478: step 130, examples 6500, loss = 1.272580624 (83.278 examples/sec; 0.600 sec/batch)\n",
      "2019-03-15 22:29:58.007844: step 140, examples 7000, loss = 1.291498303 (88.806 examples/sec; 0.563 sec/batch)\n",
      "2019-03-15 22:30:03.858490: step 150, examples 7500, loss = 1.169216871 (83.537 examples/sec; 0.599 sec/batch)\n",
      "2019-03-15 22:30:09.750504: step 160, examples 8000, loss = 1.149334431 (81.671 examples/sec; 0.612 sec/batch)\n",
      "2019-03-15 22:30:15.501810: step 170, examples 8500, loss = 1.248967886 (84.419 examples/sec; 0.592 sec/batch)\n",
      "2019-03-15 22:30:21.229251: step 180, examples 9000, loss = 1.088047862 (89.755 examples/sec; 0.557 sec/batch)\n",
      "2019-03-15 22:30:27.073624: step 190, examples 9500, loss = 1.262210727 (87.540 examples/sec; 0.571 sec/batch)\n",
      "2019-03-15 22:30:32.841501: step 200, examples 10000, loss = 1.273302197 (86.058 examples/sec; 0.581 sec/batch)\n",
      "Top 1 validation accuracy: 0.46226415038108826 and top 2 validation accuracy: 0.698113203048706\n",
      "Model Saved!\n",
      "2019-03-15 22:30:40.798079: step 210, examples 10500, loss = 1.256154776 (85.882 examples/sec; 0.582 sec/batch)\n",
      "2019-03-15 22:30:46.623149: step 220, examples 11000, loss = 1.114826679 (86.946 examples/sec; 0.575 sec/batch)\n",
      "2019-03-15 22:30:52.471283: step 230, examples 11500, loss = 1.374544144 (84.878 examples/sec; 0.589 sec/batch)\n",
      "2019-03-15 22:30:58.378391: step 240, examples 12000, loss = 1.200404286 (86.285 examples/sec; 0.579 sec/batch)\n",
      "2019-03-15 22:31:04.216365: step 250, examples 12500, loss = 1.004817486 (86.443 examples/sec; 0.578 sec/batch)\n",
      "2019-03-15 22:31:09.935317: step 260, examples 13000, loss = 1.121305704 (89.664 examples/sec; 0.558 sec/batch)\n",
      "2019-03-15 22:31:15.789346: step 270, examples 13500, loss = 0.860882223 (82.995 examples/sec; 0.602 sec/batch)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2019-03-15 22:31:21.594444: step 280, examples 14000, loss = 1.238872290 (84.446 examples/sec; 0.592 sec/batch)\n",
      "2019-03-15 22:31:27.424649: step 290, examples 14500, loss = 1.075294256 (81.725 examples/sec; 0.612 sec/batch)\n",
      "2019-03-15 22:31:33.351918: step 300, examples 15000, loss = 0.924402058 (87.676 examples/sec; 0.570 sec/batch)\n",
      "Top 1 validation accuracy: 0.5188679099082947 and top 2 validation accuracy: 0.7452830076217651\n",
      "Model Saved!\n",
      "2019-03-15 22:31:41.113515: step 310, examples 15500, loss = 1.294166446 (88.998 examples/sec; 0.562 sec/batch)\n",
      "2019-03-15 22:31:47.075166: step 320, examples 16000, loss = 1.055491447 (87.201 examples/sec; 0.573 sec/batch)\n",
      "2019-03-15 22:31:52.891173: step 330, examples 16500, loss = 0.970112503 (90.493 examples/sec; 0.553 sec/batch)\n",
      "2019-03-15 22:31:58.703465: step 340, examples 17000, loss = 0.888216138 (83.822 examples/sec; 0.597 sec/batch)\n",
      "2019-03-15 22:32:04.626060: step 350, examples 17500, loss = 1.259779334 (84.809 examples/sec; 0.590 sec/batch)\n",
      "2019-03-15 22:32:10.501804: step 360, examples 18000, loss = 0.878522277 (84.051 examples/sec; 0.595 sec/batch)\n",
      "2019-03-15 22:32:16.363230: step 370, examples 18500, loss = 0.905401111 (81.629 examples/sec; 0.613 sec/batch)\n",
      "2019-03-15 22:32:22.123450: step 380, examples 19000, loss = 0.832993627 (88.974 examples/sec; 0.562 sec/batch)\n",
      "2019-03-15 22:32:27.877978: step 390, examples 19500, loss = 0.903875351 (82.657 examples/sec; 0.605 sec/batch)\n",
      "2019-03-15 22:32:33.828562: step 400, examples 20000, loss = 1.019198298 (84.410 examples/sec; 0.592 sec/batch)\n",
      "Top 1 validation accuracy: 0.5424528121948242 and top 2 validation accuracy: 0.7547169923782349\n",
      "Model Saved!\n",
      "2019-03-15 22:32:41.603676: step 410, examples 20500, loss = 0.838551223 (85.145 examples/sec; 0.587 sec/batch)\n",
      "2019-03-15 22:32:47.448753: step 420, examples 21000, loss = 0.864467025 (87.596 examples/sec; 0.571 sec/batch)\n",
      "2019-03-15 22:32:53.272123: step 430, examples 21500, loss = 0.789579690 (85.942 examples/sec; 0.582 sec/batch)\n",
      "2019-03-15 22:32:59.112418: step 440, examples 22000, loss = 0.696758986 (84.167 examples/sec; 0.594 sec/batch)\n",
      "2019-03-15 22:33:05.032205: step 450, examples 22500, loss = 0.762327790 (85.971 examples/sec; 0.582 sec/batch)\n",
      "2019-03-15 22:33:10.851986: step 460, examples 23000, loss = 0.687620044 (88.709 examples/sec; 0.564 sec/batch)\n",
      "2019-03-15 22:33:16.643931: step 470, examples 23500, loss = 0.959739983 (81.347 examples/sec; 0.615 sec/batch)\n",
      "2019-03-15 22:33:22.487097: step 480, examples 24000, loss = 0.919334650 (88.641 examples/sec; 0.564 sec/batch)\n",
      "2019-03-15 22:33:28.353262: step 490, examples 24500, loss = 1.018751979 (80.813 examples/sec; 0.619 sec/batch)\n",
      "2019-03-15 22:33:34.304067: step 500, examples 25000, loss = 0.805357337 (86.026 examples/sec; 0.581 sec/batch)\n",
      "Top 1 validation accuracy: 0.5094339847564697 and top 2 validation accuracy: 0.7735849022865295\n",
      "Model Saved!\n",
      "2019-03-15 22:33:42.097335: step 510, examples 25500, loss = 0.846601307 (84.069 examples/sec; 0.595 sec/batch)\n",
      "2019-03-15 22:33:47.927713: step 520, examples 26000, loss = 0.535950840 (87.448 examples/sec; 0.572 sec/batch)\n",
      "2019-03-15 22:33:53.818112: step 530, examples 26500, loss = 0.614293575 (83.569 examples/sec; 0.598 sec/batch)\n",
      "2019-03-15 22:33:59.688185: step 540, examples 27000, loss = 0.997059584 (88.377 examples/sec; 0.566 sec/batch)\n",
      "2019-03-15 22:34:05.518053: step 550, examples 27500, loss = 0.531080186 (83.040 examples/sec; 0.602 sec/batch)\n",
      "2019-03-15 22:34:11.346724: step 560, examples 28000, loss = 0.767252624 (83.904 examples/sec; 0.596 sec/batch)\n",
      "2019-03-15 22:34:17.108751: step 570, examples 28500, loss = 0.390082717 (88.850 examples/sec; 0.563 sec/batch)\n",
      "2019-03-15 22:34:22.830474: step 580, examples 29000, loss = 0.813910306 (88.808 examples/sec; 0.563 sec/batch)\n",
      "2019-03-15 22:34:28.668949: step 590, examples 29500, loss = 0.559677243 (84.705 examples/sec; 0.590 sec/batch)\n",
      "2019-03-15 22:34:34.471343: step 600, examples 30000, loss = 0.683915496 (86.492 examples/sec; 0.578 sec/batch)\n",
      "Top 1 validation accuracy: 0.5471698045730591 and top 2 validation accuracy: 0.7830188870429993\n",
      "Model Saved!\n",
      "2019-03-15 22:34:42.426252: step 610, examples 30500, loss = 0.644926131 (86.192 examples/sec; 0.580 sec/batch)\n",
      "2019-03-15 22:34:48.172910: step 620, examples 31000, loss = 0.600036561 (86.453 examples/sec; 0.578 sec/batch)\n",
      "2019-03-15 22:34:53.968956: step 630, examples 31500, loss = 0.706128716 (86.897 examples/sec; 0.575 sec/batch)\n",
      "2019-03-15 22:34:59.812958: step 640, examples 32000, loss = 0.576813579 (91.803 examples/sec; 0.545 sec/batch)\n",
      "2019-03-15 22:35:05.653782: step 650, examples 32500, loss = 0.518302441 (84.619 examples/sec; 0.591 sec/batch)\n",
      "2019-03-15 22:35:11.487402: step 660, examples 33000, loss = 0.551849663 (83.870 examples/sec; 0.596 sec/batch)\n",
      "2019-03-15 22:35:17.272870: step 670, examples 33500, loss = 0.555140555 (88.486 examples/sec; 0.565 sec/batch)\n",
      "2019-03-15 22:35:23.099124: step 680, examples 34000, loss = 0.539220572 (83.718 examples/sec; 0.597 sec/batch)\n",
      "2019-03-15 22:35:29.081743: step 690, examples 34500, loss = 0.404860854 (84.022 examples/sec; 0.595 sec/batch)\n",
      "2019-03-15 22:35:34.891012: step 700, examples 35000, loss = 0.513686895 (87.599 examples/sec; 0.571 sec/batch)\n",
      "Top 1 validation accuracy: 0.5471698045730591 and top 2 validation accuracy: 0.8160377144813538\n",
      "Model Saved!\n",
      "2019-03-15 22:35:42.653766: step 710, examples 35500, loss = 0.487706065 (83.663 examples/sec; 0.598 sec/batch)\n",
      "2019-03-15 22:35:48.502651: step 720, examples 36000, loss = 0.501517415 (86.134 examples/sec; 0.580 sec/batch)\n",
      "2019-03-15 22:35:54.282294: step 730, examples 36500, loss = 0.607405901 (88.929 examples/sec; 0.562 sec/batch)\n",
      "2019-03-15 22:36:00.170832: step 740, examples 37000, loss = 0.842172861 (82.054 examples/sec; 0.609 sec/batch)\n",
      "2019-03-15 22:36:05.967094: step 750, examples 37500, loss = 0.507499874 (87.113 examples/sec; 0.574 sec/batch)\n",
      "2019-03-15 22:36:11.797799: step 760, examples 38000, loss = 0.602442145 (85.928 examples/sec; 0.582 sec/batch)\n",
      "2019-03-15 22:36:17.640939: step 770, examples 38500, loss = 0.538808048 (84.009 examples/sec; 0.595 sec/batch)\n",
      "2019-03-15 22:36:23.544138: step 780, examples 39000, loss = 0.514057517 (78.692 examples/sec; 0.635 sec/batch)\n",
      "2019-03-15 22:36:29.409088: step 790, examples 39500, loss = 0.564941466 (88.126 examples/sec; 0.567 sec/batch)\n",
      "2019-03-15 22:36:35.355539: step 800, examples 40000, loss = 0.512883902 (84.890 examples/sec; 0.589 sec/batch)\n",
      "Top 1 validation accuracy: 0.5801886916160583 and top 2 validation accuracy: 0.8066037893295288\n",
      "Model Saved!\n",
      "2019-03-15 22:36:43.126254: step 810, examples 40500, loss = 0.701126456 (88.870 examples/sec; 0.563 sec/batch)\n",
      "2019-03-15 22:36:48.954294: step 820, examples 41000, loss = 0.472764671 (86.779 examples/sec; 0.576 sec/batch)\n",
      "2019-03-15 22:36:54.815992: step 830, examples 41500, loss = 0.535310030 (83.901 examples/sec; 0.596 sec/batch)\n",
      "2019-03-15 22:37:00.685197: step 840, examples 42000, loss = 0.648443818 (82.462 examples/sec; 0.606 sec/batch)\n",
      "2019-03-15 22:37:06.517958: step 850, examples 42500, loss = 0.412522972 (86.335 examples/sec; 0.579 sec/batch)\n",
      "2019-03-15 22:37:12.339269: step 860, examples 43000, loss = 0.536689162 (84.913 examples/sec; 0.589 sec/batch)\n",
      "2019-03-15 22:37:18.100380: step 870, examples 43500, loss = 0.472409755 (83.551 examples/sec; 0.598 sec/batch)\n",
      "2019-03-15 22:37:24.035021: step 880, examples 44000, loss = 0.668410897 (88.612 examples/sec; 0.564 sec/batch)\n",
      "2019-03-15 22:37:29.769339: step 890, examples 44500, loss = 0.810458362 (88.597 examples/sec; 0.564 sec/batch)\n",
      "2019-03-15 22:37:35.594779: step 900, examples 45000, loss = 0.386140585 (84.233 examples/sec; 0.594 sec/batch)\n",
      "Top 1 validation accuracy: 0.5613207817077637 and top 2 validation accuracy: 0.7877358198165894\n",
      "Model Saved!\n",
      "2019-03-15 22:37:43.460017: step 910, examples 45500, loss = 0.595817566 (81.203 examples/sec; 0.616 sec/batch)\n",
      "2019-03-15 22:37:49.298168: step 920, examples 46000, loss = 0.385235667 (86.440 examples/sec; 0.578 sec/batch)\n",
      "2019-03-15 22:37:55.217750: step 930, examples 46500, loss = 0.662818134 (84.033 examples/sec; 0.595 sec/batch)\n",
      "2019-03-15 22:38:01.082287: step 940, examples 47000, loss = 0.503958642 (86.251 examples/sec; 0.580 sec/batch)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2019-03-15 22:38:06.891025: step 950, examples 47500, loss = 0.623467922 (89.465 examples/sec; 0.559 sec/batch)\n",
      "2019-03-15 22:38:12.799268: step 960, examples 48000, loss = 0.585890710 (84.008 examples/sec; 0.595 sec/batch)\n",
      "2019-03-15 22:38:18.638560: step 970, examples 48500, loss = 0.461982131 (81.788 examples/sec; 0.611 sec/batch)\n",
      "2019-03-15 22:38:24.561037: step 980, examples 49000, loss = 0.425914586 (76.439 examples/sec; 0.654 sec/batch)\n",
      "2019-03-15 22:38:30.408691: step 990, examples 49500, loss = 0.570369422 (85.755 examples/sec; 0.583 sec/batch)\n",
      "Top 1 validation accuracy: 0.5896226167678833 and top 2 validation accuracy: 0.8066037893295288\n",
      "Model Saved!\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "filter_size = [8,8,9,9,10,10]\n",
    "j=0\n",
    "best_val = {}\n",
    "for tl in range(500,1001,100):\n",
    "    num_cls = 4\n",
    "    mstp = 1000\n",
    "    lfrq = 10\n",
    "    bsz = 50\n",
    "    msf = 100\n",
    "    tr = './trained_model_final/DCNN_reg_t'+str(tl)\n",
    "    os.mkdir(tr)\n",
    "    start = 0\n",
    "    stop = tl\n",
    "    step = 100\n",
    "    time_length = tl\n",
    "    fsz = filter_size[j]\n",
    "    j = j+1\n",
    "    use_batchnorm = True\n",
    "    use_dropout = True\n",
    "    use_l2loss = True\n",
    "    acc = 'Accuracy'+str(tl)\n",
    "    path = 'Path'+str(tl)\n",
    "\n",
    "    best_val[acc],best_val[path] = train_model_tb(tr,start,stop,step,time_length,fsz,use_batchnorm,use_dropout,use_l2loss,num_cls,mstp,lfrq,bsz,msf)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "#best model is 601\n",
    "\n",
    "def test_model_tb(model_dir,start,stop,step,time_length,fsz,use_batchnorm,use_dropout,use_l2loss):\n",
    "    print(\"Loading datasets...\")\n",
    "    trainSet, testSet, valSet, labelNames = data_loader_tb(time_length)\n",
    "    print(\"Dataset loading completes.\")\n",
    "    \n",
    "    # reset default graph\n",
    "    tf.reset_default_graph()\n",
    "    \n",
    "    # create model\n",
    "    \n",
    "    model = Model(config, labelNames,start,stop,step,time_length,fsz,use_batchnorm,use_dropout,use_l2loss)\n",
    "    # training setups\n",
    "    saver = tf.train.Saver(max_to_keep=100)\n",
    "    test_accuracy = [0, 0]\n",
    "    \n",
    "    config_proto = tf.ConfigProto()\n",
    "\n",
    "    off = rewriter_config_pb2.RewriterConfig.OFF\n",
    "    config_proto.graph_options.rewrite_options.arithmetic_optimization = off\n",
    "\n",
    "    with tf.Session(config=config_proto) as session:\n",
    "        session.run(tf.global_variables_initializer())\n",
    "        saver.restore(session, model_dir)\n",
    "        # test model\n",
    "        exp_results = run_single_step(session, model, testSet, mode='test')\n",
    "        test_accuracy[0] = exp_results['top_1_accuracy']\n",
    "        test_accuracy[1] = exp_results['top_2_accuracy']\n",
    "        print('top_1_accuracy_test = ', test_accuracy[0], 'top_2_accuracy_test = ', test_accuracy[1])\n",
    "        \n",
    "    top1_acc = test_accuracy[0]\n",
    "    top2_acc = test_accuracy[1]\n",
    "    return top1_acc,top2_acc\n",
    "\n",
    "\n",
    "def run_single_step(\n",
    "        session,\n",
    "        model,\n",
    "        batch,\n",
    "        mode='test',\n",
    "        log=True,\n",
    "):\n",
    "    # construct feed dict\n",
    "    feed_dict = {\n",
    "        model.input: batch['data'],\n",
    "        # model.coarse_labels: batch['coarse_labels'],\n",
    "        model.fine_labels: batch['labels'],\n",
    "        # model.label_mapping: label_mapping,\n",
    "        model.is_training: mode == 'train'\n",
    "    }\n",
    "    \n",
    "    # select proper summary op\n",
    "    if mode == 'train':\n",
    "        summary_op = model.train_summary_op\n",
    "    elif mode == 'val':\n",
    "        summary_op = model.val_summary_op\n",
    "    else:\n",
    "        summary_op = model.test_summary_op\n",
    "    \n",
    "    # construct fetch list\n",
    "    fetch_list = [model.global_step, summary_op, model.loss, model.accuracy, model.top_2_accuracy]\n",
    "\n",
    "    # run single step\n",
    "    _start_time = time.time()\n",
    "    _step, _summary, _loss, _top_1, _top_2 = session.run(fetch_list, feed_dict=feed_dict)[:5]\n",
    "    _end_time = time.time()\n",
    "    \n",
    "    # collect step statistics\n",
    "    step_time = _end_time - _start_time\n",
    "    batch_size = batch['data'].shape[0]\n",
    "    \n",
    "    # log in console\n",
    "    if log:\n",
    "        print(('[{:5s} step {:4d}] loss: {:.5f}; top_1_accuracy: {:.5f}; top_5_accuracy: {:5f} ' +\n",
    "              '({:.3f} sec/batch; {:.3f} instances/sec)'\n",
    "              ).format(mode, _step, _loss, _top_1, _top_2, \n",
    "                       step_time, batch_size / step_time))\n",
    "    \n",
    "    # log results to file and return statistics\n",
    "    if mode == 'test':\n",
    "        test_fetch_list = [model.per_class_accuracy,\n",
    "                model.top_2_per_class_accuracy,\n",
    "                model.confusion_matrix, \n",
    "                model.pred, model.probs]\n",
    "        _top_1_c,  _top_2_c, _cm, _pred, _probs = \\\n",
    "                session.run(test_fetch_list, feed_dict=feed_dict)\n",
    "        \n",
    "        \n",
    "        # Log detailed test results in pickle format\n",
    "        stats = {\n",
    "            \"loss\": _loss,\n",
    "            \"top_1_accuracy\": _top_1,\n",
    "            \"top_2_accuracy\": _top_2,\n",
    "            \"top_1_perclass_accuracy\": _top_1_c,\n",
    "            \"top_2_perclass_accuracy\": _top_2_c,\n",
    "            \"confusion_matrix\": _cm,\n",
    "            \"pred\": _pred,\n",
    "            \"probs\": _probs\n",
    "        }\n",
    "    else:\n",
    "        stats = {\n",
    "            \"step\": _step,\n",
    "            \"loss\": _loss,\n",
    "            \"top_1_accuracy\": _top_1,\n",
    "            \"top_2_accuracy\": _top_2\n",
    "        }\n",
    "        \n",
    "    return stats"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "#best model is 601\n",
    "\n",
    "def val_model_tb(model_dir,start,stop,step,time_length,fsz,use_batchnorm,use_dropout,use_l2loss):\n",
    "    print(\"Loading datasets...\")\n",
    "    trainSet, testSet, valSet, labelNames = data_loader_tb(time_length)\n",
    "    print(\"Dataset loading completes.\")\n",
    "    \n",
    "    # reset default graph\n",
    "    tf.reset_default_graph()\n",
    "    \n",
    "    # create model\n",
    "    \n",
    "    model = Model(config, labelNames,start,stop,step,time_length,fsz,use_batchnorm,use_dropout,use_l2loss)\n",
    "    # training setups\n",
    "    saver = tf.train.Saver(max_to_keep=100)\n",
    "    val_accuracy = [0, 0]\n",
    "    \n",
    "    config_proto = tf.ConfigProto()\n",
    "\n",
    "    off = rewriter_config_pb2.RewriterConfig.OFF\n",
    "    config_proto.graph_options.rewrite_options.arithmetic_optimization = off\n",
    "\n",
    "    with tf.Session(config=config_proto) as session:\n",
    "        session.run(tf.global_variables_initializer())\n",
    "        saver.restore(session, model_dir)\n",
    "        # test model\n",
    "        exp_results = run_single_step(session, model, valSet, mode='val')\n",
    "        val_accuracy[0] = exp_results['top_1_accuracy']\n",
    "        val_accuracy[1] = exp_results['top_2_accuracy']\n",
    "        print('top_1_accuracy_val = ', val_accuracy[0], 'top_2_accuracy_val = ', val_accuracy[1])\n",
    "        \n",
    "    top1_acc = val_accuracy[0]\n",
    "    top2_acc = val_accuracy[1]\n",
    "    return top1_acc,top2_acc\n",
    "\n",
    "\n",
    "def run_single_step(\n",
    "        session,\n",
    "        model,\n",
    "        batch,\n",
    "        mode='test',\n",
    "        log=True,\n",
    "):\n",
    "    # construct feed dict\n",
    "    feed_dict = {\n",
    "        model.input: batch['data'],\n",
    "        # model.coarse_labels: batch['coarse_labels'],\n",
    "        model.fine_labels: batch['labels'],\n",
    "        # model.label_mapping: label_mapping,\n",
    "        model.is_training: mode == 'train'\n",
    "    }\n",
    "    \n",
    "    # select proper summary op\n",
    "    if mode == 'train':\n",
    "        summary_op = model.train_summary_op\n",
    "    elif mode == 'val':\n",
    "        summary_op = model.val_summary_op\n",
    "    else:\n",
    "        summary_op = model.test_summary_op\n",
    "    \n",
    "    # construct fetch list\n",
    "    fetch_list = [model.global_step, summary_op, model.loss, model.accuracy, model.top_2_accuracy]\n",
    "\n",
    "    # run single step\n",
    "    _start_time = time.time()\n",
    "    _step, _summary, _loss, _top_1, _top_2 = session.run(fetch_list, feed_dict=feed_dict)[:5]\n",
    "    _end_time = time.time()\n",
    "    \n",
    "    # collect step statistics\n",
    "    step_time = _end_time - _start_time\n",
    "    batch_size = batch['data'].shape[0]\n",
    "    \n",
    "    # log in console\n",
    "    if log:\n",
    "        print(('[{:5s} step {:4d}] loss: {:.5f}; top_1_accuracy: {:.5f}; top_5_accuracy: {:5f} ' +\n",
    "              '({:.3f} sec/batch; {:.3f} instances/sec)'\n",
    "              ).format(mode, _step, _loss, _top_1, _top_2, \n",
    "                       step_time, batch_size / step_time))\n",
    "    \n",
    "    # log results to file and return statistics\n",
    "    if mode == 'test':\n",
    "        test_fetch_list = [model.per_class_accuracy,\n",
    "                model.top_2_per_class_accuracy,\n",
    "                model.confusion_matrix, \n",
    "                model.pred, model.probs]\n",
    "        _top_1_c,  _top_2_c, _cm, _pred, _probs = \\\n",
    "                session.run(test_fetch_list, feed_dict=feed_dict)\n",
    "        \n",
    "        \n",
    "        # Log detailed test results in pickle format\n",
    "        stats = {\n",
    "            \"loss\": _loss,\n",
    "            \"top_1_accuracy\": _top_1,\n",
    "            \"top_2_accuracy\": _top_2,\n",
    "            \"top_1_perclass_accuracy\": _top_1_c,\n",
    "            \"top_2_perclass_accuracy\": _top_2_c,\n",
    "            \"confusion_matrix\": _cm,\n",
    "            \"pred\": _pred,\n",
    "            \"probs\": _probs\n",
    "        }\n",
    "    else:\n",
    "        stats = {\n",
    "            \"step\": _step,\n",
    "            \"loss\": _loss,\n",
    "            \"top_1_accuracy\": _top_1,\n",
    "            \"top_2_accuracy\": _top_2\n",
    "        }\n",
    "        \n",
    "    return stats"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading datasets...\n",
      "Dataset loading completes.\n",
      "INFO:tensorflow:Restoring parameters from ./trained_model_final/DCNN_reg_t500/model.ckpt-1\n",
      "[val   step    1] loss: 1.47676; top_1_accuracy: 0.20755; top_5_accuracy: 0.490566 (0.445 sec/batch; 476.317 instances/sec)\n",
      "top_1_accuracy_val =  0.20754717 top_2_accuracy_val =  0.49056605\n",
      "Loading datasets...\n",
      "Dataset loading completes.\n",
      "INFO:tensorflow:Restoring parameters from ./trained_model_final/DCNN_reg_t500/model.ckpt-101\n",
      "[val   step  101] loss: 1.39558; top_1_accuracy: 0.41509; top_5_accuracy: 0.674528 (0.430 sec/batch; 492.657 instances/sec)\n",
      "top_1_accuracy_val =  0.41509435 top_2_accuracy_val =  0.6745283\n",
      "Loading datasets...\n",
      "Dataset loading completes.\n",
      "INFO:tensorflow:Restoring parameters from ./trained_model_final/DCNN_reg_t500/model.ckpt-201\n",
      "[val   step  201] loss: 1.28704; top_1_accuracy: 0.49057; top_5_accuracy: 0.740566 (0.426 sec/batch; 497.584 instances/sec)\n",
      "top_1_accuracy_val =  0.49056605 top_2_accuracy_val =  0.740566\n",
      "Loading datasets...\n",
      "Dataset loading completes.\n",
      "INFO:tensorflow:Restoring parameters from ./trained_model_final/DCNN_reg_t500/model.ckpt-301\n",
      "[val   step  301] loss: 1.35243; top_1_accuracy: 0.49528; top_5_accuracy: 0.740566 (0.480 sec/batch; 441.376 instances/sec)\n",
      "top_1_accuracy_val =  0.495283 top_2_accuracy_val =  0.740566\n",
      "Loading datasets...\n",
      "Dataset loading completes.\n",
      "INFO:tensorflow:Restoring parameters from ./trained_model_final/DCNN_reg_t500/model.ckpt-401\n",
      "[val   step  401] loss: 1.37112; top_1_accuracy: 0.51887; top_5_accuracy: 0.764151 (0.427 sec/batch; 496.803 instances/sec)\n",
      "top_1_accuracy_val =  0.5188679 top_2_accuracy_val =  0.7641509\n",
      "Loading datasets...\n",
      "Dataset loading completes.\n",
      "INFO:tensorflow:Restoring parameters from ./trained_model_final/DCNN_reg_t500/model.ckpt-501\n",
      "[val   step  501] loss: 1.19216; top_1_accuracy: 0.56604; top_5_accuracy: 0.830189 (0.448 sec/batch; 472.942 instances/sec)\n",
      "top_1_accuracy_val =  0.5660377 top_2_accuracy_val =  0.8301887\n",
      "Loading datasets...\n",
      "Dataset loading completes.\n",
      "INFO:tensorflow:Restoring parameters from ./trained_model_final/DCNN_reg_t500/model.ckpt-601\n",
      "[val   step  601] loss: 1.27992; top_1_accuracy: 0.57547; top_5_accuracy: 0.797170 (0.433 sec/batch; 489.910 instances/sec)\n",
      "top_1_accuracy_val =  0.5754717 top_2_accuracy_val =  0.7971698\n",
      "Loading datasets...\n",
      "Dataset loading completes.\n",
      "INFO:tensorflow:Restoring parameters from ./trained_model_final/DCNN_reg_t500/model.ckpt-701\n",
      "[val   step  701] loss: 1.38747; top_1_accuracy: 0.53302; top_5_accuracy: 0.811321 (0.426 sec/batch; 497.421 instances/sec)\n",
      "top_1_accuracy_val =  0.5330189 top_2_accuracy_val =  0.8113208\n",
      "Loading datasets...\n",
      "Dataset loading completes.\n",
      "INFO:tensorflow:Restoring parameters from ./trained_model_final/DCNN_reg_t500/model.ckpt-801\n",
      "[val   step  801] loss: 1.58647; top_1_accuracy: 0.53302; top_5_accuracy: 0.735849 (0.423 sec/batch; 500.935 instances/sec)\n",
      "top_1_accuracy_val =  0.5330189 top_2_accuracy_val =  0.7358491\n",
      "Loading datasets...\n",
      "Dataset loading completes.\n",
      "INFO:tensorflow:Restoring parameters from ./trained_model_final/DCNN_reg_t500/model.ckpt-901\n",
      "[val   step  901] loss: 1.58667; top_1_accuracy: 0.55189; top_5_accuracy: 0.792453 (0.433 sec/batch; 489.190 instances/sec)\n",
      "top_1_accuracy_val =  0.5518868 top_2_accuracy_val =  0.7924528\n",
      "Loading datasets...\n",
      "Dataset loading completes.\n",
      "INFO:tensorflow:Restoring parameters from ./trained_model_final/DCNN_reg_t500/model.ckpt-1000\n",
      "[val   step 1000] loss: 1.55549; top_1_accuracy: 0.52358; top_5_accuracy: 0.787736 (0.414 sec/batch; 512.401 instances/sec)\n",
      "top_1_accuracy_val =  0.5235849 top_2_accuracy_val =  0.7877358\n",
      "Loading datasets...\n",
      "Dataset loading completes.\n",
      "INFO:tensorflow:Restoring parameters from ./trained_model_final/DCNN_reg_t600/model.ckpt-1\n",
      "[val   step    1] loss: 1.48458; top_1_accuracy: 0.26887; top_5_accuracy: 0.528302 (0.484 sec/batch; 437.765 instances/sec)\n",
      "top_1_accuracy_val =  0.2688679 top_2_accuracy_val =  0.5283019\n",
      "Loading datasets...\n",
      "Dataset loading completes.\n",
      "INFO:tensorflow:Restoring parameters from ./trained_model_final/DCNN_reg_t600/model.ckpt-101\n",
      "[val   step  101] loss: 1.35280; top_1_accuracy: 0.45755; top_5_accuracy: 0.674528 (0.495 sec/batch; 428.206 instances/sec)\n",
      "top_1_accuracy_val =  0.45754716 top_2_accuracy_val =  0.6745283\n",
      "Loading datasets...\n",
      "Dataset loading completes.\n",
      "INFO:tensorflow:Restoring parameters from ./trained_model_final/DCNN_reg_t600/model.ckpt-201\n",
      "[val   step  201] loss: 1.31571; top_1_accuracy: 0.47642; top_5_accuracy: 0.707547 (0.496 sec/batch; 427.360 instances/sec)\n",
      "top_1_accuracy_val =  0.4764151 top_2_accuracy_val =  0.7075472\n",
      "Loading datasets...\n",
      "Dataset loading completes.\n",
      "INFO:tensorflow:Restoring parameters from ./trained_model_final/DCNN_reg_t600/model.ckpt-301\n",
      "[val   step  301] loss: 1.29280; top_1_accuracy: 0.57075; top_5_accuracy: 0.768868 (0.505 sec/batch; 419.542 instances/sec)\n",
      "top_1_accuracy_val =  0.5707547 top_2_accuracy_val =  0.7688679\n",
      "Loading datasets...\n",
      "Dataset loading completes.\n",
      "INFO:tensorflow:Restoring parameters from ./trained_model_final/DCNN_reg_t600/model.ckpt-401\n",
      "[val   step  401] loss: 1.23783; top_1_accuracy: 0.53302; top_5_accuracy: 0.797170 (0.490 sec/batch; 432.326 instances/sec)\n",
      "top_1_accuracy_val =  0.5330189 top_2_accuracy_val =  0.7971698\n",
      "Loading datasets...\n",
      "Dataset loading completes.\n",
      "INFO:tensorflow:Restoring parameters from ./trained_model_final/DCNN_reg_t600/model.ckpt-501\n",
      "[val   step  501] loss: 1.42300; top_1_accuracy: 0.55189; top_5_accuracy: 0.801887 (0.501 sec/batch; 422.872 instances/sec)\n",
      "top_1_accuracy_val =  0.5518868 top_2_accuracy_val =  0.8018868\n",
      "Loading datasets...\n",
      "Dataset loading completes.\n",
      "INFO:tensorflow:Restoring parameters from ./trained_model_final/DCNN_reg_t600/model.ckpt-601\n",
      "[val   step  601] loss: 1.49556; top_1_accuracy: 0.50000; top_5_accuracy: 0.811321 (0.508 sec/batch; 417.414 instances/sec)\n",
      "top_1_accuracy_val =  0.5 top_2_accuracy_val =  0.8113208\n",
      "Loading datasets...\n",
      "Dataset loading completes.\n",
      "INFO:tensorflow:Restoring parameters from ./trained_model_final/DCNN_reg_t600/model.ckpt-701\n",
      "[val   step  701] loss: 1.31418; top_1_accuracy: 0.63208; top_5_accuracy: 0.825472 (0.539 sec/batch; 393.372 instances/sec)\n",
      "top_1_accuracy_val =  0.6320755 top_2_accuracy_val =  0.8254717\n",
      "Loading datasets...\n",
      "Dataset loading completes.\n",
      "INFO:tensorflow:Restoring parameters from ./trained_model_final/DCNN_reg_t600/model.ckpt-801\n",
      "[val   step  801] loss: 1.44062; top_1_accuracy: 0.54717; top_5_accuracy: 0.787736 (0.499 sec/batch; 424.566 instances/sec)\n",
      "top_1_accuracy_val =  0.5471698 top_2_accuracy_val =  0.7877358\n",
      "Loading datasets...\n",
      "Dataset loading completes.\n",
      "INFO:tensorflow:Restoring parameters from ./trained_model_final/DCNN_reg_t600/model.ckpt-901\n",
      "[val   step  901] loss: 1.71335; top_1_accuracy: 0.52358; top_5_accuracy: 0.740566 (0.474 sec/batch; 446.872 instances/sec)\n",
      "top_1_accuracy_val =  0.5235849 top_2_accuracy_val =  0.740566\n",
      "Loading datasets...\n",
      "Dataset loading completes.\n",
      "INFO:tensorflow:Restoring parameters from ./trained_model_final/DCNN_reg_t600/model.ckpt-1000\n",
      "[val   step 1000] loss: 1.55180; top_1_accuracy: 0.58962; top_5_accuracy: 0.816038 (0.481 sec/batch; 441.116 instances/sec)\n",
      "top_1_accuracy_val =  0.5896226 top_2_accuracy_val =  0.8160377\n",
      "Loading datasets...\n",
      "Dataset loading completes.\n",
      "INFO:tensorflow:Restoring parameters from ./trained_model_final/DCNN_reg_t700/model.ckpt-1\n",
      "[val   step    1] loss: 1.51659; top_1_accuracy: 0.21698; top_5_accuracy: 0.500000 (0.588 sec/batch; 360.548 instances/sec)\n",
      "top_1_accuracy_val =  0.21698113 top_2_accuracy_val =  0.5\n",
      "Loading datasets...\n",
      "Dataset loading completes.\n",
      "INFO:tensorflow:Restoring parameters from ./trained_model_final/DCNN_reg_t700/model.ckpt-101\n",
      "[val   step  101] loss: 1.33358; top_1_accuracy: 0.42925; top_5_accuracy: 0.669811 (0.594 sec/batch; 357.157 instances/sec)\n",
      "top_1_accuracy_val =  0.4292453 top_2_accuracy_val =  0.6698113\n",
      "Loading datasets...\n",
      "Dataset loading completes.\n",
      "INFO:tensorflow:Restoring parameters from ./trained_model_final/DCNN_reg_t700/model.ckpt-201\n",
      "[val   step  201] loss: 1.27431; top_1_accuracy: 0.50000; top_5_accuracy: 0.726415 (0.557 sec/batch; 380.437 instances/sec)\n",
      "top_1_accuracy_val =  0.5 top_2_accuracy_val =  0.7264151\n",
      "Loading datasets...\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dataset loading completes.\n",
      "INFO:tensorflow:Restoring parameters from ./trained_model_final/DCNN_reg_t700/model.ckpt-301\n",
      "[val   step  301] loss: 1.26042; top_1_accuracy: 0.51887; top_5_accuracy: 0.764151 (0.543 sec/batch; 390.532 instances/sec)\n",
      "top_1_accuracy_val =  0.5188679 top_2_accuracy_val =  0.7641509\n",
      "Loading datasets...\n",
      "Dataset loading completes.\n",
      "INFO:tensorflow:Restoring parameters from ./trained_model_final/DCNN_reg_t700/model.ckpt-401\n",
      "[val   step  401] loss: 1.22889; top_1_accuracy: 0.55660; top_5_accuracy: 0.792453 (0.591 sec/batch; 358.979 instances/sec)\n",
      "top_1_accuracy_val =  0.5566038 top_2_accuracy_val =  0.7924528\n",
      "Loading datasets...\n",
      "Dataset loading completes.\n",
      "INFO:tensorflow:Restoring parameters from ./trained_model_final/DCNN_reg_t700/model.ckpt-501\n",
      "[val   step  501] loss: 1.36093; top_1_accuracy: 0.53774; top_5_accuracy: 0.759434 (0.551 sec/batch; 384.965 instances/sec)\n",
      "top_1_accuracy_val =  0.5377358 top_2_accuracy_val =  0.759434\n",
      "Loading datasets...\n",
      "Dataset loading completes.\n",
      "INFO:tensorflow:Restoring parameters from ./trained_model_final/DCNN_reg_t700/model.ckpt-601\n",
      "[val   step  601] loss: 1.23337; top_1_accuracy: 0.59434; top_5_accuracy: 0.801887 (0.532 sec/batch; 398.278 instances/sec)\n",
      "top_1_accuracy_val =  0.5943396 top_2_accuracy_val =  0.8018868\n",
      "Loading datasets...\n",
      "Dataset loading completes.\n",
      "INFO:tensorflow:Restoring parameters from ./trained_model_final/DCNN_reg_t700/model.ckpt-701\n",
      "[val   step  701] loss: 1.49289; top_1_accuracy: 0.55660; top_5_accuracy: 0.764151 (0.549 sec/batch; 386.409 instances/sec)\n",
      "top_1_accuracy_val =  0.5566038 top_2_accuracy_val =  0.7641509\n",
      "Loading datasets...\n",
      "Dataset loading completes.\n",
      "INFO:tensorflow:Restoring parameters from ./trained_model_final/DCNN_reg_t700/model.ckpt-801\n",
      "[val   step  801] loss: 1.58976; top_1_accuracy: 0.52830; top_5_accuracy: 0.797170 (0.573 sec/batch; 369.776 instances/sec)\n",
      "top_1_accuracy_val =  0.5283019 top_2_accuracy_val =  0.7971698\n",
      "Loading datasets...\n",
      "Dataset loading completes.\n",
      "INFO:tensorflow:Restoring parameters from ./trained_model_final/DCNN_reg_t700/model.ckpt-901\n",
      "[val   step  901] loss: 1.63584; top_1_accuracy: 0.57547; top_5_accuracy: 0.773585 (0.571 sec/batch; 371.257 instances/sec)\n",
      "top_1_accuracy_val =  0.5754717 top_2_accuracy_val =  0.7735849\n",
      "Loading datasets...\n",
      "Dataset loading completes.\n",
      "INFO:tensorflow:Restoring parameters from ./trained_model_final/DCNN_reg_t700/model.ckpt-1000\n",
      "[val   step 1000] loss: 1.70243; top_1_accuracy: 0.56132; top_5_accuracy: 0.773585 (0.631 sec/batch; 335.966 instances/sec)\n",
      "top_1_accuracy_val =  0.5613208 top_2_accuracy_val =  0.7735849\n",
      "Loading datasets...\n",
      "Dataset loading completes.\n",
      "INFO:tensorflow:Restoring parameters from ./trained_model_final/DCNN_reg_t800/model.ckpt-1\n",
      "[val   step    1] loss: 1.50804; top_1_accuracy: 0.25943; top_5_accuracy: 0.490566 (0.667 sec/batch; 317.674 instances/sec)\n",
      "top_1_accuracy_val =  0.25943395 top_2_accuracy_val =  0.49056605\n",
      "Loading datasets...\n",
      "Dataset loading completes.\n",
      "INFO:tensorflow:Restoring parameters from ./trained_model_final/DCNN_reg_t800/model.ckpt-101\n",
      "[val   step  101] loss: 1.41227; top_1_accuracy: 0.42925; top_5_accuracy: 0.646226 (0.645 sec/batch; 328.890 instances/sec)\n",
      "top_1_accuracy_val =  0.4292453 top_2_accuracy_val =  0.6462264\n",
      "Loading datasets...\n",
      "Dataset loading completes.\n",
      "INFO:tensorflow:Restoring parameters from ./trained_model_final/DCNN_reg_t800/model.ckpt-201\n",
      "[val   step  201] loss: 1.27140; top_1_accuracy: 0.49057; top_5_accuracy: 0.731132 (0.645 sec/batch; 328.845 instances/sec)\n",
      "top_1_accuracy_val =  0.49056605 top_2_accuracy_val =  0.7311321\n",
      "Loading datasets...\n",
      "Dataset loading completes.\n",
      "INFO:tensorflow:Restoring parameters from ./trained_model_final/DCNN_reg_t800/model.ckpt-301\n",
      "[val   step  301] loss: 1.28575; top_1_accuracy: 0.54245; top_5_accuracy: 0.783019 (0.620 sec/batch; 341.781 instances/sec)\n",
      "top_1_accuracy_val =  0.5424528 top_2_accuracy_val =  0.7830189\n",
      "Loading datasets...\n",
      "Dataset loading completes.\n",
      "INFO:tensorflow:Restoring parameters from ./trained_model_final/DCNN_reg_t800/model.ckpt-401\n",
      "[val   step  401] loss: 1.37534; top_1_accuracy: 0.54245; top_5_accuracy: 0.787736 (0.671 sec/batch; 315.994 instances/sec)\n",
      "top_1_accuracy_val =  0.5424528 top_2_accuracy_val =  0.7877358\n",
      "Loading datasets...\n",
      "Dataset loading completes.\n",
      "INFO:tensorflow:Restoring parameters from ./trained_model_final/DCNN_reg_t800/model.ckpt-501\n",
      "[val   step  501] loss: 1.37150; top_1_accuracy: 0.53774; top_5_accuracy: 0.787736 (0.762 sec/batch; 278.311 instances/sec)\n",
      "top_1_accuracy_val =  0.5377358 top_2_accuracy_val =  0.7877358\n",
      "Loading datasets...\n",
      "Dataset loading completes.\n",
      "INFO:tensorflow:Restoring parameters from ./trained_model_final/DCNN_reg_t800/model.ckpt-601\n",
      "[val   step  601] loss: 1.40753; top_1_accuracy: 0.56132; top_5_accuracy: 0.754717 (0.658 sec/batch; 322.336 instances/sec)\n",
      "top_1_accuracy_val =  0.5613208 top_2_accuracy_val =  0.754717\n",
      "Loading datasets...\n",
      "Dataset loading completes.\n",
      "INFO:tensorflow:Restoring parameters from ./trained_model_final/DCNN_reg_t800/model.ckpt-701\n",
      "[val   step  701] loss: 1.53975; top_1_accuracy: 0.52358; top_5_accuracy: 0.825472 (0.656 sec/batch; 323.013 instances/sec)\n",
      "top_1_accuracy_val =  0.5235849 top_2_accuracy_val =  0.8254717\n",
      "Loading datasets...\n",
      "Dataset loading completes.\n",
      "INFO:tensorflow:Restoring parameters from ./trained_model_final/DCNN_reg_t800/model.ckpt-801\n",
      "[val   step  801] loss: 1.70845; top_1_accuracy: 0.54245; top_5_accuracy: 0.783019 (0.659 sec/batch; 321.703 instances/sec)\n",
      "top_1_accuracy_val =  0.5424528 top_2_accuracy_val =  0.7830189\n",
      "Loading datasets...\n",
      "Dataset loading completes.\n",
      "INFO:tensorflow:Restoring parameters from ./trained_model_final/DCNN_reg_t800/model.ckpt-901\n",
      "[val   step  901] loss: 2.04697; top_1_accuracy: 0.54717; top_5_accuracy: 0.778302 (0.656 sec/batch; 323.324 instances/sec)\n",
      "top_1_accuracy_val =  0.5471698 top_2_accuracy_val =  0.7783019\n",
      "Loading datasets...\n",
      "Dataset loading completes.\n",
      "INFO:tensorflow:Restoring parameters from ./trained_model_final/DCNN_reg_t800/model.ckpt-1000\n",
      "[val   step 1000] loss: 1.74855; top_1_accuracy: 0.57075; top_5_accuracy: 0.797170 (0.643 sec/batch; 329.671 instances/sec)\n",
      "top_1_accuracy_val =  0.5707547 top_2_accuracy_val =  0.7971698\n",
      "Loading datasets...\n",
      "Dataset loading completes.\n",
      "INFO:tensorflow:Restoring parameters from ./trained_model_final/DCNN_reg_t900/model.ckpt-1\n",
      "[val   step    1] loss: 1.54062; top_1_accuracy: 0.27830; top_5_accuracy: 0.495283 (0.856 sec/batch; 247.697 instances/sec)\n",
      "top_1_accuracy_val =  0.2783019 top_2_accuracy_val =  0.495283\n",
      "Loading datasets...\n",
      "Dataset loading completes.\n",
      "INFO:tensorflow:Restoring parameters from ./trained_model_final/DCNN_reg_t900/model.ckpt-101\n",
      "[val   step  101] loss: 1.43791; top_1_accuracy: 0.42925; top_5_accuracy: 0.660377 (0.757 sec/batch; 280.177 instances/sec)\n",
      "top_1_accuracy_val =  0.4292453 top_2_accuracy_val =  0.6603774\n",
      "Loading datasets...\n",
      "Dataset loading completes.\n",
      "INFO:tensorflow:Restoring parameters from ./trained_model_final/DCNN_reg_t900/model.ckpt-201\n",
      "[val   step  201] loss: 1.34897; top_1_accuracy: 0.49528; top_5_accuracy: 0.735849 (0.729 sec/batch; 291.000 instances/sec)\n",
      "top_1_accuracy_val =  0.495283 top_2_accuracy_val =  0.7358491\n",
      "Loading datasets...\n",
      "Dataset loading completes.\n",
      "INFO:tensorflow:Restoring parameters from ./trained_model_final/DCNN_reg_t900/model.ckpt-301\n",
      "[val   step  301] loss: 1.34901; top_1_accuracy: 0.52358; top_5_accuracy: 0.778302 (0.740 sec/batch; 286.378 instances/sec)\n",
      "top_1_accuracy_val =  0.5235849 top_2_accuracy_val =  0.7783019\n",
      "Loading datasets...\n",
      "Dataset loading completes.\n",
      "INFO:tensorflow:Restoring parameters from ./trained_model_final/DCNN_reg_t900/model.ckpt-401\n",
      "[val   step  401] loss: 1.43551; top_1_accuracy: 0.54245; top_5_accuracy: 0.750000 (0.737 sec/batch; 287.641 instances/sec)\n",
      "top_1_accuracy_val =  0.5424528 top_2_accuracy_val =  0.75\n",
      "Loading datasets...\n",
      "Dataset loading completes.\n",
      "INFO:tensorflow:Restoring parameters from ./trained_model_final/DCNN_reg_t900/model.ckpt-501\n",
      "[val   step  501] loss: 1.47025; top_1_accuracy: 0.48585; top_5_accuracy: 0.754717 (0.723 sec/batch; 293.280 instances/sec)\n",
      "top_1_accuracy_val =  0.48584905 top_2_accuracy_val =  0.754717\n",
      "Loading datasets...\n",
      "Dataset loading completes.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Restoring parameters from ./trained_model_final/DCNN_reg_t900/model.ckpt-601\n",
      "[val   step  601] loss: 1.44636; top_1_accuracy: 0.54717; top_5_accuracy: 0.759434 (0.706 sec/batch; 300.459 instances/sec)\n",
      "top_1_accuracy_val =  0.5471698 top_2_accuracy_val =  0.759434\n",
      "Loading datasets...\n",
      "Dataset loading completes.\n",
      "INFO:tensorflow:Restoring parameters from ./trained_model_final/DCNN_reg_t900/model.ckpt-701\n",
      "[val   step  701] loss: 1.66897; top_1_accuracy: 0.50472; top_5_accuracy: 0.750000 (0.704 sec/batch; 301.283 instances/sec)\n",
      "top_1_accuracy_val =  0.504717 top_2_accuracy_val =  0.75\n",
      "Loading datasets...\n",
      "Dataset loading completes.\n",
      "INFO:tensorflow:Restoring parameters from ./trained_model_final/DCNN_reg_t900/model.ckpt-801\n",
      "[val   step  801] loss: 1.68642; top_1_accuracy: 0.54245; top_5_accuracy: 0.759434 (0.686 sec/batch; 309.089 instances/sec)\n",
      "top_1_accuracy_val =  0.5424528 top_2_accuracy_val =  0.759434\n",
      "Loading datasets...\n",
      "Dataset loading completes.\n",
      "INFO:tensorflow:Restoring parameters from ./trained_model_final/DCNN_reg_t900/model.ckpt-901\n",
      "[val   step  901] loss: 1.71960; top_1_accuracy: 0.55660; top_5_accuracy: 0.773585 (0.701 sec/batch; 302.346 instances/sec)\n",
      "top_1_accuracy_val =  0.5566038 top_2_accuracy_val =  0.7735849\n",
      "Loading datasets...\n",
      "Dataset loading completes.\n",
      "INFO:tensorflow:Restoring parameters from ./trained_model_final/DCNN_reg_t900/model.ckpt-1000\n",
      "[val   step 1000] loss: 1.79094; top_1_accuracy: 0.56604; top_5_accuracy: 0.787736 (0.713 sec/batch; 297.208 instances/sec)\n",
      "top_1_accuracy_val =  0.5660377 top_2_accuracy_val =  0.7877358\n",
      "Loading datasets...\n",
      "Dataset loading completes.\n",
      "INFO:tensorflow:Restoring parameters from ./trained_model_final/DCNN_reg_t1000/model.ckpt-1\n",
      "[val   step    1] loss: 1.54193; top_1_accuracy: 0.23585; top_5_accuracy: 0.481132 (0.776 sec/batch; 273.138 instances/sec)\n",
      "top_1_accuracy_val =  0.23584905 top_2_accuracy_val =  0.4811321\n",
      "Loading datasets...\n",
      "Dataset loading completes.\n",
      "INFO:tensorflow:Restoring parameters from ./trained_model_final/DCNN_reg_t1000/model.ckpt-101\n",
      "[val   step  101] loss: 1.39077; top_1_accuracy: 0.41981; top_5_accuracy: 0.712264 (0.778 sec/batch; 272.418 instances/sec)\n",
      "top_1_accuracy_val =  0.4198113 top_2_accuracy_val =  0.7122642\n",
      "Loading datasets...\n",
      "Dataset loading completes.\n",
      "INFO:tensorflow:Restoring parameters from ./trained_model_final/DCNN_reg_t1000/model.ckpt-201\n",
      "[val   step  201] loss: 1.43938; top_1_accuracy: 0.45283; top_5_accuracy: 0.683962 (0.795 sec/batch; 266.795 instances/sec)\n",
      "top_1_accuracy_val =  0.4528302 top_2_accuracy_val =  0.6839623\n",
      "Loading datasets...\n",
      "Dataset loading completes.\n",
      "INFO:tensorflow:Restoring parameters from ./trained_model_final/DCNN_reg_t1000/model.ckpt-301\n",
      "[val   step  301] loss: 1.45787; top_1_accuracy: 0.50000; top_5_accuracy: 0.679245 (0.770 sec/batch; 275.389 instances/sec)\n",
      "top_1_accuracy_val =  0.5 top_2_accuracy_val =  0.6792453\n",
      "Loading datasets...\n",
      "Dataset loading completes.\n",
      "INFO:tensorflow:Restoring parameters from ./trained_model_final/DCNN_reg_t1000/model.ckpt-401\n",
      "[val   step  401] loss: 1.38571; top_1_accuracy: 0.52830; top_5_accuracy: 0.797170 (0.769 sec/batch; 275.670 instances/sec)\n",
      "top_1_accuracy_val =  0.5283019 top_2_accuracy_val =  0.7971698\n",
      "Loading datasets...\n",
      "Dataset loading completes.\n",
      "INFO:tensorflow:Restoring parameters from ./trained_model_final/DCNN_reg_t1000/model.ckpt-501\n",
      "[val   step  501] loss: 1.44456; top_1_accuracy: 0.51415; top_5_accuracy: 0.783019 (0.769 sec/batch; 275.651 instances/sec)\n",
      "top_1_accuracy_val =  0.5141509 top_2_accuracy_val =  0.7830189\n",
      "Loading datasets...\n",
      "Dataset loading completes.\n",
      "INFO:tensorflow:Restoring parameters from ./trained_model_final/DCNN_reg_t1000/model.ckpt-601\n",
      "[val   step  601] loss: 1.61945; top_1_accuracy: 0.47642; top_5_accuracy: 0.792453 (0.771 sec/batch; 274.800 instances/sec)\n",
      "top_1_accuracy_val =  0.4764151 top_2_accuracy_val =  0.7924528\n",
      "Loading datasets...\n",
      "Dataset loading completes.\n",
      "INFO:tensorflow:Restoring parameters from ./trained_model_final/DCNN_reg_t1000/model.ckpt-701\n",
      "[val   step  701] loss: 1.60511; top_1_accuracy: 0.54717; top_5_accuracy: 0.778302 (0.752 sec/batch; 281.825 instances/sec)\n",
      "top_1_accuracy_val =  0.5471698 top_2_accuracy_val =  0.7783019\n",
      "Loading datasets...\n",
      "Dataset loading completes.\n",
      "INFO:tensorflow:Restoring parameters from ./trained_model_final/DCNN_reg_t1000/model.ckpt-801\n",
      "[val   step  801] loss: 1.82634; top_1_accuracy: 0.53774; top_5_accuracy: 0.783019 (0.759 sec/batch; 279.137 instances/sec)\n",
      "top_1_accuracy_val =  0.5377358 top_2_accuracy_val =  0.7830189\n",
      "Loading datasets...\n",
      "Dataset loading completes.\n",
      "INFO:tensorflow:Restoring parameters from ./trained_model_final/DCNN_reg_t1000/model.ckpt-901\n",
      "[val   step  901] loss: 1.80400; top_1_accuracy: 0.55189; top_5_accuracy: 0.825472 (0.752 sec/batch; 281.774 instances/sec)\n",
      "top_1_accuracy_val =  0.5518868 top_2_accuracy_val =  0.8254717\n",
      "Loading datasets...\n",
      "Dataset loading completes.\n",
      "INFO:tensorflow:Restoring parameters from ./trained_model_final/DCNN_reg_t1000/model.ckpt-1000\n",
      "[val   step 1000] loss: 1.86208; top_1_accuracy: 0.59434; top_5_accuracy: 0.797170 (0.762 sec/batch; 278.188 instances/sec)\n",
      "top_1_accuracy_val =  0.5943396 top_2_accuracy_val =  0.7971698\n"
     ]
    }
   ],
   "source": [
    "best_val = {}\n",
    "mod_num= np.arange(1,902,100)\n",
    "ns = mod_num.shape\n",
    "mod_num = np.insert(mod_num,ns,1000,axis=0)\n",
    "filter_size = [8,8,9,9,10,10]\n",
    "j=0\n",
    "for tl in range(500,1001,100):\n",
    "    acc = 'Accuracy'+str(tl)\n",
    "    path = 'Path'+str(tl)\n",
    "    start = 0\n",
    "    stop = tl\n",
    "    step = 100\n",
    "    time_length = tl\n",
    "    #Nb = BATCH_SIZE\n",
    "    fsz = filter_size[j]\n",
    "    j = j+1\n",
    "    use_batchnorm = True\n",
    "    use_dropout = True\n",
    "    use_l2loss = True\n",
    "    best_val_acc = 0\n",
    "    best_val_path = '.'\n",
    "    for mn in mod_num:\n",
    "        model_dir = './trained_model_final/DCNN_reg_t'+str(tl)+'/model.ckpt-'+str(mn)\n",
    "        top_1_acc_val, top_2_acc_val = val_model_tb(model_dir,start,stop,step,time_length,fsz,use_batchnorm,use_dropout,use_l2loss)\n",
    "        if top_1_acc_val>best_val_acc:\n",
    "            best_val_acc = top_1_acc_val\n",
    "            best_val_path = model_dir\n",
    "    best_val[acc] = best_val_acc\n",
    "    best_val[path] = best_val_path"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy for Time bin: 500\n",
      "Loading datasets...\n",
      "Dataset loading completes.\n",
      "INFO:tensorflow:Restoring parameters from ./trained_model_final/DCNN_reg_t500/model.ckpt-601\n",
      "[test  step  601] loss: 1.29574; top_1_accuracy: 0.54853; top_5_accuracy: 0.778781 (0.806 sec/batch; 549.542 instances/sec)\n",
      "top_1_accuracy_test =  0.5485327 top_2_accuracy_test =  0.77878106\n",
      "Accuracy for Time bin: 600\n",
      "Loading datasets...\n",
      "Dataset loading completes.\n",
      "INFO:tensorflow:Restoring parameters from ./trained_model_final/DCNN_reg_t600/model.ckpt-701\n",
      "[test  step  701] loss: 1.30332; top_1_accuracy: 0.57336; top_5_accuracy: 0.830700 (0.953 sec/batch; 464.765 instances/sec)\n",
      "top_1_accuracy_test =  0.5733634 top_2_accuracy_test =  0.8306998\n",
      "Accuracy for Time bin: 700\n",
      "Loading datasets...\n",
      "Dataset loading completes.\n",
      "INFO:tensorflow:Restoring parameters from ./trained_model_final/DCNN_reg_t700/model.ckpt-601\n",
      "[test  step  601] loss: 1.38312; top_1_accuracy: 0.58239; top_5_accuracy: 0.819413 (1.121 sec/batch; 395.199 instances/sec)\n",
      "top_1_accuracy_test =  0.58239275 top_2_accuracy_test =  0.81941307\n",
      "Accuracy for Time bin: 800\n",
      "Loading datasets...\n",
      "Dataset loading completes.\n",
      "INFO:tensorflow:Restoring parameters from ./trained_model_final/DCNN_reg_t800/model.ckpt-1000\n",
      "[test  step 1000] loss: 1.75755; top_1_accuracy: 0.56208; top_5_accuracy: 0.799097 (1.287 sec/batch; 344.187 instances/sec)\n",
      "top_1_accuracy_test =  0.56207675 top_2_accuracy_test =  0.79909706\n",
      "Accuracy for Time bin: 900\n",
      "Loading datasets...\n",
      "Dataset loading completes.\n",
      "INFO:tensorflow:Restoring parameters from ./trained_model_final/DCNN_reg_t900/model.ckpt-1000\n",
      "[test  step 1000] loss: 1.74670; top_1_accuracy: 0.56433; top_5_accuracy: 0.814898 (1.433 sec/batch; 309.086 instances/sec)\n",
      "top_1_accuracy_test =  0.5643341 top_2_accuracy_test =  0.81489843\n",
      "Accuracy for Time bin: 1000\n",
      "Loading datasets...\n",
      "Dataset loading completes.\n",
      "INFO:tensorflow:Restoring parameters from ./trained_model_final/DCNN_reg_t1000/model.ckpt-1000\n",
      "[test  step 1000] loss: 1.76987; top_1_accuracy: 0.57788; top_5_accuracy: 0.810384 (1.568 sec/batch; 282.467 instances/sec)\n",
      "top_1_accuracy_test =  0.5778781 top_2_accuracy_test =  0.81038374\n",
      "The time bin 700 has the best test accuracy: 0.5823927521705627\n"
     ]
    }
   ],
   "source": [
    "# Accuracy for testSet(best)\n",
    "filter_size = [8,8,9,9,10,10]\n",
    "j=0\n",
    "best_test_acc = 0\n",
    "best_test_time_bin = 500\n",
    "for tl in range(500,1001,100):\n",
    "    path = 'Path'+str(tl)\n",
    "    model_dir = best_val[path]\n",
    "    start = 0\n",
    "    stop = tl\n",
    "    step = 100\n",
    "    time_length = tl\n",
    "    #Nb = BATCH_SIZE\n",
    "    fsz = filter_size[j]\n",
    "    j = j+1\n",
    "    use_batchnorm = True\n",
    "    use_dropout = True\n",
    "    use_l2loss = True\n",
    "    print('Accuracy for Time bin: {}'.format(tl))\n",
    "    top_1_acc_test, top_2_acc_test = test_model_tb(model_dir,start,stop,step,time_length,fsz,use_batchnorm,use_dropout,use_l2loss)\n",
    "    if top_1_acc_test > best_test_acc:\n",
    "        best_test_acc = top_1_acc_test\n",
    "        best_test_time_bin = tl\n",
    "\n",
    "print('The time bin {} has the best test accuracy: {}'.format(best_test_time_bin,best_test_acc))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "def data_loader_ds(time_bin,ds):\n",
    "    X_test = np.load(\"X_test.npy\")\n",
    "    X_test = X_test[:,0:22,0:time_bin:ds]\n",
    "    y_test = np.load(\"y_test.npy\")\n",
    "    person_test = np.load(\"person_test.npy\")\n",
    "\n",
    "    X_train_valid = np.load(\"X_train_valid.npy\")\n",
    "    X_train_valid = X_train_valid[:,0:22,0:time_bin:ds]\n",
    "    y_train_valid = np.load(\"y_train_valid.npy\")\n",
    "    person_train_valid = np.load(\"person_train_valid.npy\")\n",
    "    \n",
    "    N_train = X_train_valid.shape[0]\n",
    "    idx_train_valid = np.arange(N_train,dtype='int')\n",
    "\n",
    "    X_train, X_val, idx_train, idx_val = train_test_split(X_train_valid, idx_train_valid, test_size=0.1, random_state=21)\n",
    "\n",
    "    y_train = y_train_valid[idx_train]\n",
    "    person_train = person_train_valid[idx_train]\n",
    "    y_val = y_train_valid[idx_val]\n",
    "    person_val = person_train_valid[idx_val]\n",
    "\n",
    "    tl = X_train.shape[2]\n",
    "    X_test = np.reshape(X_test,(-1,22,tl,1))\n",
    "    X_train = np.reshape(X_train,(-1,22,tl,1))\n",
    "    X_val = np.reshape(X_val,(-1,22,tl,1))\n",
    "\n",
    "    label0 = 769\n",
    "    new_label0 = 0\n",
    "    for i in range(4):\n",
    "        m1 = (y_test==label0)\n",
    "        m2 = (y_train==label0)\n",
    "        m3 = (y_val==label0)\n",
    "        np.place(y_test,m1,new_label0)\n",
    "        np.place(y_train,m2,new_label0)\n",
    "        np.place(y_val,m3,new_label0)\n",
    "        label0 += 1\n",
    "        new_label0 += 1\n",
    "\n",
    "    labelNames = [0,1,2,3]\n",
    "    train_set = {'data': X_train, 'labels': y_train, 'person': person_train}\n",
    "    test_set = {'data': X_test, 'labels': y_test, 'person': person_test}\n",
    "    val_set = {'data': X_val, 'labels': y_val, 'person': person_val}\n",
    "    return train_set, test_set, val_set, labelNames\n",
    "\n",
    "\n",
    "def sample_batch(dataset, batch_size):\n",
    "    N = dataset['data'].shape[0]\n",
    "    indices = np.random.randint(N, size=batch_size)\n",
    "    return {key: dataset[key][indices] for key in dataset}\n",
    "\n",
    "def train_model_ds(target_dir,start,stop,step,time_length,fsz,use_batchnorm,use_dropout,use_l2loss,num_class,max_step,log_frequency,batch_size,model_saving_freq,ds):\n",
    "    # load data\n",
    "    print(\"Loading datasets...\")\n",
    "    trainSet, testSet, valSet, labelNames = data_loader_ds(time_length,ds)\n",
    "    print(\"Dataset loading completes.\")\n",
    "    \n",
    "    best_val_acc = 0\n",
    "    best_val_path = target_dir\n",
    "    \n",
    "    time_bin = trainSet['data'].shape[2]\n",
    "    stop = trainSet['data'].shape[2]\n",
    "\n",
    "    # reset default graph\n",
    "    tf.reset_default_graph()\n",
    "\n",
    "    global_step = tf.train.get_or_create_global_step()\n",
    "    \n",
    "    model = Model(config, labelNames,start,stop,step,time_bin,fsz,use_batchnorm,use_dropout,use_l2loss)\n",
    "\n",
    "    # training setups\n",
    "    saver = tf.train.Saver(max_to_keep=100)\n",
    "\n",
    "    # Build an initialization operation to run below.\n",
    "    init = tf.global_variables_initializer()\n",
    "    \n",
    "    config_proto = tf.ConfigProto()\n",
    "\n",
    "    off = rewriter_config_pb2.RewriterConfig.OFF\n",
    "    config_proto.graph_options.rewrite_options.arithmetic_optimization = off\n",
    "    \n",
    "    sess = tf.Session(config=config_proto)\n",
    "\n",
    "    sess.run(init)\n",
    "\n",
    "    # main loop\n",
    "    for step in range(max_step):\n",
    "        start_time = time.time()\n",
    "\n",
    "        # prepare data\n",
    "        train_batch = sample_batch(trainSet, batch_size)\n",
    "        # feed dict\n",
    "        feed_dict = {\n",
    "            model.input: train_batch['data'],\n",
    "            model.fine_labels: train_batch['labels'],\n",
    "            model.is_training: True,\n",
    "        }\n",
    "        \n",
    "        fetch_list = [model.optimizer_op, model.loss, model.global_step]\n",
    "        _, loss_value, global_step_value = sess.run(fetch_list, feed_dict=feed_dict)\n",
    "        duration = time.time() - start_time\n",
    "        assert not np.isnan(loss_value), 'Model diverged with loss = NaN'\n",
    "\n",
    "        # log\n",
    "        if step % log_frequency == 0:\n",
    "            num_examples_per_step = batch_size\n",
    "            examples_per_sec = num_examples_per_step / duration\n",
    "            sec_per_batch = duration\n",
    "            format_str = (\n",
    "                '%s: step %d, examples %d, loss = %.9f (%.3f examples/sec; %.3f sec/batch)'\n",
    "            )\n",
    "            print(\n",
    "                format_str % (\n",
    "                    datetime.now(), step, batch_size * step,\n",
    "                    loss_value,\n",
    "                    examples_per_sec, sec_per_batch\n",
    "                )\n",
    "            )\n",
    "\n",
    "        # Save the model checkpoint periodically.\n",
    "        if step % model_saving_freq == 0 or (step + 1) == max_step:\n",
    "            fetch_list = [model.accuracy,model.top_2_accuracy]\n",
    "            feed_dict = {\n",
    "                model.input: valSet['data'],\n",
    "                model.fine_labels: valSet['labels'],\n",
    "                model.is_training: False,\n",
    "            }\n",
    "            val_acc_1, val_acc_2 =  sess.run(fetch_list, feed_dict=feed_dict)\n",
    "            checkpoint_path = os.path.join(target_dir, 'model.ckpt')\n",
    "            saver.save(sess, checkpoint_path, global_step=int(global_step_value))\n",
    "            print('Top 1 validation accuracy: {} and top 2 validation accuracy: {}'.format(val_acc_1,val_acc_2))\n",
    "            print('Model Saved!')\n",
    "            if val_acc_1>best_val_acc:\n",
    "                best_val_acc = val_acc_1\n",
    "                best_val_path = checkpoint_path+'-'+str(int(global_step_value))\n",
    "    return best_val_acc,best_val_path\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading datasets...\n",
      "Dataset loading completes.\n",
      "2019-03-16 02:40:51.252357: step 0, examples 0, loss = 1.458157659 (61.909 examples/sec; 0.808 sec/batch)\n",
      "Top 1 validation accuracy: 0.2358490526676178 and top 2 validation accuracy: 0.4858490526676178\n",
      "Model Saved!\n",
      "2019-03-16 02:40:56.888053: step 10, examples 500, loss = 1.511277199 (130.592 examples/sec; 0.383 sec/batch)\n",
      "2019-03-16 02:41:00.755084: step 20, examples 1000, loss = 1.507617474 (133.732 examples/sec; 0.374 sec/batch)\n",
      "2019-03-16 02:41:04.675550: step 30, examples 1500, loss = 1.431611300 (128.111 examples/sec; 0.390 sec/batch)\n",
      "2019-03-16 02:41:08.536811: step 40, examples 2000, loss = 1.411809087 (127.407 examples/sec; 0.392 sec/batch)\n",
      "2019-03-16 02:41:12.365177: step 50, examples 2500, loss = 1.353659272 (132.486 examples/sec; 0.377 sec/batch)\n",
      "2019-03-16 02:41:16.225225: step 60, examples 3000, loss = 1.414247036 (127.619 examples/sec; 0.392 sec/batch)\n",
      "2019-03-16 02:41:20.113713: step 70, examples 3500, loss = 1.285899758 (128.230 examples/sec; 0.390 sec/batch)\n",
      "2019-03-16 02:41:23.972502: step 80, examples 4000, loss = 1.289775491 (127.986 examples/sec; 0.391 sec/batch)\n",
      "2019-03-16 02:41:27.831002: step 90, examples 4500, loss = 1.213803411 (133.588 examples/sec; 0.374 sec/batch)\n",
      "2019-03-16 02:41:31.637366: step 100, examples 5000, loss = 1.191492915 (130.547 examples/sec; 0.383 sec/batch)\n",
      "Top 1 validation accuracy: 0.4858490526676178 and top 2 validation accuracy: 0.7405660152435303\n",
      "Model Saved!\n",
      "2019-03-16 02:41:37.169280: step 110, examples 5500, loss = 1.067927957 (130.242 examples/sec; 0.384 sec/batch)\n",
      "2019-03-16 02:41:41.095386: step 120, examples 6000, loss = 1.306930304 (128.810 examples/sec; 0.388 sec/batch)\n",
      "2019-03-16 02:41:44.988128: step 130, examples 6500, loss = 1.088774800 (133.319 examples/sec; 0.375 sec/batch)\n",
      "2019-03-16 02:41:48.850860: step 140, examples 7000, loss = 1.293283105 (138.392 examples/sec; 0.361 sec/batch)\n",
      "2019-03-16 02:41:52.739801: step 150, examples 7500, loss = 1.243879676 (127.022 examples/sec; 0.394 sec/batch)\n",
      "2019-03-16 02:41:56.688135: step 160, examples 8000, loss = 1.484554768 (125.885 examples/sec; 0.397 sec/batch)\n",
      "2019-03-16 02:42:00.594043: step 170, examples 8500, loss = 1.243137956 (122.243 examples/sec; 0.409 sec/batch)\n",
      "2019-03-16 02:42:04.505191: step 180, examples 9000, loss = 0.954561591 (127.547 examples/sec; 0.392 sec/batch)\n",
      "2019-03-16 02:42:08.473555: step 190, examples 9500, loss = 1.202575088 (132.684 examples/sec; 0.377 sec/batch)\n",
      "2019-03-16 02:42:12.397771: step 200, examples 10000, loss = 1.130581737 (126.827 examples/sec; 0.394 sec/batch)\n",
      "Top 1 validation accuracy: 0.5094339847564697 and top 2 validation accuracy: 0.7311320900917053\n",
      "Model Saved!\n",
      "2019-03-16 02:42:18.003238: step 210, examples 10500, loss = 0.978625715 (133.329 examples/sec; 0.375 sec/batch)\n",
      "2019-03-16 02:42:21.925587: step 220, examples 11000, loss = 1.012153029 (132.234 examples/sec; 0.378 sec/batch)\n",
      "2019-03-16 02:42:25.878134: step 230, examples 11500, loss = 0.925570726 (123.786 examples/sec; 0.404 sec/batch)\n",
      "2019-03-16 02:42:29.774069: step 240, examples 12000, loss = 1.061378598 (127.345 examples/sec; 0.393 sec/batch)\n",
      "2019-03-16 02:42:33.646200: step 250, examples 12500, loss = 0.984848142 (132.830 examples/sec; 0.376 sec/batch)\n",
      "2019-03-16 02:42:37.504648: step 260, examples 13000, loss = 0.964125216 (127.777 examples/sec; 0.391 sec/batch)\n",
      "2019-03-16 02:42:41.453454: step 270, examples 13500, loss = 0.863665819 (127.961 examples/sec; 0.391 sec/batch)\n",
      "2019-03-16 02:42:45.342214: step 280, examples 14000, loss = 0.991699874 (124.693 examples/sec; 0.401 sec/batch)\n",
      "2019-03-16 02:42:49.323186: step 290, examples 14500, loss = 1.196745157 (120.694 examples/sec; 0.414 sec/batch)\n",
      "2019-03-16 02:42:53.128887: step 300, examples 15000, loss = 1.021277666 (133.829 examples/sec; 0.374 sec/batch)\n",
      "Top 1 validation accuracy: 0.5613207817077637 and top 2 validation accuracy: 0.7877358198165894\n",
      "Model Saved!\n",
      "2019-03-16 02:42:58.565599: step 310, examples 15500, loss = 0.989334285 (126.792 examples/sec; 0.394 sec/batch)\n",
      "2019-03-16 02:43:02.474117: step 320, examples 16000, loss = 0.789294362 (127.244 examples/sec; 0.393 sec/batch)\n",
      "2019-03-16 02:43:06.380751: step 330, examples 16500, loss = 0.977902293 (127.328 examples/sec; 0.393 sec/batch)\n",
      "2019-03-16 02:43:10.307033: step 340, examples 17000, loss = 0.750842810 (130.938 examples/sec; 0.382 sec/batch)\n",
      "2019-03-16 02:43:14.603086: step 350, examples 17500, loss = 0.841093481 (122.223 examples/sec; 0.409 sec/batch)\n",
      "2019-03-16 02:43:18.535920: step 360, examples 18000, loss = 0.928972840 (131.739 examples/sec; 0.380 sec/batch)\n",
      "2019-03-16 02:43:22.474017: step 370, examples 18500, loss = 0.792502642 (129.450 examples/sec; 0.386 sec/batch)\n",
      "2019-03-16 02:43:26.380701: step 380, examples 19000, loss = 1.054206729 (127.447 examples/sec; 0.392 sec/batch)\n",
      "2019-03-16 02:43:30.381017: step 390, examples 19500, loss = 0.920655727 (132.301 examples/sec; 0.378 sec/batch)\n",
      "2019-03-16 02:43:34.320458: step 400, examples 20000, loss = 0.810448587 (122.871 examples/sec; 0.407 sec/batch)\n",
      "Top 1 validation accuracy: 0.5943396091461182 and top 2 validation accuracy: 0.8254716992378235\n",
      "Model Saved!\n",
      "2019-03-16 02:43:39.807151: step 410, examples 20500, loss = 1.006721735 (133.665 examples/sec; 0.374 sec/batch)\n",
      "2019-03-16 02:43:43.780838: step 420, examples 21000, loss = 0.770317852 (122.684 examples/sec; 0.408 sec/batch)\n",
      "2019-03-16 02:43:47.672299: step 430, examples 21500, loss = 1.070511818 (132.455 examples/sec; 0.377 sec/batch)\n",
      "2019-03-16 02:43:51.581558: step 440, examples 22000, loss = 0.639372528 (129.174 examples/sec; 0.387 sec/batch)\n",
      "2019-03-16 02:43:55.542797: step 450, examples 22500, loss = 0.795893133 (124.332 examples/sec; 0.402 sec/batch)\n",
      "2019-03-16 02:43:59.473686: step 460, examples 23000, loss = 0.863236964 (117.734 examples/sec; 0.425 sec/batch)\n",
      "2019-03-16 02:44:03.365454: step 470, examples 23500, loss = 0.579716802 (131.369 examples/sec; 0.381 sec/batch)\n",
      "2019-03-16 02:44:07.275556: step 480, examples 24000, loss = 0.814456463 (130.982 examples/sec; 0.382 sec/batch)\n",
      "2019-03-16 02:44:11.489386: step 490, examples 24500, loss = 0.780238628 (128.457 examples/sec; 0.389 sec/batch)\n",
      "2019-03-16 02:44:15.848491: step 500, examples 25000, loss = 0.806513608 (117.485 examples/sec; 0.426 sec/batch)\n",
      "Top 1 validation accuracy: 0.49056604504585266 and top 2 validation accuracy: 0.7452830076217651\n",
      "Model Saved!\n",
      "2019-03-16 02:44:22.094862: step 510, examples 25500, loss = 0.775943458 (123.729 examples/sec; 0.404 sec/batch)\n",
      "2019-03-16 02:44:26.169661: step 520, examples 26000, loss = 0.711225510 (119.586 examples/sec; 0.418 sec/batch)\n",
      "2019-03-16 02:44:30.761635: step 530, examples 26500, loss = 0.617364645 (109.118 examples/sec; 0.458 sec/batch)\n",
      "2019-03-16 02:44:35.422076: step 540, examples 27000, loss = 0.597672284 (118.873 examples/sec; 0.421 sec/batch)\n",
      "2019-03-16 02:44:40.193823: step 550, examples 27500, loss = 0.651329696 (107.816 examples/sec; 0.464 sec/batch)\n",
      "2019-03-16 02:44:45.132457: step 560, examples 28000, loss = 0.900280833 (102.712 examples/sec; 0.487 sec/batch)\n",
      "2019-03-16 02:44:50.193037: step 570, examples 28500, loss = 0.811970532 (92.862 examples/sec; 0.538 sec/batch)\n",
      "2019-03-16 02:44:54.723712: step 580, examples 29000, loss = 0.616782963 (118.449 examples/sec; 0.422 sec/batch)\n",
      "2019-03-16 02:44:59.017778: step 590, examples 29500, loss = 0.562902808 (114.112 examples/sec; 0.438 sec/batch)\n",
      "2019-03-16 02:45:03.203910: step 600, examples 30000, loss = 0.551512420 (118.449 examples/sec; 0.422 sec/batch)\n",
      "Top 1 validation accuracy: 0.5330188870429993 and top 2 validation accuracy: 0.7924528121948242\n",
      "Model Saved!\n",
      "2019-03-16 02:45:09.150792: step 610, examples 30500, loss = 0.514264643 (118.309 examples/sec; 0.423 sec/batch)\n",
      "2019-03-16 02:45:13.456241: step 620, examples 31000, loss = 0.755928874 (109.237 examples/sec; 0.458 sec/batch)\n",
      "2019-03-16 02:45:17.739045: step 630, examples 31500, loss = 0.644467056 (117.750 examples/sec; 0.425 sec/batch)\n",
      "2019-03-16 02:45:22.117711: step 640, examples 32000, loss = 0.577790022 (111.679 examples/sec; 0.448 sec/batch)\n",
      "2019-03-16 02:45:26.434190: step 650, examples 32500, loss = 0.735458076 (116.922 examples/sec; 0.428 sec/batch)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2019-03-16 02:45:30.770720: step 660, examples 33000, loss = 0.496823847 (117.611 examples/sec; 0.425 sec/batch)\n",
      "2019-03-16 02:45:35.200501: step 670, examples 33500, loss = 0.660404384 (111.435 examples/sec; 0.449 sec/batch)\n",
      "2019-03-16 02:45:39.608723: step 680, examples 34000, loss = 0.595655501 (115.835 examples/sec; 0.432 sec/batch)\n",
      "2019-03-16 02:45:43.925734: step 690, examples 34500, loss = 0.505445361 (113.326 examples/sec; 0.441 sec/batch)\n",
      "2019-03-16 02:45:48.307514: step 700, examples 35000, loss = 0.630921066 (114.769 examples/sec; 0.436 sec/batch)\n",
      "Top 1 validation accuracy: 0.6084905862808228 and top 2 validation accuracy: 0.801886796951294\n",
      "Model Saved!\n",
      "2019-03-16 02:45:54.562798: step 710, examples 35500, loss = 0.591579676 (117.334 examples/sec; 0.426 sec/batch)\n",
      "2019-03-16 02:45:58.869822: step 720, examples 36000, loss = 0.582153082 (114.374 examples/sec; 0.437 sec/batch)\n",
      "2019-03-16 02:46:03.225921: step 730, examples 36500, loss = 0.666428566 (120.598 examples/sec; 0.415 sec/batch)\n",
      "2019-03-16 02:46:07.545417: step 740, examples 37000, loss = 0.617036641 (112.567 examples/sec; 0.444 sec/batch)\n",
      "2019-03-16 02:46:11.882000: step 750, examples 37500, loss = 0.607273936 (119.728 examples/sec; 0.418 sec/batch)\n",
      "2019-03-16 02:46:16.186625: step 760, examples 38000, loss = 0.416065037 (114.234 examples/sec; 0.438 sec/batch)\n",
      "2019-03-16 02:46:20.507654: step 770, examples 38500, loss = 0.522474825 (117.472 examples/sec; 0.426 sec/batch)\n",
      "2019-03-16 02:46:24.853771: step 780, examples 39000, loss = 0.704016805 (126.727 examples/sec; 0.395 sec/batch)\n",
      "2019-03-16 02:46:29.046920: step 790, examples 39500, loss = 0.533854067 (117.766 examples/sec; 0.425 sec/batch)\n",
      "2019-03-16 02:46:33.307946: step 800, examples 40000, loss = 0.728347957 (121.479 examples/sec; 0.412 sec/batch)\n",
      "Top 1 validation accuracy: 0.5707547068595886 and top 2 validation accuracy: 0.75\n",
      "Model Saved!\n",
      "2019-03-16 02:46:39.314072: step 810, examples 40500, loss = 0.767228067 (113.206 examples/sec; 0.442 sec/batch)\n",
      "2019-03-16 02:46:43.592448: step 820, examples 41000, loss = 0.613544583 (120.890 examples/sec; 0.414 sec/batch)\n",
      "2019-03-16 02:46:47.937002: step 830, examples 41500, loss = 0.550801814 (119.299 examples/sec; 0.419 sec/batch)\n",
      "2019-03-16 02:46:52.260536: step 840, examples 42000, loss = 0.574727356 (119.442 examples/sec; 0.419 sec/batch)\n",
      "2019-03-16 02:46:56.674274: step 850, examples 42500, loss = 0.415031791 (111.434 examples/sec; 0.449 sec/batch)\n",
      "2019-03-16 02:47:00.993270: step 860, examples 43000, loss = 0.468568146 (119.729 examples/sec; 0.418 sec/batch)\n",
      "2019-03-16 02:47:05.329802: step 870, examples 43500, loss = 0.574159443 (118.029 examples/sec; 0.424 sec/batch)\n",
      "2019-03-16 02:47:09.639932: step 880, examples 44000, loss = 0.731889069 (113.206 examples/sec; 0.442 sec/batch)\n",
      "2019-03-16 02:47:14.018576: step 890, examples 44500, loss = 0.574314594 (119.585 examples/sec; 0.418 sec/batch)\n",
      "2019-03-16 02:47:18.341071: step 900, examples 45000, loss = 0.851989090 (120.451 examples/sec; 0.415 sec/batch)\n",
      "Top 1 validation accuracy: 0.5283018946647644 and top 2 validation accuracy: 0.7924528121948242\n",
      "Model Saved!\n",
      "2019-03-16 02:47:24.096514: step 910, examples 45500, loss = 0.499500513 (125.291 examples/sec; 0.399 sec/batch)\n",
      "2019-03-16 02:47:28.266640: step 920, examples 46000, loss = 0.480848074 (117.059 examples/sec; 0.427 sec/batch)\n",
      "2019-03-16 02:47:32.376078: step 930, examples 46500, loss = 0.629478574 (124.668 examples/sec; 0.401 sec/batch)\n",
      "2019-03-16 02:47:36.514583: step 940, examples 47000, loss = 0.747245193 (116.648 examples/sec; 0.429 sec/batch)\n",
      "2019-03-16 02:47:40.684171: step 950, examples 47500, loss = 0.690015793 (122.674 examples/sec; 0.408 sec/batch)\n",
      "2019-03-16 02:47:44.819667: step 960, examples 48000, loss = 0.615606070 (121.184 examples/sec; 0.413 sec/batch)\n",
      "2019-03-16 02:47:49.050935: step 970, examples 48500, loss = 0.395775974 (118.590 examples/sec; 0.422 sec/batch)\n",
      "2019-03-16 02:47:53.236610: step 980, examples 49000, loss = 0.339419186 (106.326 examples/sec; 0.470 sec/batch)\n",
      "2019-03-16 02:47:57.414720: step 990, examples 49500, loss = 0.432328999 (116.922 examples/sec; 0.428 sec/batch)\n",
      "Top 1 validation accuracy: 0.5377358198165894 and top 2 validation accuracy: 0.7830188870429993\n",
      "Model Saved!\n",
      "Loading datasets...\n",
      "Dataset loading completes.\n",
      "2019-03-16 02:48:05.861044: step 0, examples 0, loss = 1.445745230 (86.876 examples/sec; 0.576 sec/batch)\n",
      "Top 1 validation accuracy: 0.24528302252292633 and top 2 validation accuracy: 0.5141509175300598\n",
      "Model Saved!\n",
      "2019-03-16 02:48:09.328279: step 10, examples 500, loss = 1.432792783 (268.824 examples/sec; 0.186 sec/batch)\n",
      "2019-03-16 02:48:11.236883: step 20, examples 1000, loss = 1.440596104 (262.456 examples/sec; 0.191 sec/batch)\n",
      "2019-03-16 02:48:13.202609: step 30, examples 1500, loss = 1.359186172 (244.446 examples/sec; 0.205 sec/batch)\n",
      "2019-03-16 02:48:15.175868: step 40, examples 2000, loss = 1.283689380 (242.664 examples/sec; 0.206 sec/batch)\n",
      "2019-03-16 02:48:17.176204: step 50, examples 2500, loss = 1.513397336 (251.855 examples/sec; 0.199 sec/batch)\n",
      "2019-03-16 02:48:19.145453: step 60, examples 3000, loss = 1.389026403 (252.476 examples/sec; 0.198 sec/batch)\n",
      "2019-03-16 02:48:21.099649: step 70, examples 3500, loss = 1.360051394 (251.219 examples/sec; 0.199 sec/batch)\n",
      "2019-03-16 02:48:23.071925: step 80, examples 4000, loss = 1.271278977 (259.722 examples/sec; 0.193 sec/batch)\n",
      "2019-03-16 02:48:25.016094: step 90, examples 4500, loss = 1.321238995 (259.724 examples/sec; 0.193 sec/batch)\n",
      "2019-03-16 02:48:26.970304: step 100, examples 5000, loss = 1.246469975 (260.402 examples/sec; 0.192 sec/batch)\n",
      "Top 1 validation accuracy: 0.4103773534297943 and top 2 validation accuracy: 0.6933962106704712\n",
      "Model Saved!\n",
      "2019-03-16 02:48:30.418598: step 110, examples 5500, loss = 1.244244337 (259.725 examples/sec; 0.193 sec/batch)\n",
      "2019-03-16 02:48:32.426436: step 120, examples 6000, loss = 1.123887420 (256.386 examples/sec; 0.195 sec/batch)\n",
      "2019-03-16 02:48:34.375240: step 130, examples 6500, loss = 1.281280160 (260.403 examples/sec; 0.192 sec/batch)\n",
      "2019-03-16 02:48:36.309954: step 140, examples 7000, loss = 1.289066911 (259.724 examples/sec; 0.193 sec/batch)\n",
      "2019-03-16 02:48:38.241591: step 150, examples 7500, loss = 1.147621751 (260.402 examples/sec; 0.192 sec/batch)\n",
      "2019-03-16 02:48:40.198319: step 160, examples 8000, loss = 1.198542595 (259.049 examples/sec; 0.193 sec/batch)\n",
      "2019-03-16 02:48:42.183114: step 170, examples 8500, loss = 1.128462195 (250.589 examples/sec; 0.200 sec/batch)\n",
      "2019-03-16 02:48:44.116300: step 180, examples 9000, loss = 1.185473919 (257.046 examples/sec; 0.195 sec/batch)\n",
      "2019-03-16 02:48:46.095234: step 190, examples 9500, loss = 1.073467731 (257.711 examples/sec; 0.194 sec/batch)\n",
      "2019-03-16 02:48:48.120642: step 200, examples 10000, loss = 1.160767794 (263.152 examples/sec; 0.190 sec/batch)\n",
      "Top 1 validation accuracy: 0.4575471580028534 and top 2 validation accuracy: 0.7122641801834106\n",
      "Model Saved!\n",
      "2019-03-16 02:48:51.517474: step 210, examples 10500, loss = 1.289198995 (262.458 examples/sec; 0.191 sec/batch)\n",
      "2019-03-16 02:48:53.430060: step 220, examples 11000, loss = 1.071452856 (270.281 examples/sec; 0.185 sec/batch)\n",
      "2019-03-16 02:48:55.347158: step 230, examples 11500, loss = 1.105238318 (247.481 examples/sec; 0.202 sec/batch)\n",
      "2019-03-16 02:48:57.274806: step 240, examples 12000, loss = 1.289146662 (267.385 examples/sec; 0.187 sec/batch)\n",
      "2019-03-16 02:48:59.172352: step 250, examples 12500, loss = 0.990973115 (268.103 examples/sec; 0.186 sec/batch)\n",
      "2019-03-16 02:49:01.076917: step 260, examples 13000, loss = 1.227981210 (256.385 examples/sec; 0.195 sec/batch)\n",
      "2019-03-16 02:49:03.048174: step 270, examples 13500, loss = 1.107040167 (246.866 examples/sec; 0.203 sec/batch)\n",
      "2019-03-16 02:49:05.059021: step 280, examples 14000, loss = 1.156224489 (261.084 examples/sec; 0.192 sec/batch)\n",
      "2019-03-16 02:49:07.022742: step 290, examples 14500, loss = 1.047800660 (259.724 examples/sec; 0.193 sec/batch)\n",
      "2019-03-16 02:49:08.952373: step 300, examples 15000, loss = 1.262478352 (263.846 examples/sec; 0.190 sec/batch)\n",
      "Top 1 validation accuracy: 0.5094339847564697 and top 2 validation accuracy: 0.7688679099082947\n",
      "Model Saved!\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2019-03-16 02:49:12.325212: step 310, examples 15500, loss = 0.982916772 (256.386 examples/sec; 0.195 sec/batch)\n",
      "2019-03-16 02:49:14.280892: step 320, examples 16000, loss = 0.949410200 (251.220 examples/sec; 0.199 sec/batch)\n",
      "2019-03-16 02:49:16.263545: step 330, examples 16500, loss = 0.815233529 (249.961 examples/sec; 0.200 sec/batch)\n",
      "2019-03-16 02:49:18.208215: step 340, examples 17000, loss = 1.089880228 (261.083 examples/sec; 0.192 sec/batch)\n",
      "2019-03-16 02:49:20.187979: step 350, examples 17500, loss = 1.046365619 (261.083 examples/sec; 0.192 sec/batch)\n",
      "2019-03-16 02:49:22.126151: step 360, examples 18000, loss = 0.974002361 (259.725 examples/sec; 0.193 sec/batch)\n",
      "2019-03-16 02:49:24.044764: step 370, examples 18500, loss = 1.156610847 (265.250 examples/sec; 0.189 sec/batch)\n",
      "2019-03-16 02:49:25.957851: step 380, examples 19000, loss = 0.722630262 (263.847 examples/sec; 0.190 sec/batch)\n",
      "2019-03-16 02:49:27.920570: step 390, examples 19500, loss = 0.826190054 (254.424 examples/sec; 0.197 sec/batch)\n",
      "2019-03-16 02:49:29.852206: step 400, examples 20000, loss = 0.987943172 (256.387 examples/sec; 0.195 sec/batch)\n",
      "Top 1 validation accuracy: 0.5471698045730591 and top 2 validation accuracy: 0.7924528121948242\n",
      "Model Saved!\n",
      "2019-03-16 02:49:33.432403: step 410, examples 20500, loss = 1.037138820 (247.480 examples/sec; 0.202 sec/batch)\n",
      "2019-03-16 02:49:35.520199: step 420, examples 21000, loss = 0.788510203 (235.221 examples/sec; 0.213 sec/batch)\n",
      "2019-03-16 02:49:37.753637: step 430, examples 21500, loss = 0.836043358 (234.118 examples/sec; 0.214 sec/batch)\n",
      "2019-03-16 02:49:39.881824: step 440, examples 22000, loss = 0.717550695 (247.478 examples/sec; 0.202 sec/batch)\n",
      "2019-03-16 02:49:41.940574: step 450, examples 22500, loss = 0.682263792 (250.894 examples/sec; 0.199 sec/batch)\n",
      "2019-03-16 02:49:44.153306: step 460, examples 23000, loss = 0.976090729 (209.526 examples/sec; 0.239 sec/batch)\n",
      "2019-03-16 02:49:46.521503: step 470, examples 23500, loss = 0.820821702 (237.462 examples/sec; 0.211 sec/batch)\n",
      "2019-03-16 02:49:48.689892: step 480, examples 24000, loss = 0.866522312 (240.308 examples/sec; 0.208 sec/batch)\n",
      "2019-03-16 02:49:50.945678: step 490, examples 24500, loss = 0.828078628 (217.286 examples/sec; 0.230 sec/batch)\n",
      "2019-03-16 02:49:53.122466: step 500, examples 25000, loss = 1.108426571 (215.417 examples/sec; 0.232 sec/batch)\n",
      "Top 1 validation accuracy: 0.5943396091461182 and top 2 validation accuracy: 0.801886796951294\n",
      "Model Saved!\n",
      "2019-03-16 02:49:57.261845: step 510, examples 25500, loss = 1.024300456 (253.119 examples/sec; 0.198 sec/batch)\n",
      "2019-03-16 02:49:59.274196: step 520, examples 26000, loss = 0.875369847 (251.854 examples/sec; 0.199 sec/batch)\n",
      "2019-03-16 02:50:01.267998: step 530, examples 26500, loss = 0.728685737 (249.337 examples/sec; 0.201 sec/batch)\n",
      "2019-03-16 02:50:03.242760: step 540, examples 27000, loss = 0.812890291 (257.711 examples/sec; 0.194 sec/batch)\n",
      "2019-03-16 02:50:05.493262: step 550, examples 27500, loss = 0.922544122 (217.285 examples/sec; 0.230 sec/batch)\n",
      "2019-03-16 02:50:07.824963: step 560, examples 28000, loss = 1.080494046 (209.966 examples/sec; 0.238 sec/batch)\n",
      "2019-03-16 02:50:09.961656: step 570, examples 28500, loss = 0.849080384 (230.319 examples/sec; 0.217 sec/batch)\n",
      "2019-03-16 02:50:11.935907: step 580, examples 29000, loss = 0.650290966 (253.776 examples/sec; 0.197 sec/batch)\n",
      "2019-03-16 02:50:13.839494: step 590, examples 29500, loss = 0.695672452 (255.729 examples/sec; 0.196 sec/batch)\n",
      "2019-03-16 02:50:15.802715: step 600, examples 30000, loss = 0.925463736 (259.050 examples/sec; 0.193 sec/batch)\n",
      "Top 1 validation accuracy: 0.5471698045730591 and top 2 validation accuracy: 0.7547169923782349\n",
      "Model Saved!\n",
      "2019-03-16 02:50:19.219300: step 610, examples 30500, loss = 0.560132861 (244.447 examples/sec; 0.205 sec/batch)\n",
      "2019-03-16 02:50:21.213603: step 620, examples 31000, loss = 0.746322870 (248.095 examples/sec; 0.202 sec/batch)\n",
      "2019-03-16 02:50:23.203999: step 630, examples 31500, loss = 1.024189949 (246.256 examples/sec; 0.203 sec/batch)\n",
      "2019-03-16 02:50:25.208158: step 640, examples 32000, loss = 0.843379259 (254.662 examples/sec; 0.196 sec/batch)\n",
      "2019-03-16 02:50:27.193452: step 650, examples 32500, loss = 0.823252738 (252.492 examples/sec; 0.198 sec/batch)\n",
      "2019-03-16 02:50:29.146645: step 660, examples 33000, loss = 0.959100366 (256.386 examples/sec; 0.195 sec/batch)\n",
      "2019-03-16 02:50:31.154104: step 670, examples 33500, loss = 0.871961594 (257.710 examples/sec; 0.194 sec/batch)\n",
      "2019-03-16 02:50:33.108802: step 680, examples 34000, loss = 0.754842699 (259.725 examples/sec; 0.193 sec/batch)\n",
      "2019-03-16 02:50:35.064022: step 690, examples 34500, loss = 0.650496423 (253.131 examples/sec; 0.198 sec/batch)\n",
      "2019-03-16 02:50:37.045289: step 700, examples 35000, loss = 0.730080247 (261.084 examples/sec; 0.192 sec/batch)\n",
      "Top 1 validation accuracy: 0.49528300762176514 and top 2 validation accuracy: 0.7688679099082947\n",
      "Model Saved!\n",
      "2019-03-16 02:50:40.603542: step 710, examples 35500, loss = 0.911157846 (233.022 examples/sec; 0.215 sec/batch)\n",
      "2019-03-16 02:50:42.732701: step 720, examples 36000, loss = 0.709549308 (232.480 examples/sec; 0.215 sec/batch)\n",
      "2019-03-16 02:50:44.775634: step 730, examples 36500, loss = 0.596252680 (249.336 examples/sec; 0.201 sec/batch)\n",
      "2019-03-16 02:50:46.780967: step 740, examples 37000, loss = 0.573701441 (251.218 examples/sec; 0.199 sec/batch)\n",
      "2019-03-16 02:50:48.769781: step 750, examples 37500, loss = 0.676428020 (249.334 examples/sec; 0.201 sec/batch)\n",
      "2019-03-16 02:50:50.771103: step 760, examples 38000, loss = 0.515623927 (253.132 examples/sec; 0.198 sec/batch)\n",
      "2019-03-16 02:50:52.770920: step 770, examples 38500, loss = 0.543390691 (240.324 examples/sec; 0.208 sec/batch)\n",
      "2019-03-16 02:50:54.742662: step 780, examples 39000, loss = 0.711426795 (259.725 examples/sec; 0.193 sec/batch)\n",
      "2019-03-16 02:50:56.804660: step 790, examples 39500, loss = 0.771024227 (255.074 examples/sec; 0.196 sec/batch)\n",
      "2019-03-16 02:50:58.769897: step 800, examples 40000, loss = 0.882576466 (253.777 examples/sec; 0.197 sec/batch)\n",
      "Top 1 validation accuracy: 0.551886796951294 and top 2 validation accuracy: 0.7924528121948242\n",
      "Model Saved!\n",
      "2019-03-16 02:51:02.347019: step 810, examples 40500, loss = 0.811891317 (226.155 examples/sec; 0.221 sec/batch)\n",
      "2019-03-16 02:51:04.558415: step 820, examples 41000, loss = 0.670139015 (222.620 examples/sec; 0.225 sec/batch)\n",
      "2019-03-16 02:51:06.627416: step 830, examples 41500, loss = 0.729056895 (262.459 examples/sec; 0.191 sec/batch)\n",
      "2019-03-16 02:51:08.619735: step 840, examples 42000, loss = 0.954958618 (250.589 examples/sec; 0.200 sec/batch)\n",
      "2019-03-16 02:51:10.607521: step 850, examples 42500, loss = 0.721958399 (249.960 examples/sec; 0.200 sec/batch)\n",
      "2019-03-16 02:51:12.646443: step 860, examples 43000, loss = 0.818160534 (261.770 examples/sec; 0.191 sec/batch)\n",
      "2019-03-16 02:51:14.603157: step 870, examples 43500, loss = 0.512261212 (259.050 examples/sec; 0.193 sec/batch)\n",
      "2019-03-16 02:51:16.576404: step 880, examples 44000, loss = 0.614253402 (261.770 examples/sec; 0.191 sec/batch)\n",
      "2019-03-16 02:51:18.572744: step 890, examples 44500, loss = 0.631249487 (246.866 examples/sec; 0.203 sec/batch)\n",
      "2019-03-16 02:51:20.502374: step 900, examples 45000, loss = 0.626833737 (268.825 examples/sec; 0.186 sec/batch)\n",
      "Top 1 validation accuracy: 0.5754716992378235 and top 2 validation accuracy: 0.7971698045730591\n",
      "Model Saved!\n",
      "2019-03-16 02:51:23.767153: step 910, examples 45500, loss = 0.668630123 (266.670 examples/sec; 0.187 sec/batch)\n",
      "2019-03-16 02:51:25.715872: step 920, examples 46000, loss = 0.700289130 (269.552 examples/sec; 0.185 sec/batch)\n",
      "2019-03-16 02:51:27.680128: step 930, examples 46500, loss = 0.490986735 (239.746 examples/sec; 0.209 sec/batch)\n",
      "2019-03-16 02:51:29.573173: step 940, examples 47000, loss = 0.679998875 (266.669 examples/sec; 0.187 sec/batch)\n",
      "2019-03-16 02:51:31.622152: step 950, examples 47500, loss = 0.696967483 (245.047 examples/sec; 0.204 sec/batch)\n",
      "2019-03-16 02:51:33.635679: step 960, examples 48000, loss = 0.531336665 (250.588 examples/sec; 0.200 sec/batch)\n",
      "2019-03-16 02:51:35.641012: step 970, examples 48500, loss = 0.732034624 (241.486 examples/sec; 0.207 sec/batch)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2019-03-16 02:51:37.621277: step 980, examples 49000, loss = 0.730834365 (261.083 examples/sec; 0.192 sec/batch)\n",
      "2019-03-16 02:51:39.572967: step 990, examples 49500, loss = 0.789062202 (254.424 examples/sec; 0.197 sec/batch)\n",
      "Top 1 validation accuracy: 0.5754716992378235 and top 2 validation accuracy: 0.8160377144813538\n",
      "Model Saved!\n",
      "Loading datasets...\n",
      "Dataset loading completes.\n",
      "2019-03-16 02:51:45.545011: step 0, examples 0, loss = 1.427079678 (97.778 examples/sec; 0.511 sec/batch)\n",
      "Top 1 validation accuracy: 0.22641509771347046 and top 2 validation accuracy: 0.5\n",
      "Model Saved!\n",
      "2019-03-16 02:51:48.336579: step 10, examples 500, loss = 1.429236650 (405.423 examples/sec; 0.123 sec/batch)\n",
      "2019-03-16 02:51:49.598936: step 20, examples 1000, loss = 1.432451844 (403.780 examples/sec; 0.124 sec/batch)\n",
      "2019-03-16 02:51:50.870317: step 30, examples 1500, loss = 1.429117441 (370.758 examples/sec; 0.135 sec/batch)\n",
      "2019-03-16 02:51:52.381353: step 40, examples 2000, loss = 1.394075155 (323.815 examples/sec; 0.154 sec/batch)\n",
      "2019-03-16 02:51:53.927967: step 50, examples 2500, loss = 1.370665073 (336.940 examples/sec; 0.148 sec/batch)\n",
      "2019-03-16 02:51:55.435475: step 60, examples 3000, loss = 1.337975860 (328.072 examples/sec; 0.152 sec/batch)\n",
      "2019-03-16 02:51:56.930450: step 70, examples 3500, loss = 1.298645258 (361.356 examples/sec; 0.138 sec/batch)\n",
      "2019-03-16 02:51:58.462023: step 80, examples 4000, loss = 1.386574745 (319.661 examples/sec; 0.156 sec/batch)\n",
      "2019-03-16 02:52:00.019164: step 90, examples 4500, loss = 1.327131033 (303.143 examples/sec; 0.165 sec/batch)\n",
      "2019-03-16 02:52:01.540862: step 100, examples 5000, loss = 1.229802847 (313.629 examples/sec; 0.159 sec/batch)\n",
      "Top 1 validation accuracy: 0.3537735939025879 and top 2 validation accuracy: 0.650943398475647\n",
      "Model Saved!\n",
      "2019-03-16 02:52:04.487254: step 110, examples 5500, loss = 1.253037214 (340.389 examples/sec; 0.147 sec/batch)\n",
      "2019-03-16 02:52:05.863413: step 120, examples 6000, loss = 1.258689642 (383.591 examples/sec; 0.130 sec/batch)\n",
      "2019-03-16 02:52:07.129781: step 130, examples 6500, loss = 1.288560271 (397.348 examples/sec; 0.126 sec/batch)\n",
      "2019-03-16 02:52:08.393641: step 140, examples 7000, loss = 1.364799142 (402.155 examples/sec; 0.124 sec/batch)\n",
      "2019-03-16 02:52:09.656500: step 150, examples 7500, loss = 1.258670092 (400.537 examples/sec; 0.125 sec/batch)\n",
      "2019-03-16 02:52:10.934522: step 160, examples 8000, loss = 1.223691940 (386.568 examples/sec; 0.129 sec/batch)\n",
      "2019-03-16 02:52:12.214927: step 170, examples 8500, loss = 1.249080539 (395.770 examples/sec; 0.126 sec/batch)\n",
      "2019-03-16 02:52:13.481295: step 180, examples 9000, loss = 1.142101884 (398.936 examples/sec; 0.125 sec/batch)\n",
      "2019-03-16 02:52:14.754180: step 190, examples 9500, loss = 1.178327799 (383.591 examples/sec; 0.130 sec/batch)\n",
      "2019-03-16 02:52:16.083214: step 200, examples 10000, loss = 1.172708869 (376.356 examples/sec; 0.133 sec/batch)\n",
      "Top 1 validation accuracy: 0.4292452931404114 and top 2 validation accuracy: 0.6698113083839417\n",
      "Model Saved!\n",
      "2019-03-16 02:52:18.610540: step 210, examples 10500, loss = 1.241620779 (391.113 examples/sec; 0.128 sec/batch)\n",
      "2019-03-16 02:52:19.892949: step 220, examples 11000, loss = 1.282115102 (389.588 examples/sec; 0.128 sec/batch)\n",
      "2019-03-16 02:52:21.159818: step 230, examples 11500, loss = 1.167739034 (382.122 examples/sec; 0.131 sec/batch)\n",
      "2019-03-16 02:52:22.430698: step 240, examples 12000, loss = 1.172519803 (392.652 examples/sec; 0.127 sec/batch)\n",
      "2019-03-16 02:52:23.705602: step 250, examples 12500, loss = 1.118494749 (398.936 examples/sec; 0.125 sec/batch)\n",
      "2019-03-16 02:52:24.968962: step 260, examples 13000, loss = 1.344861746 (400.536 examples/sec; 0.125 sec/batch)\n",
      "2019-03-16 02:52:26.229814: step 270, examples 13500, loss = 1.117028117 (400.539 examples/sec; 0.125 sec/batch)\n",
      "2019-03-16 02:52:27.495690: step 280, examples 14000, loss = 1.120847344 (394.206 examples/sec; 0.127 sec/batch)\n",
      "2019-03-16 02:52:28.761555: step 290, examples 14500, loss = 1.113745928 (405.426 examples/sec; 0.123 sec/batch)\n",
      "2019-03-16 02:52:30.033939: step 300, examples 15000, loss = 0.996632218 (391.116 examples/sec; 0.128 sec/batch)\n",
      "Top 1 validation accuracy: 0.4386792480945587 and top 2 validation accuracy: 0.7169811129570007\n",
      "Model Saved!\n",
      "2019-03-16 02:52:32.695793: step 310, examples 15500, loss = 1.207894087 (397.349 examples/sec; 0.126 sec/batch)\n",
      "2019-03-16 02:52:33.951632: step 320, examples 16000, loss = 1.165687323 (417.299 examples/sec; 0.120 sec/batch)\n",
      "2019-03-16 02:52:35.181505: step 330, examples 16500, loss = 0.925790071 (408.748 examples/sec; 0.122 sec/batch)\n",
      "2019-03-16 02:52:36.430341: step 340, examples 17000, loss = 0.939895213 (394.207 examples/sec; 0.127 sec/batch)\n",
      "2019-03-16 02:52:37.659609: step 350, examples 17500, loss = 0.958895683 (408.747 examples/sec; 0.122 sec/batch)\n",
      "2019-03-16 02:52:38.914948: step 360, examples 18000, loss = 1.070635438 (395.767 examples/sec; 0.126 sec/batch)\n",
      "2019-03-16 02:52:40.146723: step 370, examples 18500, loss = 1.097648859 (410.426 examples/sec; 0.122 sec/batch)\n",
      "2019-03-16 02:52:41.386019: step 380, examples 19000, loss = 1.059597850 (415.559 examples/sec; 0.120 sec/batch)\n",
      "2019-03-16 02:52:42.622807: step 390, examples 19500, loss = 1.176113725 (417.297 examples/sec; 0.120 sec/batch)\n",
      "2019-03-16 02:52:43.890190: step 400, examples 20000, loss = 1.210165977 (385.073 examples/sec; 0.130 sec/batch)\n",
      "Top 1 validation accuracy: 0.49528300762176514 and top 2 validation accuracy: 0.7264150977134705\n",
      "Model Saved!\n",
      "2019-03-16 02:52:46.434999: step 410, examples 20500, loss = 0.877396643 (402.154 examples/sec; 0.124 sec/batch)\n",
      "2019-03-16 02:52:47.782081: step 420, examples 21000, loss = 0.980408430 (360.054 examples/sec; 0.139 sec/batch)\n",
      "2019-03-16 02:52:49.063990: step 430, examples 21500, loss = 1.119112134 (397.345 examples/sec; 0.126 sec/batch)\n",
      "2019-03-16 02:52:50.369963: step 440, examples 22000, loss = 0.906828880 (397.347 examples/sec; 0.126 sec/batch)\n",
      "2019-03-16 02:52:51.637332: step 450, examples 22500, loss = 0.778481543 (407.080 examples/sec; 0.123 sec/batch)\n",
      "2019-03-16 02:52:52.916734: step 460, examples 23000, loss = 1.126539588 (392.657 examples/sec; 0.127 sec/batch)\n",
      "2019-03-16 02:52:54.216256: step 470, examples 23500, loss = 1.107508063 (377.780 examples/sec; 0.132 sec/batch)\n",
      "2019-03-16 02:52:55.504682: step 480, examples 24000, loss = 0.960387230 (392.655 examples/sec; 0.127 sec/batch)\n",
      "2019-03-16 02:52:56.789098: step 490, examples 24500, loss = 0.948760509 (382.123 examples/sec; 0.131 sec/batch)\n",
      "2019-03-16 02:52:58.082538: step 500, examples 25000, loss = 0.959177196 (372.140 examples/sec; 0.134 sec/batch)\n",
      "Top 1 validation accuracy: 0.5283018946647644 and top 2 validation accuracy: 0.7216981053352356\n",
      "Model Saved!\n",
      "2019-03-16 02:53:00.757175: step 510, examples 25500, loss = 0.937154591 (392.654 examples/sec; 0.127 sec/batch)\n",
      "2019-03-16 02:53:02.043596: step 520, examples 26000, loss = 0.926125288 (353.668 examples/sec; 0.141 sec/batch)\n",
      "2019-03-16 02:53:03.344065: step 530, examples 26500, loss = 0.810973823 (377.782 examples/sec; 0.132 sec/batch)\n",
      "2019-03-16 02:53:04.645541: step 540, examples 27000, loss = 1.101756692 (391.112 examples/sec; 0.128 sec/batch)\n",
      "2019-03-16 02:53:05.921934: step 550, examples 27500, loss = 0.878907979 (388.070 examples/sec; 0.129 sec/batch)\n",
      "2019-03-16 02:53:07.208367: step 560, examples 28000, loss = 0.910604537 (395.729 examples/sec; 0.126 sec/batch)\n",
      "2019-03-16 02:53:08.506318: step 570, examples 28500, loss = 0.909804106 (383.592 examples/sec; 0.130 sec/batch)\n",
      "2019-03-16 02:53:09.777700: step 580, examples 29000, loss = 1.111944437 (388.071 examples/sec; 0.129 sec/batch)\n",
      "2019-03-16 02:53:11.067128: step 590, examples 29500, loss = 0.986850917 (398.935 examples/sec; 0.125 sec/batch)\n",
      "2019-03-16 02:53:12.340013: step 600, examples 30000, loss = 0.709778965 (394.208 examples/sec; 0.127 sec/batch)\n",
      "Top 1 validation accuracy: 0.47641509771347046 and top 2 validation accuracy: 0.7358490824699402\n",
      "Model Saved!\n",
      "2019-03-16 02:53:14.900835: step 610, examples 30500, loss = 1.059057593 (402.156 examples/sec; 0.124 sec/batch)\n",
      "2019-03-16 02:53:16.187758: step 620, examples 31000, loss = 0.887104869 (388.070 examples/sec; 0.129 sec/batch)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2019-03-16 02:53:17.507266: step 630, examples 31500, loss = 0.843805730 (398.936 examples/sec; 0.125 sec/batch)\n",
      "2019-03-16 02:53:18.786168: step 640, examples 32000, loss = 0.883151293 (389.586 examples/sec; 0.128 sec/batch)\n",
      "2019-03-16 02:53:20.107180: step 650, examples 32500, loss = 0.941706359 (392.653 examples/sec; 0.127 sec/batch)\n",
      "2019-03-16 02:53:21.379062: step 660, examples 33000, loss = 0.928657711 (395.774 examples/sec; 0.126 sec/batch)\n",
      "2019-03-16 02:53:22.655456: step 670, examples 33500, loss = 0.864767730 (397.349 examples/sec; 0.126 sec/batch)\n",
      "2019-03-16 02:53:23.940373: step 680, examples 34000, loss = 0.987384140 (402.155 examples/sec; 0.124 sec/batch)\n",
      "2019-03-16 02:53:25.211265: step 690, examples 34500, loss = 0.796272159 (392.651 examples/sec; 0.127 sec/batch)\n",
      "2019-03-16 02:53:26.487187: step 700, examples 35000, loss = 0.901980758 (379.215 examples/sec; 0.132 sec/batch)\n",
      "Top 1 validation accuracy: 0.5 and top 2 validation accuracy: 0.75\n",
      "Model Saved!\n",
      "2019-03-16 02:53:29.066584: step 710, examples 35500, loss = 0.890107393 (376.354 examples/sec; 0.133 sec/batch)\n",
      "2019-03-16 02:53:30.386594: step 720, examples 36000, loss = 0.823859572 (394.207 examples/sec; 0.127 sec/batch)\n",
      "2019-03-16 02:53:31.654968: step 730, examples 36500, loss = 0.671512306 (395.768 examples/sec; 0.126 sec/batch)\n",
      "2019-03-16 02:53:32.939382: step 740, examples 37000, loss = 0.903029323 (402.152 examples/sec; 0.124 sec/batch)\n",
      "2019-03-16 02:53:34.202241: step 750, examples 37500, loss = 0.930256844 (388.070 examples/sec; 0.129 sec/batch)\n",
      "2019-03-16 02:53:35.501208: step 760, examples 38000, loss = 0.920390666 (376.352 examples/sec; 0.133 sec/batch)\n",
      "2019-03-16 02:53:36.776097: step 770, examples 38500, loss = 0.733974159 (398.935 examples/sec; 0.125 sec/batch)\n",
      "2019-03-16 02:53:38.056000: step 780, examples 39000, loss = 0.788325131 (389.587 examples/sec; 0.128 sec/batch)\n",
      "2019-03-16 02:53:39.320362: step 790, examples 39500, loss = 0.786661267 (395.768 examples/sec; 0.126 sec/batch)\n",
      "2019-03-16 02:53:40.584246: step 800, examples 40000, loss = 0.681002498 (402.154 examples/sec; 0.124 sec/batch)\n",
      "Top 1 validation accuracy: 0.5 and top 2 validation accuracy: 0.7594339847564697\n",
      "Model Saved!\n",
      "2019-03-16 02:53:43.302490: step 810, examples 40500, loss = 0.852887034 (408.745 examples/sec; 0.122 sec/batch)\n",
      "2019-03-16 02:53:44.579887: step 820, examples 41000, loss = 1.083089232 (391.117 examples/sec; 0.128 sec/batch)\n",
      "2019-03-16 02:53:45.877337: step 830, examples 41500, loss = 0.806334853 (392.656 examples/sec; 0.127 sec/batch)\n",
      "2019-03-16 02:53:47.178798: step 840, examples 42000, loss = 0.847375453 (353.667 examples/sec; 0.141 sec/batch)\n",
      "2019-03-16 02:53:48.445695: step 850, examples 42500, loss = 0.981572926 (412.125 examples/sec; 0.121 sec/batch)\n",
      "2019-03-16 02:53:49.693512: step 860, examples 43000, loss = 0.784797847 (405.425 examples/sec; 0.123 sec/batch)\n",
      "2019-03-16 02:53:50.940328: step 870, examples 43500, loss = 0.743563294 (380.664 examples/sec; 0.131 sec/batch)\n",
      "2019-03-16 02:53:52.264850: step 880, examples 44000, loss = 1.078601241 (407.076 examples/sec; 0.123 sec/batch)\n",
      "2019-03-16 02:53:53.505649: step 890, examples 44500, loss = 0.838055253 (408.747 examples/sec; 0.122 sec/batch)\n",
      "2019-03-16 02:53:54.751963: step 900, examples 45000, loss = 0.735798359 (366.672 examples/sec; 0.136 sec/batch)\n",
      "Top 1 validation accuracy: 0.49528300762176514 and top 2 validation accuracy: 0.7264150977134705\n",
      "Model Saved!\n",
      "2019-03-16 02:53:57.326810: step 910, examples 45500, loss = 0.930016398 (368.023 examples/sec; 0.136 sec/batch)\n",
      "2019-03-16 02:53:58.730543: step 920, examples 46000, loss = 0.664306998 (372.141 examples/sec; 0.134 sec/batch)\n",
      "2019-03-16 02:54:00.136535: step 930, examples 46500, loss = 0.657463729 (386.568 examples/sec; 0.129 sec/batch)\n",
      "2019-03-16 02:54:01.433524: step 940, examples 47000, loss = 0.604922831 (385.073 examples/sec; 0.130 sec/batch)\n",
      "2019-03-16 02:54:02.785133: step 950, examples 47500, loss = 0.752833247 (373.536 examples/sec; 0.134 sec/batch)\n",
      "2019-03-16 02:54:04.178337: step 960, examples 48000, loss = 0.934742451 (368.022 examples/sec; 0.136 sec/batch)\n",
      "2019-03-16 02:54:05.553494: step 970, examples 48500, loss = 0.836552978 (363.993 examples/sec; 0.137 sec/batch)\n",
      "2019-03-16 02:54:06.938176: step 980, examples 49000, loss = 0.810411334 (368.023 examples/sec; 0.136 sec/batch)\n",
      "2019-03-16 02:54:08.311828: step 990, examples 49500, loss = 0.655531764 (402.151 examples/sec; 0.124 sec/batch)\n",
      "Top 1 validation accuracy: 0.5235849022865295 and top 2 validation accuracy: 0.75\n",
      "Model Saved!\n"
     ]
    }
   ],
   "source": [
    "filter_size = [9,6,4]\n",
    "j=0\n",
    "best_val_ds = {}\n",
    "time_bin = 700\n",
    "for ds in range(1,4,1):\n",
    "    num_cls = 4\n",
    "    mstp = 1000\n",
    "    lfrq = 10\n",
    "    bsz = 50\n",
    "    msf = 100\n",
    "    tr = './trained_model_final/DCNN_reg_ds'+str(ds)\n",
    "    if not os.path.exists(tr):\n",
    "        os.mkdir(tr)\n",
    "    start = 0\n",
    "    stop = time_bin\n",
    "    step = 100\n",
    "    time_length = time_bin\n",
    "    fsz = filter_size[j]\n",
    "    j = j+1\n",
    "    use_batchnorm = True\n",
    "    use_dropout = True\n",
    "    use_l2loss = True\n",
    "    acc = 'Accuracy'+str(ds)\n",
    "    path = 'Path'+str(ds)\n",
    "\n",
    "    best_val_ds[acc],best_val_ds[path] = train_model_ds(tr,start,stop,step,time_length,fsz,use_batchnorm,use_dropout,use_l2loss,num_cls,mstp,lfrq,bsz,msf,ds)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def test_model_ds(model_dir,start,stop,step,time_length,fsz,use_batchnorm,use_dropout,use_l2loss,ds):\n",
    "    print(\"Loading datasets...\")\n",
    "    trainSet, testSet, valSet, labelNames = data_loader_ds(time_length,ds)\n",
    "    print(\"Dataset loading completes.\")\n",
    "    \n",
    "    time_bin = testSet['data'].shape[2]\n",
    "    stop = testSet['data'].shape[2]\n",
    "    \n",
    "    # reset default graph\n",
    "    tf.reset_default_graph()\n",
    "    \n",
    "    # create model\n",
    "    \n",
    "    model = Model(config, labelNames,start,stop,step,time_bin,fsz,use_batchnorm,use_dropout,use_l2loss)\n",
    "    # training setups\n",
    "    saver = tf.train.Saver(max_to_keep=100)\n",
    "    test_accuracy = [0, 0]\n",
    "    \n",
    "    config_proto = tf.ConfigProto()\n",
    "\n",
    "    off = rewriter_config_pb2.RewriterConfig.OFF\n",
    "    config_proto.graph_options.rewrite_options.arithmetic_optimization = off\n",
    "\n",
    "    with tf.Session(config=config_proto) as session:\n",
    "        session.run(tf.global_variables_initializer())\n",
    "        saver.restore(session, model_dir)\n",
    "        # test model\n",
    "        exp_results = run_single_step(session, model, testSet, mode='test')\n",
    "        test_accuracy[0] = exp_results['top_1_accuracy']\n",
    "        test_accuracy[1] = exp_results['top_2_accuracy']\n",
    "        print('top_1_accuracy_test = ', test_accuracy[0], 'top_2_accuracy_test = ', test_accuracy[1])\n",
    "        \n",
    "    top1_acc = test_accuracy[0]\n",
    "    top2_acc = test_accuracy[1]\n",
    "    return top1_acc,top2_acc\n",
    "\n",
    "\n",
    "def run_single_step(\n",
    "        session,\n",
    "        model,\n",
    "        batch,\n",
    "        mode='test',\n",
    "        log=True,\n",
    "):\n",
    "    # construct feed dict\n",
    "    feed_dict = {\n",
    "        model.input: batch['data'],\n",
    "        # model.coarse_labels: batch['coarse_labels'],\n",
    "        model.fine_labels: batch['labels'],\n",
    "        # model.label_mapping: label_mapping,\n",
    "        model.is_training: mode == 'train'\n",
    "    }\n",
    "    \n",
    "    # select proper summary op\n",
    "    if mode == 'train':\n",
    "        summary_op = model.train_summary_op\n",
    "    elif mode == 'val':\n",
    "        summary_op = model.val_summary_op\n",
    "    else:\n",
    "        summary_op = model.test_summary_op\n",
    "    \n",
    "    # construct fetch list\n",
    "    fetch_list = [model.global_step, summary_op, model.loss, model.accuracy, model.top_2_accuracy]\n",
    "\n",
    "    # run single step\n",
    "    _start_time = time.time()\n",
    "    _step, _summary, _loss, _top_1, _top_2 = session.run(fetch_list, feed_dict=feed_dict)[:5]\n",
    "    _end_time = time.time()\n",
    "    \n",
    "    # collect step statistics\n",
    "    step_time = _end_time - _start_time\n",
    "    batch_size = batch['data'].shape[0]\n",
    "    \n",
    "    # log in console\n",
    "    if log:\n",
    "        print(('[{:5s} step {:4d}] loss: {:.5f}; top_1_accuracy: {:.5f}; top_5_accuracy: {:5f} ' +\n",
    "              '({:.3f} sec/batch; {:.3f} instances/sec)'\n",
    "              ).format(mode, _step, _loss, _top_1, _top_2, \n",
    "                       step_time, batch_size / step_time))\n",
    "    \n",
    "    # log results to file and return statistics\n",
    "    if mode == 'test':\n",
    "        test_fetch_list = [model.per_class_accuracy,\n",
    "                model.top_2_per_class_accuracy,\n",
    "                model.confusion_matrix, \n",
    "                model.pred, model.probs]\n",
    "        _top_1_c,  _top_2_c, _cm, _pred, _probs = \\\n",
    "                session.run(test_fetch_list, feed_dict=feed_dict)\n",
    "        \n",
    "        \n",
    "        # Log detailed test results in pickle format\n",
    "        stats = {\n",
    "            \"loss\": _loss,\n",
    "            \"top_1_accuracy\": _top_1,\n",
    "            \"top_2_accuracy\": _top_2,\n",
    "            \"top_1_perclass_accuracy\": _top_1_c,\n",
    "            \"top_2_perclass_accuracy\": _top_2_c,\n",
    "            \"confusion_matrix\": _cm,\n",
    "            \"pred\": _pred,\n",
    "            \"probs\": _probs\n",
    "        }\n",
    "    else:\n",
    "        stats = {\n",
    "            \"step\": _step,\n",
    "            \"loss\": _loss,\n",
    "            \"top_1_accuracy\": _top_1,\n",
    "            \"top_2_accuracy\": _top_2\n",
    "        }\n",
    "        \n",
    "    return stats"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy for Downsampling rate: 1\n",
      "Loading datasets...\n",
      "Dataset loading completes.\n",
      "INFO:tensorflow:Restoring parameters from ./trained_model_final/DCNN_reg_ds1\\model.ckpt-701\n",
      "[test  step  701] loss: 1.41690; top_1_accuracy: 0.58691; top_5_accuracy: 0.790068 (1.089 sec/batch; 406.972 instances/sec)\n",
      "top_1_accuracy_test =  0.58690745 top_2_accuracy_test =  0.79006773\n",
      "Accuracy for Downsampling rate: 2\n",
      "Loading datasets...\n",
      "Dataset loading completes.\n",
      "INFO:tensorflow:Restoring parameters from ./trained_model_final/DCNN_reg_ds2\\model.ckpt-501\n",
      "[test  step  501] loss: 1.20136; top_1_accuracy: 0.55079; top_5_accuracy: 0.810384 (0.583 sec/batch; 760.341 instances/sec)\n",
      "top_1_accuracy_test =  0.5507901 top_2_accuracy_test =  0.81038374\n",
      "Accuracy for Downsampling rate: 3\n",
      "Loading datasets...\n",
      "Dataset loading completes.\n",
      "INFO:tensorflow:Restoring parameters from ./trained_model_final/DCNN_reg_ds3\\model.ckpt-501\n",
      "[test  step  501] loss: 1.25981; top_1_accuracy: 0.50790; top_5_accuracy: 0.753950 (0.387 sec/batch; 1143.303 instances/sec)\n",
      "top_1_accuracy_test =  0.50790066 top_2_accuracy_test =  0.75395036\n",
      "The downsampling rate 1 has the best test accuracy: 0.5869074463844299\n"
     ]
    }
   ],
   "source": [
    "# Accuracy for testSet(best)\n",
    "filter_size = [9,6,4]\n",
    "j=0\n",
    "time_bin = 700\n",
    "best_test_acc_ds = 0\n",
    "best_test_ds = 0\n",
    "for ds in range(1,4,1):\n",
    "    path = 'Path'+str(ds)\n",
    "    model_dir = best_val_ds[path]\n",
    "    start = 0\n",
    "    stop = time_bin\n",
    "    step = 100\n",
    "    time_length = time_bin\n",
    "    #Nb = BATCH_SIZE\n",
    "    fsz = filter_size[j]\n",
    "    j = j+1\n",
    "    use_batchnorm = True\n",
    "    use_dropout = True\n",
    "    use_l2loss = True\n",
    "    print('Accuracy for Downsampling rate: {}'.format(ds))\n",
    "    top_1_acc_test, top_2_acc_test = test_model_ds(model_dir,start,stop,step,time_length,fsz,use_batchnorm,use_dropout,use_l2loss,ds)\n",
    "    if top_1_acc_test > best_test_acc_ds:\n",
    "        best_test_acc_ds = top_1_acc_test\n",
    "        best_test_ds = ds\n",
    "\n",
    "print('The downsampling rate {} has the best test accuracy: {}'.format(best_test_ds,best_test_acc_ds))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [],
   "source": [
    "#downsample and concatenate to increase the data size\n",
    "\n",
    "def data_loader_ss(time_bin):\n",
    "    X_test = np.load(\"X_test.npy\")\n",
    "    X_test = X_test[:,0:22,0:time_bin]\n",
    "    y_test = np.load(\"y_test.npy\")\n",
    "    person_test = np.load(\"person_test.npy\")\n",
    "\n",
    "    X_train_valid = np.load(\"X_train_valid.npy\")\n",
    "    X_train_valid = X_train_valid[:,0:22,0:time_bin]\n",
    "    y_train_valid = np.load(\"y_train_valid.npy\")\n",
    "    person_train_valid = np.load(\"person_train_valid.npy\")\n",
    "    \n",
    "    N_train = X_train_valid.shape[0]\n",
    "    idx_train_valid = np.arange(N_train,dtype='int')\n",
    "\n",
    "    X_train, X_val, idx_train, idx_val = train_test_split(X_train_valid, idx_train_valid, test_size=0.1, random_state=21)\n",
    "\n",
    "    y_train = y_train_valid[idx_train]\n",
    "    person_train = person_train_valid[idx_train]\n",
    "    y_val = y_train_valid[idx_val]\n",
    "    person_val = person_train_valid[idx_val]\n",
    "    \n",
    "    idx11 = np.arange(0,X_test.shape[2],2,dtype=int)\n",
    "    idx21 = np.arange(1,X_test.shape[2],2,dtype=int)\n",
    "    X_test_ss1 = np.take(X_test,idx11,axis=2)\n",
    "    X_test_ss2 = np.take(X_test,idx21,axis=2)\n",
    "    X_test = np.concatenate((X_test_ss1,X_test_ss2),axis=0)\n",
    "    y_test = np.concatenate((y_test,y_test),axis=0)\n",
    "    person_test = np.concatenate((person_test,person_test),axis=0)\n",
    "    \n",
    "    idx12 = np.arange(0,X_train.shape[2],2,dtype=int)\n",
    "    idx22 = np.arange(1,X_train.shape[2],2,dtype=int)\n",
    "    X_train_ss1 = np.take(X_train,idx12,axis=2)\n",
    "    X_train_ss2 = np.take(X_train,idx22,axis=2)\n",
    "    X_train = np.concatenate((X_train_ss1,X_train_ss2),axis=0)\n",
    "    y_train = np.concatenate((y_train,y_train),axis=0)\n",
    "    person_train = np.concatenate((person_train,person_train),axis=0)\n",
    "    \n",
    "    idx13 = np.arange(0,X_val.shape[2],2,dtype=int)\n",
    "    idx23 = np.arange(1,X_val.shape[2],2,dtype=int)\n",
    "    X_val_ss1 = np.take(X_val,idx13,axis=2)\n",
    "    X_val_ss2 = np.take(X_val,idx23,axis=2)\n",
    "    X_val = np.concatenate((X_val_ss1,X_val_ss2),axis=0)\n",
    "    y_val = np.concatenate((y_val,y_val),axis=0)\n",
    "    person_val = np.concatenate((person_val,person_val),axis=0)\n",
    "\n",
    "    tl = X_train.shape[2]\n",
    "    X_test = np.reshape(X_test,(-1,22,tl,1))\n",
    "    X_train = np.reshape(X_train,(-1,22,tl,1))\n",
    "    X_val = np.reshape(X_val,(-1,22,tl,1))\n",
    "\n",
    "    label0 = 769\n",
    "    new_label0 = 0\n",
    "    for i in range(4):\n",
    "        m1 = (y_test==label0)\n",
    "        m2 = (y_train==label0)\n",
    "        m3 = (y_val==label0)\n",
    "        np.place(y_test,m1,new_label0)\n",
    "        np.place(y_train,m2,new_label0)\n",
    "        np.place(y_val,m3,new_label0)\n",
    "        label0 += 1\n",
    "        new_label0 += 1\n",
    "\n",
    "    labelNames = [0,1,2,3]\n",
    "    train_set = {'data': X_train, 'labels': y_train, 'person': person_train}\n",
    "    test_set = {'data': X_test, 'labels': y_test, 'person': person_test}\n",
    "    val_set = {'data': X_val, 'labels': y_val, 'person': person_val}\n",
    "    return train_set, test_set, val_set, labelNames\n",
    "\n",
    "\n",
    "def sample_batch(dataset, batch_size):\n",
    "    N = dataset['data'].shape[0]\n",
    "    indices = np.random.randint(N, size=batch_size)\n",
    "    return {key: dataset[key][indices] for key in dataset}\n",
    "\n",
    "def train_model_ss(target_dir,start,stop,step,time_length,time_bin,fsz,use_batchnorm,use_dropout,use_l2loss,num_class,max_step,log_frequency,batch_size,model_saving_freq):\n",
    "    # load data\n",
    "    print(\"Loading datasets...\")\n",
    "    trainSet, testSet, valSet, labelNames = data_loader_ss(time_length)\n",
    "    print(\"Dataset loading completes.\")\n",
    "    \n",
    "    best_val_acc = 0\n",
    "    best_val_path = target_dir\n",
    "    \n",
    "\n",
    "\n",
    "    # reset default graph\n",
    "    tf.reset_default_graph()\n",
    "\n",
    "    global_step = tf.train.get_or_create_global_step()\n",
    "    \n",
    "    model = Model(config, labelNames,start,stop,step,time_bin,fsz,use_batchnorm,use_dropout,use_l2loss)\n",
    "\n",
    "    # training setups\n",
    "    saver = tf.train.Saver(max_to_keep=100)\n",
    "\n",
    "    # Build an initialization operation to run below.\n",
    "    init = tf.global_variables_initializer()\n",
    "    \n",
    "    config_proto = tf.ConfigProto()\n",
    "\n",
    "    off = rewriter_config_pb2.RewriterConfig.OFF\n",
    "    config_proto.graph_options.rewrite_options.arithmetic_optimization = off\n",
    "    \n",
    "    sess = tf.Session(config=config_proto)\n",
    "\n",
    "    sess.run(init)\n",
    "\n",
    "    # main loop\n",
    "    for step in range(max_step):\n",
    "        start_time = time.time()\n",
    "\n",
    "        # prepare data\n",
    "        train_batch = sample_batch(trainSet, batch_size)\n",
    "        # feed dict\n",
    "        feed_dict = {\n",
    "            model.input: train_batch['data'],\n",
    "            model.fine_labels: train_batch['labels'],\n",
    "            model.is_training: True,\n",
    "        }\n",
    "        \n",
    "        fetch_list = [model.optimizer_op, model.loss, model.global_step]\n",
    "        _, loss_value, global_step_value = sess.run(fetch_list, feed_dict=feed_dict)\n",
    "        duration = time.time() - start_time\n",
    "        assert not np.isnan(loss_value), 'Model diverged with loss = NaN'\n",
    "\n",
    "        # log\n",
    "        if step % log_frequency == 0:\n",
    "            num_examples_per_step = batch_size\n",
    "            examples_per_sec = num_examples_per_step / duration\n",
    "            sec_per_batch = duration\n",
    "            format_str = (\n",
    "                '%s: step %d, examples %d, loss = %.9f (%.3f examples/sec; %.3f sec/batch)'\n",
    "            )\n",
    "            print(\n",
    "                format_str % (\n",
    "                    datetime.now(), step, batch_size * step,\n",
    "                    loss_value,\n",
    "                    examples_per_sec, sec_per_batch\n",
    "                )\n",
    "            )\n",
    "\n",
    "        # Save the model checkpoint periodically.\n",
    "        if step % model_saving_freq == 0 or (step + 1) == max_step:\n",
    "            fetch_list = [model.accuracy,model.top_2_accuracy]\n",
    "            feed_dict = {\n",
    "                model.input: valSet['data'],\n",
    "                model.fine_labels: valSet['labels'],\n",
    "                model.is_training: False,\n",
    "            }\n",
    "            val_acc_1, val_acc_2 =  sess.run(fetch_list, feed_dict=feed_dict)\n",
    "            checkpoint_path = os.path.join(target_dir, 'model.ckpt')\n",
    "            saver.save(sess, checkpoint_path, global_step=int(global_step_value))\n",
    "            print('Top 1 validation accuracy: {} and top 2 validation accuracy: {}'.format(val_acc_1,val_acc_2))\n",
    "            print('Model Saved!')\n",
    "            if val_acc_1>best_val_acc:\n",
    "                best_val_acc = val_acc_1\n",
    "                best_val_path = checkpoint_path+'-'+str(int(global_step_value))\n",
    "    return best_val_acc,best_val_path\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading datasets...\n",
      "Dataset loading completes.\n",
      "2019-03-16 12:41:42.203048: step 0, examples 0, loss = 1.439974308 (98.401 examples/sec; 0.508 sec/batch)\n",
      "Top 1 validation accuracy: 0.2688679099082947 and top 2 validation accuracy: 0.5023584961891174\n",
      "Model Saved!\n",
      "2019-03-16 12:41:45.733314: step 10, examples 500, loss = 1.443587065 (283.336 examples/sec; 0.176 sec/batch)\n",
      "2019-03-16 12:41:47.509036: step 20, examples 1000, loss = 1.419790626 (284.954 examples/sec; 0.175 sec/batch)\n",
      "2019-03-16 12:41:49.305814: step 30, examples 1500, loss = 1.413360476 (280.152 examples/sec; 0.178 sec/batch)\n",
      "2019-03-16 12:41:51.106602: step 40, examples 2000, loss = 1.400026321 (278.587 examples/sec; 0.179 sec/batch)\n",
      "2019-03-16 12:41:52.965545: step 50, examples 2500, loss = 1.462016463 (266.669 examples/sec; 0.187 sec/batch)\n",
      "2019-03-16 12:41:54.817471: step 60, examples 3000, loss = 1.342422605 (271.015 examples/sec; 0.184 sec/batch)\n",
      "2019-03-16 12:41:56.667389: step 70, examples 3500, loss = 1.303992629 (280.153 examples/sec; 0.178 sec/batch)\n",
      "2019-03-16 12:41:58.491239: step 80, examples 4000, loss = 1.155188680 (268.103 examples/sec; 0.186 sec/batch)\n",
      "2019-03-16 12:42:00.323110: step 90, examples 4500, loss = 1.308955431 (280.154 examples/sec; 0.178 sec/batch)\n",
      "2019-03-16 12:42:02.131920: step 100, examples 5000, loss = 1.276355743 (277.039 examples/sec; 0.180 sec/batch)\n",
      "Top 1 validation accuracy: 0.400943398475647 and top 2 validation accuracy: 0.6792452931404114\n",
      "Model Saved!\n",
      "2019-03-16 12:42:05.627214: step 110, examples 5500, loss = 1.218805432 (272.498 examples/sec; 0.183 sec/batch)\n",
      "2019-03-16 12:42:07.422989: step 120, examples 6000, loss = 1.124714136 (277.039 examples/sec; 0.180 sec/batch)\n",
      "2019-03-16 12:42:09.283938: step 130, examples 6500, loss = 1.314635515 (280.152 examples/sec; 0.178 sec/batch)\n",
      "2019-03-16 12:42:11.087734: step 140, examples 7000, loss = 1.369483829 (281.735 examples/sec; 0.177 sec/batch)\n",
      "2019-03-16 12:42:12.940662: step 150, examples 7500, loss = 1.383014560 (283.336 examples/sec; 0.176 sec/batch)\n",
      "2019-03-16 12:42:14.736437: step 160, examples 8000, loss = 1.255780458 (278.587 examples/sec; 0.179 sec/batch)\n",
      "2019-03-16 12:42:16.570316: step 170, examples 8500, loss = 1.249631882 (272.494 examples/sec; 0.183 sec/batch)\n",
      "2019-03-16 12:42:18.472372: step 180, examples 9000, loss = 1.100927949 (272.496 examples/sec; 0.183 sec/batch)\n",
      "2019-03-16 12:42:20.269149: step 190, examples 9500, loss = 1.122856379 (280.152 examples/sec; 0.178 sec/batch)\n",
      "2019-03-16 12:42:22.090993: step 200, examples 10000, loss = 1.217443109 (284.954 examples/sec; 0.175 sec/batch)\n",
      "Top 1 validation accuracy: 0.4457547068595886 and top 2 validation accuracy: 0.6886792182922363\n",
      "Model Saved!\n",
      "2019-03-16 12:42:25.473989: step 210, examples 10500, loss = 1.338494778 (283.336 examples/sec; 0.176 sec/batch)\n",
      "2019-03-16 12:42:27.283802: step 220, examples 11000, loss = 1.194043398 (275.509 examples/sec; 0.181 sec/batch)\n",
      "2019-03-16 12:42:29.115673: step 230, examples 11500, loss = 1.148298621 (286.594 examples/sec; 0.174 sec/batch)\n",
      "2019-03-16 12:42:30.911449: step 240, examples 12000, loss = 1.238348961 (280.150 examples/sec; 0.178 sec/batch)\n",
      "2019-03-16 12:42:32.704215: step 250, examples 12500, loss = 1.124075413 (283.337 examples/sec; 0.176 sec/batch)\n",
      "2019-03-16 12:42:34.634349: step 260, examples 13000, loss = 1.003928065 (263.846 examples/sec; 0.190 sec/batch)\n",
      "2019-03-16 12:42:36.543424: step 270, examples 13500, loss = 1.345222950 (268.102 examples/sec; 0.186 sec/batch)\n",
      "2019-03-16 12:42:38.401364: step 280, examples 14000, loss = 1.261221409 (268.102 examples/sec; 0.186 sec/batch)\n",
      "2019-03-16 12:42:40.250281: step 290, examples 14500, loss = 0.849196076 (269.552 examples/sec; 0.185 sec/batch)\n",
      "2019-03-16 12:42:42.088168: step 300, examples 15000, loss = 0.872962236 (266.670 examples/sec; 0.187 sec/batch)\n",
      "Top 1 validation accuracy: 0.5023584961891174 and top 2 validation accuracy: 0.7028301954269409\n",
      "Model Saved!\n",
      "2019-03-16 12:42:45.580454: step 310, examples 15500, loss = 0.990317047 (269.554 examples/sec; 0.185 sec/batch)\n",
      "2019-03-16 12:42:47.451431: step 320, examples 16000, loss = 0.988081932 (272.495 examples/sec; 0.183 sec/batch)\n",
      "2019-03-16 12:42:49.300346: step 330, examples 16500, loss = 1.044172883 (263.846 examples/sec; 0.190 sec/batch)\n",
      "2019-03-16 12:42:51.151268: step 340, examples 17000, loss = 1.336831808 (273.996 examples/sec; 0.182 sec/batch)\n",
      "2019-03-16 12:42:53.000184: step 350, examples 17500, loss = 1.085557580 (273.995 examples/sec; 0.182 sec/batch)\n",
      "2019-03-16 12:42:54.831054: step 360, examples 18000, loss = 1.328186870 (275.508 examples/sec; 0.181 sec/batch)\n",
      "2019-03-16 12:42:56.698018: step 370, examples 18500, loss = 0.912399530 (265.249 examples/sec; 0.189 sec/batch)\n",
      "2019-03-16 12:42:58.564982: step 380, examples 19000, loss = 0.855551124 (269.551 examples/sec; 0.185 sec/batch)\n",
      "2019-03-16 12:43:00.475061: step 390, examples 19500, loss = 0.959500134 (269.554 examples/sec; 0.185 sec/batch)\n",
      "2019-03-16 12:43:02.322975: step 400, examples 20000, loss = 0.841342151 (262.458 examples/sec; 0.191 sec/batch)\n",
      "Top 1 validation accuracy: 0.5188679099082947 and top 2 validation accuracy: 0.7570754885673523\n",
      "Model Saved!\n",
      "2019-03-16 12:43:05.932573: step 410, examples 20500, loss = 1.222108006 (278.588 examples/sec; 0.179 sec/batch)\n",
      "2019-03-16 12:43:07.782492: step 420, examples 21000, loss = 1.018144608 (266.668 examples/sec; 0.187 sec/batch)\n",
      "2019-03-16 12:43:09.628401: step 430, examples 21500, loss = 0.787156045 (272.499 examples/sec; 0.183 sec/batch)\n",
      "2019-03-16 12:43:11.450246: step 440, examples 22000, loss = 1.069975138 (273.994 examples/sec; 0.182 sec/batch)\n",
      "2019-03-16 12:43:13.292143: step 450, examples 22500, loss = 0.831901431 (277.039 examples/sec; 0.180 sec/batch)\n",
      "2019-03-16 12:43:15.147075: step 460, examples 23000, loss = 0.970476806 (271.016 examples/sec; 0.184 sec/batch)\n",
      "2019-03-16 12:43:17.061165: step 470, examples 23500, loss = 1.152946353 (255.729 examples/sec; 0.196 sec/batch)\n",
      "2019-03-16 12:43:18.916098: step 480, examples 24000, loss = 0.840103149 (269.554 examples/sec; 0.185 sec/batch)\n",
      "2019-03-16 12:43:20.752983: step 490, examples 24500, loss = 0.737401247 (271.015 examples/sec; 0.184 sec/batch)\n",
      "2019-03-16 12:43:22.578837: step 500, examples 25000, loss = 0.798901618 (272.499 examples/sec; 0.183 sec/batch)\n",
      "Top 1 validation accuracy: 0.5353773832321167 and top 2 validation accuracy: 0.7783018946647644\n",
      "Model Saved!\n",
      "2019-03-16 12:43:26.004948: step 510, examples 25500, loss = 0.969365895 (272.498 examples/sec; 0.183 sec/batch)\n",
      "2019-03-16 12:43:27.889960: step 520, examples 26000, loss = 0.739507675 (261.085 examples/sec; 0.192 sec/batch)\n",
      "2019-03-16 12:43:29.757928: step 530, examples 26500, loss = 0.942088962 (275.507 examples/sec; 0.181 sec/batch)\n",
      "2019-03-16 12:43:31.648957: step 540, examples 27000, loss = 0.696397185 (253.130 examples/sec; 0.198 sec/batch)\n",
      "2019-03-16 12:43:33.610171: step 550, examples 27500, loss = 0.989840686 (268.102 examples/sec; 0.186 sec/batch)\n",
      "2019-03-16 12:43:35.504208: step 560, examples 28000, loss = 0.947286904 (273.995 examples/sec; 0.182 sec/batch)\n",
      "2019-03-16 12:43:37.359140: step 570, examples 28500, loss = 0.611396551 (273.995 examples/sec; 0.182 sec/batch)\n",
      "2019-03-16 12:43:39.215075: step 580, examples 29000, loss = 0.999086916 (269.552 examples/sec; 0.185 sec/batch)\n",
      "2019-03-16 12:43:41.081037: step 590, examples 29500, loss = 0.979366601 (258.378 examples/sec; 0.194 sec/batch)\n",
      "2019-03-16 12:43:42.915917: step 600, examples 30000, loss = 0.710166037 (275.506 examples/sec; 0.181 sec/batch)\n",
      "Top 1 validation accuracy: 0.49056604504585266 and top 2 validation accuracy: 0.7641509175300598\n",
      "Model Saved!\n",
      "2019-03-16 12:43:46.409205: step 610, examples 30500, loss = 0.896159887 (263.847 examples/sec; 0.190 sec/batch)\n",
      "2019-03-16 12:43:48.281183: step 620, examples 31000, loss = 0.728453636 (254.424 examples/sec; 0.197 sec/batch)\n",
      "2019-03-16 12:43:50.153162: step 630, examples 31500, loss = 0.676812530 (266.667 examples/sec; 0.187 sec/batch)\n",
      "2019-03-16 12:43:52.047197: step 640, examples 32000, loss = 0.627529383 (273.995 examples/sec; 0.182 sec/batch)\n",
      "2019-03-16 12:43:53.901127: step 650, examples 32500, loss = 0.834782362 (273.994 examples/sec; 0.182 sec/batch)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2019-03-16 12:43:55.743025: step 660, examples 33000, loss = 0.685092866 (271.017 examples/sec; 0.184 sec/batch)\n",
      "2019-03-16 12:43:57.595952: step 670, examples 33500, loss = 0.965965927 (275.509 examples/sec; 0.181 sec/batch)\n",
      "2019-03-16 12:43:59.435844: step 680, examples 34000, loss = 0.798896730 (275.509 examples/sec; 0.181 sec/batch)\n",
      "2019-03-16 12:44:01.301806: step 690, examples 34500, loss = 0.703344345 (261.084 examples/sec; 0.192 sec/batch)\n",
      "2019-03-16 12:44:03.132674: step 700, examples 35000, loss = 1.078117490 (272.498 examples/sec; 0.183 sec/batch)\n",
      "Top 1 validation accuracy: 0.5660377144813538 and top 2 validation accuracy: 0.7971698045730591\n",
      "Model Saved!\n",
      "2019-03-16 12:44:06.561793: step 710, examples 35500, loss = 0.700240493 (272.498 examples/sec; 0.183 sec/batch)\n",
      "2019-03-16 12:44:08.409707: step 720, examples 36000, loss = 0.714880288 (273.995 examples/sec; 0.182 sec/batch)\n",
      "2019-03-16 12:44:10.257620: step 730, examples 36500, loss = 0.706665397 (269.552 examples/sec; 0.185 sec/batch)\n",
      "2019-03-16 12:44:12.089492: step 740, examples 37000, loss = 0.806388080 (273.996 examples/sec; 0.182 sec/batch)\n",
      "2019-03-16 12:44:13.935400: step 750, examples 37500, loss = 0.893439651 (277.039 examples/sec; 0.180 sec/batch)\n",
      "2019-03-16 12:44:15.775293: step 760, examples 38000, loss = 0.797223806 (277.039 examples/sec; 0.180 sec/batch)\n",
      "2019-03-16 12:44:17.627217: step 770, examples 38500, loss = 0.583230793 (273.996 examples/sec; 0.182 sec/batch)\n",
      "2019-03-16 12:44:19.461094: step 780, examples 39000, loss = 0.617918968 (277.038 examples/sec; 0.180 sec/batch)\n",
      "2019-03-16 12:44:21.357135: step 790, examples 39500, loss = 0.614673436 (273.995 examples/sec; 0.182 sec/batch)\n",
      "2019-03-16 12:44:23.222094: step 800, examples 40000, loss = 0.722979784 (263.848 examples/sec; 0.190 sec/batch)\n",
      "Top 1 validation accuracy: 0.5235849022865295 and top 2 validation accuracy: 0.7688679099082947\n",
      "Model Saved!\n",
      "2019-03-16 12:44:26.756493: step 810, examples 40500, loss = 0.912814856 (273.995 examples/sec; 0.182 sec/batch)\n",
      "2019-03-16 12:44:28.584353: step 820, examples 41000, loss = 0.665604413 (269.553 examples/sec; 0.185 sec/batch)\n",
      "2019-03-16 12:44:30.425249: step 830, examples 41500, loss = 0.679976761 (268.102 examples/sec; 0.186 sec/batch)\n",
      "2019-03-16 12:44:32.331317: step 840, examples 42000, loss = 0.697553456 (259.724 examples/sec; 0.193 sec/batch)\n",
      "2019-03-16 12:44:34.283508: step 850, examples 42500, loss = 0.626052439 (266.669 examples/sec; 0.187 sec/batch)\n",
      "2019-03-16 12:44:36.202612: step 860, examples 43000, loss = 0.529320717 (244.447 examples/sec; 0.205 sec/batch)\n",
      "2019-03-16 12:44:38.294173: step 870, examples 43500, loss = 0.584236383 (269.552 examples/sec; 0.185 sec/batch)\n",
      "2019-03-16 12:44:40.423836: step 880, examples 44000, loss = 0.808139265 (273.996 examples/sec; 0.182 sec/batch)\n",
      "2019-03-16 12:44:42.442203: step 890, examples 44500, loss = 0.633393347 (265.251 examples/sec; 0.189 sec/batch)\n",
      "2019-03-16 12:44:44.372335: step 900, examples 45000, loss = 0.436953604 (259.724 examples/sec; 0.193 sec/batch)\n",
      "Top 1 validation accuracy: 0.5919811129570007 and top 2 validation accuracy: 0.823113203048706\n",
      "Model Saved!\n",
      "2019-03-16 12:44:47.885867: step 910, examples 45500, loss = 0.755901456 (275.509 examples/sec; 0.181 sec/batch)\n",
      "2019-03-16 12:44:49.826027: step 920, examples 46000, loss = 0.714424133 (265.249 examples/sec; 0.189 sec/batch)\n",
      "2019-03-16 12:44:51.681961: step 930, examples 46500, loss = 0.594240904 (266.670 examples/sec; 0.187 sec/batch)\n",
      "2019-03-16 12:44:53.588031: step 940, examples 47000, loss = 0.602964342 (266.668 examples/sec; 0.187 sec/batch)\n",
      "2019-03-16 12:44:55.484072: step 950, examples 47500, loss = 0.700618207 (258.378 examples/sec; 0.194 sec/batch)\n",
      "2019-03-16 12:44:57.382119: step 960, examples 48000, loss = 0.608888924 (271.016 examples/sec; 0.184 sec/batch)\n",
      "2019-03-16 12:44:59.234043: step 970, examples 48500, loss = 0.592110395 (275.509 examples/sec; 0.181 sec/batch)\n",
      "2019-03-16 12:45:01.124069: step 980, examples 49000, loss = 0.543125808 (259.724 examples/sec; 0.193 sec/batch)\n",
      "2019-03-16 12:45:03.002063: step 990, examples 49500, loss = 0.760015130 (265.251 examples/sec; 0.189 sec/batch)\n",
      "2019-03-16 12:45:04.890084: step 1000, examples 50000, loss = 0.602246106 (277.039 examples/sec; 0.180 sec/batch)\n",
      "Top 1 validation accuracy: 0.599056601524353 and top 2 validation accuracy: 0.7924528121948242\n",
      "Model Saved!\n",
      "2019-03-16 12:45:08.546807: step 1010, examples 50500, loss = 0.517487228 (266.669 examples/sec; 0.187 sec/batch)\n",
      "2019-03-16 12:45:10.452876: step 1020, examples 51000, loss = 0.553003907 (265.249 examples/sec; 0.189 sec/batch)\n",
      "2019-03-16 12:45:12.319840: step 1030, examples 51500, loss = 0.639984190 (268.102 examples/sec; 0.186 sec/batch)\n",
      "2019-03-16 12:45:14.176779: step 1040, examples 52000, loss = 0.518617451 (261.083 examples/sec; 0.192 sec/batch)\n",
      "2019-03-16 12:45:16.031710: step 1050, examples 52500, loss = 0.406443715 (272.498 examples/sec; 0.183 sec/batch)\n",
      "2019-03-16 12:45:17.943794: step 1060, examples 53000, loss = 0.564690530 (269.552 examples/sec; 0.185 sec/batch)\n",
      "2019-03-16 12:45:19.789703: step 1070, examples 53500, loss = 0.634900212 (273.995 examples/sec; 0.182 sec/batch)\n",
      "2019-03-16 12:45:21.694769: step 1080, examples 54000, loss = 0.625685930 (272.498 examples/sec; 0.183 sec/batch)\n",
      "2019-03-16 12:45:23.638940: step 1090, examples 54500, loss = 0.812182486 (262.458 examples/sec; 0.191 sec/batch)\n",
      "2019-03-16 12:45:25.583109: step 1100, examples 55000, loss = 0.652128339 (268.103 examples/sec; 0.186 sec/batch)\n",
      "Top 1 validation accuracy: 0.5754716992378235 and top 2 validation accuracy: 0.7995283007621765\n",
      "Model Saved!\n",
      "2019-03-16 12:45:29.061358: step 1110, examples 55500, loss = 0.756949902 (275.509 examples/sec; 0.181 sec/batch)\n",
      "2019-03-16 12:45:30.935342: step 1120, examples 56000, loss = 0.788615942 (266.668 examples/sec; 0.187 sec/batch)\n",
      "2019-03-16 12:45:32.805314: step 1130, examples 56500, loss = 0.508406520 (275.509 examples/sec; 0.181 sec/batch)\n",
      "2019-03-16 12:45:34.692331: step 1140, examples 57000, loss = 0.666361392 (269.552 examples/sec; 0.185 sec/batch)\n",
      "2019-03-16 12:45:36.570325: step 1150, examples 57500, loss = 0.719930649 (268.102 examples/sec; 0.186 sec/batch)\n",
      "2019-03-16 12:45:38.460351: step 1160, examples 58000, loss = 0.628970623 (265.250 examples/sec; 0.189 sec/batch)\n",
      "2019-03-16 12:45:40.379455: step 1170, examples 58500, loss = 0.675520957 (251.854 examples/sec; 0.199 sec/batch)\n",
      "2019-03-16 12:45:42.259453: step 1180, examples 59000, loss = 0.623945713 (251.854 examples/sec; 0.199 sec/batch)\n",
      "2019-03-16 12:45:44.157500: step 1190, examples 59500, loss = 0.435242772 (273.995 examples/sec; 0.182 sec/batch)\n",
      "2019-03-16 12:45:46.060561: step 1200, examples 60000, loss = 0.775673985 (265.249 examples/sec; 0.189 sec/batch)\n",
      "Top 1 validation accuracy: 0.5660377144813538 and top 2 validation accuracy: 0.775943398475647\n",
      "Model Saved!\n",
      "2019-03-16 12:45:49.604986: step 1210, examples 60500, loss = 0.508190632 (257.046 examples/sec; 0.195 sec/batch)\n",
      "2019-03-16 12:45:51.456910: step 1220, examples 61000, loss = 0.499228686 (269.552 examples/sec; 0.185 sec/batch)\n",
      "2019-03-16 12:45:53.308835: step 1230, examples 61500, loss = 0.587282598 (271.016 examples/sec; 0.184 sec/batch)\n",
      "2019-03-16 12:45:55.149729: step 1240, examples 62000, loss = 0.517177284 (275.510 examples/sec; 0.181 sec/batch)\n",
      "2019-03-16 12:45:57.032737: step 1250, examples 62500, loss = 0.496660948 (273.995 examples/sec; 0.182 sec/batch)\n",
      "2019-03-16 12:45:58.880650: step 1260, examples 63000, loss = 0.889238894 (268.102 examples/sec; 0.186 sec/batch)\n",
      "2019-03-16 12:46:00.735583: step 1270, examples 63500, loss = 0.445726931 (271.017 examples/sec; 0.184 sec/batch)\n",
      "2019-03-16 12:46:02.580490: step 1280, examples 64000, loss = 0.514172435 (277.039 examples/sec; 0.180 sec/batch)\n",
      "2019-03-16 12:46:04.423390: step 1290, examples 64500, loss = 0.809194684 (275.508 examples/sec; 0.181 sec/batch)\n",
      "2019-03-16 12:46:06.255260: step 1300, examples 65000, loss = 0.630388737 (275.509 examples/sec; 0.181 sec/batch)\n",
      "Top 1 validation accuracy: 0.5896226167678833 and top 2 validation accuracy: 0.8325471878051758\n",
      "Model Saved!\n",
      "2019-03-16 12:46:09.685382: step 1310, examples 65500, loss = 0.656012058 (258.379 examples/sec; 0.194 sec/batch)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2019-03-16 12:46:11.527280: step 1320, examples 66000, loss = 0.447199225 (275.509 examples/sec; 0.181 sec/batch)\n",
      "2019-03-16 12:46:13.427332: step 1330, examples 66500, loss = 0.658398032 (266.668 examples/sec; 0.187 sec/batch)\n",
      "2019-03-16 12:46:15.302318: step 1340, examples 67000, loss = 0.500437260 (266.669 examples/sec; 0.187 sec/batch)\n",
      "2019-03-16 12:46:17.165272: step 1350, examples 67500, loss = 0.846802354 (258.378 examples/sec; 0.194 sec/batch)\n",
      "2019-03-16 12:46:19.038252: step 1360, examples 68000, loss = 0.541093230 (273.995 examples/sec; 0.182 sec/batch)\n",
      "2019-03-16 12:46:20.861099: step 1370, examples 68500, loss = 0.561710835 (275.509 examples/sec; 0.181 sec/batch)\n",
      "2019-03-16 12:46:22.888490: step 1380, examples 69000, loss = 0.727548540 (261.084 examples/sec; 0.192 sec/batch)\n",
      "2019-03-16 12:46:24.767487: step 1390, examples 69500, loss = 0.716202557 (263.845 examples/sec; 0.190 sec/batch)\n",
      "2019-03-16 12:46:26.670547: step 1400, examples 70000, loss = 0.450971544 (275.509 examples/sec; 0.181 sec/batch)\n",
      "Top 1 validation accuracy: 0.599056601524353 and top 2 validation accuracy: 0.849056601524353\n",
      "Model Saved!\n",
      "2019-03-16 12:46:30.296188: step 1410, examples 70500, loss = 0.876994014 (269.550 examples/sec; 0.185 sec/batch)\n",
      "2019-03-16 12:46:32.166161: step 1420, examples 71000, loss = 0.362039298 (278.585 examples/sec; 0.179 sec/batch)\n",
      "2019-03-16 12:46:34.038138: step 1430, examples 71500, loss = 0.736948133 (273.996 examples/sec; 0.182 sec/batch)\n",
      "2019-03-16 12:46:35.931172: step 1440, examples 72000, loss = 0.688157737 (254.424 examples/sec; 0.197 sec/batch)\n",
      "2019-03-16 12:46:37.796132: step 1450, examples 72500, loss = 0.524957597 (272.498 examples/sec; 0.183 sec/batch)\n",
      "2019-03-16 12:46:39.647053: step 1460, examples 73000, loss = 0.595165372 (273.994 examples/sec; 0.182 sec/batch)\n",
      "2019-03-16 12:46:41.515020: step 1470, examples 73500, loss = 0.657160878 (269.551 examples/sec; 0.185 sec/batch)\n",
      "2019-03-16 12:46:43.370955: step 1480, examples 74000, loss = 0.411624670 (277.040 examples/sec; 0.180 sec/batch)\n",
      "2019-03-16 12:46:45.327156: step 1490, examples 74500, loss = 0.622296631 (273.996 examples/sec; 0.182 sec/batch)\n",
      "2019-03-16 12:46:47.200138: step 1500, examples 75000, loss = 0.502705634 (269.550 examples/sec; 0.185 sec/batch)\n",
      "Top 1 validation accuracy: 0.6132075190544128 and top 2 validation accuracy: 0.8160377144813538\n",
      "Model Saved!\n",
      "2019-03-16 12:46:50.688414: step 1510, examples 75500, loss = 0.550821900 (281.735 examples/sec; 0.177 sec/batch)\n",
      "2019-03-16 12:46:52.556381: step 1520, examples 76000, loss = 0.308558464 (250.588 examples/sec; 0.200 sec/batch)\n",
      "2019-03-16 12:46:54.419335: step 1530, examples 76500, loss = 0.444339991 (272.498 examples/sec; 0.183 sec/batch)\n",
      "2019-03-16 12:46:56.277275: step 1540, examples 77000, loss = 0.428696990 (266.668 examples/sec; 0.187 sec/batch)\n",
      "2019-03-16 12:46:58.148250: step 1550, examples 77500, loss = 0.481353939 (275.509 examples/sec; 0.181 sec/batch)\n",
      "2019-03-16 12:47:00.030254: step 1560, examples 78000, loss = 0.443344533 (250.588 examples/sec; 0.200 sec/batch)\n",
      "2019-03-16 12:47:01.918275: step 1570, examples 78500, loss = 0.520635724 (273.995 examples/sec; 0.182 sec/batch)\n",
      "2019-03-16 12:47:03.766188: step 1580, examples 79000, loss = 0.359480560 (266.669 examples/sec; 0.187 sec/batch)\n",
      "2019-03-16 12:47:05.610092: step 1590, examples 79500, loss = 0.688824534 (275.509 examples/sec; 0.181 sec/batch)\n",
      "2019-03-16 12:47:07.476053: step 1600, examples 80000, loss = 0.338357836 (272.498 examples/sec; 0.183 sec/batch)\n",
      "Top 1 validation accuracy: 0.6297169923782349 and top 2 validation accuracy: 0.8042452931404114\n",
      "Model Saved!\n",
      "2019-03-16 12:47:11.088659: step 1610, examples 80500, loss = 0.561214566 (277.040 examples/sec; 0.180 sec/batch)\n",
      "2019-03-16 12:47:12.974675: step 1620, examples 81000, loss = 0.445070595 (278.586 examples/sec; 0.179 sec/batch)\n",
      "2019-03-16 12:47:14.873725: step 1630, examples 81500, loss = 0.608449638 (258.378 examples/sec; 0.194 sec/batch)\n",
      "2019-03-16 12:47:16.806866: step 1640, examples 82000, loss = 0.527944207 (277.038 examples/sec; 0.180 sec/batch)\n",
      "2019-03-16 12:47:18.668816: step 1650, examples 82500, loss = 0.409479558 (271.017 examples/sec; 0.184 sec/batch)\n",
      "2019-03-16 12:47:20.535781: step 1660, examples 83000, loss = 0.504346311 (273.996 examples/sec; 0.182 sec/batch)\n",
      "2019-03-16 12:47:22.399738: step 1670, examples 83500, loss = 0.418348312 (277.038 examples/sec; 0.180 sec/batch)\n",
      "2019-03-16 12:47:24.261688: step 1680, examples 84000, loss = 0.542330801 (272.498 examples/sec; 0.183 sec/batch)\n",
      "2019-03-16 12:47:26.117623: step 1690, examples 84500, loss = 0.380747378 (277.040 examples/sec; 0.180 sec/batch)\n",
      "2019-03-16 12:47:27.991607: step 1700, examples 85000, loss = 0.603954256 (261.084 examples/sec; 0.192 sec/batch)\n",
      "Top 1 validation accuracy: 0.5707547068595886 and top 2 validation accuracy: 0.7971698045730591\n",
      "Model Saved!\n",
      "2019-03-16 12:47:31.455819: step 1710, examples 85500, loss = 0.585238874 (275.508 examples/sec; 0.181 sec/batch)\n",
      "2019-03-16 12:47:33.369908: step 1720, examples 86000, loss = 0.697937012 (265.250 examples/sec; 0.189 sec/batch)\n",
      "2019-03-16 12:47:35.236872: step 1730, examples 86500, loss = 0.561978638 (269.552 examples/sec; 0.185 sec/batch)\n",
      "2019-03-16 12:47:37.094813: step 1740, examples 87000, loss = 0.395783812 (268.102 examples/sec; 0.186 sec/batch)\n",
      "2019-03-16 12:47:38.987847: step 1750, examples 87500, loss = 0.614661932 (269.551 examples/sec; 0.185 sec/batch)\n",
      "2019-03-16 12:47:40.890908: step 1760, examples 88000, loss = 0.618348360 (255.728 examples/sec; 0.196 sec/batch)\n",
      "2019-03-16 12:47:42.768901: step 1770, examples 88500, loss = 0.496776104 (266.669 examples/sec; 0.187 sec/batch)\n",
      "2019-03-16 12:47:44.668953: step 1780, examples 89000, loss = 0.478802919 (277.040 examples/sec; 0.180 sec/batch)\n",
      "2019-03-16 12:47:46.552963: step 1790, examples 89500, loss = 0.788410783 (273.996 examples/sec; 0.182 sec/batch)\n",
      "2019-03-16 12:47:48.452014: step 1800, examples 90000, loss = 0.559320629 (249.334 examples/sec; 0.201 sec/batch)\n",
      "Top 1 validation accuracy: 0.5919811129570007 and top 2 validation accuracy: 0.7877358198165894\n",
      "Model Saved!\n",
      "2019-03-16 12:47:51.923244: step 1810, examples 90500, loss = 0.704069018 (273.995 examples/sec; 0.182 sec/batch)\n",
      "2019-03-16 12:47:53.786198: step 1820, examples 91000, loss = 0.577698231 (262.458 examples/sec; 0.191 sec/batch)\n",
      "2019-03-16 12:47:55.668202: step 1830, examples 91500, loss = 0.650682569 (268.103 examples/sec; 0.186 sec/batch)\n",
      "2019-03-16 12:47:57.528147: step 1840, examples 92000, loss = 0.741235852 (275.509 examples/sec; 0.181 sec/batch)\n",
      "2019-03-16 12:47:59.391102: step 1850, examples 92500, loss = 0.579051137 (277.039 examples/sec; 0.180 sec/batch)\n",
      "2019-03-16 12:48:01.272103: step 1860, examples 93000, loss = 0.373747259 (268.103 examples/sec; 0.186 sec/batch)\n",
      "2019-03-16 12:48:03.151100: step 1870, examples 93500, loss = 0.449609071 (273.994 examples/sec; 0.182 sec/batch)\n",
      "2019-03-16 12:48:05.102289: step 1880, examples 94000, loss = 0.661811471 (258.377 examples/sec; 0.194 sec/batch)\n",
      "2019-03-16 12:48:07.026404: step 1890, examples 94500, loss = 0.583232045 (281.736 examples/sec; 0.177 sec/batch)\n",
      "2019-03-16 12:48:08.919439: step 1900, examples 95000, loss = 0.397643954 (273.995 examples/sec; 0.182 sec/batch)\n",
      "Top 1 validation accuracy: 0.573113203048706 and top 2 validation accuracy: 0.8066037893295288\n",
      "Model Saved!\n",
      "2019-03-16 12:48:12.491938: step 1910, examples 95500, loss = 0.542986631 (266.669 examples/sec; 0.187 sec/batch)\n",
      "2019-03-16 12:48:14.354892: step 1920, examples 96000, loss = 0.477229208 (268.103 examples/sec; 0.186 sec/batch)\n",
      "2019-03-16 12:48:16.204811: step 1930, examples 96500, loss = 0.503415465 (271.017 examples/sec; 0.184 sec/batch)\n",
      "2019-03-16 12:48:18.096842: step 1940, examples 97000, loss = 0.393662095 (262.457 examples/sec; 0.191 sec/batch)\n",
      "2019-03-16 12:48:19.990878: step 1950, examples 97500, loss = 0.781659424 (253.132 examples/sec; 0.198 sec/batch)\n",
      "2019-03-16 12:48:21.885918: step 1960, examples 98000, loss = 0.546552896 (275.509 examples/sec; 0.181 sec/batch)\n",
      "2019-03-16 12:48:23.770931: step 1970, examples 98500, loss = 0.449581057 (273.994 examples/sec; 0.182 sec/batch)\n",
      "2019-03-16 12:48:25.646918: step 1980, examples 99000, loss = 0.440484703 (269.552 examples/sec; 0.185 sec/batch)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2019-03-16 12:48:27.525915: step 1990, examples 99500, loss = 0.393997908 (263.847 examples/sec; 0.190 sec/batch)\n",
      "2019-03-16 12:48:29.433990: step 2000, examples 100000, loss = 0.550537050 (271.015 examples/sec; 0.184 sec/batch)\n",
      "Top 1 validation accuracy: 0.6108490824699402 and top 2 validation accuracy: 0.8349056839942932\n",
      "Model Saved!\n",
      "2019-03-16 12:48:32.907225: step 2010, examples 100500, loss = 0.892129362 (269.552 examples/sec; 0.185 sec/batch)\n",
      "2019-03-16 12:48:34.774189: step 2020, examples 101000, loss = 0.551193595 (273.995 examples/sec; 0.182 sec/batch)\n",
      "2019-03-16 12:48:36.692290: step 2030, examples 101500, loss = 0.449397773 (268.102 examples/sec; 0.186 sec/batch)\n",
      "2019-03-16 12:48:38.570283: step 2040, examples 102000, loss = 0.603187680 (275.509 examples/sec; 0.181 sec/batch)\n",
      "2019-03-16 12:48:40.433237: step 2050, examples 102500, loss = 0.461228192 (265.249 examples/sec; 0.189 sec/batch)\n",
      "2019-03-16 12:48:42.317248: step 2060, examples 103000, loss = 0.403281450 (257.046 examples/sec; 0.195 sec/batch)\n",
      "2019-03-16 12:48:44.229332: step 2070, examples 103500, loss = 0.631541073 (272.497 examples/sec; 0.183 sec/batch)\n",
      "2019-03-16 12:48:46.096296: step 2080, examples 104000, loss = 0.393151760 (271.016 examples/sec; 0.184 sec/batch)\n",
      "2019-03-16 12:48:47.964262: step 2090, examples 104500, loss = 0.578216076 (277.040 examples/sec; 0.180 sec/batch)\n",
      "2019-03-16 12:48:49.839249: step 2100, examples 105000, loss = 0.429499328 (272.498 examples/sec; 0.183 sec/batch)\n",
      "Top 1 validation accuracy: 0.5801886916160583 and top 2 validation accuracy: 0.8160377144813538\n",
      "Model Saved!\n",
      "2019-03-16 12:48:53.352954: step 2110, examples 105500, loss = 0.483278602 (275.507 examples/sec; 0.181 sec/batch)\n",
      "2019-03-16 12:48:55.219918: step 2120, examples 106000, loss = 0.403544605 (272.498 examples/sec; 0.183 sec/batch)\n",
      "2019-03-16 12:48:57.083874: step 2130, examples 106500, loss = 0.700326502 (273.996 examples/sec; 0.182 sec/batch)\n",
      "2019-03-16 12:48:58.969890: step 2140, examples 107000, loss = 0.512069225 (265.249 examples/sec; 0.189 sec/batch)\n",
      "2019-03-16 12:49:00.872950: step 2150, examples 107500, loss = 0.335730374 (269.552 examples/sec; 0.185 sec/batch)\n",
      "2019-03-16 12:49:02.807093: step 2160, examples 108000, loss = 0.524329185 (275.509 examples/sec; 0.181 sec/batch)\n",
      "2019-03-16 12:49:04.718175: step 2170, examples 108500, loss = 0.474604368 (245.650 examples/sec; 0.204 sec/batch)\n",
      "2019-03-16 12:49:06.613214: step 2180, examples 109000, loss = 0.626713991 (272.498 examples/sec; 0.183 sec/batch)\n",
      "2019-03-16 12:49:08.538333: step 2190, examples 109500, loss = 0.403319895 (246.868 examples/sec; 0.203 sec/batch)\n",
      "2019-03-16 12:49:10.393265: step 2200, examples 110000, loss = 0.503980160 (271.017 examples/sec; 0.184 sec/batch)\n",
      "Top 1 validation accuracy: 0.6202830076217651 and top 2 validation accuracy: 0.8372641801834106\n",
      "Model Saved!\n",
      "2019-03-16 12:49:13.964762: step 2210, examples 110500, loss = 0.412412345 (269.552 examples/sec; 0.185 sec/batch)\n",
      "2019-03-16 12:49:15.834735: step 2220, examples 111000, loss = 0.467005312 (273.994 examples/sec; 0.182 sec/batch)\n",
      "2019-03-16 12:49:17.697688: step 2230, examples 111500, loss = 0.416697890 (254.424 examples/sec; 0.197 sec/batch)\n",
      "2019-03-16 12:49:19.550617: step 2240, examples 112000, loss = 0.477967352 (268.101 examples/sec; 0.186 sec/batch)\n",
      "2019-03-16 12:49:21.406551: step 2250, examples 112500, loss = 0.501335859 (259.724 examples/sec; 0.193 sec/batch)\n",
      "2019-03-16 12:49:23.273515: step 2260, examples 113000, loss = 0.515869498 (272.497 examples/sec; 0.183 sec/batch)\n",
      "2019-03-16 12:49:25.174570: step 2270, examples 113500, loss = 0.418332458 (275.510 examples/sec; 0.181 sec/batch)\n",
      "2019-03-16 12:49:27.044543: step 2280, examples 114000, loss = 0.451729864 (262.459 examples/sec; 0.191 sec/batch)\n",
      "2019-03-16 12:49:28.891454: step 2290, examples 114500, loss = 0.323080987 (273.995 examples/sec; 0.182 sec/batch)\n",
      "2019-03-16 12:49:30.739368: step 2300, examples 115000, loss = 0.416096091 (258.378 examples/sec; 0.194 sec/batch)\n",
      "Top 1 validation accuracy: 0.6084905862808228 and top 2 validation accuracy: 0.8207547068595886\n",
      "Model Saved!\n",
      "2019-03-16 12:49:34.153446: step 2310, examples 115500, loss = 0.487661600 (278.588 examples/sec; 0.179 sec/batch)\n",
      "2019-03-16 12:49:35.977296: step 2320, examples 116000, loss = 0.415807307 (277.038 examples/sec; 0.180 sec/batch)\n",
      "2019-03-16 12:49:37.825210: step 2330, examples 116500, loss = 0.442416549 (259.724 examples/sec; 0.193 sec/batch)\n",
      "2019-03-16 12:49:39.671118: step 2340, examples 117000, loss = 0.624892592 (266.671 examples/sec; 0.187 sec/batch)\n",
      "2019-03-16 12:49:41.536078: step 2350, examples 117500, loss = 0.586208165 (278.587 examples/sec; 0.179 sec/batch)\n",
      "2019-03-16 12:49:43.426103: step 2360, examples 118000, loss = 0.577611089 (242.074 examples/sec; 0.207 sec/batch)\n",
      "2019-03-16 12:49:45.308108: step 2370, examples 118500, loss = 0.414288342 (254.424 examples/sec; 0.197 sec/batch)\n",
      "2019-03-16 12:49:47.163040: step 2380, examples 119000, loss = 0.451308936 (272.498 examples/sec; 0.183 sec/batch)\n",
      "2019-03-16 12:49:49.012960: step 2390, examples 119500, loss = 0.448466718 (269.551 examples/sec; 0.185 sec/batch)\n",
      "2019-03-16 12:49:50.848841: step 2400, examples 120000, loss = 0.334947228 (271.017 examples/sec; 0.184 sec/batch)\n",
      "Top 1 validation accuracy: 0.5919811129570007 and top 2 validation accuracy: 0.8278301954269409\n",
      "Model Saved!\n",
      "2019-03-16 12:49:54.367197: step 2410, examples 120500, loss = 0.453701377 (275.509 examples/sec; 0.181 sec/batch)\n",
      "2019-03-16 12:49:56.288306: step 2420, examples 121000, loss = 0.405667543 (254.423 examples/sec; 0.197 sec/batch)\n",
      "2019-03-16 12:49:58.203398: step 2430, examples 121500, loss = 0.322883695 (251.854 examples/sec; 0.199 sec/batch)\n",
      "2019-03-16 12:50:00.044293: step 2440, examples 122000, loss = 0.307975322 (271.017 examples/sec; 0.184 sec/batch)\n",
      "2019-03-16 12:50:01.875161: step 2450, examples 122500, loss = 0.414472401 (255.729 examples/sec; 0.196 sec/batch)\n",
      "2019-03-16 12:50:03.760174: step 2460, examples 123000, loss = 0.448075533 (265.250 examples/sec; 0.189 sec/batch)\n",
      "2019-03-16 12:50:05.611246: step 2470, examples 123500, loss = 0.385453969 (269.550 examples/sec; 0.185 sec/batch)\n",
      "2019-03-16 12:50:07.450135: step 2480, examples 124000, loss = 0.522884846 (273.995 examples/sec; 0.182 sec/batch)\n",
      "2019-03-16 12:50:09.292032: step 2490, examples 124500, loss = 0.549333930 (275.510 examples/sec; 0.181 sec/batch)\n",
      "2019-03-16 12:50:11.143957: step 2500, examples 125000, loss = 0.440809071 (272.498 examples/sec; 0.183 sec/batch)\n",
      "Top 1 validation accuracy: 0.6179245114326477 and top 2 validation accuracy: 0.8278301954269409\n",
      "Model Saved!\n",
      "2019-03-16 12:50:14.604159: step 2510, examples 125500, loss = 0.455333024 (278.585 examples/sec; 0.179 sec/batch)\n",
      "2019-03-16 12:50:16.452072: step 2520, examples 126000, loss = 0.317489624 (271.017 examples/sec; 0.184 sec/batch)\n",
      "2019-03-16 12:50:18.281938: step 2530, examples 126500, loss = 0.354522407 (275.509 examples/sec; 0.181 sec/batch)\n",
      "2019-03-16 12:50:20.135868: step 2540, examples 127000, loss = 0.508161902 (271.016 examples/sec; 0.184 sec/batch)\n",
      "2019-03-16 12:50:21.975760: step 2550, examples 127500, loss = 0.411949962 (275.509 examples/sec; 0.181 sec/batch)\n",
      "2019-03-16 12:50:23.851748: step 2560, examples 128000, loss = 0.569982767 (263.846 examples/sec; 0.190 sec/batch)\n",
      "2019-03-16 12:50:25.702670: step 2570, examples 128500, loss = 0.520196259 (272.498 examples/sec; 0.183 sec/batch)\n",
      "2019-03-16 12:50:27.551587: step 2580, examples 129000, loss = 0.485977888 (272.497 examples/sec; 0.183 sec/batch)\n",
      "2019-03-16 12:50:29.453645: step 2590, examples 129500, loss = 0.443186849 (273.995 examples/sec; 0.182 sec/batch)\n",
      "2019-03-16 12:50:31.300555: step 2600, examples 130000, loss = 0.550159216 (272.499 examples/sec; 0.183 sec/batch)\n",
      "Top 1 validation accuracy: 0.599056601524353 and top 2 validation accuracy: 0.8183962106704712\n",
      "Model Saved!\n",
      "2019-03-16 12:50:34.738698: step 2610, examples 130500, loss = 0.599430203 (269.552 examples/sec; 0.185 sec/batch)\n",
      "2019-03-16 12:50:36.561545: step 2620, examples 131000, loss = 0.386987388 (271.017 examples/sec; 0.184 sec/batch)\n",
      "2019-03-16 12:50:38.391411: step 2630, examples 131500, loss = 0.427072585 (277.039 examples/sec; 0.180 sec/batch)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2019-03-16 12:50:40.233309: step 2640, examples 132000, loss = 0.511146903 (280.152 examples/sec; 0.178 sec/batch)\n",
      "2019-03-16 12:50:42.096979: step 2650, examples 132500, loss = 0.314398587 (260.111 examples/sec; 0.192 sec/batch)\n",
      "2019-03-16 12:50:44.128746: step 2660, examples 133000, loss = 0.295097709 (231.942 examples/sec; 0.216 sec/batch)\n",
      "2019-03-16 12:50:46.082943: step 2670, examples 133500, loss = 0.396839589 (261.084 examples/sec; 0.192 sec/batch)\n",
      "2019-03-16 12:50:48.113341: step 2680, examples 134000, loss = 0.448509991 (255.728 examples/sec; 0.196 sec/batch)\n",
      "2019-03-16 12:50:50.092604: step 2690, examples 134500, loss = 0.304269105 (258.379 examples/sec; 0.194 sec/batch)\n",
      "2019-03-16 12:50:52.092964: step 2700, examples 135000, loss = 0.404994667 (266.669 examples/sec; 0.187 sec/batch)\n",
      "Top 1 validation accuracy: 0.5872641801834106 and top 2 validation accuracy: 0.8136792182922363\n",
      "Model Saved!\n",
      "2019-03-16 12:50:55.674488: step 2710, examples 135500, loss = 0.427383304 (275.507 examples/sec; 0.181 sec/batch)\n",
      "2019-03-16 12:50:57.534433: step 2720, examples 136000, loss = 0.398148239 (268.103 examples/sec; 0.186 sec/batch)\n",
      "2019-03-16 12:50:59.389366: step 2730, examples 136500, loss = 0.343243629 (258.379 examples/sec; 0.194 sec/batch)\n",
      "2019-03-16 12:51:01.290421: step 2740, examples 137000, loss = 0.346078485 (277.039 examples/sec; 0.180 sec/batch)\n",
      "2019-03-16 12:51:03.150367: step 2750, examples 137500, loss = 0.502036810 (269.552 examples/sec; 0.185 sec/batch)\n",
      "2019-03-16 12:51:05.014323: step 2760, examples 138000, loss = 0.464457512 (263.847 examples/sec; 0.190 sec/batch)\n",
      "2019-03-16 12:51:06.862237: step 2770, examples 138500, loss = 0.529245257 (273.995 examples/sec; 0.182 sec/batch)\n",
      "2019-03-16 12:51:08.708146: step 2780, examples 139000, loss = 0.522507071 (272.496 examples/sec; 0.183 sec/batch)\n",
      "2019-03-16 12:51:10.552049: step 2790, examples 139500, loss = 0.332680941 (277.039 examples/sec; 0.180 sec/batch)\n",
      "2019-03-16 12:51:12.431045: step 2800, examples 140000, loss = 0.329428136 (253.132 examples/sec; 0.198 sec/batch)\n",
      "Top 1 validation accuracy: 0.5919811129570007 and top 2 validation accuracy: 0.8113207817077637\n",
      "Model Saved!\n",
      "2019-03-16 12:51:15.958024: step 2810, examples 140500, loss = 0.388009727 (249.335 examples/sec; 0.201 sec/batch)\n",
      "2019-03-16 12:51:18.067634: step 2820, examples 141000, loss = 0.360515118 (186.073 examples/sec; 0.269 sec/batch)\n",
      "2019-03-16 12:51:20.303556: step 2830, examples 141500, loss = 0.568056226 (197.886 examples/sec; 0.253 sec/batch)\n",
      "2019-03-16 12:51:22.437229: step 2840, examples 142000, loss = 0.521255493 (240.904 examples/sec; 0.208 sec/batch)\n",
      "2019-03-16 12:51:24.570903: step 2850, examples 142500, loss = 0.291272521 (239.745 examples/sec; 0.209 sec/batch)\n",
      "2019-03-16 12:51:26.612331: step 2860, examples 143000, loss = 0.404992878 (246.867 examples/sec; 0.203 sec/batch)\n",
      "2019-03-16 12:51:28.577557: step 2870, examples 143500, loss = 0.531750798 (266.669 examples/sec; 0.187 sec/batch)\n",
      "2019-03-16 12:51:30.553812: step 2880, examples 144000, loss = 0.523019433 (259.724 examples/sec; 0.193 sec/batch)\n",
      "2019-03-16 12:51:32.657406: step 2890, examples 144500, loss = 0.573479295 (222.621 examples/sec; 0.225 sec/batch)\n",
      "2019-03-16 12:51:34.749567: step 2900, examples 145000, loss = 0.333355010 (254.422 examples/sec; 0.197 sec/batch)\n",
      "Top 1 validation accuracy: 0.5872641801834106 and top 2 validation accuracy: 0.8066037893295288\n",
      "Model Saved!\n",
      "2019-03-16 12:51:38.704395: step 2910, examples 145500, loss = 0.674722195 (226.022 examples/sec; 0.221 sec/batch)\n",
      "2019-03-16 12:51:40.766880: step 2920, examples 146000, loss = 0.532028735 (260.879 examples/sec; 0.192 sec/batch)\n",
      "2019-03-16 12:51:42.684095: step 2930, examples 146500, loss = 0.416234940 (258.191 examples/sec; 0.194 sec/batch)\n",
      "2019-03-16 12:51:44.584982: step 2940, examples 147000, loss = 0.302486300 (278.187 examples/sec; 0.180 sec/batch)\n",
      "2019-03-16 12:51:46.451289: step 2950, examples 147500, loss = 0.468399584 (253.008 examples/sec; 0.198 sec/batch)\n",
      "2019-03-16 12:51:48.428550: step 2960, examples 148000, loss = 0.277643085 (263.878 examples/sec; 0.189 sec/batch)\n",
      "2019-03-16 12:51:50.301486: step 2970, examples 148500, loss = 0.338615924 (276.703 examples/sec; 0.181 sec/batch)\n",
      "2019-03-16 12:51:52.287102: step 2980, examples 149000, loss = 0.365913361 (248.713 examples/sec; 0.201 sec/batch)\n",
      "2019-03-16 12:51:54.227261: step 2990, examples 149500, loss = 0.406623304 (263.151 examples/sec; 0.190 sec/batch)\n",
      "2019-03-16 12:51:56.134356: step 3000, examples 150000, loss = 0.399865448 (270.248 examples/sec; 0.185 sec/batch)\n",
      "Top 1 validation accuracy: 0.5400943160057068 and top 2 validation accuracy: 0.8089622855186462\n",
      "Model Saved!\n",
      "2019-03-16 12:51:59.670296: step 3010, examples 150500, loss = 0.660947680 (270.282 examples/sec; 0.185 sec/batch)\n",
      "2019-03-16 12:52:01.571351: step 3020, examples 151000, loss = 0.633234203 (274.750 examples/sec; 0.182 sec/batch)\n",
      "2019-03-16 12:52:03.458193: step 3030, examples 151500, loss = 0.605495155 (271.002 examples/sec; 0.185 sec/batch)\n",
      "2019-03-16 12:52:05.341671: step 3040, examples 152000, loss = 0.334388196 (271.215 examples/sec; 0.184 sec/batch)\n",
      "2019-03-16 12:52:07.175724: step 3050, examples 152500, loss = 0.398093581 (270.491 examples/sec; 0.185 sec/batch)\n",
      "2019-03-16 12:52:08.998608: step 3060, examples 153000, loss = 0.394340038 (266.640 examples/sec; 0.188 sec/batch)\n",
      "2019-03-16 12:52:10.825181: step 3070, examples 153500, loss = 0.479702681 (266.639 examples/sec; 0.188 sec/batch)\n",
      "2019-03-16 12:52:12.684790: step 3080, examples 154000, loss = 0.400910139 (268.263 examples/sec; 0.186 sec/batch)\n",
      "2019-03-16 12:52:14.501229: step 3090, examples 154500, loss = 0.404975384 (294.219 examples/sec; 0.170 sec/batch)\n",
      "2019-03-16 12:52:16.342489: step 3100, examples 155000, loss = 0.450806737 (263.967 examples/sec; 0.189 sec/batch)\n",
      "Top 1 validation accuracy: 0.5778301954269409 and top 2 validation accuracy: 0.8089622855186462\n",
      "Model Saved!\n",
      "2019-03-16 12:52:19.809841: step 3110, examples 155500, loss = 0.422900677 (246.127 examples/sec; 0.203 sec/batch)\n",
      "2019-03-16 12:52:21.668893: step 3120, examples 156000, loss = 0.402203500 (276.970 examples/sec; 0.181 sec/batch)\n",
      "2019-03-16 12:52:23.574858: step 3130, examples 156500, loss = 0.495407283 (261.089 examples/sec; 0.192 sec/batch)\n",
      "2019-03-16 12:52:25.391958: step 3140, examples 157000, loss = 0.417374372 (283.301 examples/sec; 0.176 sec/batch)\n",
      "2019-03-16 12:52:27.233975: step 3150, examples 157500, loss = 0.368484914 (266.811 examples/sec; 0.187 sec/batch)\n",
      "2019-03-16 12:52:29.078491: step 3160, examples 158000, loss = 0.407680690 (258.148 examples/sec; 0.194 sec/batch)\n",
      "2019-03-16 12:52:30.888718: step 3170, examples 158500, loss = 0.438500285 (290.878 examples/sec; 0.172 sec/batch)\n",
      "2019-03-16 12:52:32.718570: step 3180, examples 159000, loss = 0.353841186 (285.043 examples/sec; 0.175 sec/batch)\n",
      "2019-03-16 12:52:34.559816: step 3190, examples 159500, loss = 0.368379742 (276.979 examples/sec; 0.181 sec/batch)\n",
      "2019-03-16 12:52:36.451711: step 3200, examples 160000, loss = 0.638160825 (275.664 examples/sec; 0.181 sec/batch)\n",
      "Top 1 validation accuracy: 0.6014150977134705 and top 2 validation accuracy: 0.8254716992378235\n",
      "Model Saved!\n",
      "2019-03-16 12:52:39.981678: step 3210, examples 160500, loss = 0.349511713 (266.639 examples/sec; 0.188 sec/batch)\n",
      "2019-03-16 12:52:41.842482: step 3220, examples 161000, loss = 0.457688868 (264.046 examples/sec; 0.189 sec/batch)\n",
      "2019-03-16 12:52:43.840612: step 3230, examples 161500, loss = 0.536088288 (290.877 examples/sec; 0.172 sec/batch)\n",
      "2019-03-16 12:52:45.699919: step 3240, examples 162000, loss = 0.488959610 (287.300 examples/sec; 0.174 sec/batch)\n",
      "2019-03-16 12:52:47.559640: step 3250, examples 162500, loss = 0.351537645 (268.803 examples/sec; 0.186 sec/batch)\n",
      "2019-03-16 12:52:49.408985: step 3260, examples 163000, loss = 0.435414314 (286.937 examples/sec; 0.174 sec/batch)\n",
      "2019-03-16 12:52:51.281710: step 3270, examples 163500, loss = 0.521360219 (279.335 examples/sec; 0.179 sec/batch)\n",
      "2019-03-16 12:52:53.214080: step 3280, examples 164000, loss = 0.395582676 (269.479 examples/sec; 0.186 sec/batch)\n",
      "2019-03-16 12:52:55.082814: step 3290, examples 164500, loss = 0.612226605 (273.154 examples/sec; 0.183 sec/batch)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2019-03-16 12:52:56.934255: step 3300, examples 165000, loss = 0.366421789 (266.638 examples/sec; 0.188 sec/batch)\n",
      "Top 1 validation accuracy: 0.5872641801834106 and top 2 validation accuracy: 0.801886796951294\n",
      "Model Saved!\n",
      "2019-03-16 12:53:00.404934: step 3310, examples 165500, loss = 0.380724847 (265.098 examples/sec; 0.189 sec/batch)\n",
      "2019-03-16 12:53:02.253592: step 3320, examples 166000, loss = 0.283658832 (289.126 examples/sec; 0.173 sec/batch)\n",
      "2019-03-16 12:53:04.123012: step 3330, examples 166500, loss = 0.306563020 (266.621 examples/sec; 0.188 sec/batch)\n",
      "2019-03-16 12:53:05.983651: step 3340, examples 167000, loss = 0.633226991 (266.639 examples/sec; 0.188 sec/batch)\n",
      "2019-03-16 12:53:07.871726: step 3350, examples 167500, loss = 0.501171350 (266.638 examples/sec; 0.188 sec/batch)\n",
      "2019-03-16 12:53:09.747175: step 3360, examples 168000, loss = 0.468441784 (290.876 examples/sec; 0.172 sec/batch)\n",
      "2019-03-16 12:53:11.622806: step 3370, examples 168500, loss = 0.606741250 (287.227 examples/sec; 0.174 sec/batch)\n",
      "2019-03-16 12:53:13.498455: step 3380, examples 169000, loss = 0.520607591 (295.525 examples/sec; 0.169 sec/batch)\n",
      "2019-03-16 12:53:15.431691: step 3390, examples 169500, loss = 0.489487350 (255.075 examples/sec; 0.196 sec/batch)\n",
      "2019-03-16 12:53:17.405440: step 3400, examples 170000, loss = 0.370070934 (263.152 examples/sec; 0.190 sec/batch)\n",
      "Top 1 validation accuracy: 0.6084905862808228 and top 2 validation accuracy: 0.8183962106704712\n",
      "Model Saved!\n",
      "2019-03-16 12:53:21.095287: step 3410, examples 170500, loss = 0.261376590 (253.776 examples/sec; 0.197 sec/batch)\n",
      "2019-03-16 12:53:22.974829: step 3420, examples 171000, loss = 0.409592688 (271.016 examples/sec; 0.184 sec/batch)\n",
      "2019-03-16 12:53:24.897943: step 3430, examples 171500, loss = 0.454557955 (271.017 examples/sec; 0.184 sec/batch)\n",
      "2019-03-16 12:53:26.763661: step 3440, examples 172000, loss = 0.483257234 (263.151 examples/sec; 0.190 sec/batch)\n",
      "2019-03-16 12:53:28.654317: step 3450, examples 172500, loss = 0.412519038 (264.558 examples/sec; 0.189 sec/batch)\n",
      "2019-03-16 12:53:30.512062: step 3460, examples 173000, loss = 0.417950898 (274.398 examples/sec; 0.182 sec/batch)\n",
      "2019-03-16 12:53:32.358966: step 3470, examples 173500, loss = 0.383983076 (262.361 examples/sec; 0.191 sec/batch)\n",
      "2019-03-16 12:53:34.184095: step 3480, examples 174000, loss = 0.469066203 (271.657 examples/sec; 0.184 sec/batch)\n",
      "2019-03-16 12:53:36.012860: step 3490, examples 174500, loss = 0.382396638 (290.879 examples/sec; 0.172 sec/batch)\n",
      "2019-03-16 12:53:37.916067: step 3500, examples 175000, loss = 0.477130979 (246.127 examples/sec; 0.203 sec/batch)\n",
      "Top 1 validation accuracy: 0.6061320900917053 and top 2 validation accuracy: 0.8254716992378235\n",
      "Model Saved!\n",
      "2019-03-16 12:53:41.405051: step 3510, examples 175500, loss = 0.326563120 (263.274 examples/sec; 0.190 sec/batch)\n",
      "2019-03-16 12:53:43.263831: step 3520, examples 176000, loss = 0.421596885 (245.017 examples/sec; 0.204 sec/batch)\n",
      "2019-03-16 12:53:45.102412: step 3530, examples 176500, loss = 0.365318239 (272.558 examples/sec; 0.183 sec/batch)\n",
      "2019-03-16 12:53:46.934403: step 3540, examples 177000, loss = 0.440285057 (290.876 examples/sec; 0.172 sec/batch)\n",
      "2019-03-16 12:53:48.778320: step 3550, examples 177500, loss = 0.352323562 (290.878 examples/sec; 0.172 sec/batch)\n",
      "2019-03-16 12:53:50.610784: step 3560, examples 178000, loss = 0.423548579 (286.422 examples/sec; 0.175 sec/batch)\n",
      "2019-03-16 12:53:52.444768: step 3570, examples 178500, loss = 0.429434657 (261.686 examples/sec; 0.191 sec/batch)\n",
      "2019-03-16 12:53:54.284300: step 3580, examples 179000, loss = 0.654599607 (274.378 examples/sec; 0.182 sec/batch)\n",
      "2019-03-16 12:53:56.151551: step 3590, examples 179500, loss = 0.494138718 (247.954 examples/sec; 0.202 sec/batch)\n",
      "2019-03-16 12:53:57.985358: step 3600, examples 180000, loss = 0.364814490 (266.637 examples/sec; 0.188 sec/batch)\n",
      "Top 1 validation accuracy: 0.5943396091461182 and top 2 validation accuracy: 0.775943398475647\n",
      "Model Saved!\n",
      "2019-03-16 12:54:01.405310: step 3610, examples 180500, loss = 0.431823224 (289.448 examples/sec; 0.173 sec/batch)\n",
      "2019-03-16 12:54:03.234795: step 3620, examples 181000, loss = 0.349318802 (264.207 examples/sec; 0.189 sec/batch)\n",
      "2019-03-16 12:54:05.094721: step 3630, examples 181500, loss = 0.363919348 (261.663 examples/sec; 0.191 sec/batch)\n",
      "2019-03-16 12:54:06.951897: step 3640, examples 182000, loss = 0.464106560 (266.639 examples/sec; 0.188 sec/batch)\n",
      "2019-03-16 12:54:08.778063: step 3650, examples 182500, loss = 0.412390053 (266.638 examples/sec; 0.188 sec/batch)\n",
      "2019-03-16 12:54:10.623822: step 3660, examples 183000, loss = 0.295829237 (291.118 examples/sec; 0.172 sec/batch)\n",
      "2019-03-16 12:54:12.514737: step 3670, examples 183500, loss = 0.402279854 (272.806 examples/sec; 0.183 sec/batch)\n",
      "2019-03-16 12:54:14.342765: step 3680, examples 184000, loss = 0.358984411 (263.929 examples/sec; 0.189 sec/batch)\n",
      "2019-03-16 12:54:16.184227: step 3690, examples 184500, loss = 0.355948716 (269.694 examples/sec; 0.185 sec/batch)\n",
      "2019-03-16 12:54:18.000616: step 3700, examples 185000, loss = 0.279042959 (290.877 examples/sec; 0.172 sec/batch)\n",
      "Top 1 validation accuracy: 0.5896226167678833 and top 2 validation accuracy: 0.8301886916160583\n",
      "Model Saved!\n",
      "2019-03-16 12:54:21.532601: step 3710, examples 185500, loss = 0.430275083 (263.467 examples/sec; 0.190 sec/batch)\n",
      "2019-03-16 12:54:23.342644: step 3720, examples 186000, loss = 0.329038382 (287.156 examples/sec; 0.174 sec/batch)\n",
      "2019-03-16 12:54:25.183864: step 3730, examples 186500, loss = 0.392117321 (255.371 examples/sec; 0.196 sec/batch)\n",
      "2019-03-16 12:54:27.004803: step 3740, examples 187000, loss = 0.714266419 (266.639 examples/sec; 0.188 sec/batch)\n",
      "2019-03-16 12:54:28.947418: step 3750, examples 187500, loss = 0.631711543 (249.238 examples/sec; 0.201 sec/batch)\n",
      "2019-03-16 12:54:30.828158: step 3760, examples 188000, loss = 0.332607418 (266.637 examples/sec; 0.188 sec/batch)\n",
      "2019-03-16 12:54:32.670316: step 3770, examples 188500, loss = 0.371878028 (272.407 examples/sec; 0.184 sec/batch)\n",
      "2019-03-16 12:54:34.498312: step 3780, examples 189000, loss = 0.364656478 (277.986 examples/sec; 0.180 sec/batch)\n",
      "2019-03-16 12:54:36.328807: step 3790, examples 189500, loss = 0.288920641 (265.992 examples/sec; 0.188 sec/batch)\n",
      "2019-03-16 12:54:38.152850: step 3800, examples 190000, loss = 0.430248469 (290.871 examples/sec; 0.172 sec/batch)\n",
      "Top 1 validation accuracy: 0.6132075190544128 and top 2 validation accuracy: 0.8160377144813538\n",
      "Model Saved!\n",
      "2019-03-16 12:54:41.623341: step 3810, examples 190500, loss = 0.509735286 (268.826 examples/sec; 0.186 sec/batch)\n",
      "2019-03-16 12:54:43.780512: step 3820, examples 191000, loss = 0.406674564 (206.917 examples/sec; 0.242 sec/batch)\n",
      "2019-03-16 12:54:45.777742: step 3830, examples 191500, loss = 0.262884974 (266.638 examples/sec; 0.188 sec/batch)\n",
      "2019-03-16 12:54:47.627153: step 3840, examples 192000, loss = 0.470502555 (270.371 examples/sec; 0.185 sec/batch)\n",
      "2019-03-16 12:54:49.451178: step 3850, examples 192500, loss = 0.426227182 (273.986 examples/sec; 0.182 sec/batch)\n",
      "2019-03-16 12:54:51.330949: step 3860, examples 193000, loss = 0.380095631 (266.669 examples/sec; 0.187 sec/batch)\n",
      "2019-03-16 12:54:53.247656: step 3870, examples 193500, loss = 0.362800032 (277.745 examples/sec; 0.180 sec/batch)\n",
      "2019-03-16 12:54:55.168694: step 3880, examples 194000, loss = 0.316692084 (279.437 examples/sec; 0.179 sec/batch)\n",
      "2019-03-16 12:54:57.012978: step 3890, examples 194500, loss = 0.426794648 (266.639 examples/sec; 0.188 sec/batch)\n",
      "2019-03-16 12:54:58.840878: step 3900, examples 195000, loss = 0.381929040 (266.639 examples/sec; 0.188 sec/batch)\n",
      "Top 1 validation accuracy: 0.5966981053352356 and top 2 validation accuracy: 0.823113203048706\n",
      "Model Saved!\n",
      "2019-03-16 12:55:02.253594: step 3910, examples 195500, loss = 0.669861555 (281.762 examples/sec; 0.177 sec/batch)\n",
      "2019-03-16 12:55:04.107413: step 3920, examples 196000, loss = 0.297556370 (283.162 examples/sec; 0.177 sec/batch)\n",
      "2019-03-16 12:55:05.981727: step 3930, examples 196500, loss = 0.436340988 (266.639 examples/sec; 0.188 sec/batch)\n",
      "2019-03-16 12:55:07.840612: step 3940, examples 197000, loss = 0.461061150 (266.636 examples/sec; 0.188 sec/batch)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2019-03-16 12:55:09.684208: step 3950, examples 197500, loss = 0.364966094 (301.671 examples/sec; 0.166 sec/batch)\n",
      "2019-03-16 12:55:11.534193: step 3960, examples 198000, loss = 0.444897592 (261.758 examples/sec; 0.191 sec/batch)\n",
      "2019-03-16 12:55:13.358503: step 3970, examples 198500, loss = 0.320079654 (263.539 examples/sec; 0.190 sec/batch)\n",
      "2019-03-16 12:55:15.250411: step 3980, examples 199000, loss = 0.406709969 (255.728 examples/sec; 0.196 sec/batch)\n",
      "2019-03-16 12:55:17.222669: step 3990, examples 199500, loss = 0.467290461 (265.249 examples/sec; 0.189 sec/batch)\n",
      "2019-03-16 12:55:19.128094: step 4000, examples 200000, loss = 0.354816914 (260.594 examples/sec; 0.192 sec/batch)\n",
      "Top 1 validation accuracy: 0.6226415038108826 and top 2 validation accuracy: 0.8254716992378235\n",
      "Model Saved!\n",
      "2019-03-16 12:55:22.709941: step 4010, examples 200500, loss = 0.387349308 (269.552 examples/sec; 0.185 sec/batch)\n",
      "2019-03-16 12:55:24.647594: step 4020, examples 201000, loss = 0.453674495 (273.244 examples/sec; 0.183 sec/batch)\n",
      "2019-03-16 12:55:26.630883: step 4030, examples 201500, loss = 0.417654991 (261.085 examples/sec; 0.192 sec/batch)\n",
      "2019-03-16 12:55:28.482672: step 4040, examples 202000, loss = 0.456978738 (272.955 examples/sec; 0.183 sec/batch)\n",
      "2019-03-16 12:55:30.302106: step 4050, examples 202500, loss = 0.294257343 (258.619 examples/sec; 0.193 sec/batch)\n",
      "2019-03-16 12:55:32.168356: step 4060, examples 203000, loss = 0.390717089 (240.535 examples/sec; 0.208 sec/batch)\n",
      "2019-03-16 12:55:34.034658: step 4070, examples 203500, loss = 0.338571429 (266.636 examples/sec; 0.188 sec/batch)\n",
      "2019-03-16 12:55:35.955751: step 4080, examples 204000, loss = 0.395524442 (240.905 examples/sec; 0.208 sec/batch)\n",
      "2019-03-16 12:55:37.894589: step 4090, examples 204500, loss = 0.466365367 (266.639 examples/sec; 0.188 sec/batch)\n",
      "2019-03-16 12:55:39.767832: step 4100, examples 205000, loss = 0.549970448 (266.639 examples/sec; 0.188 sec/batch)\n",
      "Top 1 validation accuracy: 0.5801886916160583 and top 2 validation accuracy: 0.8160377144813538\n",
      "Model Saved!\n",
      "2019-03-16 12:55:43.286715: step 4110, examples 205500, loss = 0.685298324 (242.143 examples/sec; 0.206 sec/batch)\n",
      "2019-03-16 12:55:45.264977: step 4120, examples 206000, loss = 0.492657930 (228.747 examples/sec; 0.219 sec/batch)\n",
      "2019-03-16 12:55:47.144323: step 4130, examples 206500, loss = 0.357192904 (258.264 examples/sec; 0.194 sec/batch)\n",
      "2019-03-16 12:55:49.044065: step 4140, examples 207000, loss = 0.388120651 (266.638 examples/sec; 0.188 sec/batch)\n",
      "2019-03-16 12:55:51.131633: step 4150, examples 207500, loss = 0.583064318 (237.811 examples/sec; 0.210 sec/batch)\n",
      "2019-03-16 12:55:53.107376: step 4160, examples 208000, loss = 0.531926572 (265.114 examples/sec; 0.189 sec/batch)\n",
      "2019-03-16 12:55:55.082649: step 4170, examples 208500, loss = 0.383527398 (240.066 examples/sec; 0.208 sec/batch)\n",
      "2019-03-16 12:55:57.086940: step 4180, examples 209000, loss = 0.259232938 (233.308 examples/sec; 0.214 sec/batch)\n",
      "2019-03-16 12:55:59.044140: step 4190, examples 209500, loss = 0.334223032 (266.638 examples/sec; 0.188 sec/batch)\n",
      "2019-03-16 12:56:00.892031: step 4200, examples 210000, loss = 0.367690712 (266.639 examples/sec; 0.188 sec/batch)\n",
      "Top 1 validation accuracy: 0.5872641801834106 and top 2 validation accuracy: 0.8160377144813538\n",
      "Model Saved!\n",
      "2019-03-16 12:56:04.445785: step 4210, examples 210500, loss = 0.833974063 (259.452 examples/sec; 0.193 sec/batch)\n",
      "2019-03-16 12:56:06.269613: step 4220, examples 211000, loss = 0.658713937 (284.442 examples/sec; 0.176 sec/batch)\n",
      "2019-03-16 12:56:08.107123: step 4230, examples 211500, loss = 0.393623829 (266.610 examples/sec; 0.188 sec/batch)\n",
      "2019-03-16 12:56:09.934916: step 4240, examples 212000, loss = 0.322947264 (290.878 examples/sec; 0.172 sec/batch)\n",
      "2019-03-16 12:56:11.789782: step 4250, examples 212500, loss = 0.351736963 (251.031 examples/sec; 0.199 sec/batch)\n",
      "2019-03-16 12:56:13.728451: step 4260, examples 213000, loss = 0.267676473 (262.459 examples/sec; 0.191 sec/batch)\n",
      "2019-03-16 12:56:15.590700: step 4270, examples 213500, loss = 0.329300970 (269.180 examples/sec; 0.186 sec/batch)\n",
      "2019-03-16 12:56:17.451414: step 4280, examples 214000, loss = 0.398224592 (274.056 examples/sec; 0.182 sec/batch)\n",
      "2019-03-16 12:56:19.342550: step 4290, examples 214500, loss = 0.451864600 (263.057 examples/sec; 0.190 sec/batch)\n",
      "2019-03-16 12:56:21.269019: step 4300, examples 215000, loss = 0.438010454 (300.982 examples/sec; 0.166 sec/batch)\n",
      "Top 1 validation accuracy: 0.599056601524353 and top 2 validation accuracy: 0.8089622855186462\n",
      "Model Saved!\n",
      "2019-03-16 12:56:24.753947: step 4310, examples 215500, loss = 0.419804692 (274.640 examples/sec; 0.182 sec/batch)\n",
      "2019-03-16 12:56:26.623045: step 4320, examples 216000, loss = 0.418854296 (290.882 examples/sec; 0.172 sec/batch)\n",
      "2019-03-16 12:56:28.482646: step 4330, examples 216500, loss = 0.367039680 (254.800 examples/sec; 0.196 sec/batch)\n",
      "2019-03-16 12:56:30.324353: step 4340, examples 217000, loss = 0.426055193 (275.569 examples/sec; 0.181 sec/batch)\n",
      "2019-03-16 12:56:32.213100: step 4350, examples 217500, loss = 0.374362826 (266.668 examples/sec; 0.187 sec/batch)\n",
      "2019-03-16 12:56:34.088392: step 4360, examples 218000, loss = 0.388286918 (272.498 examples/sec; 0.183 sec/batch)\n",
      "2019-03-16 12:56:36.016512: step 4370, examples 218500, loss = 0.618742585 (266.638 examples/sec; 0.188 sec/batch)\n",
      "2019-03-16 12:56:37.880639: step 4380, examples 219000, loss = 0.395151168 (266.638 examples/sec; 0.188 sec/batch)\n",
      "2019-03-16 12:56:39.778421: step 4390, examples 219500, loss = 0.587072253 (266.638 examples/sec; 0.188 sec/batch)\n",
      "2019-03-16 12:56:41.653035: step 4400, examples 220000, loss = 0.497896314 (269.014 examples/sec; 0.186 sec/batch)\n",
      "Top 1 validation accuracy: 0.5778301954269409 and top 2 validation accuracy: 0.8160377144813538\n",
      "Model Saved!\n",
      "2019-03-16 12:56:45.185933: step 4410, examples 220500, loss = 0.449367940 (265.125 examples/sec; 0.189 sec/batch)\n",
      "2019-03-16 12:56:47.043885: step 4420, examples 221000, loss = 0.360645235 (266.639 examples/sec; 0.188 sec/batch)\n",
      "2019-03-16 12:56:48.925743: step 4430, examples 221500, loss = 0.399968386 (266.638 examples/sec; 0.188 sec/batch)\n",
      "2019-03-16 12:56:50.777641: step 4440, examples 222000, loss = 0.380433798 (266.638 examples/sec; 0.188 sec/batch)\n",
      "2019-03-16 12:56:52.669094: step 4450, examples 222500, loss = 0.415577620 (269.515 examples/sec; 0.186 sec/batch)\n",
      "2019-03-16 12:56:54.550386: step 4460, examples 223000, loss = 0.471940666 (246.868 examples/sec; 0.203 sec/batch)\n",
      "2019-03-16 12:56:56.744295: step 4470, examples 223500, loss = 0.474559903 (275.201 examples/sec; 0.182 sec/batch)\n",
      "2019-03-16 12:56:58.626039: step 4480, examples 224000, loss = 0.505292058 (226.499 examples/sec; 0.221 sec/batch)\n",
      "2019-03-16 12:57:00.808844: step 4490, examples 224500, loss = 0.423320353 (235.222 examples/sec; 0.213 sec/batch)\n",
      "2019-03-16 12:57:03.024040: step 4500, examples 225000, loss = 0.390799224 (236.340 examples/sec; 0.212 sec/batch)\n",
      "Top 1 validation accuracy: 0.5754716992378235 and top 2 validation accuracy: 0.7948113083839417\n",
      "Model Saved!\n",
      "2019-03-16 12:57:06.954674: step 4510, examples 225500, loss = 0.414445609 (290.878 examples/sec; 0.172 sec/batch)\n",
      "2019-03-16 12:57:09.210747: step 4520, examples 226000, loss = 0.328834534 (225.647 examples/sec; 0.222 sec/batch)\n",
      "2019-03-16 12:57:11.304593: step 4530, examples 226500, loss = 0.400998712 (235.973 examples/sec; 0.212 sec/batch)\n",
      "2019-03-16 12:57:13.376168: step 4540, examples 227000, loss = 0.508614600 (256.844 examples/sec; 0.195 sec/batch)\n",
      "2019-03-16 12:57:15.479405: step 4550, examples 227500, loss = 0.493167847 (210.409 examples/sec; 0.238 sec/batch)\n",
      "2019-03-16 12:57:17.576633: step 4560, examples 228000, loss = 0.379279345 (271.429 examples/sec; 0.184 sec/batch)\n",
      "2019-03-16 12:57:19.468287: step 4570, examples 228500, loss = 0.404323548 (262.721 examples/sec; 0.190 sec/batch)\n",
      "2019-03-16 12:57:21.322360: step 4580, examples 229000, loss = 0.403441310 (267.643 examples/sec; 0.187 sec/batch)\n",
      "2019-03-16 12:57:23.145069: step 4590, examples 229500, loss = 0.497242391 (256.218 examples/sec; 0.195 sec/batch)\n",
      "2019-03-16 12:57:25.011150: step 4600, examples 230000, loss = 0.720738828 (290.877 examples/sec; 0.172 sec/batch)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Top 1 validation accuracy: 0.5707547068595886 and top 2 validation accuracy: 0.8089622855186462\n",
      "Model Saved!\n",
      "2019-03-16 12:57:28.451822: step 4610, examples 230500, loss = 0.321591407 (277.686 examples/sec; 0.180 sec/batch)\n",
      "2019-03-16 12:57:30.546657: step 4620, examples 231000, loss = 0.421681494 (184.693 examples/sec; 0.271 sec/batch)\n",
      "2019-03-16 12:57:33.119345: step 4630, examples 231500, loss = 0.468222260 (158.308 examples/sec; 0.316 sec/batch)\n",
      "2019-03-16 12:57:35.253913: step 4640, examples 232000, loss = 0.351315707 (270.844 examples/sec; 0.185 sec/batch)\n",
      "2019-03-16 12:57:37.107156: step 4650, examples 232500, loss = 0.359872371 (264.833 examples/sec; 0.189 sec/batch)\n",
      "2019-03-16 12:57:39.200004: step 4660, examples 233000, loss = 0.298920274 (259.955 examples/sec; 0.192 sec/batch)\n",
      "2019-03-16 12:57:41.246855: step 4670, examples 233500, loss = 0.334362924 (244.446 examples/sec; 0.205 sec/batch)\n",
      "2019-03-16 12:57:43.202566: step 4680, examples 234000, loss = 0.294347644 (239.745 examples/sec; 0.209 sec/batch)\n",
      "2019-03-16 12:57:45.056495: step 4690, examples 234500, loss = 0.318964601 (290.877 examples/sec; 0.172 sec/batch)\n",
      "2019-03-16 12:57:46.919842: step 4700, examples 235000, loss = 0.356051415 (266.639 examples/sec; 0.188 sec/batch)\n",
      "Top 1 validation accuracy: 0.6155660152435303 and top 2 validation accuracy: 0.823113203048706\n",
      "Model Saved!\n",
      "2019-03-16 12:57:50.430483: step 4710, examples 235500, loss = 0.405032337 (271.324 examples/sec; 0.184 sec/batch)\n",
      "2019-03-16 12:57:52.232915: step 4720, examples 236000, loss = 0.379200757 (266.909 examples/sec; 0.187 sec/batch)\n",
      "2019-03-16 12:57:54.149103: step 4730, examples 236500, loss = 0.447017491 (253.265 examples/sec; 0.197 sec/batch)\n",
      "2019-03-16 12:57:55.993774: step 4740, examples 237000, loss = 0.413701147 (266.639 examples/sec; 0.188 sec/batch)\n",
      "2019-03-16 12:57:57.840442: step 4750, examples 237500, loss = 0.425429404 (290.878 examples/sec; 0.172 sec/batch)\n",
      "2019-03-16 12:57:59.669300: step 4760, examples 238000, loss = 0.334472388 (273.255 examples/sec; 0.183 sec/batch)\n",
      "2019-03-16 12:58:01.512999: step 4770, examples 238500, loss = 0.446635097 (267.465 examples/sec; 0.187 sec/batch)\n",
      "2019-03-16 12:58:03.342438: step 4780, examples 239000, loss = 0.485551804 (287.044 examples/sec; 0.174 sec/batch)\n",
      "2019-03-16 12:58:05.168564: step 4790, examples 239500, loss = 0.350473523 (269.352 examples/sec; 0.186 sec/batch)\n",
      "2019-03-16 12:58:06.984862: step 4800, examples 240000, loss = 0.311450958 (290.878 examples/sec; 0.172 sec/batch)\n",
      "Top 1 validation accuracy: 0.6014150977134705 and top 2 validation accuracy: 0.8183962106704712\n",
      "Model Saved!\n",
      "2019-03-16 12:58:10.389929: step 4810, examples 240500, loss = 0.320324630 (286.147 examples/sec; 0.175 sec/batch)\n",
      "2019-03-16 12:58:12.253364: step 4820, examples 241000, loss = 0.363112867 (257.151 examples/sec; 0.194 sec/batch)\n",
      "2019-03-16 12:58:14.152954: step 4830, examples 241500, loss = 0.451310903 (246.068 examples/sec; 0.203 sec/batch)\n",
      "2019-03-16 12:58:16.100134: step 4840, examples 242000, loss = 0.476469368 (259.614 examples/sec; 0.193 sec/batch)\n",
      "2019-03-16 12:58:17.903777: step 4850, examples 242500, loss = 0.387258351 (266.638 examples/sec; 0.188 sec/batch)\n",
      "2019-03-16 12:58:19.764455: step 4860, examples 243000, loss = 0.392260313 (266.637 examples/sec; 0.188 sec/batch)\n",
      "2019-03-16 12:58:21.606051: step 4870, examples 243500, loss = 0.409019351 (260.935 examples/sec; 0.192 sec/batch)\n",
      "2019-03-16 12:58:23.466721: step 4880, examples 244000, loss = 0.423260510 (266.809 examples/sec; 0.187 sec/batch)\n",
      "2019-03-16 12:58:25.355897: step 4890, examples 244500, loss = 0.361642659 (266.634 examples/sec; 0.188 sec/batch)\n",
      "2019-03-16 12:58:27.199768: step 4900, examples 245000, loss = 0.446911573 (266.398 examples/sec; 0.188 sec/batch)\n",
      "Top 1 validation accuracy: 0.5849056839942932 and top 2 validation accuracy: 0.8301886916160583\n",
      "Model Saved!\n",
      "2019-03-16 12:58:30.650793: step 4910, examples 245500, loss = 0.334896147 (272.956 examples/sec; 0.183 sec/batch)\n",
      "2019-03-16 12:58:32.845195: step 4920, examples 246000, loss = 0.371910572 (204.373 examples/sec; 0.245 sec/batch)\n",
      "2019-03-16 12:58:35.342468: step 4930, examples 246500, loss = 0.409717321 (205.214 examples/sec; 0.244 sec/batch)\n",
      "2019-03-16 12:58:37.652611: step 4940, examples 247000, loss = 0.387247652 (246.867 examples/sec; 0.203 sec/batch)\n",
      "2019-03-16 12:58:40.065333: step 4950, examples 247500, loss = 0.653632641 (236.336 examples/sec; 0.212 sec/batch)\n",
      "2019-03-16 12:58:42.376061: step 4960, examples 248000, loss = 0.463267565 (229.916 examples/sec; 0.217 sec/batch)\n",
      "2019-03-16 12:58:44.358824: step 4970, examples 248500, loss = 0.398320526 (260.339 examples/sec; 0.192 sec/batch)\n",
      "2019-03-16 12:58:46.337266: step 4980, examples 249000, loss = 0.383923590 (270.452 examples/sec; 0.185 sec/batch)\n",
      "2019-03-16 12:58:48.273381: step 4990, examples 249500, loss = 0.285210669 (275.434 examples/sec; 0.182 sec/batch)\n",
      "Top 1 validation accuracy: 0.573113203048706 and top 2 validation accuracy: 0.8042452931404114\n",
      "Model Saved!\n"
     ]
    }
   ],
   "source": [
    "best_val_ss = {}\n",
    "\n",
    "num_cls = 4\n",
    "mstp = 5000\n",
    "lfrq = 10\n",
    "bsz = 50\n",
    "msf = 100\n",
    "tr = './trained_model_final/DCNN_reg_ss'\n",
    "if not os.path.exists(tr):\n",
    "    os.mkdir(tr)\n",
    "start = 0\n",
    "stop = 350\n",
    "step = 100\n",
    "time_length = 700\n",
    "time_bin = 350\n",
    "fsz = 6\n",
    "use_batchnorm = True\n",
    "use_dropout = True\n",
    "use_l2loss = True\n",
    "acc = 'Accuracy'\n",
    "path = 'Path'\n",
    "\n",
    "best_val_ss[acc],best_val_ss[path] = train_model_ss(tr,start,stop,step,time_length,time_bin,fsz,use_batchnorm,use_dropout,use_l2loss,num_cls,mstp,lfrq,bsz,msf)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def test_model_ss(model_dir,start,stop,step,time_length,time_bin,fsz,use_batchnorm,use_dropout,use_l2loss):\n",
    "    print(\"Loading datasets...\")\n",
    "    trainSet, testSet, valSet, labelNames = data_loader_ss(time_length)\n",
    "    print(\"Dataset loading completes.\")\n",
    "    \n",
    "    # reset default graph\n",
    "    tf.reset_default_graph()\n",
    "    \n",
    "    # create model\n",
    "    \n",
    "    model = Model(config, labelNames,start,stop,step,time_bin,fsz,use_batchnorm,use_dropout,use_l2loss)\n",
    "    # training setups\n",
    "    saver = tf.train.Saver(max_to_keep=100)\n",
    "    test_accuracy = [0, 0]\n",
    "    \n",
    "    config_proto = tf.ConfigProto()\n",
    "\n",
    "    off = rewriter_config_pb2.RewriterConfig.OFF\n",
    "    config_proto.graph_options.rewrite_options.arithmetic_optimization = off\n",
    "\n",
    "    with tf.Session(config=config_proto) as session:\n",
    "        session.run(tf.global_variables_initializer())\n",
    "        saver.restore(session, model_dir)\n",
    "        # test model\n",
    "        exp_results = run_single_step(session, model, testSet, mode='test')\n",
    "        test_accuracy[0] = exp_results['top_1_accuracy']\n",
    "        test_accuracy[1] = exp_results['top_2_accuracy']\n",
    "        print('top_1_accuracy_test = ', test_accuracy[0], 'top_2_accuracy_test = ', test_accuracy[1])\n",
    "        \n",
    "    top1_acc = test_accuracy[0]\n",
    "    top2_acc = test_accuracy[1]\n",
    "    return top1_acc,top2_acc\n",
    "\n",
    "\n",
    "def run_single_step(\n",
    "        session,\n",
    "        model,\n",
    "        batch,\n",
    "        mode='test',\n",
    "        log=True,\n",
    "):\n",
    "    # construct feed dict\n",
    "    feed_dict = {\n",
    "        model.input: batch['data'],\n",
    "        # model.coarse_labels: batch['coarse_labels'],\n",
    "        model.fine_labels: batch['labels'],\n",
    "        # model.label_mapping: label_mapping,\n",
    "        model.is_training: mode == 'train'\n",
    "    }\n",
    "    \n",
    "    # select proper summary op\n",
    "    if mode == 'train':\n",
    "        summary_op = model.train_summary_op\n",
    "    elif mode == 'val':\n",
    "        summary_op = model.val_summary_op\n",
    "    else:\n",
    "        summary_op = model.test_summary_op\n",
    "    \n",
    "    # construct fetch list\n",
    "    fetch_list = [model.global_step, summary_op, model.loss, model.accuracy, model.top_2_accuracy]\n",
    "\n",
    "    # run single step\n",
    "    _start_time = time.time()\n",
    "    _step, _summary, _loss, _top_1, _top_2 = session.run(fetch_list, feed_dict=feed_dict)[:5]\n",
    "    _end_time = time.time()\n",
    "    \n",
    "    # collect step statistics\n",
    "    step_time = _end_time - _start_time\n",
    "    batch_size = batch['data'].shape[0]\n",
    "    \n",
    "    # log in console\n",
    "    if log:\n",
    "        print(('[{:5s} step {:4d}] loss: {:.5f}; top_1_accuracy: {:.5f}; top_5_accuracy: {:5f} ' +\n",
    "              '({:.3f} sec/batch; {:.3f} instances/sec)'\n",
    "              ).format(mode, _step, _loss, _top_1, _top_2, \n",
    "                       step_time, batch_size / step_time))\n",
    "    \n",
    "    # log results to file and return statistics\n",
    "    if mode == 'test':\n",
    "        test_fetch_list = [model.per_class_accuracy,\n",
    "                model.top_2_per_class_accuracy,\n",
    "                model.confusion_matrix, \n",
    "                model.pred, model.probs]\n",
    "        _top_1_c,  _top_2_c, _cm, _pred, _probs = \\\n",
    "                session.run(test_fetch_list, feed_dict=feed_dict)\n",
    "        \n",
    "        \n",
    "        # Log detailed test results in pickle format\n",
    "        stats = {\n",
    "            \"loss\": _loss,\n",
    "            \"top_1_accuracy\": _top_1,\n",
    "            \"top_2_accuracy\": _top_2,\n",
    "            \"top_1_perclass_accuracy\": _top_1_c,\n",
    "            \"top_2_perclass_accuracy\": _top_2_c,\n",
    "            \"confusion_matrix\": _cm,\n",
    "            \"pred\": _pred,\n",
    "            \"probs\": _probs\n",
    "        }\n",
    "    else:\n",
    "        stats = {\n",
    "            \"step\": _step,\n",
    "            \"loss\": _loss,\n",
    "            \"top_1_accuracy\": _top_1,\n",
    "            \"top_2_accuracy\": _top_2\n",
    "        }\n",
    "        \n",
    "    return stats"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test Accuracy for Subsampling:\n",
      "Loading datasets...\n",
      "Dataset loading completes.\n",
      "INFO:tensorflow:Restoring parameters from ./trained_model_final/DCNN_reg_ss\\model.ckpt-1601\n",
      "[test  step 1601] loss: 1.43090; top_1_accuracy: 0.59594; top_5_accuracy: 0.811512 (1.050 sec/batch; 843.693 instances/sec)\n",
      "top_1_accuracy_test =  0.5959368 top_2_accuracy_test =  0.8115124\n"
     ]
    }
   ],
   "source": [
    "# Accuracy for testSet(best)\n",
    "\n",
    "path = 'Path'\n",
    "model_dir = best_val_ss[path]\n",
    "start = 0\n",
    "stop = 350\n",
    "step = 100\n",
    "time_length = 700\n",
    "time_bin = 350\n",
    "#Nb = BATCH_SIZE\n",
    "fsz = 6\n",
    "use_batchnorm = True\n",
    "use_dropout = True\n",
    "use_l2loss = True\n",
    "print('Test Accuracy for Subsampling:')\n",
    "best_test_acc_ss, best_test_acc2_ss = test_model_ss(model_dir,start,stop,step,time_length,time_bin,fsz,use_batchnorm,use_dropout,use_l2loss)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading datasets...\n",
      "Dataset loading completes.\n",
      "2019-03-16 16:40:52.871784: step 0, examples 0, loss = 1.441268325 (118.512 examples/sec; 0.844 sec/batch)\n",
      "Top 1 validation accuracy: 0.25943395495414734 and top 2 validation accuracy: 0.5070754885673523\n",
      "Model Saved!\n",
      "2019-03-16 16:40:59.747225: step 10, examples 1000, loss = 1.427458048 (199.686 examples/sec; 0.501 sec/batch)\n",
      "2019-03-16 16:41:04.706026: step 20, examples 2000, loss = 1.415421605 (197.539 examples/sec; 0.506 sec/batch)\n",
      "2019-03-16 16:41:09.684045: step 30, examples 3000, loss = 1.361649752 (206.474 examples/sec; 0.484 sec/batch)\n",
      "2019-03-16 16:41:14.622343: step 40, examples 4000, loss = 1.359479785 (193.929 examples/sec; 0.516 sec/batch)\n",
      "2019-03-16 16:41:19.559762: step 50, examples 5000, loss = 1.280585289 (212.384 examples/sec; 0.471 sec/batch)\n",
      "2019-03-16 16:41:24.605970: step 60, examples 6000, loss = 1.238089681 (190.103 examples/sec; 0.526 sec/batch)\n",
      "2019-03-16 16:41:29.498151: step 70, examples 7000, loss = 1.238902211 (205.451 examples/sec; 0.487 sec/batch)\n",
      "2019-03-16 16:41:34.466911: step 80, examples 8000, loss = 1.169672966 (207.423 examples/sec; 0.482 sec/batch)\n",
      "2019-03-16 16:41:39.498837: step 90, examples 9000, loss = 1.205262303 (203.143 examples/sec; 0.492 sec/batch)\n",
      "2019-03-16 16:41:44.659753: step 100, examples 10000, loss = 1.210416794 (195.715 examples/sec; 0.511 sec/batch)\n",
      "Top 1 validation accuracy: 0.4150943458080292 and top 2 validation accuracy: 0.6297169923782349\n",
      "Model Saved!\n",
      "2019-03-16 16:41:51.498813: step 110, examples 11000, loss = 1.271164060 (201.870 examples/sec; 0.495 sec/batch)\n",
      "2019-03-16 16:41:56.580323: step 120, examples 12000, loss = 1.201634169 (191.975 examples/sec; 0.521 sec/batch)\n",
      "2019-03-16 16:42:01.544095: step 130, examples 13000, loss = 1.222645760 (199.823 examples/sec; 0.500 sec/batch)\n",
      "2019-03-16 16:42:06.581721: step 140, examples 14000, loss = 1.190919042 (186.016 examples/sec; 0.538 sec/batch)\n",
      "2019-03-16 16:42:11.532371: step 150, examples 15000, loss = 1.150428176 (198.238 examples/sec; 0.504 sec/batch)\n",
      "2019-03-16 16:42:16.543433: step 160, examples 16000, loss = 1.111266375 (200.035 examples/sec; 0.500 sec/batch)\n",
      "2019-03-16 16:42:21.535678: step 170, examples 17000, loss = 1.216961503 (197.220 examples/sec; 0.507 sec/batch)\n",
      "2019-03-16 16:42:26.498965: step 180, examples 18000, loss = 1.065438867 (196.749 examples/sec; 0.508 sec/batch)\n",
      "2019-03-16 16:42:31.525312: step 190, examples 19000, loss = 1.016609073 (201.186 examples/sec; 0.497 sec/batch)\n",
      "2019-03-16 16:42:36.682576: step 200, examples 20000, loss = 0.993782461 (200.590 examples/sec; 0.499 sec/batch)\n",
      "Top 1 validation accuracy: 0.4811320900917053 and top 2 validation accuracy: 0.7264150977134705\n",
      "Model Saved!\n",
      "2019-03-16 16:42:43.686880: step 210, examples 21000, loss = 1.009600759 (192.884 examples/sec; 0.518 sec/batch)\n",
      "2019-03-16 16:42:48.758660: step 220, examples 22000, loss = 1.010742545 (191.981 examples/sec; 0.521 sec/batch)\n",
      "2019-03-16 16:42:53.752243: step 230, examples 23000, loss = 0.982182682 (206.849 examples/sec; 0.483 sec/batch)\n",
      "2019-03-16 16:42:58.778414: step 240, examples 24000, loss = 1.062026501 (206.285 examples/sec; 0.485 sec/batch)\n",
      "2019-03-16 16:43:03.871477: step 250, examples 25000, loss = 0.781407535 (201.057 examples/sec; 0.497 sec/batch)\n",
      "2019-03-16 16:43:08.888781: step 260, examples 26000, loss = 0.867587686 (206.738 examples/sec; 0.484 sec/batch)\n",
      "2019-03-16 16:43:13.906980: step 270, examples 27000, loss = 0.893044829 (199.385 examples/sec; 0.502 sec/batch)\n",
      "2019-03-16 16:43:18.926008: step 280, examples 28000, loss = 0.926372945 (208.164 examples/sec; 0.480 sec/batch)\n",
      "2019-03-16 16:43:23.920253: step 290, examples 29000, loss = 0.836813629 (194.110 examples/sec; 0.515 sec/batch)\n",
      "2019-03-16 16:43:28.966272: step 300, examples 30000, loss = 1.097922564 (200.312 examples/sec; 0.499 sec/batch)\n",
      "Top 1 validation accuracy: 0.5117924809455872 and top 2 validation accuracy: 0.7594339847564697\n",
      "Model Saved!\n",
      "2019-03-16 16:43:35.828407: step 310, examples 31000, loss = 0.857353628 (199.999 examples/sec; 0.500 sec/batch)\n",
      "2019-03-16 16:43:40.873955: step 320, examples 32000, loss = 0.971020460 (206.414 examples/sec; 0.484 sec/batch)\n",
      "2019-03-16 16:43:45.982995: step 330, examples 33000, loss = 0.689017415 (199.901 examples/sec; 0.500 sec/batch)\n",
      "2019-03-16 16:43:51.095265: step 340, examples 34000, loss = 0.801391661 (186.621 examples/sec; 0.536 sec/batch)\n",
      "2019-03-16 16:43:56.147787: step 350, examples 35000, loss = 0.864649832 (195.911 examples/sec; 0.510 sec/batch)\n",
      "2019-03-16 16:44:01.224116: step 360, examples 36000, loss = 0.864592254 (193.653 examples/sec; 0.516 sec/batch)\n",
      "2019-03-16 16:44:06.260022: step 370, examples 37000, loss = 0.903664112 (207.855 examples/sec; 0.481 sec/batch)\n",
      "2019-03-16 16:44:11.283978: step 380, examples 38000, loss = 0.876021981 (209.749 examples/sec; 0.477 sec/batch)\n",
      "2019-03-16 16:44:16.373696: step 390, examples 39000, loss = 0.837822616 (195.399 examples/sec; 0.512 sec/batch)\n",
      "2019-03-16 16:44:21.521482: step 400, examples 40000, loss = 0.741630256 (194.727 examples/sec; 0.514 sec/batch)\n",
      "Top 1 validation accuracy: 0.5660377144813538 and top 2 validation accuracy: 0.7806603908538818\n",
      "Model Saved!\n",
      "2019-03-16 16:44:28.520705: step 410, examples 41000, loss = 0.722619891 (187.877 examples/sec; 0.532 sec/batch)\n",
      "2019-03-16 16:44:33.606314: step 420, examples 42000, loss = 0.725284398 (196.170 examples/sec; 0.510 sec/batch)\n",
      "2019-03-16 16:44:38.730883: step 430, examples 43000, loss = 0.658787131 (194.031 examples/sec; 0.515 sec/batch)\n",
      "2019-03-16 16:44:43.733736: step 440, examples 44000, loss = 0.553748310 (204.326 examples/sec; 0.489 sec/batch)\n",
      "2019-03-16 16:44:48.751387: step 450, examples 45000, loss = 0.820707679 (203.660 examples/sec; 0.491 sec/batch)\n",
      "2019-03-16 16:44:53.882782: step 460, examples 46000, loss = 0.721494019 (202.824 examples/sec; 0.493 sec/batch)\n",
      "2019-03-16 16:44:58.955678: step 470, examples 47000, loss = 0.767200589 (194.687 examples/sec; 0.514 sec/batch)\n",
      "2019-03-16 16:45:03.961692: step 480, examples 48000, loss = 0.533470929 (202.047 examples/sec; 0.495 sec/batch)\n",
      "2019-03-16 16:45:09.092928: step 490, examples 49000, loss = 0.592232347 (198.936 examples/sec; 0.503 sec/batch)\n",
      "2019-03-16 16:45:14.316259: step 500, examples 50000, loss = 0.608340681 (191.493 examples/sec; 0.522 sec/batch)\n",
      "Top 1 validation accuracy: 0.5424528121948242 and top 2 validation accuracy: 0.7806603908538818\n",
      "Model Saved!\n",
      "2019-03-16 16:45:21.244802: step 510, examples 51000, loss = 0.492324054 (190.446 examples/sec; 0.525 sec/batch)\n",
      "2019-03-16 16:45:26.326146: step 520, examples 52000, loss = 0.712280869 (202.730 examples/sec; 0.493 sec/batch)\n",
      "2019-03-16 16:45:31.358218: step 530, examples 53000, loss = 0.649689615 (199.449 examples/sec; 0.501 sec/batch)\n",
      "2019-03-16 16:45:36.332661: step 540, examples 54000, loss = 0.524226606 (202.504 examples/sec; 0.494 sec/batch)\n",
      "2019-03-16 16:45:41.343165: step 550, examples 55000, loss = 0.726536572 (193.023 examples/sec; 0.518 sec/batch)\n",
      "2019-03-16 16:45:46.464660: step 560, examples 56000, loss = 0.707867563 (193.323 examples/sec; 0.517 sec/batch)\n",
      "2019-03-16 16:45:51.877339: step 570, examples 57000, loss = 0.764400601 (192.887 examples/sec; 0.518 sec/batch)\n",
      "2019-03-16 16:45:57.306773: step 580, examples 58000, loss = 0.556553721 (203.352 examples/sec; 0.492 sec/batch)\n",
      "2019-03-16 16:46:02.334859: step 590, examples 59000, loss = 0.498818278 (201.970 examples/sec; 0.495 sec/batch)\n",
      "2019-03-16 16:46:07.520274: step 600, examples 60000, loss = 0.635984838 (192.243 examples/sec; 0.520 sec/batch)\n",
      "Top 1 validation accuracy: 0.5589622855186462 and top 2 validation accuracy: 0.775943398475647\n",
      "Model Saved!\n",
      "2019-03-16 16:46:14.435629: step 610, examples 61000, loss = 0.647051632 (187.828 examples/sec; 0.532 sec/batch)\n",
      "2019-03-16 16:46:19.543360: step 620, examples 62000, loss = 0.570669949 (194.388 examples/sec; 0.514 sec/batch)\n",
      "2019-03-16 16:46:24.747205: step 630, examples 63000, loss = 0.499953806 (198.946 examples/sec; 0.503 sec/batch)\n",
      "2019-03-16 16:46:29.826123: step 640, examples 64000, loss = 0.678225517 (205.664 examples/sec; 0.486 sec/batch)\n",
      "2019-03-16 16:46:34.932482: step 650, examples 65000, loss = 0.410184771 (206.650 examples/sec; 0.484 sec/batch)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2019-03-16 16:46:39.939083: step 660, examples 66000, loss = 0.400830775 (200.779 examples/sec; 0.498 sec/batch)\n",
      "2019-03-16 16:46:44.983823: step 670, examples 67000, loss = 0.538155675 (199.613 examples/sec; 0.501 sec/batch)\n",
      "2019-03-16 16:46:49.994361: step 680, examples 68000, loss = 0.662711024 (201.462 examples/sec; 0.496 sec/batch)\n",
      "2019-03-16 16:46:55.074607: step 690, examples 69000, loss = 0.441506356 (201.759 examples/sec; 0.496 sec/batch)\n",
      "2019-03-16 16:47:00.199999: step 700, examples 70000, loss = 0.588956058 (193.961 examples/sec; 0.516 sec/batch)\n",
      "Top 1 validation accuracy: 0.5542452931404114 and top 2 validation accuracy: 0.7783018946647644\n",
      "Model Saved!\n",
      "2019-03-16 16:47:06.950417: step 710, examples 71000, loss = 0.549572229 (200.455 examples/sec; 0.499 sec/batch)\n",
      "2019-03-16 16:47:11.966814: step 720, examples 72000, loss = 0.552448273 (194.203 examples/sec; 0.515 sec/batch)\n",
      "2019-03-16 16:47:16.974275: step 730, examples 73000, loss = 0.557506084 (191.334 examples/sec; 0.523 sec/batch)\n",
      "2019-03-16 16:47:21.955216: step 740, examples 74000, loss = 0.588821411 (198.680 examples/sec; 0.503 sec/batch)\n",
      "2019-03-16 16:47:26.897282: step 750, examples 75000, loss = 0.490886897 (203.447 examples/sec; 0.492 sec/batch)\n",
      "2019-03-16 16:47:31.938851: step 760, examples 76000, loss = 0.710684776 (197.826 examples/sec; 0.505 sec/batch)\n",
      "2019-03-16 16:47:36.950164: step 770, examples 77000, loss = 0.695251524 (199.358 examples/sec; 0.502 sec/batch)\n",
      "2019-03-16 16:47:41.922115: step 780, examples 78000, loss = 0.641600907 (205.977 examples/sec; 0.485 sec/batch)\n",
      "2019-03-16 16:47:47.067155: step 790, examples 79000, loss = 0.495726198 (185.485 examples/sec; 0.539 sec/batch)\n",
      "2019-03-16 16:47:52.090493: step 800, examples 80000, loss = 0.616566896 (200.557 examples/sec; 0.499 sec/batch)\n",
      "Top 1 validation accuracy: 0.5943396091461182 and top 2 validation accuracy: 0.8089622855186462\n",
      "Model Saved!\n",
      "2019-03-16 16:47:59.374482: step 810, examples 81000, loss = 0.906615794 (180.065 examples/sec; 0.555 sec/batch)\n",
      "2019-03-16 16:48:05.005215: step 820, examples 82000, loss = 0.547528327 (180.548 examples/sec; 0.554 sec/batch)\n",
      "2019-03-16 16:48:10.445521: step 830, examples 83000, loss = 0.524909258 (206.195 examples/sec; 0.485 sec/batch)\n",
      "2019-03-16 16:48:15.451539: step 840, examples 84000, loss = 0.508215547 (201.985 examples/sec; 0.495 sec/batch)\n",
      "2019-03-16 16:48:20.532536: step 850, examples 85000, loss = 0.542341590 (189.065 examples/sec; 0.529 sec/batch)\n",
      "2019-03-16 16:48:25.574732: step 860, examples 86000, loss = 0.447518796 (198.290 examples/sec; 0.504 sec/batch)\n",
      "2019-03-16 16:48:30.637176: step 870, examples 87000, loss = 0.444316804 (202.796 examples/sec; 0.493 sec/batch)\n",
      "2019-03-16 16:48:35.700109: step 880, examples 88000, loss = 0.475491822 (199.763 examples/sec; 0.501 sec/batch)\n",
      "2019-03-16 16:48:40.958183: step 890, examples 89000, loss = 0.691886485 (195.392 examples/sec; 0.512 sec/batch)\n",
      "2019-03-16 16:48:45.954047: step 900, examples 90000, loss = 0.386453092 (198.839 examples/sec; 0.503 sec/batch)\n",
      "Top 1 validation accuracy: 0.5660377144813538 and top 2 validation accuracy: 0.7665094137191772\n",
      "Model Saved!\n",
      "2019-03-16 16:48:52.871653: step 910, examples 91000, loss = 0.420808673 (207.575 examples/sec; 0.482 sec/batch)\n",
      "2019-03-16 16:48:57.994704: step 920, examples 92000, loss = 0.463239700 (184.594 examples/sec; 0.542 sec/batch)\n",
      "2019-03-16 16:49:03.086908: step 930, examples 93000, loss = 0.452858299 (189.508 examples/sec; 0.528 sec/batch)\n",
      "2019-03-16 16:49:08.144239: step 940, examples 94000, loss = 0.407831848 (191.631 examples/sec; 0.522 sec/batch)\n",
      "2019-03-16 16:49:13.122291: step 950, examples 95000, loss = 0.412208915 (206.276 examples/sec; 0.485 sec/batch)\n",
      "2019-03-16 16:49:18.152456: step 960, examples 96000, loss = 0.447820693 (188.336 examples/sec; 0.531 sec/batch)\n",
      "2019-03-16 16:49:23.199372: step 970, examples 97000, loss = 0.528519034 (208.016 examples/sec; 0.481 sec/batch)\n",
      "2019-03-16 16:49:28.358490: step 980, examples 98000, loss = 0.581402302 (194.625 examples/sec; 0.514 sec/batch)\n",
      "2019-03-16 16:49:33.482584: step 990, examples 99000, loss = 0.468614042 (187.957 examples/sec; 0.532 sec/batch)\n",
      "2019-03-16 16:49:38.540575: step 1000, examples 100000, loss = 0.408289373 (195.023 examples/sec; 0.513 sec/batch)\n",
      "Top 1 validation accuracy: 0.5683962106704712 and top 2 validation accuracy: 0.7971698045730591\n",
      "Model Saved!\n",
      "2019-03-16 16:49:45.530857: step 1010, examples 101000, loss = 0.473666787 (190.135 examples/sec; 0.526 sec/batch)\n",
      "2019-03-16 16:49:50.527495: step 1020, examples 102000, loss = 0.479735851 (192.643 examples/sec; 0.519 sec/batch)\n",
      "2019-03-16 16:49:55.559178: step 1030, examples 103000, loss = 0.407074153 (200.091 examples/sec; 0.500 sec/batch)\n",
      "2019-03-16 16:50:00.639666: step 1040, examples 104000, loss = 0.436191142 (205.441 examples/sec; 0.487 sec/batch)\n",
      "2019-03-16 16:50:05.673313: step 1050, examples 105000, loss = 0.485047191 (192.197 examples/sec; 0.520 sec/batch)\n",
      "2019-03-16 16:50:10.673781: step 1060, examples 106000, loss = 0.296717942 (204.123 examples/sec; 0.490 sec/batch)\n",
      "2019-03-16 16:50:15.684034: step 1070, examples 107000, loss = 0.510351777 (206.481 examples/sec; 0.484 sec/batch)\n",
      "2019-03-16 16:50:20.785709: step 1080, examples 108000, loss = 0.462746441 (199.299 examples/sec; 0.502 sec/batch)\n",
      "2019-03-16 16:50:25.843713: step 1090, examples 109000, loss = 0.445920110 (199.675 examples/sec; 0.501 sec/batch)\n",
      "2019-03-16 16:50:30.937478: step 1100, examples 110000, loss = 0.468602836 (197.617 examples/sec; 0.506 sec/batch)\n",
      "Top 1 validation accuracy: 0.573113203048706 and top 2 validation accuracy: 0.7924528121948242\n",
      "Model Saved!\n",
      "2019-03-16 16:50:38.036898: step 1110, examples 111000, loss = 0.379050910 (191.481 examples/sec; 0.522 sec/batch)\n",
      "2019-03-16 16:50:43.291643: step 1120, examples 112000, loss = 0.491723955 (191.714 examples/sec; 0.522 sec/batch)\n",
      "2019-03-16 16:50:48.656418: step 1130, examples 113000, loss = 0.420132160 (195.354 examples/sec; 0.512 sec/batch)\n",
      "2019-03-16 16:50:53.849617: step 1140, examples 114000, loss = 0.280491948 (197.520 examples/sec; 0.506 sec/batch)\n",
      "2019-03-16 16:50:59.105334: step 1150, examples 115000, loss = 0.513696432 (178.085 examples/sec; 0.562 sec/batch)\n",
      "2019-03-16 16:51:04.422814: step 1160, examples 116000, loss = 0.335729957 (190.233 examples/sec; 0.526 sec/batch)\n",
      "2019-03-16 16:51:09.590913: step 1170, examples 117000, loss = 0.475147754 (199.807 examples/sec; 0.500 sec/batch)\n",
      "2019-03-16 16:51:15.072993: step 1180, examples 118000, loss = 0.453761935 (184.686 examples/sec; 0.541 sec/batch)\n",
      "2019-03-16 16:51:20.443140: step 1190, examples 119000, loss = 0.398388684 (192.846 examples/sec; 0.519 sec/batch)\n",
      "2019-03-16 16:51:25.670453: step 1200, examples 120000, loss = 0.443243593 (192.496 examples/sec; 0.519 sec/batch)\n",
      "Top 1 validation accuracy: 0.5495283007621765 and top 2 validation accuracy: 0.7853773832321167\n",
      "Model Saved!\n",
      "2019-03-16 16:51:32.965590: step 1210, examples 121000, loss = 0.352628738 (194.447 examples/sec; 0.514 sec/batch)\n",
      "2019-03-16 16:51:38.268988: step 1220, examples 122000, loss = 0.619785011 (185.360 examples/sec; 0.539 sec/batch)\n",
      "2019-03-16 16:51:43.559276: step 1230, examples 123000, loss = 0.416619778 (179.207 examples/sec; 0.558 sec/batch)\n",
      "2019-03-16 16:51:48.923356: step 1240, examples 124000, loss = 0.529385984 (193.137 examples/sec; 0.518 sec/batch)\n",
      "2019-03-16 16:51:54.146081: step 1250, examples 125000, loss = 0.436808079 (180.507 examples/sec; 0.554 sec/batch)\n",
      "2019-03-16 16:51:59.358264: step 1260, examples 126000, loss = 0.314505279 (199.105 examples/sec; 0.502 sec/batch)\n",
      "2019-03-16 16:52:04.638795: step 1270, examples 127000, loss = 0.430519998 (181.778 examples/sec; 0.550 sec/batch)\n",
      "2019-03-16 16:52:09.965888: step 1280, examples 128000, loss = 0.391239077 (200.383 examples/sec; 0.499 sec/batch)\n",
      "2019-03-16 16:52:15.200435: step 1290, examples 129000, loss = 0.492607236 (194.471 examples/sec; 0.514 sec/batch)\n",
      "2019-03-16 16:52:20.431148: step 1300, examples 130000, loss = 0.370990634 (180.565 examples/sec; 0.554 sec/batch)\n",
      "Top 1 validation accuracy: 0.5070754885673523 and top 2 validation accuracy: 0.7688679099082947\n",
      "Model Saved!\n",
      "2019-03-16 16:52:27.544042: step 1310, examples 131000, loss = 0.412706435 (187.943 examples/sec; 0.532 sec/batch)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2019-03-16 16:52:32.742864: step 1320, examples 132000, loss = 0.313344002 (201.779 examples/sec; 0.496 sec/batch)\n",
      "2019-03-16 16:52:38.062218: step 1330, examples 133000, loss = 0.311183989 (177.454 examples/sec; 0.564 sec/batch)\n",
      "2019-03-16 16:52:43.314601: step 1340, examples 134000, loss = 0.417152643 (187.107 examples/sec; 0.534 sec/batch)\n",
      "2019-03-16 16:52:48.583555: step 1350, examples 135000, loss = 0.435539961 (190.942 examples/sec; 0.524 sec/batch)\n",
      "2019-03-16 16:52:53.923902: step 1360, examples 136000, loss = 0.398967862 (192.928 examples/sec; 0.518 sec/batch)\n",
      "2019-03-16 16:52:59.268416: step 1370, examples 137000, loss = 0.349134684 (186.048 examples/sec; 0.537 sec/batch)\n",
      "2019-03-16 16:53:04.482928: step 1380, examples 138000, loss = 0.325918943 (191.649 examples/sec; 0.522 sec/batch)\n",
      "2019-03-16 16:53:10.309114: step 1390, examples 139000, loss = 0.289816320 (171.512 examples/sec; 0.583 sec/batch)\n",
      "2019-03-16 16:53:16.222372: step 1400, examples 140000, loss = 0.405950606 (160.732 examples/sec; 0.622 sec/batch)\n",
      "Top 1 validation accuracy: 0.5542452931404114 and top 2 validation accuracy: 0.7877358198165894\n",
      "Model Saved!\n",
      "2019-03-16 16:53:24.420564: step 1410, examples 141000, loss = 0.344203591 (183.242 examples/sec; 0.546 sec/batch)\n",
      "2019-03-16 16:53:29.809041: step 1420, examples 142000, loss = 0.490928650 (185.113 examples/sec; 0.540 sec/batch)\n",
      "2019-03-16 16:53:35.199469: step 1430, examples 143000, loss = 0.380684704 (188.486 examples/sec; 0.531 sec/batch)\n",
      "2019-03-16 16:53:40.450579: step 1440, examples 144000, loss = 0.341948330 (178.914 examples/sec; 0.559 sec/batch)\n",
      "2019-03-16 16:53:45.858738: step 1450, examples 145000, loss = 0.407959402 (193.356 examples/sec; 0.517 sec/batch)\n",
      "2019-03-16 16:53:51.106709: step 1460, examples 146000, loss = 0.275293887 (188.172 examples/sec; 0.531 sec/batch)\n",
      "2019-03-16 16:53:56.447099: step 1470, examples 147000, loss = 0.320237219 (174.806 examples/sec; 0.572 sec/batch)\n",
      "2019-03-16 16:54:01.787197: step 1480, examples 148000, loss = 0.332909405 (184.158 examples/sec; 0.543 sec/batch)\n",
      "2019-03-16 16:54:07.003023: step 1490, examples 149000, loss = 0.377171874 (186.572 examples/sec; 0.536 sec/batch)\n",
      "2019-03-16 16:54:12.341735: step 1500, examples 150000, loss = 0.229888946 (177.560 examples/sec; 0.563 sec/batch)\n",
      "Top 1 validation accuracy: 0.5495283007621765 and top 2 validation accuracy: 0.7547169923782349\n",
      "Model Saved!\n",
      "2019-03-16 16:54:19.543990: step 1510, examples 151000, loss = 0.334481299 (185.294 examples/sec; 0.540 sec/batch)\n",
      "2019-03-16 16:54:24.793906: step 1520, examples 152000, loss = 0.359559834 (198.966 examples/sec; 0.503 sec/batch)\n",
      "2019-03-16 16:54:30.012148: step 1530, examples 153000, loss = 0.358978748 (188.832 examples/sec; 0.530 sec/batch)\n",
      "2019-03-16 16:54:35.215914: step 1540, examples 154000, loss = 0.329815269 (182.671 examples/sec; 0.547 sec/batch)\n",
      "2019-03-16 16:54:40.452061: step 1550, examples 155000, loss = 0.433958232 (192.664 examples/sec; 0.519 sec/batch)\n",
      "2019-03-16 16:54:45.715160: step 1560, examples 156000, loss = 0.382562190 (193.996 examples/sec; 0.515 sec/batch)\n",
      "2019-03-16 16:54:51.120138: step 1570, examples 157000, loss = 0.281124473 (188.186 examples/sec; 0.531 sec/batch)\n",
      "2019-03-16 16:54:56.404904: step 1580, examples 158000, loss = 0.297496140 (178.069 examples/sec; 0.562 sec/batch)\n",
      "2019-03-16 16:55:01.716101: step 1590, examples 159000, loss = 0.512833178 (182.679 examples/sec; 0.547 sec/batch)\n",
      "2019-03-16 16:55:06.966206: step 1600, examples 160000, loss = 0.338781714 (194.380 examples/sec; 0.514 sec/batch)\n",
      "Top 1 validation accuracy: 0.5966981053352356 and top 2 validation accuracy: 0.8160377144813538\n",
      "Model Saved!\n",
      "2019-03-16 16:55:14.183608: step 1610, examples 161000, loss = 0.432674825 (189.365 examples/sec; 0.528 sec/batch)\n",
      "2019-03-16 16:55:19.498665: step 1620, examples 162000, loss = 0.320759177 (199.127 examples/sec; 0.502 sec/batch)\n",
      "2019-03-16 16:55:24.739785: step 1630, examples 163000, loss = 0.350468993 (201.916 examples/sec; 0.495 sec/batch)\n",
      "2019-03-16 16:55:29.960538: step 1640, examples 164000, loss = 0.330910265 (185.977 examples/sec; 0.538 sec/batch)\n",
      "2019-03-16 16:55:35.259270: step 1650, examples 165000, loss = 0.360836327 (178.648 examples/sec; 0.560 sec/batch)\n",
      "2019-03-16 16:55:40.537152: step 1660, examples 166000, loss = 0.343248874 (188.484 examples/sec; 0.531 sec/batch)\n",
      "2019-03-16 16:55:45.954710: step 1670, examples 167000, loss = 0.279266357 (186.427 examples/sec; 0.536 sec/batch)\n",
      "2019-03-16 16:55:51.451320: step 1680, examples 168000, loss = 0.410261869 (166.957 examples/sec; 0.599 sec/batch)\n",
      "2019-03-16 16:55:56.918314: step 1690, examples 169000, loss = 0.213551879 (178.509 examples/sec; 0.560 sec/batch)\n",
      "2019-03-16 16:56:02.122651: step 1700, examples 170000, loss = 0.360995442 (199.580 examples/sec; 0.501 sec/batch)\n",
      "Top 1 validation accuracy: 0.5896226167678833 and top 2 validation accuracy: 0.801886796951294\n",
      "Model Saved!\n",
      "2019-03-16 16:56:08.991812: step 1710, examples 171000, loss = 0.301783055 (190.646 examples/sec; 0.525 sec/batch)\n",
      "2019-03-16 16:56:13.968785: step 1720, examples 172000, loss = 0.483583897 (199.459 examples/sec; 0.501 sec/batch)\n",
      "2019-03-16 16:56:18.962520: step 1730, examples 173000, loss = 0.365490705 (195.885 examples/sec; 0.511 sec/batch)\n",
      "2019-03-16 16:56:24.024907: step 1740, examples 174000, loss = 0.396772742 (197.251 examples/sec; 0.507 sec/batch)\n",
      "2019-03-16 16:56:29.059228: step 1750, examples 175000, loss = 0.298256457 (206.430 examples/sec; 0.484 sec/batch)\n",
      "2019-03-16 16:56:34.147122: step 1760, examples 176000, loss = 0.382578641 (190.213 examples/sec; 0.526 sec/batch)\n",
      "2019-03-16 16:56:39.260707: step 1770, examples 177000, loss = 0.340064257 (199.460 examples/sec; 0.501 sec/batch)\n",
      "2019-03-16 16:56:44.284252: step 1780, examples 178000, loss = 0.328722954 (194.199 examples/sec; 0.515 sec/batch)\n",
      "2019-03-16 16:56:49.358845: step 1790, examples 179000, loss = 0.282558382 (195.274 examples/sec; 0.512 sec/batch)\n",
      "2019-03-16 16:56:54.405606: step 1800, examples 180000, loss = 0.444854558 (193.234 examples/sec; 0.518 sec/batch)\n",
      "Top 1 validation accuracy: 0.5966981053352356 and top 2 validation accuracy: 0.7877358198165894\n",
      "Model Saved!\n",
      "2019-03-16 16:57:01.244357: step 1810, examples 181000, loss = 0.296181142 (201.384 examples/sec; 0.497 sec/batch)\n",
      "2019-03-16 16:57:06.278611: step 1820, examples 182000, loss = 0.324390769 (202.934 examples/sec; 0.493 sec/batch)\n",
      "2019-03-16 16:57:11.315442: step 1830, examples 183000, loss = 0.263145268 (208.799 examples/sec; 0.479 sec/batch)\n",
      "2019-03-16 16:57:16.307363: step 1840, examples 184000, loss = 0.351458251 (208.033 examples/sec; 0.481 sec/batch)\n",
      "2019-03-16 16:57:21.358930: step 1850, examples 185000, loss = 0.402152777 (196.015 examples/sec; 0.510 sec/batch)\n",
      "2019-03-16 16:57:26.574919: step 1860, examples 186000, loss = 0.460759491 (188.518 examples/sec; 0.530 sec/batch)\n",
      "2019-03-16 16:57:31.543296: step 1870, examples 187000, loss = 0.409586400 (198.568 examples/sec; 0.504 sec/batch)\n",
      "2019-03-16 16:57:36.559103: step 1880, examples 188000, loss = 0.204853326 (200.016 examples/sec; 0.500 sec/batch)\n",
      "2019-03-16 16:57:41.688822: step 1890, examples 189000, loss = 0.404728830 (191.999 examples/sec; 0.521 sec/batch)\n",
      "2019-03-16 16:57:46.822906: step 1900, examples 190000, loss = 0.260159820 (201.219 examples/sec; 0.497 sec/batch)\n",
      "Top 1 validation accuracy: 0.5613207817077637 and top 2 validation accuracy: 0.7830188870429993\n",
      "Model Saved!\n",
      "2019-03-16 16:57:53.606164: step 1910, examples 191000, loss = 0.468694896 (206.596 examples/sec; 0.484 sec/batch)\n",
      "2019-03-16 16:57:58.670502: step 1920, examples 192000, loss = 0.349506438 (199.025 examples/sec; 0.502 sec/batch)\n",
      "2019-03-16 16:58:03.717905: step 1930, examples 193000, loss = 0.261133581 (205.933 examples/sec; 0.486 sec/batch)\n",
      "2019-03-16 16:58:08.804851: step 1940, examples 194000, loss = 0.332001805 (209.888 examples/sec; 0.476 sec/batch)\n",
      "2019-03-16 16:58:13.981370: step 1950, examples 195000, loss = 0.331293523 (188.590 examples/sec; 0.530 sec/batch)\n",
      "2019-03-16 16:58:19.043684: step 1960, examples 196000, loss = 0.391579807 (199.978 examples/sec; 0.500 sec/batch)\n",
      "2019-03-16 16:58:24.168467: step 1970, examples 197000, loss = 0.403349400 (177.882 examples/sec; 0.562 sec/batch)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2019-03-16 16:58:29.684326: step 1980, examples 198000, loss = 0.367703974 (173.173 examples/sec; 0.577 sec/batch)\n",
      "2019-03-16 16:58:34.939577: step 1990, examples 199000, loss = 0.381784260 (202.112 examples/sec; 0.495 sec/batch)\n",
      "2019-03-16 16:58:39.978063: step 2000, examples 200000, loss = 0.403036058 (190.007 examples/sec; 0.526 sec/batch)\n",
      "Top 1 validation accuracy: 0.5683962106704712 and top 2 validation accuracy: 0.7712264060974121\n",
      "Model Saved!\n",
      "2019-03-16 16:58:46.927504: step 2010, examples 201000, loss = 0.379186749 (191.642 examples/sec; 0.522 sec/batch)\n",
      "2019-03-16 16:58:51.926740: step 2020, examples 202000, loss = 0.411801457 (210.640 examples/sec; 0.475 sec/batch)\n",
      "2019-03-16 16:58:56.952939: step 2030, examples 203000, loss = 0.345443606 (199.592 examples/sec; 0.501 sec/batch)\n",
      "2019-03-16 16:59:02.059290: step 2040, examples 204000, loss = 0.236854076 (199.891 examples/sec; 0.500 sec/batch)\n",
      "2019-03-16 16:59:07.239929: step 2050, examples 205000, loss = 0.352337897 (197.307 examples/sec; 0.507 sec/batch)\n",
      "2019-03-16 16:59:12.291202: step 2060, examples 206000, loss = 0.314180404 (197.825 examples/sec; 0.505 sec/batch)\n",
      "2019-03-16 16:59:17.389544: step 2070, examples 207000, loss = 0.338909656 (212.624 examples/sec; 0.470 sec/batch)\n",
      "2019-03-16 16:59:22.438694: step 2080, examples 208000, loss = 0.321483314 (196.153 examples/sec; 0.510 sec/batch)\n",
      "2019-03-16 16:59:27.483003: step 2090, examples 209000, loss = 0.332536995 (194.368 examples/sec; 0.514 sec/batch)\n",
      "2019-03-16 16:59:32.543383: step 2100, examples 210000, loss = 0.254422069 (192.492 examples/sec; 0.520 sec/batch)\n",
      "Top 1 validation accuracy: 0.5707547068595886 and top 2 validation accuracy: 0.7971698045730591\n",
      "Model Saved!\n",
      "2019-03-16 16:59:39.374530: step 2110, examples 211000, loss = 0.276955187 (205.707 examples/sec; 0.486 sec/batch)\n",
      "2019-03-16 16:59:44.540981: step 2120, examples 212000, loss = 0.372983098 (189.110 examples/sec; 0.529 sec/batch)\n",
      "2019-03-16 16:59:49.582463: step 2130, examples 213000, loss = 0.412505865 (191.685 examples/sec; 0.522 sec/batch)\n",
      "2019-03-16 16:59:54.657966: step 2140, examples 214000, loss = 0.365939796 (204.391 examples/sec; 0.489 sec/batch)\n",
      "2019-03-16 16:59:59.725361: step 2150, examples 215000, loss = 0.348958135 (199.471 examples/sec; 0.501 sec/batch)\n",
      "2019-03-16 17:00:04.885379: step 2160, examples 216000, loss = 0.293951839 (184.153 examples/sec; 0.543 sec/batch)\n",
      "2019-03-16 17:00:09.999904: step 2170, examples 217000, loss = 0.295352399 (199.594 examples/sec; 0.501 sec/batch)\n",
      "2019-03-16 17:00:15.014260: step 2180, examples 218000, loss = 0.309407055 (205.878 examples/sec; 0.486 sec/batch)\n",
      "2019-03-16 17:00:20.122576: step 2190, examples 219000, loss = 0.342361838 (188.539 examples/sec; 0.530 sec/batch)\n",
      "2019-03-16 17:00:25.152700: step 2200, examples 220000, loss = 0.283284664 (200.093 examples/sec; 0.500 sec/batch)\n",
      "Top 1 validation accuracy: 0.5683962106704712 and top 2 validation accuracy: 0.7783018946647644\n",
      "Model Saved!\n",
      "2019-03-16 17:00:31.934965: step 2210, examples 221000, loss = 0.323216319 (194.881 examples/sec; 0.513 sec/batch)\n",
      "2019-03-16 17:00:37.085764: step 2220, examples 222000, loss = 0.462117314 (195.616 examples/sec; 0.511 sec/batch)\n",
      "2019-03-16 17:00:42.092709: step 2230, examples 223000, loss = 0.387695611 (187.649 examples/sec; 0.533 sec/batch)\n",
      "2019-03-16 17:00:47.236926: step 2240, examples 224000, loss = 0.452674747 (186.232 examples/sec; 0.537 sec/batch)\n",
      "2019-03-16 17:00:52.235711: step 2250, examples 225000, loss = 0.364206195 (186.790 examples/sec; 0.535 sec/batch)\n",
      "2019-03-16 17:00:57.358336: step 2260, examples 226000, loss = 0.287822634 (187.515 examples/sec; 0.533 sec/batch)\n",
      "2019-03-16 17:01:02.445639: step 2270, examples 227000, loss = 0.307328403 (196.596 examples/sec; 0.509 sec/batch)\n",
      "2019-03-16 17:01:07.576324: step 2280, examples 228000, loss = 0.254111648 (193.591 examples/sec; 0.517 sec/batch)\n",
      "2019-03-16 17:01:12.669112: step 2290, examples 229000, loss = 0.337573409 (190.390 examples/sec; 0.525 sec/batch)\n",
      "2019-03-16 17:01:17.716423: step 2300, examples 230000, loss = 0.343963802 (193.577 examples/sec; 0.517 sec/batch)\n",
      "Top 1 validation accuracy: 0.5825471878051758 and top 2 validation accuracy: 0.7948113083839417\n",
      "Model Saved!\n",
      "2019-03-16 17:01:24.590914: step 2310, examples 231000, loss = 0.387590170 (188.184 examples/sec; 0.531 sec/batch)\n",
      "2019-03-16 17:01:29.532669: step 2320, examples 232000, loss = 0.260281682 (204.740 examples/sec; 0.488 sec/batch)\n",
      "2019-03-16 17:01:34.498799: step 2330, examples 233000, loss = 0.384373963 (202.766 examples/sec; 0.493 sec/batch)\n",
      "2019-03-16 17:01:39.658274: step 2340, examples 234000, loss = 0.275734216 (197.916 examples/sec; 0.505 sec/batch)\n",
      "2019-03-16 17:01:44.762987: step 2350, examples 235000, loss = 0.377839357 (196.774 examples/sec; 0.508 sec/batch)\n",
      "2019-03-16 17:01:49.852130: step 2360, examples 236000, loss = 0.398299575 (193.964 examples/sec; 0.516 sec/batch)\n",
      "2019-03-16 17:01:54.829942: step 2370, examples 237000, loss = 0.333960772 (205.421 examples/sec; 0.487 sec/batch)\n",
      "2019-03-16 17:01:59.908878: step 2380, examples 238000, loss = 0.286856592 (198.411 examples/sec; 0.504 sec/batch)\n",
      "2019-03-16 17:02:05.012609: step 2390, examples 239000, loss = 0.265259564 (204.047 examples/sec; 0.490 sec/batch)\n",
      "2019-03-16 17:02:10.029970: step 2400, examples 240000, loss = 0.390326232 (197.254 examples/sec; 0.507 sec/batch)\n",
      "Top 1 validation accuracy: 0.5589622855186462 and top 2 validation accuracy: 0.7688679099082947\n",
      "Model Saved!\n",
      "2019-03-16 17:02:16.806333: step 2410, examples 241000, loss = 0.267516673 (200.250 examples/sec; 0.499 sec/batch)\n",
      "2019-03-16 17:02:21.888487: step 2420, examples 242000, loss = 0.239270777 (190.477 examples/sec; 0.525 sec/batch)\n",
      "2019-03-16 17:02:26.907247: step 2430, examples 243000, loss = 0.336217940 (199.243 examples/sec; 0.502 sec/batch)\n",
      "2019-03-16 17:02:32.043609: step 2440, examples 244000, loss = 0.227079049 (199.978 examples/sec; 0.500 sec/batch)\n",
      "2019-03-16 17:02:37.106866: step 2450, examples 245000, loss = 0.449995935 (193.539 examples/sec; 0.517 sec/batch)\n",
      "2019-03-16 17:02:42.107059: step 2460, examples 246000, loss = 0.259422362 (206.004 examples/sec; 0.485 sec/batch)\n",
      "2019-03-16 17:02:47.285198: step 2470, examples 247000, loss = 0.338313103 (187.631 examples/sec; 0.533 sec/batch)\n",
      "2019-03-16 17:02:52.293888: step 2480, examples 248000, loss = 0.298166752 (195.567 examples/sec; 0.511 sec/batch)\n",
      "2019-03-16 17:02:57.293743: step 2490, examples 249000, loss = 0.358570933 (198.692 examples/sec; 0.503 sec/batch)\n",
      "2019-03-16 17:03:02.389894: step 2500, examples 250000, loss = 0.303837836 (195.049 examples/sec; 0.513 sec/batch)\n",
      "Top 1 validation accuracy: 0.5636792182922363 and top 2 validation accuracy: 0.7948113083839417\n",
      "Model Saved!\n",
      "2019-03-16 17:03:09.536504: step 2510, examples 251000, loss = 0.450909674 (190.990 examples/sec; 0.524 sec/batch)\n",
      "2019-03-16 17:03:14.747032: step 2520, examples 252000, loss = 0.408441246 (208.527 examples/sec; 0.480 sec/batch)\n",
      "2019-03-16 17:03:19.939189: step 2530, examples 253000, loss = 0.387115955 (194.977 examples/sec; 0.513 sec/batch)\n",
      "2019-03-16 17:03:24.965457: step 2540, examples 254000, loss = 0.419732451 (207.362 examples/sec; 0.482 sec/batch)\n",
      "2019-03-16 17:03:29.949696: step 2550, examples 255000, loss = 0.390445948 (207.620 examples/sec; 0.482 sec/batch)\n",
      "2019-03-16 17:03:35.011089: step 2560, examples 256000, loss = 0.490138620 (203.834 examples/sec; 0.491 sec/batch)\n",
      "2019-03-16 17:03:40.043456: step 2570, examples 257000, loss = 0.346073419 (199.979 examples/sec; 0.500 sec/batch)\n",
      "2019-03-16 17:03:45.150759: step 2580, examples 258000, loss = 0.255479693 (194.730 examples/sec; 0.514 sec/batch)\n",
      "2019-03-16 17:03:50.268950: step 2590, examples 259000, loss = 0.320943117 (181.388 examples/sec; 0.551 sec/batch)\n",
      "2019-03-16 17:03:55.259815: step 2600, examples 260000, loss = 0.260729373 (203.147 examples/sec; 0.492 sec/batch)\n",
      "Top 1 validation accuracy: 0.599056601524353 and top 2 validation accuracy: 0.8160377144813538\n",
      "Model Saved!\n",
      "2019-03-16 17:04:02.120450: step 2610, examples 261000, loss = 0.378245741 (198.907 examples/sec; 0.503 sec/batch)\n",
      "2019-03-16 17:04:07.200064: step 2620, examples 262000, loss = 0.404670119 (199.950 examples/sec; 0.500 sec/batch)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2019-03-16 17:04:12.324227: step 2630, examples 263000, loss = 0.262681931 (201.536 examples/sec; 0.496 sec/batch)\n",
      "2019-03-16 17:04:17.300072: step 2640, examples 264000, loss = 0.348822594 (203.810 examples/sec; 0.491 sec/batch)\n",
      "2019-03-16 17:04:22.342773: step 2650, examples 265000, loss = 0.385422468 (205.682 examples/sec; 0.486 sec/batch)\n",
      "2019-03-16 17:04:27.451437: step 2660, examples 266000, loss = 0.266425759 (208.494 examples/sec; 0.480 sec/batch)\n",
      "2019-03-16 17:04:32.451347: step 2670, examples 267000, loss = 0.274459481 (200.688 examples/sec; 0.498 sec/batch)\n",
      "2019-03-16 17:04:37.536450: step 2680, examples 268000, loss = 0.493863881 (198.715 examples/sec; 0.503 sec/batch)\n",
      "2019-03-16 17:04:42.574818: step 2690, examples 269000, loss = 0.347118676 (194.408 examples/sec; 0.514 sec/batch)\n",
      "2019-03-16 17:04:47.653349: step 2700, examples 270000, loss = 0.264167756 (199.734 examples/sec; 0.501 sec/batch)\n",
      "Top 1 validation accuracy: 0.5400943160057068 and top 2 validation accuracy: 0.7924528121948242\n",
      "Model Saved!\n",
      "2019-03-16 17:04:54.389720: step 2710, examples 271000, loss = 0.467901826 (205.343 examples/sec; 0.487 sec/batch)\n",
      "2019-03-16 17:04:59.358452: step 2720, examples 272000, loss = 0.305014461 (199.911 examples/sec; 0.500 sec/batch)\n",
      "2019-03-16 17:05:04.716049: step 2730, examples 273000, loss = 0.396602720 (176.748 examples/sec; 0.566 sec/batch)\n",
      "2019-03-16 17:05:10.371370: step 2740, examples 274000, loss = 0.450948417 (152.264 examples/sec; 0.657 sec/batch)\n",
      "2019-03-16 17:05:16.164500: step 2750, examples 275000, loss = 0.229518592 (168.433 examples/sec; 0.594 sec/batch)\n",
      "2019-03-16 17:05:21.498692: step 2760, examples 276000, loss = 0.324299634 (199.385 examples/sec; 0.502 sec/batch)\n",
      "2019-03-16 17:05:26.851987: step 2770, examples 277000, loss = 0.318269759 (202.764 examples/sec; 0.493 sec/batch)\n",
      "2019-03-16 17:05:31.977268: step 2780, examples 278000, loss = 0.316074073 (190.129 examples/sec; 0.526 sec/batch)\n",
      "2019-03-16 17:05:37.034690: step 2790, examples 279000, loss = 0.248897195 (199.946 examples/sec; 0.500 sec/batch)\n",
      "2019-03-16 17:05:42.152827: step 2800, examples 280000, loss = 0.384941697 (194.661 examples/sec; 0.514 sec/batch)\n",
      "Top 1 validation accuracy: 0.5707547068595886 and top 2 validation accuracy: 0.7806603908538818\n",
      "Model Saved!\n",
      "2019-03-16 17:05:49.058996: step 2810, examples 281000, loss = 0.340186894 (199.992 examples/sec; 0.500 sec/batch)\n",
      "2019-03-16 17:05:54.168689: step 2820, examples 282000, loss = 0.258538097 (188.232 examples/sec; 0.531 sec/batch)\n",
      "2019-03-16 17:05:59.299752: step 2830, examples 283000, loss = 0.417568475 (200.994 examples/sec; 0.498 sec/batch)\n",
      "2019-03-16 17:06:04.405540: step 2840, examples 284000, loss = 0.275788873 (197.797 examples/sec; 0.506 sec/batch)\n",
      "2019-03-16 17:06:09.451634: step 2850, examples 285000, loss = 0.442950904 (196.990 examples/sec; 0.508 sec/batch)\n",
      "2019-03-16 17:06:14.498025: step 2860, examples 286000, loss = 0.307204306 (195.275 examples/sec; 0.512 sec/batch)\n",
      "2019-03-16 17:06:19.590812: step 2870, examples 287000, loss = 0.251704812 (183.607 examples/sec; 0.545 sec/batch)\n",
      "2019-03-16 17:06:24.686616: step 2880, examples 288000, loss = 0.323999226 (192.896 examples/sec; 0.518 sec/batch)\n",
      "2019-03-16 17:06:29.770217: step 2890, examples 289000, loss = 0.424385011 (199.519 examples/sec; 0.501 sec/batch)\n",
      "2019-03-16 17:06:34.843123: step 2900, examples 290000, loss = 0.288063049 (206.121 examples/sec; 0.485 sec/batch)\n",
      "Top 1 validation accuracy: 0.5566037893295288 and top 2 validation accuracy: 0.801886796951294\n",
      "Model Saved!\n",
      "2019-03-16 17:06:41.690534: step 2910, examples 291000, loss = 0.260111779 (210.610 examples/sec; 0.475 sec/batch)\n",
      "2019-03-16 17:06:46.861199: step 2920, examples 292000, loss = 0.241029844 (198.998 examples/sec; 0.503 sec/batch)\n",
      "2019-03-16 17:06:51.905719: step 2930, examples 293000, loss = 0.284045279 (193.846 examples/sec; 0.516 sec/batch)\n",
      "2019-03-16 17:06:57.037424: step 2940, examples 294000, loss = 0.343457282 (198.129 examples/sec; 0.505 sec/batch)\n",
      "2019-03-16 17:07:02.107382: step 2950, examples 295000, loss = 0.334738344 (206.015 examples/sec; 0.485 sec/batch)\n",
      "2019-03-16 17:07:07.168574: step 2960, examples 296000, loss = 0.261489868 (200.045 examples/sec; 0.500 sec/batch)\n",
      "2019-03-16 17:07:12.232327: step 2970, examples 297000, loss = 0.316886455 (193.655 examples/sec; 0.516 sec/batch)\n",
      "2019-03-16 17:07:17.339102: step 2980, examples 298000, loss = 0.322392702 (189.360 examples/sec; 0.528 sec/batch)\n",
      "2019-03-16 17:07:22.436391: step 2990, examples 299000, loss = 0.305897593 (196.019 examples/sec; 0.510 sec/batch)\n",
      "2019-03-16 17:07:27.428358: step 3000, examples 300000, loss = 0.298289686 (198.361 examples/sec; 0.504 sec/batch)\n",
      "Top 1 validation accuracy: 0.5825471878051758 and top 2 validation accuracy: 0.8183962106704712\n",
      "Model Saved!\n",
      "2019-03-16 17:07:34.343028: step 3010, examples 301000, loss = 0.394243002 (200.694 examples/sec; 0.498 sec/batch)\n",
      "2019-03-16 17:07:39.467275: step 3020, examples 302000, loss = 0.304950595 (199.435 examples/sec; 0.501 sec/batch)\n",
      "2019-03-16 17:07:44.542624: step 3030, examples 303000, loss = 0.354994297 (200.509 examples/sec; 0.499 sec/batch)\n",
      "2019-03-16 17:07:49.637767: step 3040, examples 304000, loss = 0.350143373 (194.165 examples/sec; 0.515 sec/batch)\n",
      "2019-03-16 17:07:54.696801: step 3050, examples 305000, loss = 0.254202366 (195.092 examples/sec; 0.513 sec/batch)\n",
      "2019-03-16 17:07:59.804434: step 3060, examples 306000, loss = 0.350091636 (205.835 examples/sec; 0.486 sec/batch)\n",
      "2019-03-16 17:08:04.937291: step 3070, examples 307000, loss = 0.421870500 (188.106 examples/sec; 0.532 sec/batch)\n",
      "2019-03-16 17:08:09.917198: step 3080, examples 308000, loss = 0.239446804 (208.373 examples/sec; 0.480 sec/batch)\n",
      "2019-03-16 17:08:14.903011: step 3090, examples 309000, loss = 0.441027880 (194.710 examples/sec; 0.514 sec/batch)\n",
      "2019-03-16 17:08:19.878538: step 3100, examples 310000, loss = 0.274636120 (198.456 examples/sec; 0.504 sec/batch)\n",
      "Top 1 validation accuracy: 0.6061320900917053 and top 2 validation accuracy: 0.8136792182922363\n",
      "Model Saved!\n",
      "2019-03-16 17:08:26.854877: step 3110, examples 311000, loss = 0.350006044 (192.088 examples/sec; 0.521 sec/batch)\n",
      "2019-03-16 17:08:31.868641: step 3120, examples 312000, loss = 0.252935678 (196.077 examples/sec; 0.510 sec/batch)\n",
      "2019-03-16 17:08:36.980292: step 3130, examples 313000, loss = 0.350546956 (201.231 examples/sec; 0.497 sec/batch)\n",
      "2019-03-16 17:08:42.027112: step 3140, examples 314000, loss = 0.322417080 (203.767 examples/sec; 0.491 sec/batch)\n",
      "2019-03-16 17:08:47.000394: step 3150, examples 315000, loss = 0.335365921 (207.335 examples/sec; 0.482 sec/batch)\n",
      "2019-03-16 17:08:52.080177: step 3160, examples 316000, loss = 0.292559862 (191.999 examples/sec; 0.521 sec/batch)\n",
      "2019-03-16 17:08:57.095093: step 3170, examples 317000, loss = 0.304064363 (198.176 examples/sec; 0.505 sec/batch)\n",
      "2019-03-16 17:09:02.107252: step 3180, examples 318000, loss = 0.290092230 (206.009 examples/sec; 0.485 sec/batch)\n",
      "2019-03-16 17:09:07.244347: step 3190, examples 319000, loss = 0.350463867 (191.636 examples/sec; 0.522 sec/batch)\n",
      "2019-03-16 17:09:12.338044: step 3200, examples 320000, loss = 0.385161668 (186.083 examples/sec; 0.537 sec/batch)\n",
      "Top 1 validation accuracy: 0.5825471878051758 and top 2 validation accuracy: 0.8160377144813538\n",
      "Model Saved!\n",
      "2019-03-16 17:09:19.342847: step 3210, examples 321000, loss = 0.357283860 (195.510 examples/sec; 0.511 sec/batch)\n",
      "2019-03-16 17:09:24.373757: step 3220, examples 322000, loss = 0.484528363 (188.104 examples/sec; 0.532 sec/batch)\n",
      "2019-03-16 17:09:29.482769: step 3230, examples 323000, loss = 0.537664711 (193.662 examples/sec; 0.516 sec/batch)\n",
      "2019-03-16 17:09:34.543675: step 3240, examples 324000, loss = 0.302837670 (198.691 examples/sec; 0.503 sec/batch)\n",
      "2019-03-16 17:09:39.541486: step 3250, examples 325000, loss = 0.272135198 (200.755 examples/sec; 0.498 sec/batch)\n",
      "2019-03-16 17:09:44.715611: step 3260, examples 326000, loss = 0.437417269 (204.161 examples/sec; 0.490 sec/batch)\n",
      "2019-03-16 17:09:49.812910: step 3270, examples 327000, loss = 0.414683878 (197.280 examples/sec; 0.507 sec/batch)\n",
      "2019-03-16 17:09:54.786559: step 3280, examples 328000, loss = 0.221389800 (208.588 examples/sec; 0.479 sec/batch)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2019-03-16 17:09:59.819539: step 3290, examples 329000, loss = 0.343237758 (207.619 examples/sec; 0.482 sec/batch)\n",
      "2019-03-16 17:10:04.856148: step 3300, examples 330000, loss = 0.361011028 (194.695 examples/sec; 0.514 sec/batch)\n",
      "Top 1 validation accuracy: 0.5660377144813538 and top 2 validation accuracy: 0.7688679099082947\n",
      "Model Saved!\n",
      "2019-03-16 17:10:11.903602: step 3310, examples 331000, loss = 0.226317808 (194.438 examples/sec; 0.514 sec/batch)\n",
      "2019-03-16 17:10:17.299918: step 3320, examples 332000, loss = 0.341535330 (187.588 examples/sec; 0.533 sec/batch)\n",
      "2019-03-16 17:10:22.607448: step 3330, examples 333000, loss = 0.250280052 (182.226 examples/sec; 0.549 sec/batch)\n",
      "2019-03-16 17:10:27.925445: step 3340, examples 334000, loss = 0.354892343 (186.569 examples/sec; 0.536 sec/batch)\n",
      "2019-03-16 17:10:33.200091: step 3350, examples 335000, loss = 0.364586174 (188.276 examples/sec; 0.531 sec/batch)\n",
      "2019-03-16 17:10:38.405287: step 3360, examples 336000, loss = 0.231449530 (187.577 examples/sec; 0.533 sec/batch)\n",
      "2019-03-16 17:10:43.652854: step 3370, examples 337000, loss = 0.414883792 (183.348 examples/sec; 0.545 sec/batch)\n",
      "2019-03-16 17:10:48.980161: step 3380, examples 338000, loss = 0.255217761 (195.056 examples/sec; 0.513 sec/batch)\n",
      "2019-03-16 17:10:54.276973: step 3390, examples 339000, loss = 0.411939204 (183.351 examples/sec; 0.545 sec/batch)\n",
      "2019-03-16 17:10:59.590670: step 3400, examples 340000, loss = 0.262739718 (177.784 examples/sec; 0.562 sec/batch)\n",
      "Top 1 validation accuracy: 0.5754716992378235 and top 2 validation accuracy: 0.801886796951294\n",
      "Model Saved!\n",
      "2019-03-16 17:11:06.965623: step 3410, examples 341000, loss = 0.406681061 (190.011 examples/sec; 0.526 sec/batch)\n",
      "2019-03-16 17:11:12.168779: step 3420, examples 342000, loss = 0.325410247 (183.300 examples/sec; 0.546 sec/batch)\n",
      "2019-03-16 17:11:17.404909: step 3430, examples 343000, loss = 0.295309961 (199.389 examples/sec; 0.502 sec/batch)\n",
      "2019-03-16 17:11:22.715315: step 3440, examples 344000, loss = 0.329297066 (188.210 examples/sec; 0.531 sec/batch)\n",
      "2019-03-16 17:11:27.909276: step 3450, examples 345000, loss = 0.291585088 (198.358 examples/sec; 0.504 sec/batch)\n",
      "2019-03-16 17:11:33.244396: step 3460, examples 346000, loss = 0.311077952 (194.866 examples/sec; 0.513 sec/batch)\n",
      "2019-03-16 17:11:38.498914: step 3470, examples 347000, loss = 0.363112420 (179.054 examples/sec; 0.558 sec/batch)\n",
      "2019-03-16 17:11:43.705350: step 3480, examples 348000, loss = 0.348309696 (186.884 examples/sec; 0.535 sec/batch)\n",
      "2019-03-16 17:11:49.096773: step 3490, examples 349000, loss = 0.301750064 (191.469 examples/sec; 0.522 sec/batch)\n",
      "2019-03-16 17:11:54.276571: step 3500, examples 350000, loss = 0.308656394 (194.526 examples/sec; 0.514 sec/batch)\n",
      "Top 1 validation accuracy: 0.5636792182922363 and top 2 validation accuracy: 0.7783018946647644\n",
      "Model Saved!\n",
      "2019-03-16 17:12:01.686807: step 3510, examples 351000, loss = 0.400439471 (192.822 examples/sec; 0.519 sec/batch)\n",
      "2019-03-16 17:12:06.923411: step 3520, examples 352000, loss = 0.314714193 (193.131 examples/sec; 0.518 sec/batch)\n",
      "2019-03-16 17:12:12.199852: step 3530, examples 353000, loss = 0.309330642 (183.511 examples/sec; 0.545 sec/batch)\n",
      "2019-03-16 17:12:17.451687: step 3540, examples 354000, loss = 0.282523394 (193.497 examples/sec; 0.517 sec/batch)\n",
      "2019-03-16 17:12:22.720583: step 3550, examples 355000, loss = 0.294387281 (191.996 examples/sec; 0.521 sec/batch)\n",
      "2019-03-16 17:12:27.924036: step 3560, examples 356000, loss = 0.284269273 (200.691 examples/sec; 0.498 sec/batch)\n",
      "2019-03-16 17:12:33.144944: step 3570, examples 357000, loss = 0.308901906 (191.191 examples/sec; 0.523 sec/batch)\n",
      "2019-03-16 17:12:38.482556: step 3580, examples 358000, loss = 0.349323094 (190.221 examples/sec; 0.526 sec/batch)\n",
      "2019-03-16 17:12:43.673706: step 3590, examples 359000, loss = 0.251369178 (191.980 examples/sec; 0.521 sec/batch)\n",
      "2019-03-16 17:12:49.152895: step 3600, examples 360000, loss = 0.230844975 (175.768 examples/sec; 0.569 sec/batch)\n",
      "Top 1 validation accuracy: 0.5707547068595886 and top 2 validation accuracy: 0.7877358198165894\n",
      "Model Saved!\n",
      "2019-03-16 17:12:56.343235: step 3610, examples 361000, loss = 0.244995952 (203.904 examples/sec; 0.490 sec/batch)\n",
      "2019-03-16 17:13:01.404980: step 3620, examples 362000, loss = 0.320316374 (193.072 examples/sec; 0.518 sec/batch)\n",
      "2019-03-16 17:13:06.451656: step 3630, examples 363000, loss = 0.352509588 (182.247 examples/sec; 0.549 sec/batch)\n",
      "2019-03-16 17:13:11.539695: step 3640, examples 364000, loss = 0.303653419 (194.293 examples/sec; 0.515 sec/batch)\n",
      "2019-03-16 17:13:16.543926: step 3650, examples 365000, loss = 0.339198411 (199.943 examples/sec; 0.500 sec/batch)\n",
      "2019-03-16 17:13:21.542509: step 3660, examples 366000, loss = 0.237066358 (201.674 examples/sec; 0.496 sec/batch)\n",
      "2019-03-16 17:13:26.575141: step 3670, examples 367000, loss = 0.262591779 (201.251 examples/sec; 0.497 sec/batch)\n",
      "2019-03-16 17:13:31.671125: step 3680, examples 368000, loss = 0.267984271 (192.838 examples/sec; 0.519 sec/batch)\n",
      "2019-03-16 17:13:36.703127: step 3690, examples 369000, loss = 0.259841412 (186.897 examples/sec; 0.535 sec/batch)\n",
      "2019-03-16 17:13:41.903816: step 3700, examples 370000, loss = 0.433251560 (184.741 examples/sec; 0.541 sec/batch)\n",
      "Top 1 validation accuracy: 0.5471698045730591 and top 2 validation accuracy: 0.7830188870429993\n",
      "Model Saved!\n",
      "2019-03-16 17:13:48.841336: step 3710, examples 371000, loss = 0.273266673 (207.265 examples/sec; 0.482 sec/batch)\n",
      "2019-03-16 17:13:53.951611: step 3720, examples 372000, loss = 0.233090609 (193.849 examples/sec; 0.516 sec/batch)\n",
      "2019-03-16 17:13:58.965617: step 3730, examples 373000, loss = 0.337239325 (200.570 examples/sec; 0.499 sec/batch)\n",
      "2019-03-16 17:14:04.140005: step 3740, examples 374000, loss = 0.329280078 (193.019 examples/sec; 0.518 sec/batch)\n",
      "2019-03-16 17:14:09.199305: step 3750, examples 375000, loss = 0.274136156 (197.095 examples/sec; 0.507 sec/batch)\n",
      "2019-03-16 17:14:14.268408: step 3760, examples 376000, loss = 0.280351818 (199.847 examples/sec; 0.500 sec/batch)\n",
      "2019-03-16 17:14:19.259753: step 3770, examples 377000, loss = 0.328384936 (198.141 examples/sec; 0.505 sec/batch)\n",
      "2019-03-16 17:14:24.260602: step 3780, examples 378000, loss = 0.246636897 (204.194 examples/sec; 0.490 sec/batch)\n",
      "2019-03-16 17:14:29.342689: step 3790, examples 379000, loss = 0.315679103 (193.066 examples/sec; 0.518 sec/batch)\n",
      "2019-03-16 17:14:34.444166: step 3800, examples 380000, loss = 0.291187048 (196.494 examples/sec; 0.509 sec/batch)\n",
      "Top 1 validation accuracy: 0.5424528121948242 and top 2 validation accuracy: 0.7594339847564697\n",
      "Model Saved!\n",
      "2019-03-16 17:14:41.329910: step 3810, examples 381000, loss = 0.280809760 (188.893 examples/sec; 0.529 sec/batch)\n",
      "2019-03-16 17:14:46.451338: step 3820, examples 382000, loss = 0.275396407 (193.527 examples/sec; 0.517 sec/batch)\n",
      "2019-03-16 17:14:51.482536: step 3830, examples 383000, loss = 0.335788161 (205.499 examples/sec; 0.487 sec/batch)\n",
      "2019-03-16 17:14:56.405819: step 3840, examples 384000, loss = 0.274909884 (198.874 examples/sec; 0.503 sec/batch)\n",
      "2019-03-16 17:15:01.514055: step 3850, examples 385000, loss = 0.280049562 (193.524 examples/sec; 0.517 sec/batch)\n",
      "2019-03-16 17:15:06.590596: step 3860, examples 386000, loss = 0.404573500 (194.595 examples/sec; 0.514 sec/batch)\n",
      "2019-03-16 17:15:12.122266: step 3870, examples 387000, loss = 0.203827888 (188.558 examples/sec; 0.530 sec/batch)\n",
      "2019-03-16 17:15:17.228845: step 3880, examples 388000, loss = 0.326610327 (201.115 examples/sec; 0.497 sec/batch)\n",
      "2019-03-16 17:15:22.260506: step 3890, examples 389000, loss = 0.239696339 (195.351 examples/sec; 0.512 sec/batch)\n",
      "2019-03-16 17:15:27.439630: step 3900, examples 390000, loss = 0.276225805 (188.347 examples/sec; 0.531 sec/batch)\n",
      "Top 1 validation accuracy: 0.5495283007621765 and top 2 validation accuracy: 0.7877358198165894\n",
      "Model Saved!\n",
      "2019-03-16 17:15:34.386743: step 3910, examples 391000, loss = 0.406865120 (188.468 examples/sec; 0.531 sec/batch)\n",
      "2019-03-16 17:15:39.405333: step 3920, examples 392000, loss = 0.284158766 (187.479 examples/sec; 0.533 sec/batch)\n",
      "2019-03-16 17:15:44.437306: step 3930, examples 393000, loss = 0.328957200 (201.213 examples/sec; 0.497 sec/batch)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2019-03-16 17:15:49.498319: step 3940, examples 394000, loss = 0.357687175 (202.441 examples/sec; 0.494 sec/batch)\n",
      "2019-03-16 17:15:54.498604: step 3950, examples 395000, loss = 0.275132984 (205.031 examples/sec; 0.488 sec/batch)\n",
      "2019-03-16 17:15:59.405693: step 3960, examples 396000, loss = 0.391265929 (200.171 examples/sec; 0.500 sec/batch)\n",
      "2019-03-16 17:16:04.684750: step 3970, examples 397000, loss = 0.302908003 (199.560 examples/sec; 0.501 sec/batch)\n",
      "2019-03-16 17:16:09.747937: step 3980, examples 398000, loss = 0.297354519 (198.604 examples/sec; 0.504 sec/batch)\n",
      "2019-03-16 17:16:14.866790: step 3990, examples 399000, loss = 0.220366731 (186.068 examples/sec; 0.537 sec/batch)\n",
      "2019-03-16 17:16:19.934811: step 4000, examples 400000, loss = 0.315451384 (205.787 examples/sec; 0.486 sec/batch)\n",
      "Top 1 validation accuracy: 0.5589622855186462 and top 2 validation accuracy: 0.7948113083839417\n",
      "Model Saved!\n",
      "2019-03-16 17:16:26.888161: step 4010, examples 401000, loss = 0.401183337 (188.743 examples/sec; 0.530 sec/batch)\n",
      "2019-03-16 17:16:31.975041: step 4020, examples 402000, loss = 0.252668589 (203.081 examples/sec; 0.492 sec/batch)\n",
      "2019-03-16 17:16:37.059468: step 4030, examples 403000, loss = 0.228329629 (193.918 examples/sec; 0.516 sec/batch)\n",
      "2019-03-16 17:16:42.059536: step 4040, examples 404000, loss = 0.399039149 (206.443 examples/sec; 0.484 sec/batch)\n",
      "2019-03-16 17:16:47.093735: step 4050, examples 405000, loss = 0.327757120 (186.981 examples/sec; 0.535 sec/batch)\n",
      "2019-03-16 17:16:52.168743: step 4060, examples 406000, loss = 0.360554338 (188.492 examples/sec; 0.531 sec/batch)\n",
      "2019-03-16 17:16:57.275497: step 4070, examples 407000, loss = 0.256343842 (207.400 examples/sec; 0.482 sec/batch)\n",
      "2019-03-16 17:17:02.284442: step 4080, examples 408000, loss = 0.292213857 (202.452 examples/sec; 0.494 sec/batch)\n",
      "2019-03-16 17:17:07.389857: step 4090, examples 409000, loss = 0.304329902 (187.346 examples/sec; 0.534 sec/batch)\n",
      "2019-03-16 17:17:12.558918: step 4100, examples 410000, loss = 0.466551095 (198.125 examples/sec; 0.505 sec/batch)\n",
      "Top 1 validation accuracy: 0.5754716992378235 and top 2 validation accuracy: 0.8183962106704712\n",
      "Model Saved!\n",
      "2019-03-16 17:17:19.482720: step 4110, examples 411000, loss = 0.271389723 (187.546 examples/sec; 0.533 sec/batch)\n",
      "2019-03-16 17:17:24.498394: step 4120, examples 412000, loss = 0.322883993 (194.456 examples/sec; 0.514 sec/batch)\n",
      "2019-03-16 17:17:29.559483: step 4130, examples 413000, loss = 0.365960777 (207.378 examples/sec; 0.482 sec/batch)\n",
      "2019-03-16 17:17:34.544082: step 4140, examples 414000, loss = 0.196574211 (198.299 examples/sec; 0.504 sec/batch)\n",
      "2019-03-16 17:17:39.622008: step 4150, examples 415000, loss = 0.342123032 (194.074 examples/sec; 0.515 sec/batch)\n",
      "2019-03-16 17:17:44.765722: step 4160, examples 416000, loss = 0.239331782 (201.253 examples/sec; 0.497 sec/batch)\n",
      "2019-03-16 17:17:49.756266: step 4170, examples 417000, loss = 0.235983849 (208.256 examples/sec; 0.480 sec/batch)\n",
      "2019-03-16 17:17:54.783995: step 4180, examples 418000, loss = 0.296245664 (196.700 examples/sec; 0.508 sec/batch)\n",
      "2019-03-16 17:17:59.885406: step 4190, examples 419000, loss = 0.248101175 (195.756 examples/sec; 0.511 sec/batch)\n",
      "2019-03-16 17:18:05.091627: step 4200, examples 420000, loss = 0.223921567 (199.757 examples/sec; 0.501 sec/batch)\n",
      "Top 1 validation accuracy: 0.599056601524353 and top 2 validation accuracy: 0.8301886916160583\n",
      "Model Saved!\n",
      "2019-03-16 17:18:11.871688: step 4210, examples 421000, loss = 0.355632544 (200.820 examples/sec; 0.498 sec/batch)\n",
      "2019-03-16 17:18:17.014169: step 4220, examples 422000, loss = 0.357681185 (192.943 examples/sec; 0.518 sec/batch)\n",
      "2019-03-16 17:18:22.107360: step 4230, examples 423000, loss = 0.354887456 (182.476 examples/sec; 0.548 sec/batch)\n",
      "2019-03-16 17:18:27.148825: step 4240, examples 424000, loss = 0.231564522 (195.655 examples/sec; 0.511 sec/batch)\n",
      "2019-03-16 17:18:32.183826: step 4250, examples 425000, loss = 0.419446766 (200.126 examples/sec; 0.500 sec/batch)\n",
      "2019-03-16 17:18:37.152448: step 4260, examples 426000, loss = 0.461574972 (197.771 examples/sec; 0.506 sec/batch)\n",
      "2019-03-16 17:18:42.238989: step 4270, examples 427000, loss = 0.318209112 (204.137 examples/sec; 0.490 sec/batch)\n",
      "2019-03-16 17:18:47.343136: step 4280, examples 428000, loss = 0.351209104 (205.708 examples/sec; 0.486 sec/batch)\n",
      "2019-03-16 17:18:52.451364: step 4290, examples 429000, loss = 0.262324363 (201.486 examples/sec; 0.496 sec/batch)\n",
      "2019-03-16 17:18:57.559016: step 4300, examples 430000, loss = 0.275885731 (188.247 examples/sec; 0.531 sec/batch)\n",
      "Top 1 validation accuracy: 0.5589622855186462 and top 2 validation accuracy: 0.8113207817077637\n",
      "Model Saved!\n",
      "2019-03-16 17:19:04.575442: step 4310, examples 431000, loss = 0.323162973 (209.671 examples/sec; 0.477 sec/batch)\n",
      "2019-03-16 17:19:09.652710: step 4320, examples 432000, loss = 0.268418938 (206.503 examples/sec; 0.484 sec/batch)\n",
      "2019-03-16 17:19:14.637946: step 4330, examples 433000, loss = 0.288645446 (205.147 examples/sec; 0.487 sec/batch)\n",
      "2019-03-16 17:19:19.700587: step 4340, examples 434000, loss = 0.285677075 (208.381 examples/sec; 0.480 sec/batch)\n",
      "2019-03-16 17:19:24.751240: step 4350, examples 435000, loss = 0.288068324 (203.607 examples/sec; 0.491 sec/batch)\n",
      "2019-03-16 17:19:29.797272: step 4360, examples 436000, loss = 0.300009668 (201.192 examples/sec; 0.497 sec/batch)\n",
      "2019-03-16 17:19:34.856604: step 4370, examples 437000, loss = 0.324276716 (192.394 examples/sec; 0.520 sec/batch)\n",
      "2019-03-16 17:19:39.829855: step 4380, examples 438000, loss = 0.403056055 (205.514 examples/sec; 0.487 sec/batch)\n",
      "2019-03-16 17:19:44.996393: step 4390, examples 439000, loss = 0.322291166 (183.710 examples/sec; 0.544 sec/batch)\n",
      "2019-03-16 17:19:50.043483: step 4400, examples 440000, loss = 0.211602002 (206.430 examples/sec; 0.484 sec/batch)\n",
      "Top 1 validation accuracy: 0.5707547068595886 and top 2 validation accuracy: 0.7924528121948242\n",
      "Model Saved!\n",
      "2019-03-16 17:19:56.924914: step 4410, examples 441000, loss = 0.325060099 (192.544 examples/sec; 0.519 sec/batch)\n",
      "2019-03-16 17:20:01.908582: step 4420, examples 442000, loss = 0.339832991 (198.888 examples/sec; 0.503 sec/batch)\n",
      "2019-03-16 17:20:07.259961: step 4430, examples 443000, loss = 0.343583941 (192.381 examples/sec; 0.520 sec/batch)\n",
      "2019-03-16 17:20:12.366035: step 4440, examples 444000, loss = 0.295925140 (193.806 examples/sec; 0.516 sec/batch)\n",
      "2019-03-16 17:20:17.405405: step 4450, examples 445000, loss = 0.242402077 (191.959 examples/sec; 0.521 sec/batch)\n",
      "2019-03-16 17:20:22.652876: step 4460, examples 446000, loss = 0.224538475 (183.681 examples/sec; 0.544 sec/batch)\n",
      "2019-03-16 17:20:27.746987: step 4470, examples 447000, loss = 0.310546339 (196.450 examples/sec; 0.509 sec/batch)\n",
      "2019-03-16 17:20:33.208646: step 4480, examples 448000, loss = 0.361424387 (203.124 examples/sec; 0.492 sec/batch)\n",
      "2019-03-16 17:20:38.405243: step 4490, examples 449000, loss = 0.305909336 (200.859 examples/sec; 0.498 sec/batch)\n",
      "2019-03-16 17:20:43.443186: step 4500, examples 450000, loss = 0.320865512 (202.929 examples/sec; 0.493 sec/batch)\n",
      "Top 1 validation accuracy: 0.5613207817077637 and top 2 validation accuracy: 0.7900943160057068\n",
      "Model Saved!\n",
      "2019-03-16 17:20:50.184088: step 4510, examples 451000, loss = 0.427968204 (199.511 examples/sec; 0.501 sec/batch)\n",
      "2019-03-16 17:20:55.275361: step 4520, examples 452000, loss = 0.223796859 (202.291 examples/sec; 0.494 sec/batch)\n",
      "2019-03-16 17:21:00.275817: step 4530, examples 453000, loss = 0.342218935 (204.145 examples/sec; 0.490 sec/batch)\n",
      "2019-03-16 17:21:05.325986: step 4540, examples 454000, loss = 0.380733967 (188.745 examples/sec; 0.530 sec/batch)\n",
      "2019-03-16 17:21:10.374119: step 4550, examples 455000, loss = 0.317012668 (199.002 examples/sec; 0.503 sec/batch)\n",
      "2019-03-16 17:21:15.374311: step 4560, examples 456000, loss = 0.259607792 (199.196 examples/sec; 0.502 sec/batch)\n",
      "2019-03-16 17:21:20.422518: step 4570, examples 457000, loss = 0.276369333 (192.704 examples/sec; 0.519 sec/batch)\n",
      "2019-03-16 17:21:25.605897: step 4580, examples 458000, loss = 0.362241924 (186.512 examples/sec; 0.536 sec/batch)\n",
      "2019-03-16 17:21:30.735659: step 4590, examples 459000, loss = 0.334546208 (193.477 examples/sec; 0.517 sec/batch)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2019-03-16 17:21:35.747137: step 4600, examples 460000, loss = 0.279576302 (198.916 examples/sec; 0.503 sec/batch)\n",
      "Top 1 validation accuracy: 0.6014150977134705 and top 2 validation accuracy: 0.823113203048706\n",
      "Model Saved!\n",
      "2019-03-16 17:21:42.673799: step 4610, examples 461000, loss = 0.252703637 (197.815 examples/sec; 0.506 sec/batch)\n",
      "2019-03-16 17:21:47.792394: step 4620, examples 462000, loss = 0.239071518 (191.090 examples/sec; 0.523 sec/batch)\n",
      "2019-03-16 17:21:52.778127: step 4630, examples 463000, loss = 0.229563385 (198.926 examples/sec; 0.503 sec/batch)\n",
      "2019-03-16 17:21:57.856753: step 4640, examples 464000, loss = 0.304680109 (207.084 examples/sec; 0.483 sec/batch)\n",
      "2019-03-16 17:22:02.860971: step 4650, examples 465000, loss = 0.293845713 (205.443 examples/sec; 0.487 sec/batch)\n",
      "2019-03-16 17:22:07.945684: step 4660, examples 466000, loss = 0.341687858 (202.337 examples/sec; 0.494 sec/batch)\n",
      "2019-03-16 17:22:12.984706: step 4670, examples 467000, loss = 0.371105433 (199.092 examples/sec; 0.502 sec/batch)\n",
      "2019-03-16 17:22:18.045244: step 4680, examples 468000, loss = 0.314958394 (198.673 examples/sec; 0.503 sec/batch)\n",
      "2019-03-16 17:22:23.152570: step 4690, examples 469000, loss = 0.350669414 (188.377 examples/sec; 0.531 sec/batch)\n",
      "2019-03-16 17:22:28.168389: step 4700, examples 470000, loss = 0.265337169 (194.852 examples/sec; 0.513 sec/batch)\n",
      "Top 1 validation accuracy: 0.5754716992378235 and top 2 validation accuracy: 0.8113207817077637\n",
      "Model Saved!\n",
      "2019-03-16 17:22:35.002469: step 4710, examples 471000, loss = 0.271313578 (204.925 examples/sec; 0.488 sec/batch)\n",
      "2019-03-16 17:22:40.043497: step 4720, examples 472000, loss = 0.458207726 (199.978 examples/sec; 0.500 sec/batch)\n",
      "2019-03-16 17:22:45.183708: step 4730, examples 473000, loss = 0.408823311 (194.879 examples/sec; 0.513 sec/batch)\n",
      "2019-03-16 17:22:50.220993: step 4740, examples 474000, loss = 0.340216637 (199.306 examples/sec; 0.502 sec/batch)\n",
      "2019-03-16 17:22:55.244165: step 4750, examples 475000, loss = 0.360801280 (201.310 examples/sec; 0.497 sec/batch)\n",
      "2019-03-16 17:23:00.199719: step 4760, examples 476000, loss = 0.313199461 (200.209 examples/sec; 0.499 sec/batch)\n",
      "2019-03-16 17:23:05.299511: step 4770, examples 477000, loss = 0.340035439 (195.772 examples/sec; 0.511 sec/batch)\n",
      "2019-03-16 17:23:10.450368: step 4780, examples 478000, loss = 0.381117254 (200.028 examples/sec; 0.500 sec/batch)\n",
      "2019-03-16 17:23:15.519360: step 4790, examples 479000, loss = 0.242246836 (199.494 examples/sec; 0.501 sec/batch)\n",
      "2019-03-16 17:23:20.621768: step 4800, examples 480000, loss = 0.294287562 (200.569 examples/sec; 0.499 sec/batch)\n",
      "Top 1 validation accuracy: 0.5778301954269409 and top 2 validation accuracy: 0.8066037893295288\n",
      "Model Saved!\n",
      "2019-03-16 17:23:27.430699: step 4810, examples 481000, loss = 0.332542062 (196.212 examples/sec; 0.510 sec/batch)\n",
      "2019-03-16 17:23:32.467365: step 4820, examples 482000, loss = 0.222455442 (191.375 examples/sec; 0.523 sec/batch)\n",
      "2019-03-16 17:23:37.466736: step 4830, examples 483000, loss = 0.270186633 (207.167 examples/sec; 0.483 sec/batch)\n",
      "2019-03-16 17:23:42.482986: step 4840, examples 484000, loss = 0.234066218 (199.989 examples/sec; 0.500 sec/batch)\n",
      "2019-03-16 17:23:47.543915: step 4850, examples 485000, loss = 0.264066368 (199.864 examples/sec; 0.500 sec/batch)\n",
      "2019-03-16 17:23:52.637217: step 4860, examples 486000, loss = 0.327102602 (194.469 examples/sec; 0.514 sec/batch)\n",
      "2019-03-16 17:23:57.669089: step 4870, examples 487000, loss = 0.391388178 (199.612 examples/sec; 0.501 sec/batch)\n",
      "2019-03-16 17:24:02.762345: step 4880, examples 488000, loss = 0.313236773 (190.553 examples/sec; 0.525 sec/batch)\n",
      "2019-03-16 17:24:07.871855: step 4890, examples 489000, loss = 0.340899229 (194.854 examples/sec; 0.513 sec/batch)\n",
      "2019-03-16 17:24:12.924919: step 4900, examples 490000, loss = 0.330281734 (201.598 examples/sec; 0.496 sec/batch)\n",
      "Top 1 validation accuracy: 0.573113203048706 and top 2 validation accuracy: 0.8136792182922363\n",
      "Model Saved!\n",
      "2019-03-16 17:24:19.775869: step 4910, examples 491000, loss = 0.250097096 (206.609 examples/sec; 0.484 sec/batch)\n",
      "2019-03-16 17:24:24.821514: step 4920, examples 492000, loss = 0.307918906 (205.674 examples/sec; 0.486 sec/batch)\n",
      "2019-03-16 17:24:29.856196: step 4930, examples 493000, loss = 0.286571145 (207.392 examples/sec; 0.482 sec/batch)\n",
      "2019-03-16 17:24:34.898462: step 4940, examples 494000, loss = 0.236193255 (202.743 examples/sec; 0.493 sec/batch)\n",
      "2019-03-16 17:24:40.026626: step 4950, examples 495000, loss = 0.254265547 (197.611 examples/sec; 0.506 sec/batch)\n",
      "2019-03-16 17:24:45.028527: step 4960, examples 496000, loss = 0.299803674 (206.429 examples/sec; 0.484 sec/batch)\n",
      "2019-03-16 17:24:50.153099: step 4970, examples 497000, loss = 0.381460786 (188.381 examples/sec; 0.531 sec/batch)\n",
      "2019-03-16 17:24:55.765500: step 4980, examples 498000, loss = 0.299697220 (154.519 examples/sec; 0.647 sec/batch)\n",
      "2019-03-16 17:25:02.210860: step 4990, examples 499000, loss = 0.263350189 (149.981 examples/sec; 0.667 sec/batch)\n",
      "Top 1 validation accuracy: 0.5943396091461182 and top 2 validation accuracy: 0.8066037893295288\n",
      "Model Saved!\n"
     ]
    }
   ],
   "source": [
    "#try with 1000 timelength\n",
    "\n",
    "num_cls = 4\n",
    "mstp = 5000\n",
    "lfrq = 10\n",
    "bsz = 100\n",
    "msf = 100\n",
    "tr = './trained_model_final/DCNN_reg_ss1000'\n",
    "if not os.path.exists(tr):\n",
    "    os.mkdir(tr)\n",
    "start = 0\n",
    "stop = 500\n",
    "step = 100\n",
    "time_length = 1000\n",
    "time_bin = 500\n",
    "fsz = 5\n",
    "use_batchnorm = True\n",
    "use_dropout = True\n",
    "use_l2loss = True\n",
    "acc = 'Accuracy1000'\n",
    "path = 'Path1000'\n",
    "\n",
    "best_val_ss[acc],best_val_ss[path] = train_model_ss(tr,start,stop,step,time_length,time_bin,fsz,use_batchnorm,use_dropout,use_l2loss,num_cls,mstp,lfrq,bsz,msf)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test Accuracy for Subsampling:\n",
      "Loading datasets...\n",
      "Dataset loading completes.\n",
      "INFO:tensorflow:Restoring parameters from ./trained_model_final/DCNN_reg_ss1000\\model.ckpt-3101\n",
      "[test  step 3101] loss: 2.22320; top_1_accuracy: 0.56772; top_5_accuracy: 0.802483 (1.451 sec/batch; 610.616 instances/sec)\n",
      "top_1_accuracy_test =  0.5677201 top_2_accuracy_test =  0.8024831\n"
     ]
    }
   ],
   "source": [
    "# Accuracy for testSet(best)\n",
    "\n",
    "path = 'Path1000'\n",
    "model_dir = best_val_ss[path]\n",
    "start = 0\n",
    "stop = 500\n",
    "step = 100\n",
    "time_length = 1000\n",
    "time_bin = 500\n",
    "#Nb = BATCH_SIZE\n",
    "fsz = 5\n",
    "use_batchnorm = True\n",
    "use_dropout = True\n",
    "use_l2loss = True\n",
    "print('Test Accuracy for Subsampling:')\n",
    "best_test_acc_ss1000, best_test_acc2_ss1000 = test_model_ss(model_dir,start,stop,step,time_length,time_bin,fsz,use_batchnorm,use_dropout,use_l2loss)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading datasets...\n",
      "Dataset loading completes.\n",
      "2019-03-16 21:57:08.009881: step 0, examples 0, loss = 1.419823050 (51.416 examples/sec; 0.972 sec/batch)\n",
      "Top 1 validation accuracy: 0.2641509473323822 and top 2 validation accuracy: 0.5094339847564697\n",
      "Model Saved!\n",
      "2019-03-16 21:57:17.371099: step 10, examples 500, loss = 1.422534585 (77.302 examples/sec; 0.647 sec/batch)\n",
      "2019-03-16 21:57:23.702835: step 20, examples 1000, loss = 1.412981749 (81.505 examples/sec; 0.613 sec/batch)\n",
      "2019-03-16 21:57:30.084881: step 30, examples 1500, loss = 1.397699714 (78.495 examples/sec; 0.637 sec/batch)\n",
      "2019-03-16 21:57:36.608701: step 40, examples 2000, loss = 1.410016060 (75.445 examples/sec; 0.663 sec/batch)\n",
      "2019-03-16 21:57:43.051827: step 50, examples 2500, loss = 1.431589603 (80.750 examples/sec; 0.619 sec/batch)\n",
      "2019-03-16 21:57:49.555563: step 60, examples 3000, loss = 1.396692991 (78.712 examples/sec; 0.635 sec/batch)\n",
      "2019-03-16 21:57:56.184767: step 70, examples 3500, loss = 1.369373441 (75.897 examples/sec; 0.659 sec/batch)\n",
      "2019-03-16 21:58:02.732237: step 80, examples 4000, loss = 1.351469636 (75.993 examples/sec; 0.658 sec/batch)\n",
      "2019-03-16 21:58:09.367451: step 90, examples 4500, loss = 1.383486032 (73.831 examples/sec; 0.677 sec/batch)\n",
      "2019-03-16 21:58:15.881724: step 100, examples 5000, loss = 1.306603193 (76.439 examples/sec; 0.654 sec/batch)\n",
      "Top 1 validation accuracy: 0.34433960914611816 and top 2 validation accuracy: 0.5801886916160583\n",
      "Model Saved!\n",
      "2019-03-16 21:58:25.178753: step 110, examples 5500, loss = 1.354307532 (77.936 examples/sec; 0.642 sec/batch)\n",
      "2019-03-16 21:58:31.641195: step 120, examples 6000, loss = 1.308985472 (75.900 examples/sec; 0.659 sec/batch)\n",
      "2019-03-16 21:58:38.147354: step 130, examples 6500, loss = 1.282451868 (75.371 examples/sec; 0.663 sec/batch)\n",
      "2019-03-16 21:58:44.782668: step 140, examples 7000, loss = 1.369189024 (74.419 examples/sec; 0.672 sec/batch)\n",
      "2019-03-16 21:58:51.303424: step 150, examples 7500, loss = 1.321072817 (76.995 examples/sec; 0.649 sec/batch)\n",
      "2019-03-16 21:58:57.853314: step 160, examples 8000, loss = 1.285909295 (74.821 examples/sec; 0.668 sec/batch)\n",
      "2019-03-16 21:59:04.358153: step 170, examples 8500, loss = 1.286789298 (75.377 examples/sec; 0.663 sec/batch)\n",
      "2019-03-16 21:59:10.906116: step 180, examples 9000, loss = 1.410467744 (74.314 examples/sec; 0.673 sec/batch)\n",
      "2019-03-16 21:59:17.446355: step 190, examples 9500, loss = 1.333903670 (74.561 examples/sec; 0.671 sec/batch)\n",
      "2019-03-16 21:59:23.975789: step 200, examples 10000, loss = 1.296132684 (75.308 examples/sec; 0.664 sec/batch)\n",
      "Top 1 validation accuracy: 0.33018869161605835 and top 2 validation accuracy: 0.6297169923782349\n",
      "Model Saved!\n",
      "2019-03-16 21:59:33.259555: step 210, examples 10500, loss = 1.266350150 (75.501 examples/sec; 0.662 sec/batch)\n",
      "2019-03-16 21:59:39.759479: step 220, examples 11000, loss = 1.210334778 (78.876 examples/sec; 0.634 sec/batch)\n",
      "2019-03-16 21:59:46.300148: step 230, examples 11500, loss = 1.320458055 (78.652 examples/sec; 0.636 sec/batch)\n",
      "2019-03-16 21:59:52.824474: step 240, examples 12000, loss = 1.303983212 (74.984 examples/sec; 0.667 sec/batch)\n",
      "2019-03-16 21:59:59.329731: step 250, examples 12500, loss = 1.226008654 (73.474 examples/sec; 0.681 sec/batch)\n",
      "2019-03-16 22:00:05.858304: step 260, examples 13000, loss = 1.136819601 (77.874 examples/sec; 0.642 sec/batch)\n",
      "2019-03-16 22:00:12.470495: step 270, examples 13500, loss = 1.288854361 (74.389 examples/sec; 0.672 sec/batch)\n",
      "2019-03-16 22:00:19.035764: step 280, examples 14000, loss = 1.227681398 (76.782 examples/sec; 0.651 sec/batch)\n",
      "2019-03-16 22:00:25.537684: step 290, examples 14500, loss = 1.276885629 (75.937 examples/sec; 0.658 sec/batch)\n",
      "2019-03-16 22:00:32.092215: step 300, examples 15000, loss = 1.147868872 (72.908 examples/sec; 0.686 sec/batch)\n",
      "Top 1 validation accuracy: 0.4292452931404114 and top 2 validation accuracy: 0.7169811129570007\n",
      "Model Saved!\n",
      "2019-03-16 22:00:41.520743: step 310, examples 15500, loss = 1.212013721 (70.985 examples/sec; 0.704 sec/batch)\n",
      "2019-03-16 22:00:48.260165: step 320, examples 16000, loss = 1.000585556 (74.651 examples/sec; 0.670 sec/batch)\n",
      "2019-03-16 22:00:54.976800: step 330, examples 16500, loss = 1.147765279 (74.747 examples/sec; 0.669 sec/batch)\n",
      "2019-03-16 22:01:01.537226: step 340, examples 17000, loss = 1.285288453 (74.888 examples/sec; 0.668 sec/batch)\n",
      "2019-03-16 22:01:08.146471: step 350, examples 17500, loss = 1.108913302 (81.004 examples/sec; 0.617 sec/batch)\n",
      "2019-03-16 22:01:14.722136: step 360, examples 18000, loss = 1.121671438 (75.518 examples/sec; 0.662 sec/batch)\n",
      "2019-03-16 22:01:21.570325: step 370, examples 18500, loss = 1.209126234 (77.601 examples/sec; 0.644 sec/batch)\n",
      "2019-03-16 22:01:28.103840: step 380, examples 19000, loss = 1.168810844 (75.919 examples/sec; 0.659 sec/batch)\n",
      "2019-03-16 22:01:34.575326: step 390, examples 19500, loss = 1.034491181 (75.443 examples/sec; 0.663 sec/batch)\n",
      "2019-03-16 22:01:41.192654: step 400, examples 20000, loss = 1.214308023 (74.685 examples/sec; 0.669 sec/batch)\n",
      "Top 1 validation accuracy: 0.4363207519054413 and top 2 validation accuracy: 0.6933962106704712\n",
      "Model Saved!\n",
      "2019-03-16 22:01:50.469921: step 410, examples 20500, loss = 1.107802391 (78.735 examples/sec; 0.635 sec/batch)\n",
      "2019-03-16 22:01:57.094820: step 420, examples 21000, loss = 1.167793036 (76.802 examples/sec; 0.651 sec/batch)\n",
      "2019-03-16 22:02:03.565144: step 430, examples 21500, loss = 1.421501756 (78.876 examples/sec; 0.634 sec/batch)\n",
      "2019-03-16 22:02:10.071113: step 440, examples 22000, loss = 1.151347518 (76.804 examples/sec; 0.651 sec/batch)\n",
      "2019-03-16 22:02:16.570524: step 450, examples 22500, loss = 0.966365695 (77.638 examples/sec; 0.644 sec/batch)\n",
      "2019-03-16 22:02:22.969095: step 460, examples 23000, loss = 1.275885940 (77.209 examples/sec; 0.648 sec/batch)\n",
      "2019-03-16 22:02:29.537266: step 470, examples 23500, loss = 1.135560274 (76.903 examples/sec; 0.650 sec/batch)\n",
      "2019-03-16 22:02:35.965046: step 480, examples 24000, loss = 1.105695486 (79.557 examples/sec; 0.628 sec/batch)\n",
      "2019-03-16 22:02:42.515763: step 490, examples 24500, loss = 1.050553203 (73.947 examples/sec; 0.676 sec/batch)\n",
      "2019-03-16 22:02:48.990630: step 500, examples 25000, loss = 1.102988958 (78.357 examples/sec; 0.638 sec/batch)\n",
      "Top 1 validation accuracy: 0.49056604504585266 and top 2 validation accuracy: 0.7051886916160583\n",
      "Model Saved!\n",
      "2019-03-16 22:02:58.466842: step 510, examples 25500, loss = 1.085514903 (74.988 examples/sec; 0.667 sec/batch)\n",
      "2019-03-16 22:03:05.252385: step 520, examples 26000, loss = 1.062186003 (76.075 examples/sec; 0.657 sec/batch)\n",
      "2019-03-16 22:03:11.898502: step 530, examples 26500, loss = 1.095790148 (77.571 examples/sec; 0.645 sec/batch)\n",
      "2019-03-16 22:03:18.429118: step 540, examples 27000, loss = 1.079958320 (78.041 examples/sec; 0.641 sec/batch)\n",
      "2019-03-16 22:03:24.854903: step 550, examples 27500, loss = 1.138365746 (79.047 examples/sec; 0.633 sec/batch)\n",
      "2019-03-16 22:03:31.440879: step 560, examples 28000, loss = 0.971592307 (77.828 examples/sec; 0.642 sec/batch)\n",
      "2019-03-16 22:03:37.909235: step 570, examples 28500, loss = 1.153414130 (76.168 examples/sec; 0.656 sec/batch)\n",
      "2019-03-16 22:03:44.524398: step 580, examples 29000, loss = 0.876102269 (73.612 examples/sec; 0.679 sec/batch)\n",
      "2019-03-16 22:03:50.973454: step 590, examples 29500, loss = 1.146688223 (80.483 examples/sec; 0.621 sec/batch)\n",
      "2019-03-16 22:03:57.537186: step 600, examples 30000, loss = 0.956130207 (73.512 examples/sec; 0.680 sec/batch)\n",
      "Top 1 validation accuracy: 0.5235849022865295 and top 2 validation accuracy: 0.7523584961891174\n",
      "Model Saved!\n",
      "2019-03-16 22:04:07.352063: step 610, examples 30500, loss = 0.982187271 (73.131 examples/sec; 0.684 sec/batch)\n",
      "2019-03-16 22:04:14.053782: step 620, examples 31000, loss = 0.949333549 (77.401 examples/sec; 0.646 sec/batch)\n",
      "2019-03-16 22:04:20.801098: step 630, examples 31500, loss = 1.114781380 (79.993 examples/sec; 0.625 sec/batch)\n",
      "2019-03-16 22:04:27.444776: step 640, examples 32000, loss = 0.957482994 (76.387 examples/sec; 0.655 sec/batch)\n",
      "2019-03-16 22:04:34.229471: step 650, examples 32500, loss = 1.043637633 (75.620 examples/sec; 0.661 sec/batch)\n",
      "2019-03-16 22:04:41.037707: step 660, examples 33000, loss = 1.075211525 (71.357 examples/sec; 0.701 sec/batch)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2019-03-16 22:04:47.812763: step 670, examples 33500, loss = 0.948702991 (73.864 examples/sec; 0.677 sec/batch)\n",
      "2019-03-16 22:04:54.643132: step 680, examples 34000, loss = 1.092903852 (73.764 examples/sec; 0.678 sec/batch)\n",
      "2019-03-16 22:05:01.356340: step 690, examples 34500, loss = 1.193002820 (77.178 examples/sec; 0.648 sec/batch)\n",
      "2019-03-16 22:05:08.200232: step 700, examples 35000, loss = 0.961881459 (75.057 examples/sec; 0.666 sec/batch)\n",
      "Top 1 validation accuracy: 0.5377358198165894 and top 2 validation accuracy: 0.75\n",
      "Model Saved!\n",
      "2019-03-16 22:05:17.844918: step 710, examples 35500, loss = 1.169107318 (71.569 examples/sec; 0.699 sec/batch)\n",
      "2019-03-16 22:05:24.637679: step 720, examples 36000, loss = 1.106561661 (73.668 examples/sec; 0.679 sec/batch)\n",
      "2019-03-16 22:05:31.422005: step 730, examples 36500, loss = 1.093246102 (75.349 examples/sec; 0.664 sec/batch)\n",
      "2019-03-16 22:05:38.293704: step 740, examples 37000, loss = 1.204229355 (72.109 examples/sec; 0.693 sec/batch)\n",
      "2019-03-16 22:05:45.045905: step 750, examples 37500, loss = 1.002519250 (73.493 examples/sec; 0.680 sec/batch)\n",
      "2019-03-16 22:05:51.838794: step 760, examples 38000, loss = 0.924029946 (70.222 examples/sec; 0.712 sec/batch)\n",
      "2019-03-16 22:05:58.561586: step 770, examples 38500, loss = 1.083671570 (76.007 examples/sec; 0.658 sec/batch)\n",
      "2019-03-16 22:06:05.384263: step 780, examples 39000, loss = 0.870346665 (74.224 examples/sec; 0.674 sec/batch)\n",
      "2019-03-16 22:06:12.146358: step 790, examples 39500, loss = 1.019587398 (73.888 examples/sec; 0.677 sec/batch)\n",
      "2019-03-16 22:06:18.825304: step 800, examples 40000, loss = 1.033074617 (73.606 examples/sec; 0.679 sec/batch)\n",
      "Top 1 validation accuracy: 0.5542452931404114 and top 2 validation accuracy: 0.7735849022865295\n",
      "Model Saved!\n",
      "2019-03-16 22:06:28.535585: step 810, examples 40500, loss = 0.899901032 (75.027 examples/sec; 0.666 sec/batch)\n",
      "2019-03-16 22:06:35.209467: step 820, examples 41000, loss = 0.949964166 (74.370 examples/sec; 0.672 sec/batch)\n",
      "2019-03-16 22:06:42.022221: step 830, examples 41500, loss = 1.178856254 (74.606 examples/sec; 0.670 sec/batch)\n",
      "2019-03-16 22:06:48.909151: step 840, examples 42000, loss = 1.202957749 (76.180 examples/sec; 0.656 sec/batch)\n",
      "2019-03-16 22:06:55.718419: step 850, examples 42500, loss = 1.030888319 (67.275 examples/sec; 0.743 sec/batch)\n",
      "2019-03-16 22:07:02.469477: step 860, examples 43000, loss = 1.028622389 (74.320 examples/sec; 0.673 sec/batch)\n",
      "2019-03-16 22:07:09.184142: step 870, examples 43500, loss = 1.176969647 (71.716 examples/sec; 0.697 sec/batch)\n",
      "2019-03-16 22:07:15.934749: step 880, examples 44000, loss = 0.878313720 (77.064 examples/sec; 0.649 sec/batch)\n",
      "2019-03-16 22:07:22.631231: step 890, examples 44500, loss = 1.004739404 (73.862 examples/sec; 0.677 sec/batch)\n",
      "2019-03-16 22:07:29.360719: step 900, examples 45000, loss = 1.017785311 (76.484 examples/sec; 0.654 sec/batch)\n",
      "Top 1 validation accuracy: 0.573113203048706 and top 2 validation accuracy: 0.7688679099082947\n",
      "Model Saved!\n",
      "2019-03-16 22:07:39.114603: step 910, examples 45500, loss = 0.953060329 (73.779 examples/sec; 0.678 sec/batch)\n",
      "2019-03-16 22:07:45.899580: step 920, examples 46000, loss = 0.896251678 (71.554 examples/sec; 0.699 sec/batch)\n",
      "2019-03-16 22:07:52.719811: step 930, examples 46500, loss = 1.086430311 (72.558 examples/sec; 0.689 sec/batch)\n",
      "2019-03-16 22:07:59.570008: step 940, examples 47000, loss = 1.152979851 (73.425 examples/sec; 0.681 sec/batch)\n",
      "2019-03-16 22:08:06.238251: step 950, examples 47500, loss = 0.981581390 (75.269 examples/sec; 0.664 sec/batch)\n",
      "2019-03-16 22:08:13.177479: step 960, examples 48000, loss = 1.106185794 (72.452 examples/sec; 0.690 sec/batch)\n",
      "2019-03-16 22:08:19.977083: step 970, examples 48500, loss = 1.031507730 (75.465 examples/sec; 0.663 sec/batch)\n",
      "2019-03-16 22:08:26.748682: step 980, examples 49000, loss = 1.137189746 (74.775 examples/sec; 0.669 sec/batch)\n",
      "2019-03-16 22:08:33.513854: step 990, examples 49500, loss = 1.121918082 (72.263 examples/sec; 0.692 sec/batch)\n",
      "2019-03-16 22:08:40.209959: step 1000, examples 50000, loss = 1.079964399 (76.112 examples/sec; 0.657 sec/batch)\n",
      "Top 1 validation accuracy: 0.5966981053352356 and top 2 validation accuracy: 0.7783018946647644\n",
      "Model Saved!\n",
      "2019-03-16 22:08:49.920685: step 1010, examples 50500, loss = 1.074506164 (74.877 examples/sec; 0.668 sec/batch)\n",
      "2019-03-16 22:08:56.593706: step 1020, examples 51000, loss = 0.896058917 (75.647 examples/sec; 0.661 sec/batch)\n",
      "2019-03-16 22:09:03.374813: step 1030, examples 51500, loss = 0.952698588 (70.176 examples/sec; 0.712 sec/batch)\n",
      "2019-03-16 22:09:10.033771: step 1040, examples 52000, loss = 0.932392418 (73.547 examples/sec; 0.680 sec/batch)\n",
      "2019-03-16 22:09:16.801493: step 1050, examples 52500, loss = 1.060518622 (74.647 examples/sec; 0.670 sec/batch)\n",
      "2019-03-16 22:09:23.530248: step 1060, examples 53000, loss = 0.881585300 (71.963 examples/sec; 0.695 sec/batch)\n",
      "2019-03-16 22:09:30.324148: step 1070, examples 53500, loss = 0.923004925 (72.649 examples/sec; 0.688 sec/batch)\n",
      "2019-03-16 22:09:37.132407: step 1080, examples 54000, loss = 0.858647645 (74.738 examples/sec; 0.669 sec/batch)\n",
      "2019-03-16 22:09:44.005760: step 1090, examples 54500, loss = 0.929572940 (67.875 examples/sec; 0.737 sec/batch)\n",
      "2019-03-16 22:09:50.708873: step 1100, examples 55000, loss = 1.003132105 (75.339 examples/sec; 0.664 sec/batch)\n",
      "Top 1 validation accuracy: 0.5849056839942932 and top 2 validation accuracy: 0.8066037893295288\n",
      "Model Saved!\n",
      "2019-03-16 22:10:00.812753: step 1110, examples 55500, loss = 1.000175834 (71.751 examples/sec; 0.697 sec/batch)\n",
      "2019-03-16 22:10:08.101778: step 1120, examples 56000, loss = 0.851640403 (70.332 examples/sec; 0.711 sec/batch)\n",
      "2019-03-16 22:10:15.002151: step 1130, examples 56500, loss = 0.913417459 (71.700 examples/sec; 0.697 sec/batch)\n",
      "2019-03-16 22:10:21.773579: step 1140, examples 57000, loss = 0.888340354 (75.655 examples/sec; 0.661 sec/batch)\n",
      "2019-03-16 22:10:28.516146: step 1150, examples 57500, loss = 1.046238542 (76.168 examples/sec; 0.656 sec/batch)\n",
      "2019-03-16 22:10:35.222668: step 1160, examples 58000, loss = 1.039813995 (72.251 examples/sec; 0.692 sec/batch)\n",
      "2019-03-16 22:10:41.943800: step 1170, examples 58500, loss = 0.893931985 (73.369 examples/sec; 0.681 sec/batch)\n",
      "2019-03-16 22:10:48.682680: step 1180, examples 59000, loss = 1.025554299 (75.634 examples/sec; 0.661 sec/batch)\n",
      "2019-03-16 22:10:55.467172: step 1190, examples 59500, loss = 0.873773932 (70.972 examples/sec; 0.705 sec/batch)\n",
      "2019-03-16 22:11:02.237627: step 1200, examples 60000, loss = 0.926908672 (75.018 examples/sec; 0.667 sec/batch)\n",
      "Top 1 validation accuracy: 0.6084905862808228 and top 2 validation accuracy: 0.7971698045730591\n",
      "Model Saved!\n",
      "2019-03-16 22:11:11.900120: step 1210, examples 60500, loss = 1.007349253 (70.517 examples/sec; 0.709 sec/batch)\n",
      "2019-03-16 22:11:18.779371: step 1220, examples 61000, loss = 0.919032276 (71.892 examples/sec; 0.695 sec/batch)\n",
      "2019-03-16 22:11:25.442409: step 1230, examples 61500, loss = 0.730274081 (72.727 examples/sec; 0.687 sec/batch)\n",
      "2019-03-16 22:11:32.193656: step 1240, examples 62000, loss = 1.007017136 (75.936 examples/sec; 0.658 sec/batch)\n",
      "2019-03-16 22:11:38.959448: step 1250, examples 62500, loss = 1.041417837 (73.370 examples/sec; 0.681 sec/batch)\n",
      "2019-03-16 22:11:45.828565: step 1260, examples 63000, loss = 1.070856094 (70.191 examples/sec; 0.712 sec/batch)\n",
      "2019-03-16 22:11:52.574085: step 1270, examples 63500, loss = 1.034211397 (75.647 examples/sec; 0.661 sec/batch)\n",
      "2019-03-16 22:11:59.460384: step 1280, examples 64000, loss = 0.905460536 (70.970 examples/sec; 0.705 sec/batch)\n",
      "2019-03-16 22:12:06.505119: step 1290, examples 64500, loss = 0.956715226 (65.070 examples/sec; 0.768 sec/batch)\n",
      "2019-03-16 22:12:13.593661: step 1300, examples 65000, loss = 0.894032657 (71.350 examples/sec; 0.701 sec/batch)\n",
      "Top 1 validation accuracy: 0.599056601524353 and top 2 validation accuracy: 0.7712264060974121\n",
      "Model Saved!\n",
      "2019-03-16 22:12:23.687341: step 1310, examples 65500, loss = 0.938783348 (74.620 examples/sec; 0.670 sec/batch)\n",
      "2019-03-16 22:12:30.438741: step 1320, examples 66000, loss = 1.007476807 (72.111 examples/sec; 0.693 sec/batch)\n",
      "2019-03-16 22:12:37.237976: step 1330, examples 66500, loss = 1.043143988 (73.317 examples/sec; 0.682 sec/batch)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2019-03-16 22:12:44.120162: step 1340, examples 67000, loss = 0.961541951 (73.119 examples/sec; 0.684 sec/batch)\n",
      "2019-03-16 22:12:51.175450: step 1350, examples 67500, loss = 0.903099060 (70.285 examples/sec; 0.711 sec/batch)\n",
      "2019-03-16 22:12:57.902270: step 1360, examples 68000, loss = 0.995333314 (75.311 examples/sec; 0.664 sec/batch)\n",
      "2019-03-16 22:13:04.689359: step 1370, examples 68500, loss = 0.909675241 (73.577 examples/sec; 0.680 sec/batch)\n",
      "2019-03-16 22:13:11.367693: step 1380, examples 69000, loss = 0.830238819 (76.310 examples/sec; 0.655 sec/batch)\n",
      "2019-03-16 22:13:18.227918: step 1390, examples 69500, loss = 0.928257167 (69.815 examples/sec; 0.716 sec/batch)\n",
      "2019-03-16 22:13:25.165313: step 1400, examples 70000, loss = 1.003360987 (72.842 examples/sec; 0.686 sec/batch)\n",
      "Top 1 validation accuracy: 0.5896226167678833 and top 2 validation accuracy: 0.801886796951294\n",
      "Model Saved!\n",
      "2019-03-16 22:13:35.253788: step 1410, examples 70500, loss = 1.104883194 (71.389 examples/sec; 0.700 sec/batch)\n",
      "2019-03-16 22:13:42.230362: step 1420, examples 71000, loss = 0.924447656 (73.860 examples/sec; 0.677 sec/batch)\n",
      "2019-03-16 22:13:49.034125: step 1430, examples 71500, loss = 0.944706619 (75.369 examples/sec; 0.663 sec/batch)\n",
      "2019-03-16 22:13:55.859821: step 1440, examples 72000, loss = 0.888988316 (73.108 examples/sec; 0.684 sec/batch)\n",
      "2019-03-16 22:14:02.619272: step 1450, examples 72500, loss = 0.909828961 (75.804 examples/sec; 0.660 sec/batch)\n",
      "2019-03-16 22:14:09.420803: step 1460, examples 73000, loss = 0.963395715 (73.426 examples/sec; 0.681 sec/batch)\n",
      "2019-03-16 22:14:16.130875: step 1470, examples 73500, loss = 0.811850369 (72.950 examples/sec; 0.685 sec/batch)\n",
      "2019-03-16 22:14:22.788581: step 1480, examples 74000, loss = 0.718342423 (72.235 examples/sec; 0.692 sec/batch)\n",
      "2019-03-16 22:14:29.537629: step 1490, examples 74500, loss = 1.014835835 (76.574 examples/sec; 0.653 sec/batch)\n",
      "2019-03-16 22:14:36.274045: step 1500, examples 75000, loss = 0.887670159 (75.695 examples/sec; 0.661 sec/batch)\n",
      "Top 1 validation accuracy: 0.5542452931404114 and top 2 validation accuracy: 0.8042452931404114\n",
      "Model Saved!\n",
      "2019-03-16 22:14:45.998729: step 1510, examples 75500, loss = 0.961067796 (77.351 examples/sec; 0.646 sec/batch)\n",
      "2019-03-16 22:14:52.704121: step 1520, examples 76000, loss = 0.972866237 (73.398 examples/sec; 0.681 sec/batch)\n",
      "2019-03-16 22:14:59.460908: step 1530, examples 76500, loss = 0.873772979 (74.716 examples/sec; 0.669 sec/batch)\n",
      "2019-03-16 22:15:06.128671: step 1540, examples 77000, loss = 0.946120381 (74.827 examples/sec; 0.668 sec/batch)\n",
      "2019-03-16 22:15:12.878439: step 1550, examples 77500, loss = 0.914058030 (75.298 examples/sec; 0.664 sec/batch)\n",
      "2019-03-16 22:15:19.537613: step 1560, examples 78000, loss = 0.858183265 (77.026 examples/sec; 0.649 sec/batch)\n",
      "2019-03-16 22:15:26.225103: step 1570, examples 78500, loss = 0.940695584 (71.811 examples/sec; 0.696 sec/batch)\n",
      "2019-03-16 22:15:32.974851: step 1580, examples 79000, loss = 0.798739910 (76.681 examples/sec; 0.652 sec/batch)\n",
      "2019-03-16 22:15:39.703855: step 1590, examples 79500, loss = 0.926676750 (70.368 examples/sec; 0.711 sec/batch)\n",
      "2019-03-16 22:15:46.887442: step 1600, examples 80000, loss = 0.978664219 (70.432 examples/sec; 0.710 sec/batch)\n",
      "Top 1 validation accuracy: 0.5566037893295288 and top 2 validation accuracy: 0.7570754885673523\n",
      "Model Saved!\n",
      "2019-03-16 22:15:56.708920: step 1610, examples 80500, loss = 1.000745535 (73.331 examples/sec; 0.682 sec/batch)\n",
      "2019-03-16 22:16:03.476437: step 1620, examples 81000, loss = 1.015001774 (74.812 examples/sec; 0.668 sec/batch)\n",
      "2019-03-16 22:16:10.193756: step 1630, examples 81500, loss = 0.897093415 (71.354 examples/sec; 0.701 sec/batch)\n",
      "2019-03-16 22:16:16.931132: step 1640, examples 82000, loss = 0.779051542 (77.453 examples/sec; 0.646 sec/batch)\n",
      "2019-03-16 22:16:23.761989: step 1650, examples 82500, loss = 0.933775723 (73.699 examples/sec; 0.678 sec/batch)\n",
      "2019-03-16 22:16:30.462865: step 1660, examples 83000, loss = 0.756139040 (74.647 examples/sec; 0.670 sec/batch)\n",
      "2019-03-16 22:16:37.276277: step 1670, examples 83500, loss = 0.894461513 (77.248 examples/sec; 0.647 sec/batch)\n",
      "2019-03-16 22:16:43.989583: step 1680, examples 84000, loss = 1.003338218 (74.972 examples/sec; 0.667 sec/batch)\n",
      "2019-03-16 22:16:50.834603: step 1690, examples 84500, loss = 0.740377247 (74.387 examples/sec; 0.672 sec/batch)\n",
      "2019-03-16 22:16:57.537441: step 1700, examples 85000, loss = 0.858193696 (77.537 examples/sec; 0.645 sec/batch)\n",
      "Top 1 validation accuracy: 0.5943396091461182 and top 2 validation accuracy: 0.8066037893295288\n",
      "Model Saved!\n",
      "2019-03-16 22:17:07.254670: step 1710, examples 85500, loss = 0.882905602 (74.402 examples/sec; 0.672 sec/batch)\n",
      "2019-03-16 22:17:13.942505: step 1720, examples 86000, loss = 0.920378506 (74.439 examples/sec; 0.672 sec/batch)\n",
      "2019-03-16 22:17:20.738678: step 1730, examples 86500, loss = 0.827116787 (76.878 examples/sec; 0.650 sec/batch)\n",
      "2019-03-16 22:17:27.443644: step 1740, examples 87000, loss = 0.843595862 (73.900 examples/sec; 0.677 sec/batch)\n",
      "2019-03-16 22:17:34.095997: step 1750, examples 87500, loss = 0.797879279 (73.946 examples/sec; 0.676 sec/batch)\n",
      "2019-03-16 22:17:40.964592: step 1760, examples 88000, loss = 0.989879787 (70.556 examples/sec; 0.709 sec/batch)\n",
      "2019-03-16 22:17:47.903703: step 1770, examples 88500, loss = 0.729216218 (75.826 examples/sec; 0.659 sec/batch)\n",
      "2019-03-16 22:17:54.630915: step 1780, examples 89000, loss = 0.845316708 (75.970 examples/sec; 0.658 sec/batch)\n",
      "2019-03-16 22:18:01.315709: step 1790, examples 89500, loss = 0.937303185 (74.126 examples/sec; 0.675 sec/batch)\n",
      "2019-03-16 22:18:08.052671: step 1800, examples 90000, loss = 0.770247161 (75.784 examples/sec; 0.660 sec/batch)\n",
      "Top 1 validation accuracy: 0.6273584961891174 and top 2 validation accuracy: 0.8207547068595886\n",
      "Model Saved!\n",
      "2019-03-16 22:18:17.760984: step 1810, examples 90500, loss = 0.874285579 (71.504 examples/sec; 0.699 sec/batch)\n",
      "2019-03-16 22:18:24.725692: step 1820, examples 91000, loss = 0.954783618 (72.339 examples/sec; 0.691 sec/batch)\n",
      "2019-03-16 22:18:31.615644: step 1830, examples 91500, loss = 0.996129394 (74.338 examples/sec; 0.673 sec/batch)\n",
      "2019-03-16 22:18:38.496156: step 1840, examples 92000, loss = 0.784913838 (68.750 examples/sec; 0.727 sec/batch)\n",
      "2019-03-16 22:18:45.515643: step 1850, examples 92500, loss = 0.744916618 (67.491 examples/sec; 0.741 sec/batch)\n",
      "2019-03-16 22:18:52.053718: step 1860, examples 93000, loss = 0.935927749 (76.821 examples/sec; 0.651 sec/batch)\n",
      "2019-03-16 22:18:58.602580: step 1870, examples 93500, loss = 0.932831466 (76.138 examples/sec; 0.657 sec/batch)\n",
      "2019-03-16 22:19:05.138513: step 1880, examples 94000, loss = 0.656848550 (73.743 examples/sec; 0.678 sec/batch)\n",
      "2019-03-16 22:19:11.674486: step 1890, examples 94500, loss = 0.858861327 (70.334 examples/sec; 0.711 sec/batch)\n",
      "2019-03-16 22:19:18.421440: step 1900, examples 95000, loss = 0.879548848 (74.707 examples/sec; 0.669 sec/batch)\n",
      "Top 1 validation accuracy: 0.6014150977134705 and top 2 validation accuracy: 0.8207547068595886\n",
      "Model Saved!\n",
      "2019-03-16 22:19:28.146411: step 1910, examples 95500, loss = 0.935912311 (71.449 examples/sec; 0.700 sec/batch)\n",
      "2019-03-16 22:19:34.873830: step 1920, examples 96000, loss = 0.962345958 (75.903 examples/sec; 0.659 sec/batch)\n",
      "2019-03-16 22:19:41.635017: step 1930, examples 96500, loss = 0.780931354 (77.910 examples/sec; 0.642 sec/batch)\n",
      "2019-03-16 22:19:48.491325: step 1940, examples 97000, loss = 1.161366701 (71.666 examples/sec; 0.698 sec/batch)\n",
      "2019-03-16 22:19:55.216887: step 1950, examples 97500, loss = 0.990583777 (73.622 examples/sec; 0.679 sec/batch)\n",
      "2019-03-16 22:20:01.862680: step 1960, examples 98000, loss = 0.923922837 (76.607 examples/sec; 0.653 sec/batch)\n",
      "2019-03-16 22:20:08.690886: step 1970, examples 98500, loss = 0.881450295 (73.675 examples/sec; 0.679 sec/batch)\n",
      "2019-03-16 22:20:15.445037: step 1980, examples 99000, loss = 0.786163926 (71.351 examples/sec; 0.701 sec/batch)\n",
      "2019-03-16 22:20:22.132660: step 1990, examples 99500, loss = 0.867099762 (74.441 examples/sec; 0.672 sec/batch)\n",
      "2019-03-16 22:20:28.828455: step 2000, examples 100000, loss = 0.893042684 (73.334 examples/sec; 0.682 sec/batch)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Top 1 validation accuracy: 0.5966981053352356 and top 2 validation accuracy: 0.7971698045730591\n",
      "Model Saved!\n",
      "2019-03-16 22:20:38.494558: step 2010, examples 100500, loss = 1.051523685 (78.142 examples/sec; 0.640 sec/batch)\n",
      "2019-03-16 22:20:45.175909: step 2020, examples 101000, loss = 0.924017310 (71.518 examples/sec; 0.699 sec/batch)\n",
      "2019-03-16 22:20:51.991012: step 2030, examples 101500, loss = 0.968584657 (74.791 examples/sec; 0.669 sec/batch)\n",
      "2019-03-16 22:20:58.686104: step 2040, examples 102000, loss = 0.935776532 (74.886 examples/sec; 0.668 sec/batch)\n",
      "2019-03-16 22:21:05.460909: step 2050, examples 102500, loss = 0.833380044 (73.913 examples/sec; 0.676 sec/batch)\n",
      "2019-03-16 22:21:12.162680: step 2060, examples 103000, loss = 0.869185805 (73.508 examples/sec; 0.680 sec/batch)\n",
      "2019-03-16 22:21:18.879312: step 2070, examples 103500, loss = 0.787920117 (73.474 examples/sec; 0.681 sec/batch)\n",
      "2019-03-16 22:21:25.630560: step 2080, examples 104000, loss = 0.963711560 (74.853 examples/sec; 0.668 sec/batch)\n",
      "2019-03-16 22:21:32.565561: step 2090, examples 104500, loss = 0.986115456 (69.501 examples/sec; 0.719 sec/batch)\n",
      "2019-03-16 22:21:39.611296: step 2100, examples 105000, loss = 0.686929405 (71.906 examples/sec; 0.695 sec/batch)\n",
      "Top 1 validation accuracy: 0.6320754885673523 and top 2 validation accuracy: 0.8136792182922363\n",
      "Model Saved!\n",
      "2019-03-16 22:21:49.288124: step 2110, examples 105500, loss = 0.759597778 (75.566 examples/sec; 0.662 sec/batch)\n",
      "2019-03-16 22:21:56.096411: step 2120, examples 106000, loss = 0.875929832 (74.979 examples/sec; 0.667 sec/batch)\n",
      "2019-03-16 22:22:02.901345: step 2130, examples 106500, loss = 0.869706452 (74.400 examples/sec; 0.672 sec/batch)\n",
      "2019-03-16 22:22:09.689849: step 2140, examples 107000, loss = 0.778913260 (76.562 examples/sec; 0.653 sec/batch)\n",
      "2019-03-16 22:22:16.386305: step 2150, examples 107500, loss = 0.848963857 (76.811 examples/sec; 0.651 sec/batch)\n",
      "2019-03-16 22:22:23.050086: step 2160, examples 108000, loss = 0.811462104 (73.288 examples/sec; 0.682 sec/batch)\n",
      "2019-03-16 22:22:29.840459: step 2170, examples 108500, loss = 0.697480559 (76.187 examples/sec; 0.656 sec/batch)\n",
      "2019-03-16 22:22:36.501130: step 2180, examples 109000, loss = 0.910092473 (75.115 examples/sec; 0.666 sec/batch)\n",
      "2019-03-16 22:22:43.254481: step 2190, examples 109500, loss = 0.835019886 (76.008 examples/sec; 0.658 sec/batch)\n",
      "2019-03-16 22:22:49.978846: step 2200, examples 110000, loss = 1.002799392 (75.371 examples/sec; 0.663 sec/batch)\n",
      "Top 1 validation accuracy: 0.6061320900917053 and top 2 validation accuracy: 0.823113203048706\n",
      "Model Saved!\n",
      "2019-03-16 22:22:59.758709: step 2210, examples 110500, loss = 0.850290000 (74.426 examples/sec; 0.672 sec/batch)\n",
      "2019-03-16 22:23:06.476870: step 2220, examples 111000, loss = 0.754391313 (71.886 examples/sec; 0.696 sec/batch)\n",
      "2019-03-16 22:23:13.177127: step 2230, examples 111500, loss = 0.857616067 (73.557 examples/sec; 0.680 sec/batch)\n",
      "2019-03-16 22:23:19.962992: step 2240, examples 112000, loss = 0.916275501 (66.387 examples/sec; 0.753 sec/batch)\n",
      "2019-03-16 22:23:26.777098: step 2250, examples 112500, loss = 0.860355556 (72.722 examples/sec; 0.688 sec/batch)\n",
      "2019-03-16 22:23:33.552622: step 2260, examples 113000, loss = 0.711065412 (74.390 examples/sec; 0.672 sec/batch)\n",
      "2019-03-16 22:23:40.336225: step 2270, examples 113500, loss = 0.831400514 (71.387 examples/sec; 0.700 sec/batch)\n",
      "2019-03-16 22:23:47.193950: step 2280, examples 114000, loss = 0.772946298 (72.183 examples/sec; 0.693 sec/batch)\n",
      "2019-03-16 22:23:53.900854: step 2290, examples 114500, loss = 0.792173982 (77.877 examples/sec; 0.642 sec/batch)\n",
      "2019-03-16 22:24:00.928300: step 2300, examples 115000, loss = 1.011104226 (75.824 examples/sec; 0.659 sec/batch)\n",
      "Top 1 validation accuracy: 0.5636792182922363 and top 2 validation accuracy: 0.7853773832321167\n",
      "Model Saved!\n",
      "2019-03-16 22:24:10.746112: step 2310, examples 115500, loss = 0.805193305 (72.343 examples/sec; 0.691 sec/batch)\n",
      "2019-03-16 22:24:17.584035: step 2320, examples 116000, loss = 0.995981812 (73.879 examples/sec; 0.677 sec/batch)\n",
      "2019-03-16 22:24:24.430522: step 2330, examples 116500, loss = 0.981914341 (71.564 examples/sec; 0.699 sec/batch)\n",
      "2019-03-16 22:24:31.238269: step 2340, examples 117000, loss = 0.842179477 (70.052 examples/sec; 0.714 sec/batch)\n",
      "2019-03-16 22:24:37.975463: step 2350, examples 117500, loss = 0.872038662 (75.046 examples/sec; 0.666 sec/batch)\n",
      "2019-03-16 22:24:44.796725: step 2360, examples 118000, loss = 0.738837302 (71.438 examples/sec; 0.700 sec/batch)\n",
      "2019-03-16 22:24:52.074348: step 2370, examples 118500, loss = 0.818603158 (65.619 examples/sec; 0.762 sec/batch)\n",
      "2019-03-16 22:24:58.964853: step 2380, examples 119000, loss = 0.758271456 (78.437 examples/sec; 0.637 sec/batch)\n",
      "2019-03-16 22:25:05.724343: step 2390, examples 119500, loss = 0.726370454 (74.509 examples/sec; 0.671 sec/batch)\n",
      "2019-03-16 22:25:12.395953: step 2400, examples 120000, loss = 0.866920829 (77.840 examples/sec; 0.642 sec/batch)\n",
      "Top 1 validation accuracy: 0.6132075190544128 and top 2 validation accuracy: 0.8278301954269409\n",
      "Model Saved!\n",
      "2019-03-16 22:25:22.093774: step 2410, examples 120500, loss = 0.868270695 (73.451 examples/sec; 0.681 sec/batch)\n",
      "2019-03-16 22:25:28.756490: step 2420, examples 121000, loss = 0.825247586 (76.189 examples/sec; 0.656 sec/batch)\n",
      "2019-03-16 22:25:35.489992: step 2430, examples 121500, loss = 0.831886947 (69.885 examples/sec; 0.715 sec/batch)\n",
      "2019-03-16 22:25:42.288447: step 2440, examples 122000, loss = 0.787733376 (76.041 examples/sec; 0.658 sec/batch)\n",
      "2019-03-16 22:25:49.033757: step 2450, examples 122500, loss = 0.660138845 (75.092 examples/sec; 0.666 sec/batch)\n",
      "2019-03-16 22:25:55.801756: step 2460, examples 123000, loss = 0.732859790 (71.572 examples/sec; 0.699 sec/batch)\n",
      "2019-03-16 22:26:02.552815: step 2470, examples 123500, loss = 0.898141682 (71.331 examples/sec; 0.701 sec/batch)\n",
      "2019-03-16 22:26:09.385208: step 2480, examples 124000, loss = 0.848632157 (74.121 examples/sec; 0.675 sec/batch)\n",
      "2019-03-16 22:26:16.087406: step 2490, examples 124500, loss = 0.790432572 (72.907 examples/sec; 0.686 sec/batch)\n",
      "2019-03-16 22:26:22.830268: step 2500, examples 125000, loss = 0.780630946 (74.859 examples/sec; 0.668 sec/batch)\n",
      "Top 1 validation accuracy: 0.6297169923782349 and top 2 validation accuracy: 0.8183962106704712\n",
      "Model Saved!\n",
      "2019-03-16 22:26:32.582220: step 2510, examples 125500, loss = 0.770678818 (74.988 examples/sec; 0.667 sec/batch)\n",
      "2019-03-16 22:26:39.617740: step 2520, examples 126000, loss = 0.943330765 (70.954 examples/sec; 0.705 sec/batch)\n",
      "2019-03-16 22:26:46.478078: step 2530, examples 126500, loss = 0.755304754 (74.511 examples/sec; 0.671 sec/batch)\n",
      "2019-03-16 22:26:53.221616: step 2540, examples 127000, loss = 0.768604398 (74.723 examples/sec; 0.669 sec/batch)\n",
      "2019-03-16 22:27:00.033977: step 2550, examples 127500, loss = 0.726993084 (75.061 examples/sec; 0.666 sec/batch)\n",
      "2019-03-16 22:27:06.820998: step 2560, examples 128000, loss = 0.886635184 (74.072 examples/sec; 0.675 sec/batch)\n",
      "2019-03-16 22:27:13.585620: step 2570, examples 128500, loss = 0.763960958 (75.148 examples/sec; 0.665 sec/batch)\n",
      "2019-03-16 22:27:20.286890: step 2580, examples 129000, loss = 0.765570879 (76.571 examples/sec; 0.653 sec/batch)\n",
      "2019-03-16 22:27:27.054077: step 2590, examples 129500, loss = 0.799028218 (74.041 examples/sec; 0.675 sec/batch)\n",
      "2019-03-16 22:27:33.856244: step 2600, examples 130000, loss = 0.869754672 (75.108 examples/sec; 0.666 sec/batch)\n",
      "Top 1 validation accuracy: 0.6132075190544128 and top 2 validation accuracy: 0.8136792182922363\n",
      "Model Saved!\n",
      "2019-03-16 22:27:43.482448: step 2610, examples 130500, loss = 0.993565381 (65.660 examples/sec; 0.762 sec/batch)\n",
      "2019-03-16 22:27:50.193867: step 2620, examples 131000, loss = 0.823551774 (76.180 examples/sec; 0.656 sec/batch)\n",
      "2019-03-16 22:27:56.847994: step 2630, examples 131500, loss = 0.718556821 (73.028 examples/sec; 0.685 sec/batch)\n",
      "2019-03-16 22:28:03.664231: step 2640, examples 132000, loss = 0.785014510 (73.972 examples/sec; 0.676 sec/batch)\n",
      "2019-03-16 22:28:10.427657: step 2650, examples 132500, loss = 0.762663305 (72.174 examples/sec; 0.693 sec/batch)\n",
      "2019-03-16 22:28:17.136480: step 2660, examples 133000, loss = 0.815306962 (72.381 examples/sec; 0.691 sec/batch)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2019-03-16 22:28:23.876192: step 2670, examples 133500, loss = 0.695736706 (73.246 examples/sec; 0.683 sec/batch)\n",
      "2019-03-16 22:28:30.563864: step 2680, examples 134000, loss = 0.746519148 (74.382 examples/sec; 0.672 sec/batch)\n",
      "2019-03-16 22:28:37.335088: step 2690, examples 134500, loss = 0.681845725 (75.102 examples/sec; 0.666 sec/batch)\n",
      "2019-03-16 22:28:44.074336: step 2700, examples 135000, loss = 0.754707694 (72.615 examples/sec; 0.689 sec/batch)\n",
      "Top 1 validation accuracy: 0.6132075190544128 and top 2 validation accuracy: 0.8372641801834106\n",
      "Model Saved!\n",
      "2019-03-16 22:28:53.758897: step 2710, examples 135500, loss = 0.854095280 (75.679 examples/sec; 0.661 sec/batch)\n",
      "2019-03-16 22:29:00.516162: step 2720, examples 136000, loss = 0.817437947 (72.116 examples/sec; 0.693 sec/batch)\n",
      "2019-03-16 22:29:07.324472: step 2730, examples 136500, loss = 0.729559958 (72.296 examples/sec; 0.692 sec/batch)\n",
      "2019-03-16 22:29:13.992748: step 2740, examples 137000, loss = 0.972869694 (76.135 examples/sec; 0.657 sec/batch)\n",
      "2019-03-16 22:29:20.808254: step 2750, examples 137500, loss = 0.926031411 (72.888 examples/sec; 0.686 sec/batch)\n",
      "2019-03-16 22:29:27.594231: step 2760, examples 138000, loss = 0.833477676 (72.353 examples/sec; 0.691 sec/batch)\n",
      "2019-03-16 22:29:34.293249: step 2770, examples 138500, loss = 0.870326161 (76.248 examples/sec; 0.656 sec/batch)\n",
      "2019-03-16 22:29:41.197286: step 2780, examples 139000, loss = 0.721394122 (68.487 examples/sec; 0.730 sec/batch)\n",
      "2019-03-16 22:29:48.239021: step 2790, examples 139500, loss = 0.665771604 (76.177 examples/sec; 0.656 sec/batch)\n",
      "2019-03-16 22:29:54.802968: step 2800, examples 140000, loss = 0.781817317 (77.459 examples/sec; 0.646 sec/batch)\n",
      "Top 1 validation accuracy: 0.6391509175300598 and top 2 validation accuracy: 0.8113207817077637\n",
      "Model Saved!\n",
      "2019-03-16 22:30:04.019464: step 2810, examples 140500, loss = 0.902929664 (74.979 examples/sec; 0.667 sec/batch)\n",
      "2019-03-16 22:30:10.536943: step 2820, examples 141000, loss = 0.972884834 (75.075 examples/sec; 0.666 sec/batch)\n",
      "2019-03-16 22:30:17.034621: step 2830, examples 141500, loss = 0.679406464 (78.772 examples/sec; 0.635 sec/batch)\n",
      "2019-03-16 22:30:23.552409: step 2840, examples 142000, loss = 0.869038463 (73.345 examples/sec; 0.682 sec/batch)\n",
      "2019-03-16 22:30:30.005676: step 2850, examples 142500, loss = 0.838673294 (77.631 examples/sec; 0.644 sec/batch)\n",
      "2019-03-16 22:30:36.579008: step 2860, examples 143000, loss = 0.900027454 (77.766 examples/sec; 0.643 sec/batch)\n",
      "2019-03-16 22:30:43.109722: step 2870, examples 143500, loss = 0.850468636 (77.114 examples/sec; 0.648 sec/batch)\n",
      "2019-03-16 22:30:49.620649: step 2880, examples 144000, loss = 0.917116463 (77.785 examples/sec; 0.643 sec/batch)\n",
      "2019-03-16 22:30:56.125311: step 2890, examples 144500, loss = 0.676865339 (77.934 examples/sec; 0.642 sec/batch)\n",
      "2019-03-16 22:31:02.631072: step 2900, examples 145000, loss = 0.794489861 (77.067 examples/sec; 0.649 sec/batch)\n",
      "Top 1 validation accuracy: 0.6061320900917053 and top 2 validation accuracy: 0.8042452931404114\n",
      "Model Saved!\n",
      "2019-03-16 22:31:11.842581: step 2910, examples 145500, loss = 0.775162578 (73.338 examples/sec; 0.682 sec/batch)\n",
      "2019-03-16 22:31:18.318944: step 2920, examples 146000, loss = 0.789377332 (72.742 examples/sec; 0.687 sec/batch)\n",
      "2019-03-16 22:31:24.816652: step 2930, examples 146500, loss = 0.847813904 (74.657 examples/sec; 0.670 sec/batch)\n",
      "2019-03-16 22:31:31.308703: step 2940, examples 147000, loss = 1.130575180 (78.398 examples/sec; 0.638 sec/batch)\n",
      "2019-03-16 22:31:37.829544: step 2950, examples 147500, loss = 0.727617741 (76.103 examples/sec; 0.657 sec/batch)\n",
      "2019-03-16 22:31:44.469216: step 2960, examples 148000, loss = 0.826404691 (71.226 examples/sec; 0.702 sec/batch)\n",
      "2019-03-16 22:31:51.011394: step 2970, examples 148500, loss = 0.857928097 (74.135 examples/sec; 0.674 sec/batch)\n",
      "2019-03-16 22:31:57.593740: step 2980, examples 149000, loss = 0.733883858 (76.754 examples/sec; 0.651 sec/batch)\n",
      "2019-03-16 22:32:04.147909: step 2990, examples 149500, loss = 0.619021833 (81.665 examples/sec; 0.612 sec/batch)\n",
      "2019-03-16 22:32:10.642015: step 3000, examples 150000, loss = 0.829732418 (80.519 examples/sec; 0.621 sec/batch)\n",
      "Top 1 validation accuracy: 0.6485849022865295 and top 2 validation accuracy: 0.8160377144813538\n",
      "Model Saved!\n",
      "2019-03-16 22:32:20.003010: step 3010, examples 150500, loss = 0.831338882 (76.859 examples/sec; 0.651 sec/batch)\n",
      "2019-03-16 22:32:26.503271: step 3020, examples 151000, loss = 0.656737447 (74.808 examples/sec; 0.668 sec/batch)\n",
      "2019-03-16 22:32:33.080042: step 3030, examples 151500, loss = 0.696991563 (70.254 examples/sec; 0.712 sec/batch)\n",
      "2019-03-16 22:32:39.498496: step 3040, examples 152000, loss = 0.815257370 (75.241 examples/sec; 0.665 sec/batch)\n",
      "2019-03-16 22:32:46.021369: step 3050, examples 152500, loss = 0.814611733 (75.763 examples/sec; 0.660 sec/batch)\n",
      "2019-03-16 22:32:52.537628: step 3060, examples 153000, loss = 0.928430080 (77.717 examples/sec; 0.643 sec/batch)\n",
      "2019-03-16 22:32:59.101359: step 3070, examples 153500, loss = 0.703073680 (80.499 examples/sec; 0.621 sec/batch)\n",
      "2019-03-16 22:33:05.643144: step 3080, examples 154000, loss = 0.646413982 (77.491 examples/sec; 0.645 sec/batch)\n",
      "2019-03-16 22:33:12.197066: step 3090, examples 154500, loss = 0.665844083 (75.442 examples/sec; 0.663 sec/batch)\n",
      "2019-03-16 22:33:18.684613: step 3100, examples 155000, loss = 0.716012061 (75.051 examples/sec; 0.666 sec/batch)\n",
      "Top 1 validation accuracy: 0.6320754885673523 and top 2 validation accuracy: 0.849056601524353\n",
      "Model Saved!\n",
      "2019-03-16 22:33:28.046191: step 3110, examples 155500, loss = 0.846599936 (80.995 examples/sec; 0.617 sec/batch)\n",
      "2019-03-16 22:33:34.537504: step 3120, examples 156000, loss = 0.834520936 (75.357 examples/sec; 0.664 sec/batch)\n",
      "2019-03-16 22:33:41.118745: step 3130, examples 156500, loss = 0.713081717 (76.518 examples/sec; 0.653 sec/batch)\n",
      "2019-03-16 22:33:47.631587: step 3140, examples 157000, loss = 0.934855282 (73.000 examples/sec; 0.685 sec/batch)\n",
      "2019-03-16 22:33:54.161960: step 3150, examples 157500, loss = 0.816331089 (82.175 examples/sec; 0.608 sec/batch)\n",
      "2019-03-16 22:34:00.753103: step 3160, examples 158000, loss = 0.828417480 (75.135 examples/sec; 0.665 sec/batch)\n",
      "2019-03-16 22:34:07.362179: step 3170, examples 158500, loss = 0.746503711 (71.862 examples/sec; 0.696 sec/batch)\n",
      "2019-03-16 22:34:13.945140: step 3180, examples 159000, loss = 0.829999149 (78.727 examples/sec; 0.635 sec/batch)\n",
      "2019-03-16 22:34:20.467231: step 3190, examples 159500, loss = 0.770494521 (77.981 examples/sec; 0.641 sec/batch)\n",
      "2019-03-16 22:34:27.051201: step 3200, examples 160000, loss = 0.703608274 (78.305 examples/sec; 0.639 sec/batch)\n",
      "Top 1 validation accuracy: 0.6061320900917053 and top 2 validation accuracy: 0.8183962106704712\n",
      "Model Saved!\n",
      "2019-03-16 22:34:36.273627: step 3210, examples 160500, loss = 0.819597065 (75.968 examples/sec; 0.658 sec/batch)\n",
      "2019-03-16 22:34:42.795091: step 3220, examples 161000, loss = 0.983189762 (78.976 examples/sec; 0.633 sec/batch)\n",
      "2019-03-16 22:34:49.178847: step 3230, examples 161500, loss = 0.816228092 (79.901 examples/sec; 0.626 sec/batch)\n",
      "2019-03-16 22:34:55.673141: step 3240, examples 162000, loss = 0.764043391 (73.871 examples/sec; 0.677 sec/batch)\n",
      "2019-03-16 22:35:02.153081: step 3250, examples 162500, loss = 0.683318198 (78.271 examples/sec; 0.639 sec/batch)\n",
      "2019-03-16 22:35:08.650328: step 3260, examples 163000, loss = 0.855946720 (79.209 examples/sec; 0.631 sec/batch)\n",
      "2019-03-16 22:35:15.221832: step 3270, examples 163500, loss = 0.766700387 (77.681 examples/sec; 0.644 sec/batch)\n",
      "2019-03-16 22:35:21.744103: step 3280, examples 164000, loss = 0.921955884 (77.709 examples/sec; 0.643 sec/batch)\n",
      "2019-03-16 22:35:28.336419: step 3290, examples 164500, loss = 0.866845429 (77.014 examples/sec; 0.649 sec/batch)\n",
      "2019-03-16 22:35:34.870247: step 3300, examples 165000, loss = 0.657246113 (76.257 examples/sec; 0.656 sec/batch)\n",
      "Top 1 validation accuracy: 0.6037735939025879 and top 2 validation accuracy: 0.8325471878051758\n",
      "Model Saved!\n",
      "2019-03-16 22:35:44.251847: step 3310, examples 165500, loss = 0.806684017 (75.168 examples/sec; 0.665 sec/batch)\n",
      "2019-03-16 22:35:50.702632: step 3320, examples 166000, loss = 0.823103130 (78.814 examples/sec; 0.634 sec/batch)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2019-03-16 22:35:57.225230: step 3330, examples 166500, loss = 0.731500864 (74.385 examples/sec; 0.672 sec/batch)\n",
      "2019-03-16 22:36:03.807414: step 3340, examples 167000, loss = 0.754548430 (77.424 examples/sec; 0.646 sec/batch)\n",
      "2019-03-16 22:36:10.184909: step 3350, examples 167500, loss = 0.925431848 (79.172 examples/sec; 0.632 sec/batch)\n",
      "2019-03-16 22:36:16.735792: step 3360, examples 168000, loss = 0.699303806 (77.630 examples/sec; 0.644 sec/batch)\n",
      "2019-03-16 22:36:23.204098: step 3370, examples 168500, loss = 0.906763434 (76.709 examples/sec; 0.652 sec/batch)\n",
      "2019-03-16 22:36:29.775037: step 3380, examples 169000, loss = 0.809296429 (79.244 examples/sec; 0.631 sec/batch)\n",
      "2019-03-16 22:36:36.337133: step 3390, examples 169500, loss = 0.658138871 (76.940 examples/sec; 0.650 sec/batch)\n",
      "2019-03-16 22:36:42.868169: step 3400, examples 170000, loss = 0.796402514 (77.744 examples/sec; 0.643 sec/batch)\n",
      "Top 1 validation accuracy: 0.599056601524353 and top 2 validation accuracy: 0.7948113083839417\n",
      "Model Saved!\n",
      "2019-03-16 22:36:52.336255: step 3410, examples 170500, loss = 0.875335395 (75.340 examples/sec; 0.664 sec/batch)\n",
      "2019-03-16 22:36:58.829220: step 3420, examples 171000, loss = 0.730056882 (76.802 examples/sec; 0.651 sec/batch)\n",
      "2019-03-16 22:37:05.374093: step 3430, examples 171500, loss = 0.730019689 (79.195 examples/sec; 0.631 sec/batch)\n",
      "2019-03-16 22:37:11.821924: step 3440, examples 172000, loss = 0.692089379 (78.716 examples/sec; 0.635 sec/batch)\n",
      "2019-03-16 22:37:18.347266: step 3450, examples 172500, loss = 0.822084427 (75.068 examples/sec; 0.666 sec/batch)\n",
      "2019-03-16 22:37:24.828313: step 3460, examples 173000, loss = 0.706190884 (75.208 examples/sec; 0.665 sec/batch)\n",
      "2019-03-16 22:37:31.326119: step 3470, examples 173500, loss = 0.681389928 (73.688 examples/sec; 0.679 sec/batch)\n",
      "2019-03-16 22:37:37.950386: step 3480, examples 174000, loss = 0.896983504 (75.076 examples/sec; 0.666 sec/batch)\n",
      "2019-03-16 22:37:44.489416: step 3490, examples 174500, loss = 0.879102349 (77.787 examples/sec; 0.643 sec/batch)\n",
      "2019-03-16 22:37:51.101163: step 3500, examples 175000, loss = 0.747028708 (76.244 examples/sec; 0.656 sec/batch)\n",
      "Top 1 validation accuracy: 0.6603773832321167 and top 2 validation accuracy: 0.823113203048706\n",
      "Model Saved!\n",
      "2019-03-16 22:38:00.422019: step 3510, examples 175500, loss = 0.725858808 (75.252 examples/sec; 0.664 sec/batch)\n",
      "2019-03-16 22:38:06.974557: step 3520, examples 176000, loss = 0.765409768 (76.920 examples/sec; 0.650 sec/batch)\n",
      "2019-03-16 22:38:13.532045: step 3530, examples 176500, loss = 0.727804363 (75.877 examples/sec; 0.659 sec/batch)\n",
      "2019-03-16 22:38:20.025207: step 3540, examples 177000, loss = 0.594145298 (74.319 examples/sec; 0.673 sec/batch)\n",
      "2019-03-16 22:38:26.637275: step 3550, examples 177500, loss = 0.843903065 (77.320 examples/sec; 0.647 sec/batch)\n",
      "2019-03-16 22:38:33.110959: step 3560, examples 178000, loss = 0.592634976 (80.755 examples/sec; 0.619 sec/batch)\n",
      "2019-03-16 22:38:39.695956: step 3570, examples 178500, loss = 0.769792199 (75.595 examples/sec; 0.661 sec/batch)\n",
      "2019-03-16 22:38:46.214889: step 3580, examples 179000, loss = 0.669376671 (77.487 examples/sec; 0.645 sec/batch)\n",
      "2019-03-16 22:38:52.801372: step 3590, examples 179500, loss = 0.692290664 (76.395 examples/sec; 0.654 sec/batch)\n",
      "2019-03-16 22:38:59.422758: step 3600, examples 180000, loss = 0.815071106 (73.262 examples/sec; 0.682 sec/batch)\n",
      "Top 1 validation accuracy: 0.6415094137191772 and top 2 validation accuracy: 0.8301886916160583\n",
      "Model Saved!\n",
      "2019-03-16 22:39:08.658498: step 3610, examples 180500, loss = 0.783872604 (76.541 examples/sec; 0.653 sec/batch)\n",
      "2019-03-16 22:39:15.275613: step 3620, examples 181000, loss = 0.762615860 (76.870 examples/sec; 0.650 sec/batch)\n",
      "2019-03-16 22:39:21.782172: step 3630, examples 181500, loss = 0.871687531 (78.641 examples/sec; 0.636 sec/batch)\n",
      "2019-03-16 22:39:28.275886: step 3640, examples 182000, loss = 0.793724597 (74.786 examples/sec; 0.669 sec/batch)\n",
      "2019-03-16 22:39:34.717455: step 3650, examples 182500, loss = 0.724880040 (78.625 examples/sec; 0.636 sec/batch)\n",
      "2019-03-16 22:39:41.146993: step 3660, examples 183000, loss = 0.801580429 (80.219 examples/sec; 0.623 sec/batch)\n",
      "2019-03-16 22:39:47.717280: step 3670, examples 183500, loss = 0.718553066 (80.582 examples/sec; 0.620 sec/batch)\n",
      "2019-03-16 22:39:54.238123: step 3680, examples 184000, loss = 0.793371975 (76.305 examples/sec; 0.655 sec/batch)\n",
      "2019-03-16 22:40:00.830124: step 3690, examples 184500, loss = 0.711944818 (78.541 examples/sec; 0.637 sec/batch)\n",
      "2019-03-16 22:40:07.407017: step 3700, examples 185000, loss = 0.800923824 (73.770 examples/sec; 0.678 sec/batch)\n",
      "Top 1 validation accuracy: 0.6155660152435303 and top 2 validation accuracy: 0.7995283007621765\n",
      "Model Saved!\n",
      "2019-03-16 22:40:16.642028: step 3710, examples 185500, loss = 0.828945816 (77.247 examples/sec; 0.647 sec/batch)\n",
      "2019-03-16 22:40:23.092734: step 3720, examples 186000, loss = 0.700091779 (75.708 examples/sec; 0.660 sec/batch)\n",
      "2019-03-16 22:40:29.568482: step 3730, examples 186500, loss = 0.596103311 (78.262 examples/sec; 0.639 sec/batch)\n",
      "2019-03-16 22:40:36.115398: step 3740, examples 187000, loss = 0.795381427 (77.244 examples/sec; 0.647 sec/batch)\n",
      "2019-03-16 22:40:42.534872: step 3750, examples 187500, loss = 0.733971238 (75.681 examples/sec; 0.661 sec/batch)\n",
      "2019-03-16 22:40:49.089253: step 3760, examples 188000, loss = 0.757372677 (73.320 examples/sec; 0.682 sec/batch)\n",
      "2019-03-16 22:40:55.531782: step 3770, examples 188500, loss = 0.670794249 (79.116 examples/sec; 0.632 sec/batch)\n",
      "2019-03-16 22:41:02.127329: step 3780, examples 189000, loss = 0.898259521 (73.353 examples/sec; 0.682 sec/batch)\n",
      "2019-03-16 22:41:08.626287: step 3790, examples 189500, loss = 0.642410636 (76.722 examples/sec; 0.652 sec/batch)\n",
      "2019-03-16 22:41:15.146288: step 3800, examples 190000, loss = 0.709115326 (74.399 examples/sec; 0.672 sec/batch)\n",
      "Top 1 validation accuracy: 0.625 and top 2 validation accuracy: 0.8301886916160583\n",
      "Model Saved!\n",
      "2019-03-16 22:41:24.589597: step 3810, examples 190500, loss = 0.773123622 (73.746 examples/sec; 0.678 sec/batch)\n",
      "2019-03-16 22:41:31.146504: step 3820, examples 191000, loss = 0.790319085 (77.477 examples/sec; 0.645 sec/batch)\n",
      "2019-03-16 22:41:37.987776: step 3830, examples 191500, loss = 0.539490104 (71.541 examples/sec; 0.699 sec/batch)\n",
      "2019-03-16 22:41:44.769156: step 3840, examples 192000, loss = 0.643416703 (71.239 examples/sec; 0.702 sec/batch)\n",
      "2019-03-16 22:41:51.736684: step 3850, examples 192500, loss = 0.693617284 (69.842 examples/sec; 0.716 sec/batch)\n",
      "2019-03-16 22:41:58.366839: step 3860, examples 193000, loss = 0.686833203 (77.518 examples/sec; 0.645 sec/batch)\n",
      "2019-03-16 22:42:04.883299: step 3870, examples 193500, loss = 0.797753692 (78.097 examples/sec; 0.640 sec/batch)\n",
      "2019-03-16 22:42:11.357023: step 3880, examples 194000, loss = 0.758281231 (78.511 examples/sec; 0.637 sec/batch)\n",
      "2019-03-16 22:42:17.812776: step 3890, examples 194500, loss = 0.600629032 (79.945 examples/sec; 0.625 sec/batch)\n",
      "2019-03-16 22:42:24.387777: step 3900, examples 195000, loss = 0.684066653 (77.303 examples/sec; 0.647 sec/batch)\n",
      "Top 1 validation accuracy: 0.6462264060974121 and top 2 validation accuracy: 0.8160377144813538\n",
      "Model Saved!\n",
      "2019-03-16 22:42:33.624791: step 3910, examples 195500, loss = 0.660082579 (77.815 examples/sec; 0.643 sec/batch)\n",
      "2019-03-16 22:42:40.242734: step 3920, examples 196000, loss = 0.729713440 (72.467 examples/sec; 0.690 sec/batch)\n",
      "2019-03-16 22:42:46.835909: step 3930, examples 196500, loss = 0.808402061 (72.515 examples/sec; 0.690 sec/batch)\n",
      "2019-03-16 22:42:53.328492: step 3940, examples 197000, loss = 0.606588960 (75.707 examples/sec; 0.660 sec/batch)\n",
      "2019-03-16 22:42:59.843582: step 3950, examples 197500, loss = 0.662711143 (76.918 examples/sec; 0.650 sec/batch)\n",
      "2019-03-16 22:43:06.336504: step 3960, examples 198000, loss = 0.744475007 (80.321 examples/sec; 0.623 sec/batch)\n",
      "2019-03-16 22:43:12.871644: step 3970, examples 198500, loss = 0.657201469 (78.982 examples/sec; 0.633 sec/batch)\n",
      "2019-03-16 22:43:19.323507: step 3980, examples 199000, loss = 0.683624923 (78.080 examples/sec; 0.640 sec/batch)\n",
      "2019-03-16 22:43:25.777695: step 3990, examples 199500, loss = 0.778407872 (77.284 examples/sec; 0.647 sec/batch)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2019-03-16 22:43:32.336663: step 4000, examples 200000, loss = 0.791715622 (77.967 examples/sec; 0.641 sec/batch)\n",
      "Top 1 validation accuracy: 0.5778301954269409 and top 2 validation accuracy: 0.8301886916160583\n",
      "Model Saved!\n",
      "2019-03-16 22:43:41.622826: step 4010, examples 200500, loss = 0.720475554 (79.591 examples/sec; 0.628 sec/batch)\n",
      "2019-03-16 22:43:48.176463: step 4020, examples 201000, loss = 0.729038358 (80.359 examples/sec; 0.622 sec/batch)\n",
      "2019-03-16 22:43:54.696361: step 4030, examples 201500, loss = 0.700341821 (79.503 examples/sec; 0.629 sec/batch)\n",
      "2019-03-16 22:44:01.296869: step 4040, examples 202000, loss = 0.686664939 (79.704 examples/sec; 0.627 sec/batch)\n",
      "2019-03-16 22:44:07.841015: step 4050, examples 202500, loss = 0.717081308 (79.240 examples/sec; 0.631 sec/batch)\n",
      "2019-03-16 22:44:14.351931: step 4060, examples 203000, loss = 0.786885023 (75.470 examples/sec; 0.663 sec/batch)\n",
      "2019-03-16 22:44:20.896439: step 4070, examples 203500, loss = 0.616474390 (78.519 examples/sec; 0.637 sec/batch)\n",
      "2019-03-16 22:44:27.369391: step 4080, examples 204000, loss = 0.821352184 (77.724 examples/sec; 0.643 sec/batch)\n",
      "2019-03-16 22:44:33.974884: step 4090, examples 204500, loss = 0.847766399 (76.434 examples/sec; 0.654 sec/batch)\n",
      "2019-03-16 22:44:40.623464: step 4100, examples 205000, loss = 0.733626783 (77.208 examples/sec; 0.648 sec/batch)\n",
      "Top 1 validation accuracy: 0.6533018946647644 and top 2 validation accuracy: 0.8254716992378235\n",
      "Model Saved!\n",
      "2019-03-16 22:44:49.937755: step 4110, examples 205500, loss = 0.780650616 (76.840 examples/sec; 0.651 sec/batch)\n",
      "2019-03-16 22:44:56.336230: step 4120, examples 206000, loss = 0.850484192 (78.788 examples/sec; 0.635 sec/batch)\n",
      "2019-03-16 22:45:02.789261: step 4130, examples 206500, loss = 0.752550781 (77.489 examples/sec; 0.645 sec/batch)\n",
      "2019-03-16 22:45:09.308673: step 4140, examples 207000, loss = 0.747125328 (78.597 examples/sec; 0.636 sec/batch)\n",
      "2019-03-16 22:45:15.752817: step 4150, examples 207500, loss = 0.950864017 (76.364 examples/sec; 0.655 sec/batch)\n",
      "2019-03-16 22:45:22.295323: step 4160, examples 208000, loss = 0.699767172 (77.117 examples/sec; 0.648 sec/batch)\n",
      "2019-03-16 22:45:28.729695: step 4170, examples 208500, loss = 0.767219722 (78.972 examples/sec; 0.633 sec/batch)\n",
      "2019-03-16 22:45:35.230738: step 4180, examples 209000, loss = 0.702034175 (72.067 examples/sec; 0.694 sec/batch)\n",
      "2019-03-16 22:45:41.799441: step 4190, examples 209500, loss = 0.743465126 (76.153 examples/sec; 0.657 sec/batch)\n",
      "2019-03-16 22:45:48.321507: step 4200, examples 210000, loss = 0.530821145 (76.133 examples/sec; 0.657 sec/batch)\n",
      "Top 1 validation accuracy: 0.6367924809455872 and top 2 validation accuracy: 0.823113203048706\n",
      "Model Saved!\n",
      "2019-03-16 22:45:57.537313: step 4210, examples 210500, loss = 0.650336385 (80.617 examples/sec; 0.620 sec/batch)\n",
      "2019-03-16 22:46:04.098701: step 4220, examples 211000, loss = 0.695938408 (76.510 examples/sec; 0.654 sec/batch)\n",
      "2019-03-16 22:46:10.575921: step 4230, examples 211500, loss = 0.760433495 (76.966 examples/sec; 0.650 sec/batch)\n",
      "2019-03-16 22:46:17.039440: step 4240, examples 212000, loss = 0.642424166 (78.135 examples/sec; 0.640 sec/batch)\n",
      "2019-03-16 22:46:23.602508: step 4250, examples 212500, loss = 0.813480258 (73.404 examples/sec; 0.681 sec/batch)\n",
      "2019-03-16 22:46:30.028431: step 4260, examples 213000, loss = 0.584815145 (78.866 examples/sec; 0.634 sec/batch)\n",
      "2019-03-16 22:46:36.512928: step 4270, examples 213500, loss = 0.805295646 (77.795 examples/sec; 0.643 sec/batch)\n",
      "2019-03-16 22:46:43.003161: step 4280, examples 214000, loss = 0.783730030 (79.071 examples/sec; 0.632 sec/batch)\n",
      "2019-03-16 22:46:49.527308: step 4290, examples 214500, loss = 0.748009443 (73.543 examples/sec; 0.680 sec/batch)\n",
      "2019-03-16 22:46:56.010275: step 4300, examples 215000, loss = 0.769419014 (75.966 examples/sec; 0.658 sec/batch)\n",
      "Top 1 validation accuracy: 0.6367924809455872 and top 2 validation accuracy: 0.823113203048706\n",
      "Model Saved!\n",
      "2019-03-16 22:47:05.221385: step 4310, examples 215500, loss = 0.845787823 (76.001 examples/sec; 0.658 sec/batch)\n",
      "2019-03-16 22:47:11.819627: step 4320, examples 216000, loss = 0.776555181 (70.360 examples/sec; 0.711 sec/batch)\n",
      "2019-03-16 22:47:18.297630: step 4330, examples 216500, loss = 0.617283046 (76.737 examples/sec; 0.652 sec/batch)\n",
      "2019-03-16 22:47:24.780554: step 4340, examples 217000, loss = 0.685928464 (78.076 examples/sec; 0.640 sec/batch)\n",
      "2019-03-16 22:47:31.336930: step 4350, examples 217500, loss = 0.777144551 (74.981 examples/sec; 0.667 sec/batch)\n",
      "2019-03-16 22:47:37.805615: step 4360, examples 218000, loss = 0.616687179 (77.850 examples/sec; 0.642 sec/batch)\n",
      "2019-03-16 22:47:44.351765: step 4370, examples 218500, loss = 0.595404625 (75.322 examples/sec; 0.664 sec/batch)\n",
      "2019-03-16 22:47:50.859214: step 4380, examples 219000, loss = 0.860231042 (75.222 examples/sec; 0.665 sec/batch)\n",
      "2019-03-16 22:47:57.358965: step 4390, examples 219500, loss = 0.793403327 (76.447 examples/sec; 0.654 sec/batch)\n",
      "2019-03-16 22:48:03.914844: step 4400, examples 220000, loss = 0.816645265 (79.924 examples/sec; 0.626 sec/batch)\n",
      "Top 1 validation accuracy: 0.6320754885673523 and top 2 validation accuracy: 0.8372641801834106\n",
      "Model Saved!\n",
      "2019-03-16 22:48:13.150821: step 4410, examples 220500, loss = 0.655130982 (77.045 examples/sec; 0.649 sec/batch)\n",
      "2019-03-16 22:48:19.678290: step 4420, examples 221000, loss = 0.675967574 (74.387 examples/sec; 0.672 sec/batch)\n",
      "2019-03-16 22:48:26.132277: step 4430, examples 221500, loss = 0.861024261 (76.584 examples/sec; 0.653 sec/batch)\n",
      "2019-03-16 22:48:32.710384: step 4440, examples 222000, loss = 0.726957440 (78.547 examples/sec; 0.637 sec/batch)\n",
      "2019-03-16 22:48:39.193508: step 4450, examples 222500, loss = 0.659895301 (78.854 examples/sec; 0.634 sec/batch)\n",
      "2019-03-16 22:48:45.746267: step 4460, examples 223000, loss = 0.615013301 (77.141 examples/sec; 0.648 sec/batch)\n",
      "2019-03-16 22:48:52.288241: step 4470, examples 223500, loss = 0.696093798 (76.301 examples/sec; 0.655 sec/batch)\n",
      "2019-03-16 22:48:58.675982: step 4480, examples 224000, loss = 0.869880557 (77.868 examples/sec; 0.642 sec/batch)\n",
      "2019-03-16 22:49:05.198158: step 4490, examples 224500, loss = 0.638284802 (78.011 examples/sec; 0.641 sec/batch)\n",
      "2019-03-16 22:49:11.711781: step 4500, examples 225000, loss = 0.656147838 (79.959 examples/sec; 0.625 sec/batch)\n",
      "Top 1 validation accuracy: 0.6132075190544128 and top 2 validation accuracy: 0.7948113083839417\n",
      "Model Saved!\n",
      "2019-03-16 22:49:21.086560: step 4510, examples 225500, loss = 0.658615470 (77.932 examples/sec; 0.642 sec/batch)\n",
      "2019-03-16 22:49:27.555010: step 4520, examples 226000, loss = 0.821190834 (76.313 examples/sec; 0.655 sec/batch)\n",
      "2019-03-16 22:49:34.060877: step 4530, examples 226500, loss = 0.727285385 (75.862 examples/sec; 0.659 sec/batch)\n",
      "2019-03-16 22:49:40.648119: step 4540, examples 227000, loss = 0.594165981 (77.458 examples/sec; 0.646 sec/batch)\n",
      "2019-03-16 22:49:47.146934: step 4550, examples 227500, loss = 0.632215202 (76.974 examples/sec; 0.650 sec/batch)\n",
      "2019-03-16 22:49:53.641302: step 4560, examples 228000, loss = 0.619307160 (76.812 examples/sec; 0.651 sec/batch)\n",
      "2019-03-16 22:50:00.007419: step 4570, examples 228500, loss = 0.688173532 (78.721 examples/sec; 0.635 sec/batch)\n",
      "2019-03-16 22:50:06.444748: step 4580, examples 229000, loss = 0.654089451 (76.796 examples/sec; 0.651 sec/batch)\n",
      "2019-03-16 22:50:12.916489: step 4590, examples 229500, loss = 0.793747604 (83.934 examples/sec; 0.596 sec/batch)\n",
      "2019-03-16 22:50:19.404791: step 4600, examples 230000, loss = 0.770984590 (77.345 examples/sec; 0.646 sec/batch)\n",
      "Top 1 validation accuracy: 0.6108490824699402 and top 2 validation accuracy: 0.8136792182922363\n",
      "Model Saved!\n",
      "2019-03-16 22:50:28.693561: step 4610, examples 230500, loss = 0.696308017 (73.978 examples/sec; 0.676 sec/batch)\n",
      "2019-03-16 22:50:35.209660: step 4620, examples 231000, loss = 0.640775561 (76.086 examples/sec; 0.657 sec/batch)\n",
      "2019-03-16 22:50:41.700065: step 4630, examples 231500, loss = 0.746950090 (79.459 examples/sec; 0.629 sec/batch)\n",
      "2019-03-16 22:50:48.195727: step 4640, examples 232000, loss = 0.646071732 (75.712 examples/sec; 0.660 sec/batch)\n",
      "2019-03-16 22:50:54.764553: step 4650, examples 232500, loss = 0.581847072 (75.488 examples/sec; 0.662 sec/batch)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2019-03-16 22:51:01.401269: step 4660, examples 233000, loss = 0.632461786 (76.927 examples/sec; 0.650 sec/batch)\n",
      "2019-03-16 22:51:07.931217: step 4670, examples 233500, loss = 0.746389508 (75.547 examples/sec; 0.662 sec/batch)\n",
      "2019-03-16 22:51:14.403133: step 4680, examples 234000, loss = 0.627844989 (77.882 examples/sec; 0.642 sec/batch)\n",
      "2019-03-16 22:51:20.934428: step 4690, examples 234500, loss = 0.757125378 (78.845 examples/sec; 0.634 sec/batch)\n",
      "2019-03-16 22:51:27.552825: step 4700, examples 235000, loss = 0.559451222 (74.339 examples/sec; 0.673 sec/batch)\n",
      "Top 1 validation accuracy: 0.6132075190544128 and top 2 validation accuracy: 0.823113203048706\n",
      "Model Saved!\n",
      "2019-03-16 22:51:36.604647: step 4710, examples 235500, loss = 0.683856487 (75.823 examples/sec; 0.659 sec/batch)\n",
      "2019-03-16 22:51:43.133232: step 4720, examples 236000, loss = 0.560345352 (74.884 examples/sec; 0.668 sec/batch)\n",
      "2019-03-16 22:51:49.721199: step 4730, examples 236500, loss = 0.769383907 (76.115 examples/sec; 0.657 sec/batch)\n",
      "2019-03-16 22:51:56.231844: step 4740, examples 237000, loss = 0.883458316 (76.404 examples/sec; 0.654 sec/batch)\n",
      "2019-03-16 22:52:02.802621: step 4750, examples 237500, loss = 0.909875095 (74.769 examples/sec; 0.669 sec/batch)\n",
      "2019-03-16 22:52:09.336051: step 4760, examples 238000, loss = 0.642792821 (76.719 examples/sec; 0.652 sec/batch)\n",
      "2019-03-16 22:52:15.900059: step 4770, examples 238500, loss = 0.773422539 (74.781 examples/sec; 0.669 sec/batch)\n",
      "2019-03-16 22:52:22.387878: step 4780, examples 239000, loss = 0.741930306 (77.283 examples/sec; 0.647 sec/batch)\n",
      "2019-03-16 22:52:28.724605: step 4790, examples 239500, loss = 0.633039355 (78.294 examples/sec; 0.639 sec/batch)\n",
      "2019-03-16 22:52:35.258709: step 4800, examples 240000, loss = 0.637021184 (79.031 examples/sec; 0.633 sec/batch)\n",
      "Top 1 validation accuracy: 0.6084905862808228 and top 2 validation accuracy: 0.8136792182922363\n",
      "Model Saved!\n",
      "2019-03-16 22:52:44.553018: step 4810, examples 240500, loss = 0.555367827 (78.618 examples/sec; 0.636 sec/batch)\n",
      "2019-03-16 22:52:51.103213: step 4820, examples 241000, loss = 0.724608779 (80.848 examples/sec; 0.618 sec/batch)\n",
      "2019-03-16 22:52:57.626325: step 4830, examples 241500, loss = 0.693913937 (73.795 examples/sec; 0.678 sec/batch)\n",
      "2019-03-16 22:53:04.174676: step 4840, examples 242000, loss = 0.572153866 (73.876 examples/sec; 0.677 sec/batch)\n",
      "2019-03-16 22:53:10.668842: step 4850, examples 242500, loss = 0.558335602 (76.044 examples/sec; 0.658 sec/batch)\n",
      "2019-03-16 22:53:17.178407: step 4860, examples 243000, loss = 0.779559314 (78.024 examples/sec; 0.641 sec/batch)\n",
      "2019-03-16 22:53:23.856055: step 4870, examples 243500, loss = 0.682077110 (78.888 examples/sec; 0.634 sec/batch)\n",
      "2019-03-16 22:53:30.367517: step 4880, examples 244000, loss = 0.817737281 (76.334 examples/sec; 0.655 sec/batch)\n",
      "2019-03-16 22:53:36.832499: step 4890, examples 244500, loss = 0.577581108 (77.829 examples/sec; 0.642 sec/batch)\n",
      "2019-03-16 22:53:43.299680: step 4900, examples 245000, loss = 0.678742766 (75.362 examples/sec; 0.663 sec/batch)\n",
      "Top 1 validation accuracy: 0.6132075190544128 and top 2 validation accuracy: 0.8183962106704712\n",
      "Model Saved!\n",
      "2019-03-16 22:53:52.567670: step 4910, examples 245500, loss = 0.722081780 (77.046 examples/sec; 0.649 sec/batch)\n",
      "2019-03-16 22:53:59.088433: step 4920, examples 246000, loss = 0.724476695 (75.496 examples/sec; 0.662 sec/batch)\n",
      "2019-03-16 22:54:05.537660: step 4930, examples 246500, loss = 0.688918948 (77.623 examples/sec; 0.644 sec/batch)\n",
      "2019-03-16 22:54:12.002683: step 4940, examples 247000, loss = 0.680938840 (79.186 examples/sec; 0.631 sec/batch)\n",
      "2019-03-16 22:54:18.491758: step 4950, examples 247500, loss = 0.607370257 (75.731 examples/sec; 0.660 sec/batch)\n",
      "2019-03-16 22:54:25.096872: step 4960, examples 248000, loss = 0.851728618 (76.145 examples/sec; 0.657 sec/batch)\n",
      "2019-03-16 22:54:31.633510: step 4970, examples 248500, loss = 0.656988561 (78.550 examples/sec; 0.637 sec/batch)\n",
      "2019-03-16 22:54:38.146224: step 4980, examples 249000, loss = 0.698814332 (76.691 examples/sec; 0.652 sec/batch)\n",
      "2019-03-16 22:54:44.633621: step 4990, examples 249500, loss = 0.710309625 (77.079 examples/sec; 0.649 sec/batch)\n",
      "Top 1 validation accuracy: 0.6132075190544128 and top 2 validation accuracy: 0.8207547068595886\n",
      "Model Saved!\n",
      "Loading datasets...\n",
      "Dataset loading completes.\n",
      "2019-03-16 22:54:56.537087: step 0, examples 0, loss = 1.418631554 (71.198 examples/sec; 0.702 sec/batch)\n",
      "Top 1 validation accuracy: 0.275943398475647 and top 2 validation accuracy: 0.49056604504585266\n",
      "Model Saved!\n",
      "2019-03-16 22:55:02.614142: step 10, examples 500, loss = 1.416856766 (133.696 examples/sec; 0.374 sec/batch)\n",
      "2019-03-16 22:55:06.517416: step 20, examples 1000, loss = 1.409419060 (123.347 examples/sec; 0.405 sec/batch)\n",
      "2019-03-16 22:55:10.359057: step 30, examples 1500, loss = 1.416578770 (130.079 examples/sec; 0.384 sec/batch)\n",
      "2019-03-16 22:55:14.336394: step 40, examples 2000, loss = 1.434986234 (132.461 examples/sec; 0.377 sec/batch)\n",
      "2019-03-16 22:55:18.238615: step 50, examples 2500, loss = 1.351630211 (124.007 examples/sec; 0.403 sec/batch)\n",
      "2019-03-16 22:55:22.132431: step 60, examples 3000, loss = 1.361942410 (129.864 examples/sec; 0.385 sec/batch)\n",
      "2019-03-16 22:55:26.073685: step 70, examples 3500, loss = 1.359528065 (122.118 examples/sec; 0.409 sec/batch)\n",
      "2019-03-16 22:55:30.017564: step 80, examples 4000, loss = 1.370439887 (127.987 examples/sec; 0.391 sec/batch)\n",
      "2019-03-16 22:55:33.912107: step 90, examples 4500, loss = 1.371302247 (131.890 examples/sec; 0.379 sec/batch)\n",
      "2019-03-16 22:55:37.760693: step 100, examples 5000, loss = 1.278590083 (127.210 examples/sec; 0.393 sec/batch)\n",
      "Top 1 validation accuracy: 0.3042452931404114 and top 2 validation accuracy: 0.5754716992378235\n",
      "Model Saved!\n",
      "2019-03-16 22:55:43.850329: step 110, examples 5500, loss = 1.388764977 (126.964 examples/sec; 0.394 sec/batch)\n",
      "2019-03-16 22:55:47.700713: step 120, examples 6000, loss = 1.323157310 (135.489 examples/sec; 0.369 sec/batch)\n",
      "2019-03-16 22:55:51.583307: step 130, examples 6500, loss = 1.350655675 (125.779 examples/sec; 0.398 sec/batch)\n",
      "2019-03-16 22:55:55.425349: step 140, examples 7000, loss = 1.324853420 (131.673 examples/sec; 0.380 sec/batch)\n",
      "2019-03-16 22:55:59.336207: step 150, examples 7500, loss = 1.241609454 (115.398 examples/sec; 0.433 sec/batch)\n",
      "2019-03-16 22:56:03.238166: step 160, examples 8000, loss = 1.335948944 (128.827 examples/sec; 0.388 sec/batch)\n",
      "2019-03-16 22:56:07.098206: step 170, examples 8500, loss = 1.324673653 (130.140 examples/sec; 0.384 sec/batch)\n",
      "2019-03-16 22:56:10.963789: step 180, examples 9000, loss = 1.260513663 (133.319 examples/sec; 0.375 sec/batch)\n",
      "2019-03-16 22:56:14.824700: step 190, examples 9500, loss = 1.320420742 (129.443 examples/sec; 0.386 sec/batch)\n",
      "2019-03-16 22:56:18.748499: step 200, examples 10000, loss = 1.248792052 (121.299 examples/sec; 0.412 sec/batch)\n",
      "Top 1 validation accuracy: 0.3891509473323822 and top 2 validation accuracy: 0.6698113083839417\n",
      "Model Saved!\n",
      "2019-03-16 22:56:24.872420: step 210, examples 10500, loss = 1.442672849 (132.844 examples/sec; 0.376 sec/batch)\n",
      "2019-03-16 22:56:28.728194: step 220, examples 11000, loss = 1.190783978 (128.798 examples/sec; 0.388 sec/batch)\n",
      "2019-03-16 22:56:32.648979: step 230, examples 11500, loss = 1.149345279 (128.636 examples/sec; 0.389 sec/batch)\n",
      "2019-03-16 22:56:36.491843: step 240, examples 12000, loss = 1.257341981 (138.100 examples/sec; 0.362 sec/batch)\n",
      "2019-03-16 22:56:40.447913: step 250, examples 12500, loss = 1.252462506 (127.103 examples/sec; 0.393 sec/batch)\n",
      "2019-03-16 22:56:44.388375: step 260, examples 13000, loss = 1.276314259 (125.647 examples/sec; 0.398 sec/batch)\n",
      "2019-03-16 22:56:48.322465: step 270, examples 13500, loss = 1.114893198 (122.388 examples/sec; 0.409 sec/batch)\n",
      "2019-03-16 22:56:52.238038: step 280, examples 14000, loss = 1.148117423 (133.358 examples/sec; 0.375 sec/batch)\n",
      "2019-03-16 22:56:56.069564: step 290, examples 14500, loss = 1.181441188 (126.634 examples/sec; 0.395 sec/batch)\n",
      "2019-03-16 22:56:59.928677: step 300, examples 15000, loss = 1.257020354 (133.336 examples/sec; 0.375 sec/batch)\n",
      "Top 1 validation accuracy: 0.4316037595272064 and top 2 validation accuracy: 0.6957547068595886\n",
      "Model Saved!\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2019-03-16 22:57:06.018573: step 310, examples 15500, loss = 1.159198761 (133.319 examples/sec; 0.375 sec/batch)\n",
      "2019-03-16 22:57:09.927568: step 320, examples 16000, loss = 1.219865322 (127.321 examples/sec; 0.393 sec/batch)\n",
      "2019-03-16 22:57:13.787266: step 330, examples 16500, loss = 1.093982816 (130.529 examples/sec; 0.383 sec/batch)\n",
      "2019-03-16 22:57:17.602696: step 340, examples 17000, loss = 1.257836223 (133.316 examples/sec; 0.375 sec/batch)\n",
      "2019-03-16 22:57:21.537277: step 350, examples 17500, loss = 1.252784133 (126.566 examples/sec; 0.395 sec/batch)\n",
      "2019-03-16 22:57:25.444972: step 360, examples 18000, loss = 1.154241443 (123.991 examples/sec; 0.403 sec/batch)\n",
      "2019-03-16 22:57:29.285905: step 370, examples 18500, loss = 1.046567202 (121.084 examples/sec; 0.413 sec/batch)\n",
      "2019-03-16 22:57:33.161639: step 380, examples 19000, loss = 1.314674377 (134.521 examples/sec; 0.372 sec/batch)\n",
      "2019-03-16 22:57:37.037537: step 390, examples 19500, loss = 1.149490833 (133.319 examples/sec; 0.375 sec/batch)\n",
      "2019-03-16 22:57:40.901841: step 400, examples 20000, loss = 1.320333838 (130.870 examples/sec; 0.382 sec/batch)\n",
      "Top 1 validation accuracy: 0.5 and top 2 validation accuracy: 0.7311320900917053\n",
      "Model Saved!\n",
      "2019-03-16 22:57:47.115136: step 410, examples 20500, loss = 1.146655560 (133.902 examples/sec; 0.373 sec/batch)\n",
      "2019-03-16 22:57:50.990813: step 420, examples 21000, loss = 1.098272681 (123.064 examples/sec; 0.406 sec/batch)\n",
      "2019-03-16 22:57:54.881497: step 430, examples 21500, loss = 1.193456650 (137.401 examples/sec; 0.364 sec/batch)\n",
      "2019-03-16 22:57:58.818743: step 440, examples 22000, loss = 1.324786305 (133.817 examples/sec; 0.374 sec/batch)\n",
      "2019-03-16 22:58:02.706418: step 450, examples 22500, loss = 0.951628447 (134.749 examples/sec; 0.371 sec/batch)\n",
      "2019-03-16 22:58:06.575934: step 460, examples 23000, loss = 1.150072098 (129.952 examples/sec; 0.385 sec/batch)\n",
      "2019-03-16 22:58:10.573998: step 470, examples 23500, loss = 1.181775689 (126.872 examples/sec; 0.394 sec/batch)\n",
      "2019-03-16 22:58:14.430590: step 480, examples 24000, loss = 1.125824332 (128.030 examples/sec; 0.391 sec/batch)\n",
      "2019-03-16 22:58:18.291163: step 490, examples 24500, loss = 1.049879193 (126.497 examples/sec; 0.395 sec/batch)\n",
      "2019-03-16 22:58:22.159462: step 500, examples 25000, loss = 1.181531668 (124.201 examples/sec; 0.403 sec/batch)\n",
      "Top 1 validation accuracy: 0.5212264060974121 and top 2 validation accuracy: 0.7452830076217651\n",
      "Model Saved!\n",
      "2019-03-16 22:58:28.238431: step 510, examples 25500, loss = 1.249595761 (129.436 examples/sec; 0.386 sec/batch)\n",
      "2019-03-16 22:58:32.136056: step 520, examples 26000, loss = 1.126983523 (125.131 examples/sec; 0.400 sec/batch)\n",
      "2019-03-16 22:58:36.013224: step 530, examples 26500, loss = 1.158051372 (127.986 examples/sec; 0.391 sec/batch)\n",
      "2019-03-16 22:58:39.970576: step 540, examples 27000, loss = 1.022033095 (133.319 examples/sec; 0.375 sec/batch)\n",
      "2019-03-16 22:58:43.834721: step 550, examples 27500, loss = 1.075833917 (133.697 examples/sec; 0.374 sec/batch)\n",
      "2019-03-16 22:58:47.679272: step 560, examples 28000, loss = 1.133158684 (124.740 examples/sec; 0.401 sec/batch)\n",
      "2019-03-16 22:58:51.602578: step 570, examples 28500, loss = 1.241224170 (125.400 examples/sec; 0.399 sec/batch)\n",
      "2019-03-16 22:58:55.479566: step 580, examples 29000, loss = 1.042982101 (121.937 examples/sec; 0.410 sec/batch)\n",
      "2019-03-16 22:58:59.388563: step 590, examples 29500, loss = 0.973034561 (126.569 examples/sec; 0.395 sec/batch)\n",
      "2019-03-16 22:59:03.274926: step 600, examples 30000, loss = 0.888346434 (128.653 examples/sec; 0.389 sec/batch)\n",
      "Top 1 validation accuracy: 0.5353773832321167 and top 2 validation accuracy: 0.7641509175300598\n",
      "Model Saved!\n",
      "2019-03-16 22:59:09.336992: step 610, examples 30500, loss = 1.093219638 (129.516 examples/sec; 0.386 sec/batch)\n",
      "2019-03-16 22:59:13.285981: step 620, examples 31000, loss = 1.148232698 (128.422 examples/sec; 0.389 sec/batch)\n",
      "2019-03-16 22:59:17.180609: step 630, examples 31500, loss = 1.057653069 (123.164 examples/sec; 0.406 sec/batch)\n",
      "2019-03-16 22:59:21.052378: step 640, examples 32000, loss = 1.113384247 (127.988 examples/sec; 0.391 sec/batch)\n",
      "2019-03-16 22:59:24.991839: step 650, examples 32500, loss = 1.065561652 (127.987 examples/sec; 0.391 sec/batch)\n",
      "2019-03-16 22:59:28.901841: step 660, examples 33000, loss = 1.052861333 (131.976 examples/sec; 0.379 sec/batch)\n",
      "2019-03-16 22:59:32.765958: step 670, examples 33500, loss = 1.149316788 (124.370 examples/sec; 0.402 sec/batch)\n",
      "2019-03-16 22:59:36.716511: step 680, examples 34000, loss = 0.961466014 (123.271 examples/sec; 0.406 sec/batch)\n",
      "2019-03-16 22:59:40.627989: step 690, examples 34500, loss = 0.895168126 (130.996 examples/sec; 0.382 sec/batch)\n",
      "2019-03-16 22:59:44.637075: step 700, examples 35000, loss = 1.102609754 (130.004 examples/sec; 0.385 sec/batch)\n",
      "Top 1 validation accuracy: 0.5023584961891174 and top 2 validation accuracy: 0.7311320900917053\n",
      "Model Saved!\n",
      "2019-03-16 22:59:50.882363: step 710, examples 35500, loss = 1.101696968 (128.009 examples/sec; 0.391 sec/batch)\n",
      "2019-03-16 22:59:54.679337: step 720, examples 36000, loss = 1.061755061 (131.862 examples/sec; 0.379 sec/batch)\n",
      "2019-03-16 22:59:58.673254: step 730, examples 36500, loss = 1.315968394 (123.532 examples/sec; 0.405 sec/batch)\n",
      "2019-03-16 23:00:02.600930: step 740, examples 37000, loss = 1.095075011 (134.889 examples/sec; 0.371 sec/batch)\n",
      "2019-03-16 23:00:06.483760: step 750, examples 37500, loss = 0.953626931 (134.712 examples/sec; 0.371 sec/batch)\n",
      "2019-03-16 23:00:10.367451: step 760, examples 38000, loss = 0.976944029 (118.087 examples/sec; 0.423 sec/batch)\n",
      "2019-03-16 23:00:14.226137: step 770, examples 38500, loss = 1.138675213 (127.797 examples/sec; 0.391 sec/batch)\n",
      "2019-03-16 23:00:18.162501: step 780, examples 39000, loss = 1.010686517 (127.846 examples/sec; 0.391 sec/batch)\n",
      "2019-03-16 23:00:22.022031: step 790, examples 39500, loss = 1.028385282 (133.318 examples/sec; 0.375 sec/batch)\n",
      "2019-03-16 23:00:25.867815: step 800, examples 40000, loss = 1.010345817 (130.095 examples/sec; 0.384 sec/batch)\n",
      "Top 1 validation accuracy: 0.5613207817077637 and top 2 validation accuracy: 0.75\n",
      "Model Saved!\n",
      "2019-03-16 23:00:32.001991: step 810, examples 40500, loss = 1.071379662 (123.064 examples/sec; 0.406 sec/batch)\n",
      "2019-03-16 23:00:35.896972: step 820, examples 41000, loss = 1.074949265 (131.773 examples/sec; 0.379 sec/batch)\n",
      "2019-03-16 23:00:39.727926: step 830, examples 41500, loss = 1.154586434 (127.622 examples/sec; 0.392 sec/batch)\n",
      "2019-03-16 23:00:43.593273: step 840, examples 42000, loss = 1.230655670 (125.027 examples/sec; 0.400 sec/batch)\n",
      "2019-03-16 23:00:47.498900: step 850, examples 42500, loss = 0.971906662 (124.530 examples/sec; 0.402 sec/batch)\n",
      "2019-03-16 23:00:51.375747: step 860, examples 43000, loss = 0.952992618 (127.723 examples/sec; 0.391 sec/batch)\n",
      "2019-03-16 23:00:55.261143: step 870, examples 43500, loss = 1.157843232 (126.568 examples/sec; 0.395 sec/batch)\n",
      "2019-03-16 23:00:59.099020: step 880, examples 44000, loss = 0.933656216 (129.980 examples/sec; 0.385 sec/batch)\n",
      "2019-03-16 23:01:03.014950: step 890, examples 44500, loss = 1.092014909 (123.064 examples/sec; 0.406 sec/batch)\n",
      "2019-03-16 23:01:06.941860: step 900, examples 45000, loss = 1.088441014 (131.363 examples/sec; 0.381 sec/batch)\n",
      "Top 1 validation accuracy: 0.5919811129570007 and top 2 validation accuracy: 0.7853773832321167\n",
      "Model Saved!\n",
      "2019-03-16 23:01:13.084433: step 910, examples 45500, loss = 1.020474553 (124.593 examples/sec; 0.401 sec/batch)\n",
      "2019-03-16 23:01:16.941985: step 920, examples 46000, loss = 0.961302936 (128.593 examples/sec; 0.389 sec/batch)\n",
      "2019-03-16 23:01:20.834245: step 930, examples 46500, loss = 1.063557029 (128.425 examples/sec; 0.389 sec/batch)\n",
      "2019-03-16 23:01:24.714338: step 940, examples 47000, loss = 0.906233132 (131.870 examples/sec; 0.379 sec/batch)\n",
      "2019-03-16 23:01:28.598478: step 950, examples 47500, loss = 0.906195879 (128.438 examples/sec; 0.389 sec/batch)\n",
      "2019-03-16 23:01:32.492531: step 960, examples 48000, loss = 1.206534624 (126.523 examples/sec; 0.395 sec/batch)\n",
      "2019-03-16 23:01:36.444732: step 970, examples 48500, loss = 0.986633301 (133.022 examples/sec; 0.376 sec/batch)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2019-03-16 23:01:40.368217: step 980, examples 49000, loss = 1.009369254 (132.779 examples/sec; 0.377 sec/batch)\n",
      "2019-03-16 23:01:44.352067: step 990, examples 49500, loss = 0.913653672 (121.612 examples/sec; 0.411 sec/batch)\n",
      "2019-03-16 23:01:48.253990: step 1000, examples 50000, loss = 1.083810806 (128.263 examples/sec; 0.390 sec/batch)\n",
      "Top 1 validation accuracy: 0.5943396091461182 and top 2 validation accuracy: 0.7924528121948242\n",
      "Model Saved!\n",
      "2019-03-16 23:01:54.367354: step 1010, examples 50500, loss = 0.800195754 (128.226 examples/sec; 0.390 sec/batch)\n",
      "2019-03-16 23:01:58.269493: step 1020, examples 51000, loss = 1.096339822 (123.979 examples/sec; 0.403 sec/batch)\n",
      "2019-03-16 23:02:02.161654: step 1030, examples 51500, loss = 0.975665510 (129.563 examples/sec; 0.386 sec/batch)\n",
      "2019-03-16 23:02:06.007595: step 1040, examples 52000, loss = 0.931108534 (133.319 examples/sec; 0.375 sec/batch)\n",
      "2019-03-16 23:02:09.974749: step 1050, examples 52500, loss = 0.823410213 (127.987 examples/sec; 0.391 sec/batch)\n",
      "2019-03-16 23:02:13.843491: step 1060, examples 53000, loss = 1.034881473 (125.500 examples/sec; 0.398 sec/batch)\n",
      "2019-03-16 23:02:17.705405: step 1070, examples 53500, loss = 1.013773084 (135.654 examples/sec; 0.369 sec/batch)\n",
      "2019-03-16 23:02:21.625161: step 1080, examples 54000, loss = 0.841679752 (130.331 examples/sec; 0.384 sec/batch)\n",
      "2019-03-16 23:02:25.553494: step 1090, examples 54500, loss = 0.911761820 (133.023 examples/sec; 0.376 sec/batch)\n",
      "2019-03-16 23:02:29.415429: step 1100, examples 55000, loss = 0.913488448 (122.098 examples/sec; 0.410 sec/batch)\n",
      "Top 1 validation accuracy: 0.5566037893295288 and top 2 validation accuracy: 0.7924528121948242\n",
      "Model Saved!\n",
      "2019-03-16 23:02:35.638015: step 1110, examples 55500, loss = 0.963954985 (128.357 examples/sec; 0.390 sec/batch)\n",
      "2019-03-16 23:02:39.613970: step 1120, examples 56000, loss = 1.029655337 (118.792 examples/sec; 0.421 sec/batch)\n",
      "2019-03-16 23:02:43.537183: step 1130, examples 56500, loss = 1.001788616 (127.975 examples/sec; 0.391 sec/batch)\n",
      "2019-03-16 23:02:47.421683: step 1140, examples 57000, loss = 1.046545506 (128.873 examples/sec; 0.388 sec/batch)\n",
      "2019-03-16 23:02:51.259868: step 1150, examples 57500, loss = 1.035806775 (127.413 examples/sec; 0.392 sec/batch)\n",
      "2019-03-16 23:02:55.146535: step 1160, examples 58000, loss = 1.009678960 (120.442 examples/sec; 0.415 sec/batch)\n",
      "2019-03-16 23:02:59.052578: step 1170, examples 58500, loss = 1.001890540 (133.319 examples/sec; 0.375 sec/batch)\n",
      "2019-03-16 23:03:02.967079: step 1180, examples 59000, loss = 0.751974761 (129.152 examples/sec; 0.387 sec/batch)\n",
      "2019-03-16 23:03:06.840778: step 1190, examples 59500, loss = 1.029021263 (126.457 examples/sec; 0.395 sec/batch)\n",
      "2019-03-16 23:03:10.684519: step 1200, examples 60000, loss = 0.845392942 (129.577 examples/sec; 0.386 sec/batch)\n",
      "Top 1 validation accuracy: 0.5707547068595886 and top 2 validation accuracy: 0.7665094137191772\n",
      "Model Saved!\n",
      "2019-03-16 23:03:16.757151: step 1210, examples 60500, loss = 0.986283064 (133.740 examples/sec; 0.374 sec/batch)\n",
      "2019-03-16 23:03:20.599271: step 1220, examples 61000, loss = 1.127413273 (139.981 examples/sec; 0.357 sec/batch)\n",
      "2019-03-16 23:03:24.476218: step 1230, examples 61500, loss = 0.951915920 (133.984 examples/sec; 0.373 sec/batch)\n",
      "2019-03-16 23:03:28.351990: step 1240, examples 62000, loss = 1.134287357 (127.509 examples/sec; 0.392 sec/batch)\n",
      "2019-03-16 23:03:32.325727: step 1250, examples 62500, loss = 1.072325826 (121.766 examples/sec; 0.411 sec/batch)\n",
      "2019-03-16 23:03:36.268597: step 1260, examples 63000, loss = 1.025683522 (128.972 examples/sec; 0.388 sec/batch)\n",
      "2019-03-16 23:03:40.163118: step 1270, examples 63500, loss = 0.838994741 (124.529 examples/sec; 0.402 sec/batch)\n",
      "2019-03-16 23:03:44.191814: step 1280, examples 64000, loss = 0.966718972 (119.707 examples/sec; 0.418 sec/batch)\n",
      "2019-03-16 23:03:48.024118: step 1290, examples 64500, loss = 1.019351363 (133.319 examples/sec; 0.375 sec/batch)\n",
      "2019-03-16 23:03:51.881985: step 1300, examples 65000, loss = 1.115694165 (125.047 examples/sec; 0.400 sec/batch)\n",
      "Top 1 validation accuracy: 0.5825471878051758 and top 2 validation accuracy: 0.7900943160057068\n",
      "Model Saved!\n",
      "2019-03-16 23:03:57.837479: step 1310, examples 65500, loss = 0.923352897 (132.678 examples/sec; 0.377 sec/batch)\n",
      "2019-03-16 23:04:01.818364: step 1320, examples 66000, loss = 1.134682059 (134.057 examples/sec; 0.373 sec/batch)\n",
      "2019-03-16 23:04:05.704103: step 1330, examples 66500, loss = 0.931248963 (131.939 examples/sec; 0.379 sec/batch)\n",
      "2019-03-16 23:04:09.601536: step 1340, examples 67000, loss = 0.957012653 (133.232 examples/sec; 0.375 sec/batch)\n",
      "2019-03-16 23:04:13.476076: step 1350, examples 67500, loss = 0.894285858 (132.009 examples/sec; 0.379 sec/batch)\n",
      "2019-03-16 23:04:17.368269: step 1360, examples 68000, loss = 1.027110457 (129.738 examples/sec; 0.385 sec/batch)\n",
      "2019-03-16 23:04:21.199233: step 1370, examples 68500, loss = 1.062876344 (126.058 examples/sec; 0.397 sec/batch)\n",
      "2019-03-16 23:04:25.091024: step 1380, examples 69000, loss = 0.947577059 (126.712 examples/sec; 0.395 sec/batch)\n",
      "2019-03-16 23:04:28.918959: step 1390, examples 69500, loss = 0.847426414 (129.921 examples/sec; 0.385 sec/batch)\n",
      "2019-03-16 23:04:32.803880: step 1400, examples 70000, loss = 0.794254839 (136.775 examples/sec; 0.366 sec/batch)\n",
      "Top 1 validation accuracy: 0.5943396091461182 and top 2 validation accuracy: 0.7971698045730591\n",
      "Model Saved!\n",
      "2019-03-16 23:04:38.820321: step 1410, examples 70500, loss = 0.868111908 (126.214 examples/sec; 0.396 sec/batch)\n",
      "2019-03-16 23:04:42.711863: step 1420, examples 71000, loss = 0.841886222 (126.058 examples/sec; 0.397 sec/batch)\n",
      "2019-03-16 23:04:46.599445: step 1430, examples 71500, loss = 0.996421099 (128.116 examples/sec; 0.390 sec/batch)\n",
      "2019-03-16 23:04:50.577351: step 1440, examples 72000, loss = 0.923105240 (127.646 examples/sec; 0.392 sec/batch)\n",
      "2019-03-16 23:04:54.461275: step 1450, examples 72500, loss = 0.842444599 (132.829 examples/sec; 0.376 sec/batch)\n",
      "2019-03-16 23:04:58.337100: step 1460, examples 73000, loss = 0.824270546 (132.830 examples/sec; 0.376 sec/batch)\n",
      "2019-03-16 23:05:02.220820: step 1470, examples 73500, loss = 0.895649433 (125.575 examples/sec; 0.398 sec/batch)\n",
      "2019-03-16 23:05:06.144489: step 1480, examples 74000, loss = 1.097231269 (129.937 examples/sec; 0.385 sec/batch)\n",
      "2019-03-16 23:05:10.078629: step 1490, examples 74500, loss = 0.922562599 (119.185 examples/sec; 0.420 sec/batch)\n",
      "2019-03-16 23:05:13.932637: step 1500, examples 75000, loss = 1.096441746 (139.114 examples/sec; 0.359 sec/batch)\n",
      "Top 1 validation accuracy: 0.5636792182922363 and top 2 validation accuracy: 0.7783018946647644\n",
      "Model Saved!\n",
      "2019-03-16 23:05:20.167083: step 1510, examples 75500, loss = 0.877861977 (126.402 examples/sec; 0.396 sec/batch)\n",
      "2019-03-16 23:05:24.035738: step 1520, examples 76000, loss = 0.852380097 (133.318 examples/sec; 0.375 sec/batch)\n",
      "2019-03-16 23:05:27.888180: step 1530, examples 76500, loss = 0.754522979 (126.808 examples/sec; 0.394 sec/batch)\n",
      "2019-03-16 23:05:31.804945: step 1540, examples 77000, loss = 0.850766242 (129.605 examples/sec; 0.386 sec/batch)\n",
      "2019-03-16 23:05:35.733275: step 1550, examples 77500, loss = 1.035686970 (126.440 examples/sec; 0.395 sec/batch)\n",
      "2019-03-16 23:05:39.592571: step 1560, examples 78000, loss = 0.949730575 (132.435 examples/sec; 0.378 sec/batch)\n",
      "2019-03-16 23:05:43.476499: step 1570, examples 78500, loss = 0.946527302 (118.765 examples/sec; 0.421 sec/batch)\n",
      "2019-03-16 23:05:47.382393: step 1580, examples 79000, loss = 0.920374095 (130.413 examples/sec; 0.383 sec/batch)\n",
      "2019-03-16 23:05:51.367818: step 1590, examples 79500, loss = 0.738373935 (122.059 examples/sec; 0.410 sec/batch)\n",
      "2019-03-16 23:05:55.146931: step 1600, examples 80000, loss = 1.008140683 (133.360 examples/sec; 0.375 sec/batch)\n",
      "Top 1 validation accuracy: 0.5919811129570007 and top 2 validation accuracy: 0.7948113083839417\n",
      "Model Saved!\n",
      "2019-03-16 23:06:01.167995: step 1610, examples 80500, loss = 0.917288959 (124.771 examples/sec; 0.401 sec/batch)\n",
      "2019-03-16 23:06:05.024809: step 1620, examples 81000, loss = 0.948485672 (127.987 examples/sec; 0.391 sec/batch)\n",
      "2019-03-16 23:06:08.977113: step 1630, examples 81500, loss = 1.086716294 (129.418 examples/sec; 0.386 sec/batch)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2019-03-16 23:06:12.834627: step 1640, examples 82000, loss = 0.810748279 (128.480 examples/sec; 0.389 sec/batch)\n",
      "2019-03-16 23:06:16.686907: step 1650, examples 82500, loss = 0.913143814 (131.649 examples/sec; 0.380 sec/batch)\n",
      "2019-03-16 23:06:20.569721: step 1660, examples 83000, loss = 0.897469521 (134.964 examples/sec; 0.370 sec/batch)\n",
      "2019-03-16 23:06:24.505553: step 1670, examples 83500, loss = 0.840548277 (126.870 examples/sec; 0.394 sec/batch)\n",
      "2019-03-16 23:06:28.367781: step 1680, examples 84000, loss = 0.880207360 (130.072 examples/sec; 0.384 sec/batch)\n",
      "2019-03-16 23:06:32.309630: step 1690, examples 84500, loss = 0.857561886 (124.814 examples/sec; 0.401 sec/batch)\n",
      "2019-03-16 23:06:36.197784: step 1700, examples 85000, loss = 0.820025623 (137.445 examples/sec; 0.364 sec/batch)\n",
      "Top 1 validation accuracy: 0.5660377144813538 and top 2 validation accuracy: 0.7877358198165894\n",
      "Model Saved!\n",
      "2019-03-16 23:06:42.284985: step 1710, examples 85500, loss = 0.856326163 (133.807 examples/sec; 0.374 sec/batch)\n",
      "2019-03-16 23:06:46.162189: step 1720, examples 86000, loss = 0.690591574 (127.187 examples/sec; 0.393 sec/batch)\n",
      "2019-03-16 23:06:50.037297: step 1730, examples 86500, loss = 0.858032167 (133.320 examples/sec; 0.375 sec/batch)\n",
      "2019-03-16 23:06:53.925141: step 1740, examples 87000, loss = 0.906435966 (134.512 examples/sec; 0.372 sec/batch)\n",
      "2019-03-16 23:06:57.820128: step 1750, examples 87500, loss = 0.868154764 (130.181 examples/sec; 0.384 sec/batch)\n",
      "2019-03-16 23:07:01.713346: step 1760, examples 88000, loss = 0.919882774 (126.621 examples/sec; 0.395 sec/batch)\n",
      "2019-03-16 23:07:05.718595: step 1770, examples 88500, loss = 0.879182160 (136.332 examples/sec; 0.367 sec/batch)\n",
      "2019-03-16 23:07:09.634904: step 1780, examples 89000, loss = 1.231805205 (131.022 examples/sec; 0.382 sec/batch)\n",
      "2019-03-16 23:07:13.610259: step 1790, examples 89500, loss = 0.912896335 (129.735 examples/sec; 0.385 sec/batch)\n",
      "2019-03-16 23:07:17.505665: step 1800, examples 90000, loss = 0.836813927 (123.312 examples/sec; 0.405 sec/batch)\n",
      "Top 1 validation accuracy: 0.6155660152435303 and top 2 validation accuracy: 0.7948113083839417\n",
      "Model Saved!\n",
      "2019-03-16 23:07:23.683254: step 1810, examples 90500, loss = 0.938774586 (123.287 examples/sec; 0.406 sec/batch)\n",
      "2019-03-16 23:07:27.573746: step 1820, examples 91000, loss = 0.825458109 (121.815 examples/sec; 0.410 sec/batch)\n",
      "2019-03-16 23:07:31.430511: step 1830, examples 91500, loss = 0.815613925 (130.477 examples/sec; 0.383 sec/batch)\n",
      "2019-03-16 23:07:35.358210: step 1840, examples 92000, loss = 0.900198281 (125.813 examples/sec; 0.397 sec/batch)\n",
      "2019-03-16 23:07:39.269197: step 1850, examples 92500, loss = 0.816468298 (130.453 examples/sec; 0.383 sec/batch)\n",
      "2019-03-16 23:07:43.182314: step 1860, examples 93000, loss = 0.875482798 (116.076 examples/sec; 0.431 sec/batch)\n",
      "2019-03-16 23:07:47.137576: step 1870, examples 93500, loss = 0.892906249 (125.027 examples/sec; 0.400 sec/batch)\n",
      "2019-03-16 23:07:50.975609: step 1880, examples 94000, loss = 0.944426835 (133.320 examples/sec; 0.375 sec/batch)\n",
      "2019-03-16 23:07:54.855706: step 1890, examples 94500, loss = 1.049147367 (126.863 examples/sec; 0.394 sec/batch)\n",
      "2019-03-16 23:07:58.734028: step 1900, examples 95000, loss = 0.825427473 (133.582 examples/sec; 0.374 sec/batch)\n",
      "Top 1 validation accuracy: 0.6202830076217651 and top 2 validation accuracy: 0.8254716992378235\n",
      "Model Saved!\n",
      "2019-03-16 23:08:04.865386: step 1910, examples 95500, loss = 0.953749359 (133.902 examples/sec; 0.373 sec/batch)\n",
      "2019-03-16 23:08:08.787543: step 1920, examples 96000, loss = 0.967918217 (123.842 examples/sec; 0.404 sec/batch)\n",
      "2019-03-16 23:08:12.643536: step 1930, examples 96500, loss = 0.889643013 (126.532 examples/sec; 0.395 sec/batch)\n",
      "2019-03-16 23:08:16.606764: step 1940, examples 97000, loss = 0.818727195 (127.124 examples/sec; 0.393 sec/batch)\n",
      "2019-03-16 23:08:20.461025: step 1950, examples 97500, loss = 0.856607914 (135.322 examples/sec; 0.369 sec/batch)\n",
      "2019-03-16 23:08:24.336763: step 1960, examples 98000, loss = 0.704802513 (132.098 examples/sec; 0.379 sec/batch)\n",
      "2019-03-16 23:08:28.237955: step 1970, examples 98500, loss = 0.861368477 (126.012 examples/sec; 0.397 sec/batch)\n",
      "2019-03-16 23:08:32.213279: step 1980, examples 99000, loss = 0.755908787 (127.051 examples/sec; 0.394 sec/batch)\n",
      "2019-03-16 23:08:36.077593: step 1990, examples 99500, loss = 1.045986772 (125.039 examples/sec; 0.400 sec/batch)\n",
      "2019-03-16 23:08:39.957791: step 2000, examples 100000, loss = 0.939790308 (132.600 examples/sec; 0.377 sec/batch)\n",
      "Top 1 validation accuracy: 0.5707547068595886 and top 2 validation accuracy: 0.8136792182922363\n",
      "Model Saved!\n",
      "2019-03-16 23:08:46.089062: step 2010, examples 100500, loss = 0.946052074 (118.731 examples/sec; 0.421 sec/batch)\n",
      "2019-03-16 23:08:50.039641: step 2020, examples 101000, loss = 0.787237644 (133.319 examples/sec; 0.375 sec/batch)\n",
      "2019-03-16 23:08:53.911088: step 2030, examples 101500, loss = 0.792845488 (132.805 examples/sec; 0.376 sec/batch)\n",
      "2019-03-16 23:08:57.789770: step 2040, examples 102000, loss = 0.828691542 (134.606 examples/sec; 0.371 sec/batch)\n",
      "2019-03-16 23:09:01.675079: step 2050, examples 102500, loss = 0.770269394 (129.024 examples/sec; 0.388 sec/batch)\n",
      "2019-03-16 23:09:05.603037: step 2060, examples 103000, loss = 1.098277569 (128.421 examples/sec; 0.389 sec/batch)\n",
      "2019-03-16 23:09:09.430602: step 2070, examples 103500, loss = 0.935512781 (125.390 examples/sec; 0.399 sec/batch)\n",
      "2019-03-16 23:09:13.286792: step 2080, examples 104000, loss = 0.820052087 (122.702 examples/sec; 0.407 sec/batch)\n",
      "2019-03-16 23:09:17.181559: step 2090, examples 104500, loss = 0.843745887 (132.580 examples/sec; 0.377 sec/batch)\n",
      "2019-03-16 23:09:21.027727: step 2100, examples 105000, loss = 0.902580976 (139.116 examples/sec; 0.359 sec/batch)\n",
      "Top 1 validation accuracy: 0.6037735939025879 and top 2 validation accuracy: 0.7900943160057068\n",
      "Model Saved!\n",
      "2019-03-16 23:09:26.929259: step 2110, examples 105500, loss = 0.857463360 (132.863 examples/sec; 0.376 sec/batch)\n",
      "2019-03-16 23:09:30.804702: step 2120, examples 106000, loss = 0.853607655 (134.914 examples/sec; 0.371 sec/batch)\n",
      "2019-03-16 23:09:34.678044: step 2130, examples 106500, loss = 0.698109806 (127.020 examples/sec; 0.394 sec/batch)\n",
      "2019-03-16 23:09:38.590714: step 2140, examples 107000, loss = 0.867673874 (125.848 examples/sec; 0.397 sec/batch)\n",
      "2019-03-16 23:09:42.444892: step 2150, examples 107500, loss = 0.706113160 (127.612 examples/sec; 0.392 sec/batch)\n",
      "2019-03-16 23:09:46.336706: step 2160, examples 108000, loss = 0.957645714 (126.572 examples/sec; 0.395 sec/batch)\n",
      "2019-03-16 23:09:50.452754: step 2170, examples 108500, loss = 0.800508082 (117.472 examples/sec; 0.426 sec/batch)\n",
      "2019-03-16 23:09:54.646906: step 2180, examples 109000, loss = 0.920371115 (116.512 examples/sec; 0.429 sec/batch)\n",
      "2019-03-16 23:09:58.773890: step 2190, examples 109500, loss = 0.648387492 (120.744 examples/sec; 0.414 sec/batch)\n",
      "2019-03-16 23:10:02.795083: step 2200, examples 110000, loss = 0.795768499 (123.128 examples/sec; 0.406 sec/batch)\n",
      "Top 1 validation accuracy: 0.5896226167678833 and top 2 validation accuracy: 0.801886796951294\n",
      "Model Saved!\n",
      "2019-03-16 23:10:09.085580: step 2210, examples 110500, loss = 0.907939136 (129.731 examples/sec; 0.385 sec/batch)\n",
      "2019-03-16 23:10:12.942982: step 2220, examples 111000, loss = 0.917277396 (133.797 examples/sec; 0.374 sec/batch)\n",
      "2019-03-16 23:10:16.803135: step 2230, examples 111500, loss = 0.952459812 (133.341 examples/sec; 0.375 sec/batch)\n",
      "2019-03-16 23:10:20.677797: step 2240, examples 112000, loss = 0.834983766 (128.569 examples/sec; 0.389 sec/batch)\n",
      "2019-03-16 23:10:24.630382: step 2250, examples 112500, loss = 0.892299950 (128.241 examples/sec; 0.390 sec/batch)\n",
      "2019-03-16 23:10:28.537262: step 2260, examples 113000, loss = 0.774424255 (126.156 examples/sec; 0.396 sec/batch)\n",
      "2019-03-16 23:10:32.440953: step 2270, examples 113500, loss = 0.825427294 (124.979 examples/sec; 0.400 sec/batch)\n",
      "2019-03-16 23:10:36.318164: step 2280, examples 114000, loss = 0.876441717 (132.391 examples/sec; 0.378 sec/batch)\n",
      "2019-03-16 23:10:40.177312: step 2290, examples 114500, loss = 0.816874564 (123.422 examples/sec; 0.405 sec/batch)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2019-03-16 23:10:44.186843: step 2300, examples 115000, loss = 0.833217442 (124.357 examples/sec; 0.402 sec/batch)\n",
      "Top 1 validation accuracy: 0.6014150977134705 and top 2 validation accuracy: 0.8466981053352356\n",
      "Model Saved!\n",
      "2019-03-16 23:10:50.476732: step 2310, examples 115500, loss = 0.854038000 (125.452 examples/sec; 0.399 sec/batch)\n",
      "2019-03-16 23:10:54.470853: step 2320, examples 116000, loss = 0.998394191 (130.201 examples/sec; 0.384 sec/batch)\n",
      "2019-03-16 23:10:58.412910: step 2330, examples 116500, loss = 0.794106781 (125.342 examples/sec; 0.399 sec/batch)\n",
      "2019-03-16 23:11:02.317051: step 2340, examples 117000, loss = 0.822411716 (123.568 examples/sec; 0.405 sec/batch)\n",
      "2019-03-16 23:11:06.217574: step 2350, examples 117500, loss = 0.986947715 (124.837 examples/sec; 0.401 sec/batch)\n",
      "2019-03-16 23:11:10.109566: step 2360, examples 118000, loss = 0.888497531 (124.940 examples/sec; 0.400 sec/batch)\n",
      "2019-03-16 23:11:14.104072: step 2370, examples 118500, loss = 0.866564572 (133.431 examples/sec; 0.375 sec/batch)\n",
      "2019-03-16 23:11:17.986240: step 2380, examples 119000, loss = 0.920602977 (127.987 examples/sec; 0.391 sec/batch)\n",
      "2019-03-16 23:11:21.855664: step 2390, examples 119500, loss = 0.799233973 (131.837 examples/sec; 0.379 sec/batch)\n",
      "2019-03-16 23:11:25.740370: step 2400, examples 120000, loss = 0.801924407 (134.315 examples/sec; 0.372 sec/batch)\n",
      "Top 1 validation accuracy: 0.5660377144813538 and top 2 validation accuracy: 0.801886796951294\n",
      "Model Saved!\n",
      "2019-03-16 23:11:31.865095: step 2410, examples 120500, loss = 0.826119721 (135.027 examples/sec; 0.370 sec/batch)\n",
      "2019-03-16 23:11:35.755263: step 2420, examples 121000, loss = 0.769718647 (131.257 examples/sec; 0.381 sec/batch)\n",
      "2019-03-16 23:11:39.642157: step 2430, examples 121500, loss = 1.078814983 (128.435 examples/sec; 0.389 sec/batch)\n",
      "2019-03-16 23:11:43.615234: step 2440, examples 122000, loss = 0.909523249 (116.537 examples/sec; 0.429 sec/batch)\n",
      "2019-03-16 23:11:47.537640: step 2450, examples 122500, loss = 0.971622169 (127.838 examples/sec; 0.391 sec/batch)\n",
      "2019-03-16 23:11:51.420732: step 2460, examples 123000, loss = 0.793575287 (128.734 examples/sec; 0.388 sec/batch)\n",
      "2019-03-16 23:11:55.336146: step 2470, examples 123500, loss = 0.868695676 (127.669 examples/sec; 0.392 sec/batch)\n",
      "2019-03-16 23:11:59.279069: step 2480, examples 124000, loss = 0.954587162 (121.263 examples/sec; 0.412 sec/batch)\n",
      "2019-03-16 23:12:03.178037: step 2490, examples 124500, loss = 0.816515148 (129.772 examples/sec; 0.385 sec/batch)\n",
      "2019-03-16 23:12:07.037208: step 2500, examples 125000, loss = 0.747416914 (133.319 examples/sec; 0.375 sec/batch)\n",
      "Top 1 validation accuracy: 0.5849056839942932 and top 2 validation accuracy: 0.8160377144813538\n",
      "Model Saved!\n",
      "2019-03-16 23:12:13.139987: step 2510, examples 125500, loss = 0.971280396 (130.182 examples/sec; 0.384 sec/batch)\n",
      "2019-03-16 23:12:17.096725: step 2520, examples 126000, loss = 0.907080352 (121.028 examples/sec; 0.413 sec/batch)\n",
      "2019-03-16 23:12:21.014525: step 2530, examples 126500, loss = 0.855237484 (123.065 examples/sec; 0.406 sec/batch)\n",
      "2019-03-16 23:12:24.919106: step 2540, examples 127000, loss = 0.746214926 (130.884 examples/sec; 0.382 sec/batch)\n",
      "2019-03-16 23:12:28.757728: step 2550, examples 127500, loss = 0.816127598 (133.412 examples/sec; 0.375 sec/batch)\n",
      "2019-03-16 23:12:32.713299: step 2560, examples 128000, loss = 0.873190463 (132.817 examples/sec; 0.376 sec/batch)\n",
      "2019-03-16 23:12:36.605405: step 2570, examples 128500, loss = 0.774875939 (126.271 examples/sec; 0.396 sec/batch)\n",
      "2019-03-16 23:12:40.490846: step 2580, examples 129000, loss = 0.860195458 (133.484 examples/sec; 0.375 sec/batch)\n",
      "2019-03-16 23:12:44.372330: step 2590, examples 129500, loss = 0.714628398 (123.475 examples/sec; 0.405 sec/batch)\n",
      "2019-03-16 23:12:48.322379: step 2600, examples 130000, loss = 0.881211579 (124.408 examples/sec; 0.402 sec/batch)\n",
      "Top 1 validation accuracy: 0.5919811129570007 and top 2 validation accuracy: 0.7806603908538818\n",
      "Model Saved!\n",
      "2019-03-16 23:12:54.386741: step 2610, examples 130500, loss = 0.857321918 (130.731 examples/sec; 0.382 sec/batch)\n",
      "2019-03-16 23:12:58.253577: step 2620, examples 131000, loss = 1.021504045 (133.317 examples/sec; 0.375 sec/batch)\n",
      "2019-03-16 23:13:02.084949: step 2630, examples 131500, loss = 0.748781741 (129.973 examples/sec; 0.385 sec/batch)\n",
      "2019-03-16 23:13:06.072714: step 2640, examples 132000, loss = 0.956751585 (126.613 examples/sec; 0.395 sec/batch)\n",
      "2019-03-16 23:13:10.009986: step 2650, examples 132500, loss = 0.941636026 (125.581 examples/sec; 0.398 sec/batch)\n",
      "2019-03-16 23:13:13.890700: step 2660, examples 133000, loss = 0.911013365 (135.521 examples/sec; 0.369 sec/batch)\n",
      "2019-03-16 23:13:17.741119: step 2670, examples 133500, loss = 0.874106228 (136.527 examples/sec; 0.366 sec/batch)\n",
      "2019-03-16 23:13:21.724595: step 2680, examples 134000, loss = 0.730013549 (134.148 examples/sec; 0.373 sec/batch)\n",
      "2019-03-16 23:13:25.579148: step 2690, examples 134500, loss = 0.713619947 (129.595 examples/sec; 0.386 sec/batch)\n",
      "2019-03-16 23:13:29.461069: step 2700, examples 135000, loss = 0.764099121 (131.802 examples/sec; 0.379 sec/batch)\n",
      "Top 1 validation accuracy: 0.5825471878051758 and top 2 validation accuracy: 0.8207547068595886\n",
      "Model Saved!\n",
      "2019-03-16 23:13:35.582206: step 2710, examples 135500, loss = 0.744886935 (120.920 examples/sec; 0.413 sec/batch)\n",
      "2019-03-16 23:13:39.431556: step 2720, examples 136000, loss = 0.800180435 (127.072 examples/sec; 0.393 sec/batch)\n",
      "2019-03-16 23:13:43.327346: step 2730, examples 136500, loss = 0.713436544 (115.221 examples/sec; 0.434 sec/batch)\n",
      "2019-03-16 23:13:47.178014: step 2740, examples 137000, loss = 0.822403729 (133.219 examples/sec; 0.375 sec/batch)\n",
      "2019-03-16 23:13:51.096854: step 2750, examples 137500, loss = 0.907919168 (116.280 examples/sec; 0.430 sec/batch)\n",
      "2019-03-16 23:13:54.949525: step 2760, examples 138000, loss = 0.845129013 (127.987 examples/sec; 0.391 sec/batch)\n",
      "2019-03-16 23:13:58.849526: step 2770, examples 138500, loss = 0.642449021 (134.437 examples/sec; 0.372 sec/batch)\n",
      "2019-03-16 23:14:02.716281: step 2780, examples 139000, loss = 0.568187952 (129.720 examples/sec; 0.385 sec/batch)\n",
      "2019-03-16 23:14:06.601162: step 2790, examples 139500, loss = 0.810547531 (128.457 examples/sec; 0.389 sec/batch)\n",
      "2019-03-16 23:14:10.581188: step 2800, examples 140000, loss = 1.030549645 (126.314 examples/sec; 0.396 sec/batch)\n",
      "Top 1 validation accuracy: 0.6037735939025879 and top 2 validation accuracy: 0.823113203048706\n",
      "Model Saved!\n",
      "2019-03-16 23:14:16.752341: step 2810, examples 140500, loss = 0.896437824 (130.181 examples/sec; 0.384 sec/batch)\n",
      "2019-03-16 23:14:20.643763: step 2820, examples 141000, loss = 0.764843225 (127.161 examples/sec; 0.393 sec/batch)\n",
      "2019-03-16 23:14:24.590994: step 2830, examples 141500, loss = 0.778925836 (134.386 examples/sec; 0.372 sec/batch)\n",
      "2019-03-16 23:14:28.497132: step 2840, examples 142000, loss = 0.903176010 (124.660 examples/sec; 0.401 sec/batch)\n",
      "2019-03-16 23:14:32.416372: step 2850, examples 142500, loss = 0.863554537 (129.786 examples/sec; 0.385 sec/batch)\n",
      "2019-03-16 23:14:36.416247: step 2860, examples 143000, loss = 0.709940851 (119.305 examples/sec; 0.419 sec/batch)\n",
      "2019-03-16 23:14:40.394516: step 2870, examples 143500, loss = 0.723457813 (129.685 examples/sec; 0.386 sec/batch)\n",
      "2019-03-16 23:14:44.253895: step 2880, examples 144000, loss = 0.743020833 (123.134 examples/sec; 0.406 sec/batch)\n",
      "2019-03-16 23:14:48.138776: step 2890, examples 144500, loss = 0.868694484 (127.071 examples/sec; 0.393 sec/batch)\n",
      "2019-03-16 23:14:51.999792: step 2900, examples 145000, loss = 0.795147896 (133.319 examples/sec; 0.375 sec/batch)\n",
      "Top 1 validation accuracy: 0.5919811129570007 and top 2 validation accuracy: 0.8325471878051758\n",
      "Model Saved!\n",
      "2019-03-16 23:14:58.128006: step 2910, examples 145500, loss = 0.888236940 (125.446 examples/sec; 0.399 sec/batch)\n",
      "2019-03-16 23:15:02.004492: step 2920, examples 146000, loss = 1.004479289 (123.064 examples/sec; 0.406 sec/batch)\n",
      "2019-03-16 23:15:05.855684: step 2930, examples 146500, loss = 0.862506866 (132.906 examples/sec; 0.376 sec/batch)\n",
      "2019-03-16 23:15:09.734883: step 2940, examples 147000, loss = 0.909223974 (136.037 examples/sec; 0.368 sec/batch)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2019-03-16 23:15:13.774803: step 2950, examples 147500, loss = 0.703583658 (139.961 examples/sec; 0.357 sec/batch)\n",
      "2019-03-16 23:15:17.699252: step 2960, examples 148000, loss = 0.887857735 (123.781 examples/sec; 0.404 sec/batch)\n",
      "2019-03-16 23:15:21.598217: step 2970, examples 148500, loss = 0.732658565 (138.770 examples/sec; 0.360 sec/batch)\n",
      "2019-03-16 23:15:25.482738: step 2980, examples 149000, loss = 0.717263877 (129.600 examples/sec; 0.386 sec/batch)\n",
      "2019-03-16 23:15:29.407967: step 2990, examples 149500, loss = 0.741290331 (126.879 examples/sec; 0.394 sec/batch)\n",
      "2019-03-16 23:15:33.269534: step 3000, examples 150000, loss = 0.872051418 (128.907 examples/sec; 0.388 sec/batch)\n",
      "Top 1 validation accuracy: 0.6037735939025879 and top 2 validation accuracy: 0.823113203048706\n",
      "Model Saved!\n",
      "2019-03-16 23:15:39.320292: step 3010, examples 150500, loss = 0.791811764 (127.821 examples/sec; 0.391 sec/batch)\n",
      "2019-03-16 23:15:43.202615: step 3020, examples 151000, loss = 0.911787510 (116.137 examples/sec; 0.431 sec/batch)\n",
      "2019-03-16 23:15:47.095511: step 3030, examples 151500, loss = 0.811013162 (125.383 examples/sec; 0.399 sec/batch)\n",
      "2019-03-16 23:15:51.003235: step 3040, examples 152000, loss = 0.665811360 (133.319 examples/sec; 0.375 sec/batch)\n",
      "2019-03-16 23:15:54.891338: step 3050, examples 152500, loss = 0.892653525 (131.707 examples/sec; 0.380 sec/batch)\n",
      "2019-03-16 23:15:58.787063: step 3060, examples 153000, loss = 0.861603737 (128.717 examples/sec; 0.388 sec/batch)\n",
      "2019-03-16 23:16:02.744431: step 3070, examples 153500, loss = 0.796944320 (127.347 examples/sec; 0.393 sec/batch)\n",
      "2019-03-16 23:16:06.617021: step 3080, examples 154000, loss = 0.798559189 (128.324 examples/sec; 0.390 sec/batch)\n",
      "2019-03-16 23:16:10.445714: step 3090, examples 154500, loss = 0.959973991 (137.287 examples/sec; 0.364 sec/batch)\n",
      "2019-03-16 23:16:14.310709: step 3100, examples 155000, loss = 0.721309900 (125.797 examples/sec; 0.397 sec/batch)\n",
      "Top 1 validation accuracy: 0.599056601524353 and top 2 validation accuracy: 0.8183962106704712\n",
      "Model Saved!\n",
      "2019-03-16 23:16:20.515953: step 3110, examples 155500, loss = 1.053281069 (134.545 examples/sec; 0.372 sec/batch)\n",
      "2019-03-16 23:16:24.369850: step 3120, examples 156000, loss = 0.883498251 (132.943 examples/sec; 0.376 sec/batch)\n",
      "2019-03-16 23:16:28.238646: step 3130, examples 156500, loss = 0.922604024 (128.238 examples/sec; 0.390 sec/batch)\n",
      "2019-03-16 23:16:32.129690: step 3140, examples 157000, loss = 0.822094679 (123.912 examples/sec; 0.404 sec/batch)\n",
      "2019-03-16 23:16:36.054063: step 3150, examples 157500, loss = 1.009384990 (133.319 examples/sec; 0.375 sec/batch)\n",
      "2019-03-16 23:16:39.895196: step 3160, examples 158000, loss = 0.722856939 (131.603 examples/sec; 0.380 sec/batch)\n",
      "2019-03-16 23:16:43.771635: step 3170, examples 158500, loss = 0.923626125 (134.421 examples/sec; 0.372 sec/batch)\n",
      "2019-03-16 23:16:47.719465: step 3180, examples 159000, loss = 0.952640593 (119.539 examples/sec; 0.418 sec/batch)\n",
      "2019-03-16 23:16:51.603090: step 3190, examples 159500, loss = 0.654585123 (128.119 examples/sec; 0.390 sec/batch)\n",
      "2019-03-16 23:16:55.495606: step 3200, examples 160000, loss = 0.982803345 (127.405 examples/sec; 0.392 sec/batch)\n",
      "Top 1 validation accuracy: 0.6037735939025879 and top 2 validation accuracy: 0.8325471878051758\n",
      "Model Saved!\n",
      "2019-03-16 23:17:01.627545: step 3210, examples 160500, loss = 0.727083623 (124.312 examples/sec; 0.402 sec/batch)\n",
      "2019-03-16 23:17:05.554546: step 3220, examples 161000, loss = 0.871076882 (133.156 examples/sec; 0.376 sec/batch)\n",
      "2019-03-16 23:17:09.404892: step 3230, examples 161500, loss = 0.682029963 (130.404 examples/sec; 0.383 sec/batch)\n",
      "2019-03-16 23:17:13.255941: step 3240, examples 162000, loss = 0.854354203 (129.790 examples/sec; 0.385 sec/batch)\n",
      "2019-03-16 23:17:17.074400: step 3250, examples 162500, loss = 0.755186617 (128.115 examples/sec; 0.390 sec/batch)\n",
      "2019-03-16 23:17:21.007475: step 3260, examples 163000, loss = 0.847372711 (127.987 examples/sec; 0.391 sec/batch)\n",
      "2019-03-16 23:17:24.834024: step 3270, examples 163500, loss = 0.766719639 (128.753 examples/sec; 0.388 sec/batch)\n",
      "2019-03-16 23:17:28.729335: step 3280, examples 164000, loss = 0.761323988 (129.810 examples/sec; 0.385 sec/batch)\n",
      "2019-03-16 23:17:32.608149: step 3290, examples 164500, loss = 0.787907302 (131.393 examples/sec; 0.381 sec/batch)\n",
      "2019-03-16 23:17:36.484895: step 3300, examples 165000, loss = 0.656812966 (128.799 examples/sec; 0.388 sec/batch)\n",
      "Top 1 validation accuracy: 0.573113203048706 and top 2 validation accuracy: 0.8089622855186462\n",
      "Model Saved!\n",
      "2019-03-16 23:17:42.528999: step 3310, examples 165500, loss = 1.088795424 (129.994 examples/sec; 0.385 sec/batch)\n",
      "2019-03-16 23:17:46.495064: step 3320, examples 166000, loss = 0.819869697 (130.021 examples/sec; 0.385 sec/batch)\n",
      "2019-03-16 23:17:50.324067: step 3330, examples 166500, loss = 0.813468158 (126.162 examples/sec; 0.396 sec/batch)\n",
      "2019-03-16 23:17:54.324571: step 3340, examples 167000, loss = 0.801619470 (124.238 examples/sec; 0.402 sec/batch)\n",
      "2019-03-16 23:17:58.225384: step 3350, examples 167500, loss = 0.748886406 (122.940 examples/sec; 0.407 sec/batch)\n",
      "2019-03-16 23:18:02.099021: step 3360, examples 168000, loss = 0.728639305 (124.841 examples/sec; 0.401 sec/batch)\n",
      "2019-03-16 23:18:05.979047: step 3370, examples 168500, loss = 0.662318110 (132.379 examples/sec; 0.378 sec/batch)\n",
      "2019-03-16 23:18:09.927643: step 3380, examples 169000, loss = 0.579825163 (127.986 examples/sec; 0.391 sec/batch)\n",
      "2019-03-16 23:18:13.806471: step 3390, examples 169500, loss = 0.730659008 (135.867 examples/sec; 0.368 sec/batch)\n",
      "2019-03-16 23:18:17.721626: step 3400, examples 170000, loss = 0.949757814 (128.721 examples/sec; 0.388 sec/batch)\n",
      "Top 1 validation accuracy: 0.5872641801834106 and top 2 validation accuracy: 0.8301886916160583\n",
      "Model Saved!\n",
      "2019-03-16 23:18:23.873533: step 3410, examples 170500, loss = 0.817685127 (130.878 examples/sec; 0.382 sec/batch)\n",
      "2019-03-16 23:18:27.711274: step 3420, examples 171000, loss = 0.940431118 (139.312 examples/sec; 0.359 sec/batch)\n",
      "2019-03-16 23:18:31.536773: step 3430, examples 171500, loss = 0.846391141 (133.463 examples/sec; 0.375 sec/batch)\n",
      "2019-03-16 23:18:35.423116: step 3440, examples 172000, loss = 0.624007523 (126.853 examples/sec; 0.394 sec/batch)\n",
      "2019-03-16 23:18:39.355437: step 3450, examples 172500, loss = 0.941793442 (114.900 examples/sec; 0.435 sec/batch)\n",
      "2019-03-16 23:18:43.251504: step 3460, examples 173000, loss = 0.734482348 (132.323 examples/sec; 0.378 sec/batch)\n",
      "2019-03-16 23:18:47.166816: step 3470, examples 173500, loss = 0.817715585 (131.852 examples/sec; 0.379 sec/batch)\n",
      "2019-03-16 23:18:50.988110: step 3480, examples 174000, loss = 0.685589612 (133.319 examples/sec; 0.375 sec/batch)\n",
      "2019-03-16 23:18:54.824331: step 3490, examples 174500, loss = 0.827687442 (130.856 examples/sec; 0.382 sec/batch)\n",
      "2019-03-16 23:18:58.737491: step 3500, examples 175000, loss = 0.632829130 (129.729 examples/sec; 0.385 sec/batch)\n",
      "Top 1 validation accuracy: 0.5966981053352356 and top 2 validation accuracy: 0.8349056839942932\n",
      "Model Saved!\n",
      "2019-03-16 23:19:04.818628: step 3510, examples 175500, loss = 0.802800953 (134.031 examples/sec; 0.373 sec/batch)\n",
      "2019-03-16 23:19:08.666499: step 3520, examples 176000, loss = 0.986877918 (140.102 examples/sec; 0.357 sec/batch)\n",
      "2019-03-16 23:19:12.665210: step 3530, examples 176500, loss = 0.774522483 (122.850 examples/sec; 0.407 sec/batch)\n",
      "2019-03-16 23:19:16.598132: step 3540, examples 177000, loss = 0.920644045 (128.799 examples/sec; 0.388 sec/batch)\n",
      "2019-03-16 23:19:20.607026: step 3550, examples 177500, loss = 0.756043851 (123.218 examples/sec; 0.406 sec/batch)\n",
      "2019-03-16 23:19:24.606800: step 3560, examples 178000, loss = 0.703348637 (129.644 examples/sec; 0.386 sec/batch)\n",
      "2019-03-16 23:19:28.691093: step 3570, examples 178500, loss = 0.799951613 (123.984 examples/sec; 0.403 sec/batch)\n",
      "2019-03-16 23:19:32.807993: step 3580, examples 179000, loss = 0.830074847 (130.816 examples/sec; 0.382 sec/batch)\n",
      "2019-03-16 23:19:36.834188: step 3590, examples 179500, loss = 0.601562083 (128.633 examples/sec; 0.389 sec/batch)\n",
      "2019-03-16 23:19:40.682106: step 3600, examples 180000, loss = 0.896578968 (131.193 examples/sec; 0.381 sec/batch)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Top 1 validation accuracy: 0.6344339847564697 and top 2 validation accuracy: 0.8066037893295288\n",
      "Model Saved!\n",
      "2019-03-16 23:19:46.771446: step 3610, examples 180500, loss = 0.730838597 (134.302 examples/sec; 0.372 sec/batch)\n",
      "2019-03-16 23:19:50.584803: step 3620, examples 181000, loss = 0.735157967 (126.966 examples/sec; 0.394 sec/batch)\n",
      "2019-03-16 23:19:54.460486: step 3630, examples 181500, loss = 0.800325453 (130.740 examples/sec; 0.382 sec/batch)\n",
      "2019-03-16 23:19:58.336431: step 3640, examples 182000, loss = 0.660878360 (127.787 examples/sec; 0.391 sec/batch)\n",
      "2019-03-16 23:20:02.294042: step 3650, examples 182500, loss = 0.659660280 (130.964 examples/sec; 0.382 sec/batch)\n",
      "2019-03-16 23:20:06.162098: step 3660, examples 183000, loss = 1.000311017 (134.304 examples/sec; 0.372 sec/batch)\n",
      "2019-03-16 23:20:10.052752: step 3670, examples 183500, loss = 0.647063792 (133.319 examples/sec; 0.375 sec/batch)\n",
      "2019-03-16 23:20:13.896548: step 3680, examples 184000, loss = 0.797094762 (131.053 examples/sec; 0.382 sec/batch)\n",
      "2019-03-16 23:20:17.884539: step 3690, examples 184500, loss = 0.817245960 (126.437 examples/sec; 0.395 sec/batch)\n",
      "2019-03-16 23:20:21.759906: step 3700, examples 185000, loss = 0.764022350 (127.345 examples/sec; 0.393 sec/batch)\n",
      "Top 1 validation accuracy: 0.5966981053352356 and top 2 validation accuracy: 0.8066037893295288\n",
      "Model Saved!\n",
      "2019-03-16 23:20:27.945989: step 3710, examples 185500, loss = 0.794162452 (133.690 examples/sec; 0.374 sec/batch)\n",
      "2019-03-16 23:20:31.852083: step 3720, examples 186000, loss = 0.790145457 (128.205 examples/sec; 0.390 sec/batch)\n",
      "2019-03-16 23:20:35.748627: step 3730, examples 186500, loss = 0.731917322 (131.230 examples/sec; 0.381 sec/batch)\n",
      "2019-03-16 23:20:39.607641: step 3740, examples 187000, loss = 0.822168887 (129.896 examples/sec; 0.385 sec/batch)\n",
      "2019-03-16 23:20:43.509542: step 3750, examples 187500, loss = 0.673555076 (121.051 examples/sec; 0.413 sec/batch)\n",
      "2019-03-16 23:20:47.373918: step 3760, examples 188000, loss = 0.844875515 (119.788 examples/sec; 0.417 sec/batch)\n",
      "2019-03-16 23:20:51.273703: step 3770, examples 188500, loss = 0.851248801 (128.626 examples/sec; 0.389 sec/batch)\n",
      "2019-03-16 23:20:55.146913: step 3780, examples 189000, loss = 0.713639557 (133.672 examples/sec; 0.374 sec/batch)\n",
      "2019-03-16 23:20:58.971568: step 3790, examples 189500, loss = 0.733240783 (139.116 examples/sec; 0.359 sec/batch)\n",
      "2019-03-16 23:21:02.854514: step 3800, examples 190000, loss = 0.805780888 (132.390 examples/sec; 0.378 sec/batch)\n",
      "Top 1 validation accuracy: 0.6061320900917053 and top 2 validation accuracy: 0.8254716992378235\n",
      "Model Saved!\n",
      "2019-03-16 23:21:08.942384: step 3810, examples 190500, loss = 0.553976595 (138.717 examples/sec; 0.360 sec/batch)\n",
      "2019-03-16 23:21:12.823630: step 3820, examples 191000, loss = 0.754910290 (130.221 examples/sec; 0.384 sec/batch)\n",
      "2019-03-16 23:21:16.682770: step 3830, examples 191500, loss = 0.910869300 (136.127 examples/sec; 0.367 sec/batch)\n",
      "2019-03-16 23:21:20.583779: step 3840, examples 192000, loss = 0.842823565 (132.708 examples/sec; 0.377 sec/batch)\n",
      "2019-03-16 23:21:24.509145: step 3850, examples 192500, loss = 0.595422208 (122.286 examples/sec; 0.409 sec/batch)\n",
      "2019-03-16 23:21:28.397594: step 3860, examples 193000, loss = 0.755308926 (128.737 examples/sec; 0.388 sec/batch)\n",
      "2019-03-16 23:21:32.261236: step 3870, examples 193500, loss = 0.642047107 (125.551 examples/sec; 0.398 sec/batch)\n",
      "2019-03-16 23:21:36.226680: step 3880, examples 194000, loss = 0.743324757 (127.719 examples/sec; 0.391 sec/batch)\n",
      "2019-03-16 23:21:40.111722: step 3890, examples 194500, loss = 0.769565582 (129.839 examples/sec; 0.385 sec/batch)\n",
      "2019-03-16 23:21:44.056003: step 3900, examples 195000, loss = 0.860306323 (123.063 examples/sec; 0.406 sec/batch)\n",
      "Top 1 validation accuracy: 0.5943396091461182 and top 2 validation accuracy: 0.801886796951294\n",
      "Model Saved!\n",
      "2019-03-16 23:21:50.095551: step 3910, examples 195500, loss = 0.848783970 (131.067 examples/sec; 0.381 sec/batch)\n",
      "2019-03-16 23:21:54.037463: step 3920, examples 196000, loss = 0.818563402 (127.986 examples/sec; 0.391 sec/batch)\n",
      "2019-03-16 23:21:57.935236: step 3930, examples 196500, loss = 0.766097605 (136.276 examples/sec; 0.367 sec/batch)\n",
      "2019-03-16 23:22:01.834162: step 3940, examples 197000, loss = 0.766030312 (128.431 examples/sec; 0.389 sec/batch)\n",
      "2019-03-16 23:22:05.753442: step 3950, examples 197500, loss = 0.746871173 (130.618 examples/sec; 0.383 sec/batch)\n",
      "2019-03-16 23:22:09.680290: step 3960, examples 198000, loss = 0.709098816 (127.979 examples/sec; 0.391 sec/batch)\n",
      "2019-03-16 23:22:13.530195: step 3970, examples 198500, loss = 0.676747978 (130.388 examples/sec; 0.383 sec/batch)\n",
      "2019-03-16 23:22:17.392495: step 3980, examples 199000, loss = 0.682071865 (134.073 examples/sec; 0.373 sec/batch)\n",
      "2019-03-16 23:22:21.272621: step 3990, examples 199500, loss = 0.688069642 (127.166 examples/sec; 0.393 sec/batch)\n",
      "2019-03-16 23:22:25.232618: step 4000, examples 200000, loss = 0.850871384 (130.513 examples/sec; 0.383 sec/batch)\n",
      "Top 1 validation accuracy: 0.6037735939025879 and top 2 validation accuracy: 0.8372641801834106\n",
      "Model Saved!\n",
      "2019-03-16 23:22:31.436903: step 4010, examples 200500, loss = 0.865105569 (123.616 examples/sec; 0.404 sec/batch)\n",
      "2019-03-16 23:22:35.262866: step 4020, examples 201000, loss = 0.784892321 (130.981 examples/sec; 0.382 sec/batch)\n",
      "2019-03-16 23:22:39.195773: step 4030, examples 201500, loss = 0.709087431 (118.880 examples/sec; 0.421 sec/batch)\n",
      "2019-03-16 23:22:43.103926: step 4040, examples 202000, loss = 0.793742836 (128.730 examples/sec; 0.388 sec/batch)\n",
      "2019-03-16 23:22:46.998395: step 4050, examples 202500, loss = 0.729399681 (127.986 examples/sec; 0.391 sec/batch)\n",
      "2019-03-16 23:22:50.834728: step 4060, examples 203000, loss = 0.816331327 (128.326 examples/sec; 0.390 sec/batch)\n",
      "2019-03-16 23:22:54.754855: step 4070, examples 203500, loss = 0.877955914 (124.232 examples/sec; 0.402 sec/batch)\n",
      "2019-03-16 23:22:58.689900: step 4080, examples 204000, loss = 0.685819864 (128.517 examples/sec; 0.389 sec/batch)\n",
      "2019-03-16 23:23:02.533404: step 4090, examples 204500, loss = 0.820030987 (129.305 examples/sec; 0.387 sec/batch)\n",
      "2019-03-16 23:23:06.445513: step 4100, examples 205000, loss = 0.697640836 (135.239 examples/sec; 0.370 sec/batch)\n",
      "Top 1 validation accuracy: 0.6273584961891174 and top 2 validation accuracy: 0.8349056839942932\n",
      "Model Saved!\n",
      "2019-03-16 23:23:12.497708: step 4110, examples 205500, loss = 0.703694999 (133.281 examples/sec; 0.375 sec/batch)\n",
      "2019-03-16 23:23:16.398530: step 4120, examples 206000, loss = 0.833476067 (124.491 examples/sec; 0.402 sec/batch)\n",
      "2019-03-16 23:23:20.262406: step 4130, examples 206500, loss = 0.668740571 (131.380 examples/sec; 0.381 sec/batch)\n",
      "2019-03-16 23:23:24.146186: step 4140, examples 207000, loss = 0.865488231 (133.687 examples/sec; 0.374 sec/batch)\n",
      "2019-03-16 23:23:28.114576: step 4150, examples 207500, loss = 0.895853102 (123.743 examples/sec; 0.404 sec/batch)\n",
      "2019-03-16 23:23:31.964508: step 4160, examples 208000, loss = 0.737054825 (127.986 examples/sec; 0.391 sec/batch)\n",
      "2019-03-16 23:23:35.854566: step 4170, examples 208500, loss = 0.872395515 (126.874 examples/sec; 0.394 sec/batch)\n",
      "2019-03-16 23:23:39.685950: step 4180, examples 209000, loss = 0.976651192 (138.318 examples/sec; 0.361 sec/batch)\n",
      "2019-03-16 23:23:43.696960: step 4190, examples 209500, loss = 0.641150177 (114.374 examples/sec; 0.437 sec/batch)\n",
      "2019-03-16 23:23:47.598398: step 4200, examples 210000, loss = 0.626933813 (132.486 examples/sec; 0.377 sec/batch)\n",
      "Top 1 validation accuracy: 0.5636792182922363 and top 2 validation accuracy: 0.7900943160057068\n",
      "Model Saved!\n",
      "2019-03-16 23:23:53.572723: step 4210, examples 210500, loss = 0.634406865 (123.723 examples/sec; 0.404 sec/batch)\n",
      "2019-03-16 23:23:57.461480: step 4220, examples 211000, loss = 0.744440794 (132.611 examples/sec; 0.377 sec/batch)\n",
      "2019-03-16 23:24:01.422709: step 4230, examples 211500, loss = 0.847240627 (124.298 examples/sec; 0.402 sec/batch)\n",
      "2019-03-16 23:24:05.315598: step 4240, examples 212000, loss = 0.835353315 (131.083 examples/sec; 0.381 sec/batch)\n",
      "2019-03-16 23:24:09.183975: step 4250, examples 212500, loss = 0.818191528 (131.723 examples/sec; 0.380 sec/batch)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2019-03-16 23:24:13.063367: step 4260, examples 213000, loss = 0.910410702 (127.913 examples/sec; 0.391 sec/batch)\n",
      "2019-03-16 23:24:16.978009: step 4270, examples 213500, loss = 0.748643398 (127.986 examples/sec; 0.391 sec/batch)\n",
      "2019-03-16 23:24:20.912142: step 4280, examples 214000, loss = 0.702319801 (129.592 examples/sec; 0.386 sec/batch)\n",
      "2019-03-16 23:24:24.803360: step 4290, examples 214500, loss = 0.692393005 (135.028 examples/sec; 0.370 sec/batch)\n",
      "2019-03-16 23:24:28.670370: step 4300, examples 215000, loss = 0.841135502 (129.938 examples/sec; 0.385 sec/batch)\n",
      "Top 1 validation accuracy: 0.6603773832321167 and top 2 validation accuracy: 0.8372641801834106\n",
      "Model Saved!\n",
      "2019-03-16 23:24:34.686617: step 4310, examples 215500, loss = 0.794018090 (132.931 examples/sec; 0.376 sec/batch)\n",
      "2019-03-16 23:24:38.624166: step 4320, examples 216000, loss = 0.810401499 (125.473 examples/sec; 0.398 sec/batch)\n",
      "2019-03-16 23:24:42.509613: step 4330, examples 216500, loss = 0.673652649 (127.121 examples/sec; 0.393 sec/batch)\n",
      "2019-03-16 23:24:46.377688: step 4340, examples 217000, loss = 0.715900242 (129.188 examples/sec; 0.387 sec/batch)\n",
      "2019-03-16 23:24:50.328992: step 4350, examples 217500, loss = 0.840034723 (124.789 examples/sec; 0.401 sec/batch)\n",
      "2019-03-16 23:24:54.147855: step 4360, examples 218000, loss = 0.691339493 (127.894 examples/sec; 0.391 sec/batch)\n",
      "2019-03-16 23:24:58.029966: step 4370, examples 218500, loss = 0.741065979 (133.319 examples/sec; 0.375 sec/batch)\n",
      "2019-03-16 23:25:01.901175: step 4380, examples 219000, loss = 0.737031221 (134.126 examples/sec; 0.373 sec/batch)\n",
      "2019-03-16 23:25:05.778449: step 4390, examples 219500, loss = 0.709145486 (136.716 examples/sec; 0.366 sec/batch)\n",
      "2019-03-16 23:25:09.655274: step 4400, examples 220000, loss = 0.659505308 (123.500 examples/sec; 0.405 sec/batch)\n",
      "Top 1 validation accuracy: 0.6061320900917053 and top 2 validation accuracy: 0.7924528121948242\n",
      "Model Saved!\n",
      "2019-03-16 23:25:15.834027: step 4410, examples 220500, loss = 0.890731156 (128.558 examples/sec; 0.389 sec/batch)\n",
      "2019-03-16 23:25:19.732484: step 4420, examples 221000, loss = 0.601950228 (126.127 examples/sec; 0.396 sec/batch)\n",
      "2019-03-16 23:25:23.574559: step 4430, examples 221500, loss = 0.813985348 (131.600 examples/sec; 0.380 sec/batch)\n",
      "2019-03-16 23:25:27.465667: step 4440, examples 222000, loss = 0.658935249 (136.442 examples/sec; 0.366 sec/batch)\n",
      "2019-03-16 23:25:31.336096: step 4450, examples 222500, loss = 0.758601844 (126.188 examples/sec; 0.396 sec/batch)\n",
      "2019-03-16 23:25:35.262272: step 4460, examples 223000, loss = 0.736724854 (117.037 examples/sec; 0.427 sec/batch)\n",
      "2019-03-16 23:25:39.161911: step 4470, examples 223500, loss = 0.825601816 (129.077 examples/sec; 0.387 sec/batch)\n",
      "2019-03-16 23:25:43.076359: step 4480, examples 224000, loss = 0.629179239 (125.207 examples/sec; 0.399 sec/batch)\n",
      "2019-03-16 23:25:46.987562: step 4490, examples 224500, loss = 0.755495369 (127.986 examples/sec; 0.391 sec/batch)\n",
      "2019-03-16 23:25:50.900242: step 4500, examples 225000, loss = 0.704171419 (125.236 examples/sec; 0.399 sec/batch)\n",
      "Top 1 validation accuracy: 0.6132075190544128 and top 2 validation accuracy: 0.8325471878051758\n",
      "Model Saved!\n",
      "2019-03-16 23:25:56.983650: step 4510, examples 225500, loss = 0.799167156 (123.064 examples/sec; 0.406 sec/batch)\n",
      "2019-03-16 23:26:00.818282: step 4520, examples 226000, loss = 0.688860178 (134.011 examples/sec; 0.373 sec/batch)\n",
      "2019-03-16 23:26:04.677739: step 4530, examples 226500, loss = 0.931770086 (127.215 examples/sec; 0.393 sec/batch)\n",
      "2019-03-16 23:26:08.599387: step 4540, examples 227000, loss = 0.782212019 (133.569 examples/sec; 0.374 sec/batch)\n",
      "2019-03-16 23:26:12.511785: step 4550, examples 227500, loss = 0.794090569 (124.170 examples/sec; 0.403 sec/batch)\n",
      "2019-03-16 23:26:16.460960: step 4560, examples 228000, loss = 0.659100831 (133.732 examples/sec; 0.374 sec/batch)\n",
      "2019-03-16 23:26:20.289603: step 4570, examples 228500, loss = 0.666750431 (134.322 examples/sec; 0.372 sec/batch)\n",
      "2019-03-16 23:26:24.269725: step 4580, examples 229000, loss = 0.835579574 (128.792 examples/sec; 0.388 sec/batch)\n",
      "2019-03-16 23:26:28.163141: step 4590, examples 229500, loss = 0.690414906 (128.434 examples/sec; 0.389 sec/batch)\n",
      "2019-03-16 23:26:32.068608: step 4600, examples 230000, loss = 0.732089818 (129.773 examples/sec; 0.385 sec/batch)\n",
      "Top 1 validation accuracy: 0.6226415038108826 and top 2 validation accuracy: 0.8325471878051758\n",
      "Model Saved!\n",
      "2019-03-16 23:26:38.129282: step 4610, examples 230500, loss = 0.723429680 (120.792 examples/sec; 0.414 sec/batch)\n",
      "2019-03-16 23:26:42.076227: step 4620, examples 231000, loss = 0.624537528 (125.682 examples/sec; 0.398 sec/batch)\n",
      "2019-03-16 23:26:45.946870: step 4630, examples 231500, loss = 0.740489006 (126.993 examples/sec; 0.394 sec/batch)\n",
      "2019-03-16 23:26:49.834203: step 4640, examples 232000, loss = 0.755741835 (128.628 examples/sec; 0.389 sec/batch)\n",
      "2019-03-16 23:26:53.767571: step 4650, examples 232500, loss = 0.823456764 (131.610 examples/sec; 0.380 sec/batch)\n",
      "2019-03-16 23:26:57.717573: step 4660, examples 233000, loss = 0.685170949 (126.261 examples/sec; 0.396 sec/batch)\n",
      "2019-03-16 23:27:01.521126: step 4670, examples 233500, loss = 0.718133152 (128.972 examples/sec; 0.388 sec/batch)\n",
      "2019-03-16 23:27:05.392352: step 4680, examples 234000, loss = 0.585975230 (126.770 examples/sec; 0.394 sec/batch)\n",
      "2019-03-16 23:27:09.318783: step 4690, examples 234500, loss = 1.054823518 (123.602 examples/sec; 0.405 sec/batch)\n",
      "2019-03-16 23:27:13.233388: step 4700, examples 235000, loss = 0.747380078 (127.720 examples/sec; 0.391 sec/batch)\n",
      "Top 1 validation accuracy: 0.5849056839942932 and top 2 validation accuracy: 0.7853773832321167\n",
      "Model Saved!\n",
      "2019-03-16 23:27:19.383214: step 4710, examples 235500, loss = 0.776539505 (127.545 examples/sec; 0.392 sec/batch)\n",
      "2019-03-16 23:27:23.293306: step 4720, examples 236000, loss = 0.844017923 (126.084 examples/sec; 0.397 sec/batch)\n",
      "2019-03-16 23:27:27.127416: step 4730, examples 236500, loss = 0.796018362 (130.717 examples/sec; 0.383 sec/batch)\n",
      "2019-03-16 23:27:30.997511: step 4740, examples 237000, loss = 0.609613717 (127.987 examples/sec; 0.391 sec/batch)\n",
      "2019-03-16 23:27:34.847806: step 4750, examples 237500, loss = 0.762553930 (129.201 examples/sec; 0.387 sec/batch)\n",
      "2019-03-16 23:27:38.745601: step 4760, examples 238000, loss = 0.691355705 (122.274 examples/sec; 0.409 sec/batch)\n",
      "2019-03-16 23:27:42.630205: step 4770, examples 238500, loss = 0.775335073 (132.805 examples/sec; 0.376 sec/batch)\n",
      "2019-03-16 23:27:46.665398: step 4780, examples 239000, loss = 0.804377854 (121.401 examples/sec; 0.412 sec/batch)\n",
      "2019-03-16 23:27:50.582444: step 4790, examples 239500, loss = 0.589338303 (128.032 examples/sec; 0.391 sec/batch)\n",
      "2019-03-16 23:27:54.444887: step 4800, examples 240000, loss = 0.854043007 (128.644 examples/sec; 0.389 sec/batch)\n",
      "Top 1 validation accuracy: 0.6084905862808228 and top 2 validation accuracy: 0.801886796951294\n",
      "Model Saved!\n",
      "2019-03-16 23:28:00.583994: step 4810, examples 240500, loss = 0.804907978 (127.299 examples/sec; 0.393 sec/batch)\n",
      "2019-03-16 23:28:04.481054: step 4820, examples 241000, loss = 0.815537274 (130.022 examples/sec; 0.385 sec/batch)\n",
      "2019-03-16 23:28:08.336417: step 4830, examples 241500, loss = 0.887703657 (131.407 examples/sec; 0.380 sec/batch)\n",
      "2019-03-16 23:28:12.177749: step 4840, examples 242000, loss = 0.841228306 (134.929 examples/sec; 0.371 sec/batch)\n",
      "2019-03-16 23:28:16.084621: step 4850, examples 242500, loss = 0.853220642 (127.738 examples/sec; 0.391 sec/batch)\n",
      "2019-03-16 23:28:19.959483: step 4860, examples 243000, loss = 0.851361454 (127.986 examples/sec; 0.391 sec/batch)\n",
      "2019-03-16 23:28:23.867076: step 4870, examples 243500, loss = 0.769539356 (123.138 examples/sec; 0.406 sec/batch)\n",
      "2019-03-16 23:28:27.758129: step 4880, examples 244000, loss = 0.645554125 (131.674 examples/sec; 0.380 sec/batch)\n",
      "2019-03-16 23:28:31.703653: step 4890, examples 244500, loss = 0.522866905 (119.323 examples/sec; 0.419 sec/batch)\n",
      "2019-03-16 23:28:35.519186: step 4900, examples 245000, loss = 0.696218789 (129.754 examples/sec; 0.385 sec/batch)\n",
      "Top 1 validation accuracy: 0.6061320900917053 and top 2 validation accuracy: 0.8113207817077637\n",
      "Model Saved!\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2019-03-16 23:28:41.525545: step 4910, examples 245500, loss = 0.713693380 (128.563 examples/sec; 0.389 sec/batch)\n",
      "2019-03-16 23:28:45.415707: step 4920, examples 246000, loss = 0.895600319 (125.989 examples/sec; 0.397 sec/batch)\n",
      "2019-03-16 23:28:49.336310: step 4930, examples 246500, loss = 0.939253807 (132.613 examples/sec; 0.377 sec/batch)\n",
      "2019-03-16 23:28:53.199654: step 4940, examples 247000, loss = 0.689356387 (128.087 examples/sec; 0.390 sec/batch)\n",
      "2019-03-16 23:28:57.109599: step 4950, examples 247500, loss = 0.732365310 (132.192 examples/sec; 0.378 sec/batch)\n",
      "2019-03-16 23:29:01.033884: step 4960, examples 248000, loss = 0.738477468 (127.986 examples/sec; 0.391 sec/batch)\n",
      "2019-03-16 23:29:04.977603: step 4970, examples 248500, loss = 0.672557771 (127.986 examples/sec; 0.391 sec/batch)\n",
      "2019-03-16 23:29:08.823221: step 4980, examples 249000, loss = 0.691747367 (130.102 examples/sec; 0.384 sec/batch)\n",
      "2019-03-16 23:29:12.699000: step 4990, examples 249500, loss = 0.718720675 (135.622 examples/sec; 0.369 sec/batch)\n",
      "Top 1 validation accuracy: 0.5966981053352356 and top 2 validation accuracy: 0.7900943160057068\n",
      "Model Saved!\n",
      "Loading datasets...\n",
      "Dataset loading completes.\n",
      "2019-03-16 23:29:21.677921: step 0, examples 0, loss = 1.418526173 (85.652 examples/sec; 0.584 sec/batch)\n",
      "Top 1 validation accuracy: 0.2358490526676178 and top 2 validation accuracy: 0.4716981053352356\n",
      "Model Saved!\n",
      "2019-03-16 23:29:26.145050: step 10, examples 500, loss = 1.436590910 (181.988 examples/sec; 0.275 sec/batch)\n",
      "2019-03-16 23:29:28.661362: step 20, examples 1000, loss = 1.412230372 (201.085 examples/sec; 0.249 sec/batch)\n",
      "2019-03-16 23:29:31.177908: step 30, examples 1500, loss = 1.403268576 (188.449 examples/sec; 0.265 sec/batch)\n",
      "2019-03-16 23:29:33.709393: step 40, examples 2000, loss = 1.378118992 (201.589 examples/sec; 0.248 sec/batch)\n",
      "2019-03-16 23:29:36.399507: step 50, examples 2500, loss = 1.407337904 (187.629 examples/sec; 0.266 sec/batch)\n",
      "2019-03-16 23:29:38.976715: step 60, examples 3000, loss = 1.383451462 (188.215 examples/sec; 0.266 sec/batch)\n",
      "2019-03-16 23:29:41.537795: step 70, examples 3500, loss = 1.412530899 (192.140 examples/sec; 0.260 sec/batch)\n",
      "2019-03-16 23:29:44.094900: step 80, examples 4000, loss = 1.384329081 (190.120 examples/sec; 0.263 sec/batch)\n",
      "2019-03-16 23:29:46.659600: step 90, examples 4500, loss = 1.301970005 (191.800 examples/sec; 0.261 sec/batch)\n",
      "2019-03-16 23:29:49.146261: step 100, examples 5000, loss = 1.322562695 (200.441 examples/sec; 0.249 sec/batch)\n",
      "Top 1 validation accuracy: 0.3113207519054413 and top 2 validation accuracy: 0.5707547068595886\n",
      "Model Saved!\n",
      "2019-03-16 23:29:53.599978: step 110, examples 5500, loss = 1.366247892 (202.126 examples/sec; 0.247 sec/batch)\n",
      "2019-03-16 23:29:56.109670: step 120, examples 6000, loss = 1.319895744 (205.050 examples/sec; 0.244 sec/batch)\n",
      "2019-03-16 23:29:58.661170: step 130, examples 6500, loss = 1.355113745 (196.718 examples/sec; 0.254 sec/batch)\n",
      "2019-03-16 23:30:01.178814: step 140, examples 7000, loss = 1.307402611 (199.723 examples/sec; 0.250 sec/batch)\n",
      "2019-03-16 23:30:03.753991: step 150, examples 7500, loss = 1.327690125 (191.268 examples/sec; 0.261 sec/batch)\n",
      "2019-03-16 23:30:06.300830: step 160, examples 8000, loss = 1.332042098 (201.745 examples/sec; 0.248 sec/batch)\n",
      "2019-03-16 23:30:08.892760: step 170, examples 8500, loss = 1.328681827 (199.977 examples/sec; 0.250 sec/batch)\n",
      "2019-03-16 23:30:11.433964: step 180, examples 9000, loss = 1.331235170 (194.465 examples/sec; 0.257 sec/batch)\n",
      "2019-03-16 23:30:13.964147: step 190, examples 9500, loss = 1.363731861 (199.976 examples/sec; 0.250 sec/batch)\n",
      "2019-03-16 23:30:16.537078: step 200, examples 10000, loss = 1.317811608 (198.446 examples/sec; 0.252 sec/batch)\n",
      "Top 1 validation accuracy: 0.36556604504585266 and top 2 validation accuracy: 0.6084905862808228\n",
      "Model Saved!\n",
      "2019-03-16 23:30:20.883198: step 210, examples 10500, loss = 1.324221611 (199.979 examples/sec; 0.250 sec/batch)\n",
      "2019-03-16 23:30:23.460825: step 220, examples 11000, loss = 1.348424911 (186.538 examples/sec; 0.268 sec/batch)\n",
      "2019-03-16 23:30:25.997497: step 230, examples 11500, loss = 1.228986621 (199.978 examples/sec; 0.250 sec/batch)\n",
      "2019-03-16 23:30:28.537535: step 240, examples 12000, loss = 1.304316759 (204.920 examples/sec; 0.244 sec/batch)\n",
      "2019-03-16 23:30:31.096316: step 250, examples 12500, loss = 1.321345091 (193.874 examples/sec; 0.258 sec/batch)\n",
      "2019-03-16 23:30:33.621719: step 260, examples 13000, loss = 1.276752472 (199.618 examples/sec; 0.250 sec/batch)\n",
      "2019-03-16 23:30:36.201367: step 270, examples 13500, loss = 1.291484118 (183.946 examples/sec; 0.272 sec/batch)\n",
      "2019-03-16 23:30:38.747303: step 280, examples 14000, loss = 1.325826168 (186.924 examples/sec; 0.267 sec/batch)\n",
      "2019-03-16 23:30:41.320932: step 290, examples 14500, loss = 1.235199451 (187.968 examples/sec; 0.266 sec/batch)\n",
      "2019-03-16 23:30:43.882032: step 300, examples 15000, loss = 1.219472885 (188.216 examples/sec; 0.266 sec/batch)\n",
      "Top 1 validation accuracy: 0.41273584961891174 and top 2 validation accuracy: 0.6603773832321167\n",
      "Model Saved!\n",
      "2019-03-16 23:30:48.213345: step 310, examples 15500, loss = 1.226119757 (198.778 examples/sec; 0.252 sec/batch)\n",
      "2019-03-16 23:30:50.731959: step 320, examples 16000, loss = 1.293363571 (202.586 examples/sec; 0.247 sec/batch)\n",
      "2019-03-16 23:30:53.336691: step 330, examples 16500, loss = 1.267954826 (190.613 examples/sec; 0.262 sec/batch)\n",
      "2019-03-16 23:30:55.822106: step 340, examples 17000, loss = 1.243057966 (206.789 examples/sec; 0.242 sec/batch)\n",
      "2019-03-16 23:30:58.306940: step 350, examples 17500, loss = 1.258786678 (203.503 examples/sec; 0.246 sec/batch)\n",
      "2019-03-16 23:31:00.802641: step 360, examples 18000, loss = 1.357854128 (188.216 examples/sec; 0.266 sec/batch)\n",
      "2019-03-16 23:31:03.352375: step 370, examples 18500, loss = 1.196566224 (195.284 examples/sec; 0.256 sec/batch)\n",
      "2019-03-16 23:31:05.905083: step 380, examples 19000, loss = 1.320930719 (194.640 examples/sec; 0.257 sec/batch)\n",
      "2019-03-16 23:31:08.460431: step 390, examples 19500, loss = 1.214027405 (207.623 examples/sec; 0.241 sec/batch)\n",
      "2019-03-16 23:31:11.012928: step 400, examples 20000, loss = 1.180701852 (188.215 examples/sec; 0.266 sec/batch)\n",
      "Top 1 validation accuracy: 0.48349055647850037 and top 2 validation accuracy: 0.7334905862808228\n",
      "Model Saved!\n",
      "2019-03-16 23:31:15.528647: step 410, examples 20500, loss = 1.150823355 (194.897 examples/sec; 0.257 sec/batch)\n",
      "2019-03-16 23:31:18.052656: step 420, examples 21000, loss = 1.186882496 (188.215 examples/sec; 0.266 sec/batch)\n",
      "2019-03-16 23:31:20.584536: step 430, examples 21500, loss = 1.043553591 (199.658 examples/sec; 0.250 sec/batch)\n",
      "2019-03-16 23:31:23.145820: step 440, examples 22000, loss = 1.124146104 (186.363 examples/sec; 0.268 sec/batch)\n",
      "2019-03-16 23:31:25.693953: step 450, examples 22500, loss = 1.239840865 (200.833 examples/sec; 0.249 sec/batch)\n",
      "2019-03-16 23:31:28.300766: step 460, examples 23000, loss = 1.109819412 (203.601 examples/sec; 0.246 sec/batch)\n",
      "2019-03-16 23:31:30.871509: step 470, examples 23500, loss = 1.207506418 (199.980 examples/sec; 0.250 sec/batch)\n",
      "2019-03-16 23:31:33.429882: step 480, examples 24000, loss = 1.190703273 (200.892 examples/sec; 0.249 sec/batch)\n",
      "2019-03-16 23:31:35.936778: step 490, examples 24500, loss = 1.083486915 (195.182 examples/sec; 0.256 sec/batch)\n",
      "2019-03-16 23:31:38.499173: step 500, examples 25000, loss = 1.158017159 (194.980 examples/sec; 0.256 sec/batch)\n",
      "Top 1 validation accuracy: 0.4716981053352356 and top 2 validation accuracy: 0.7264150977134705\n",
      "Model Saved!\n",
      "2019-03-16 23:31:42.840585: step 510, examples 25500, loss = 1.054112792 (188.215 examples/sec; 0.266 sec/batch)\n",
      "2019-03-16 23:31:45.476272: step 520, examples 26000, loss = 1.233098269 (191.701 examples/sec; 0.261 sec/batch)\n",
      "2019-03-16 23:31:47.994107: step 530, examples 26500, loss = 1.268844962 (199.977 examples/sec; 0.250 sec/batch)\n",
      "2019-03-16 23:31:50.532254: step 540, examples 27000, loss = 1.049585104 (185.481 examples/sec; 0.270 sec/batch)\n",
      "2019-03-16 23:31:53.089380: step 550, examples 27500, loss = 1.251204252 (196.956 examples/sec; 0.254 sec/batch)\n",
      "2019-03-16 23:31:55.589572: step 560, examples 28000, loss = 1.116067529 (201.961 examples/sec; 0.248 sec/batch)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2019-03-16 23:31:58.118233: step 570, examples 28500, loss = 1.123928070 (198.412 examples/sec; 0.252 sec/batch)\n",
      "2019-03-16 23:32:00.757141: step 580, examples 29000, loss = 1.082607031 (203.235 examples/sec; 0.246 sec/batch)\n",
      "2019-03-16 23:32:03.285553: step 590, examples 29500, loss = 1.054560900 (202.516 examples/sec; 0.247 sec/batch)\n",
      "2019-03-16 23:32:05.846977: step 600, examples 30000, loss = 1.082872272 (199.978 examples/sec; 0.250 sec/batch)\n",
      "Top 1 validation accuracy: 0.49056604504585266 and top 2 validation accuracy: 0.724056601524353\n",
      "Model Saved!\n",
      "2019-03-16 23:32:10.084172: step 610, examples 30500, loss = 1.157353163 (193.954 examples/sec; 0.258 sec/batch)\n",
      "2019-03-16 23:32:12.652737: step 620, examples 31000, loss = 0.966989398 (180.077 examples/sec; 0.278 sec/batch)\n",
      "2019-03-16 23:32:15.215978: step 630, examples 31500, loss = 0.965412974 (173.960 examples/sec; 0.287 sec/batch)\n",
      "2019-03-16 23:32:17.787406: step 640, examples 32000, loss = 1.063314915 (199.978 examples/sec; 0.250 sec/batch)\n",
      "2019-03-16 23:32:20.320027: step 650, examples 32500, loss = 1.091170311 (194.382 examples/sec; 0.257 sec/batch)\n",
      "2019-03-16 23:32:22.871821: step 660, examples 33000, loss = 0.883960962 (199.978 examples/sec; 0.250 sec/batch)\n",
      "2019-03-16 23:32:25.393119: step 670, examples 33500, loss = 1.019997239 (200.541 examples/sec; 0.249 sec/batch)\n",
      "2019-03-16 23:32:27.885639: step 680, examples 34000, loss = 1.134451866 (213.309 examples/sec; 0.234 sec/batch)\n",
      "2019-03-16 23:32:30.461187: step 690, examples 34500, loss = 0.903880954 (205.725 examples/sec; 0.243 sec/batch)\n",
      "2019-03-16 23:32:33.053082: step 700, examples 35000, loss = 1.136269331 (188.215 examples/sec; 0.266 sec/batch)\n",
      "Top 1 validation accuracy: 0.5495283007621765 and top 2 validation accuracy: 0.7617924809455872\n",
      "Model Saved!\n",
      "2019-03-16 23:32:37.487289: step 710, examples 35500, loss = 1.139563084 (200.578 examples/sec; 0.249 sec/batch)\n",
      "2019-03-16 23:32:39.996867: step 720, examples 36000, loss = 0.954895973 (198.327 examples/sec; 0.252 sec/batch)\n",
      "2019-03-16 23:32:42.585930: step 730, examples 36500, loss = 1.143375158 (195.252 examples/sec; 0.256 sec/batch)\n",
      "2019-03-16 23:32:45.164469: step 740, examples 37000, loss = 1.164989352 (195.030 examples/sec; 0.256 sec/batch)\n",
      "2019-03-16 23:32:47.767185: step 750, examples 37500, loss = 1.029448509 (204.037 examples/sec; 0.245 sec/batch)\n",
      "2019-03-16 23:32:50.318253: step 760, examples 38000, loss = 1.036869645 (203.810 examples/sec; 0.245 sec/batch)\n",
      "2019-03-16 23:32:52.839249: step 770, examples 38500, loss = 1.048889041 (188.215 examples/sec; 0.266 sec/batch)\n",
      "2019-03-16 23:32:55.383067: step 780, examples 39000, loss = 1.142513514 (198.486 examples/sec; 0.252 sec/batch)\n",
      "2019-03-16 23:32:57.925845: step 790, examples 39500, loss = 0.959730148 (199.978 examples/sec; 0.250 sec/batch)\n",
      "2019-03-16 23:33:00.446321: step 800, examples 40000, loss = 0.966684341 (210.904 examples/sec; 0.237 sec/batch)\n",
      "Top 1 validation accuracy: 0.5377358198165894 and top 2 validation accuracy: 0.7641509175300598\n",
      "Model Saved!\n",
      "2019-03-16 23:33:04.819681: step 810, examples 40500, loss = 0.876242042 (188.216 examples/sec; 0.266 sec/batch)\n",
      "2019-03-16 23:33:07.336369: step 820, examples 41000, loss = 1.010032892 (206.655 examples/sec; 0.242 sec/batch)\n",
      "2019-03-16 23:33:09.911102: step 830, examples 41500, loss = 1.059672832 (199.979 examples/sec; 0.250 sec/batch)\n",
      "2019-03-16 23:33:12.436627: step 840, examples 42000, loss = 0.998294830 (205.943 examples/sec; 0.243 sec/batch)\n",
      "2019-03-16 23:33:14.991115: step 850, examples 42500, loss = 1.043312907 (177.760 examples/sec; 0.281 sec/batch)\n",
      "2019-03-16 23:33:17.525774: step 860, examples 43000, loss = 1.057825804 (193.407 examples/sec; 0.259 sec/batch)\n",
      "2019-03-16 23:33:20.080128: step 870, examples 43500, loss = 0.913575590 (183.656 examples/sec; 0.272 sec/batch)\n",
      "2019-03-16 23:33:22.648690: step 880, examples 44000, loss = 1.177389979 (200.486 examples/sec; 0.249 sec/batch)\n",
      "2019-03-16 23:33:25.162276: step 890, examples 44500, loss = 0.953269601 (200.636 examples/sec; 0.249 sec/batch)\n",
      "2019-03-16 23:33:27.711368: step 900, examples 45000, loss = 0.915181518 (201.137 examples/sec; 0.249 sec/batch)\n",
      "Top 1 validation accuracy: 0.5754716992378235 and top 2 validation accuracy: 0.7712264060974121\n",
      "Model Saved!\n",
      "2019-03-16 23:33:32.053459: step 910, examples 45500, loss = 0.934303164 (199.980 examples/sec; 0.250 sec/batch)\n",
      "2019-03-16 23:33:34.629426: step 920, examples 46000, loss = 1.003391743 (191.574 examples/sec; 0.261 sec/batch)\n",
      "2019-03-16 23:33:37.210092: step 930, examples 46500, loss = 0.969590545 (192.540 examples/sec; 0.260 sec/batch)\n",
      "2019-03-16 23:33:39.803236: step 940, examples 47000, loss = 1.093137980 (188.215 examples/sec; 0.266 sec/batch)\n",
      "2019-03-16 23:33:42.352142: step 950, examples 47500, loss = 0.899348021 (194.540 examples/sec; 0.257 sec/batch)\n",
      "2019-03-16 23:33:44.928501: step 960, examples 48000, loss = 0.870518386 (199.978 examples/sec; 0.250 sec/batch)\n",
      "2019-03-16 23:33:47.478997: step 970, examples 48500, loss = 0.888918996 (186.990 examples/sec; 0.267 sec/batch)\n",
      "2019-03-16 23:33:50.028818: step 980, examples 49000, loss = 1.121210933 (188.215 examples/sec; 0.266 sec/batch)\n",
      "2019-03-16 23:33:52.650596: step 990, examples 49500, loss = 1.002504110 (192.057 examples/sec; 0.260 sec/batch)\n",
      "2019-03-16 23:33:55.194189: step 1000, examples 50000, loss = 1.135627866 (200.254 examples/sec; 0.250 sec/batch)\n",
      "Top 1 validation accuracy: 0.5636792182922363 and top 2 validation accuracy: 0.7570754885673523\n",
      "Model Saved!\n",
      "2019-03-16 23:33:59.694230: step 1010, examples 50500, loss = 1.027551293 (197.100 examples/sec; 0.254 sec/batch)\n",
      "2019-03-16 23:34:02.217684: step 1020, examples 51000, loss = 0.817579269 (198.661 examples/sec; 0.252 sec/batch)\n",
      "2019-03-16 23:34:04.772082: step 1030, examples 51500, loss = 0.923828602 (213.307 examples/sec; 0.234 sec/batch)\n",
      "2019-03-16 23:34:07.336199: step 1040, examples 52000, loss = 0.842963755 (193.749 examples/sec; 0.258 sec/batch)\n",
      "2019-03-16 23:34:09.885591: step 1050, examples 52500, loss = 0.884892821 (199.979 examples/sec; 0.250 sec/batch)\n",
      "2019-03-16 23:34:12.426717: step 1060, examples 53000, loss = 0.984175563 (189.055 examples/sec; 0.264 sec/batch)\n",
      "2019-03-16 23:34:14.950356: step 1070, examples 53500, loss = 0.941782236 (199.979 examples/sec; 0.250 sec/batch)\n",
      "2019-03-16 23:34:17.495567: step 1080, examples 54000, loss = 1.002619267 (203.883 examples/sec; 0.245 sec/batch)\n",
      "2019-03-16 23:34:20.043972: step 1090, examples 54500, loss = 0.976569533 (199.980 examples/sec; 0.250 sec/batch)\n",
      "2019-03-16 23:34:22.568493: step 1100, examples 55000, loss = 0.842631221 (183.775 examples/sec; 0.272 sec/batch)\n",
      "Top 1 validation accuracy: 0.5495283007621765 and top 2 validation accuracy: 0.7617924809455872\n",
      "Model Saved!\n",
      "2019-03-16 23:34:26.856106: step 1110, examples 55500, loss = 1.036213517 (213.311 examples/sec; 0.234 sec/batch)\n",
      "2019-03-16 23:34:29.398921: step 1120, examples 56000, loss = 0.949077308 (197.943 examples/sec; 0.253 sec/batch)\n",
      "2019-03-16 23:34:31.949185: step 1130, examples 56500, loss = 0.780366182 (199.978 examples/sec; 0.250 sec/batch)\n",
      "2019-03-16 23:34:34.477382: step 1140, examples 57000, loss = 0.991082191 (199.606 examples/sec; 0.250 sec/batch)\n",
      "2019-03-16 23:34:37.053481: step 1150, examples 57500, loss = 0.982722163 (188.217 examples/sec; 0.266 sec/batch)\n",
      "2019-03-16 23:34:39.644768: step 1160, examples 58000, loss = 1.059713364 (191.440 examples/sec; 0.261 sec/batch)\n",
      "2019-03-16 23:34:42.209824: step 1170, examples 58500, loss = 0.905786276 (188.486 examples/sec; 0.265 sec/batch)\n",
      "2019-03-16 23:34:44.719713: step 1180, examples 59000, loss = 0.973614335 (186.687 examples/sec; 0.268 sec/batch)\n",
      "2019-03-16 23:34:47.258755: step 1190, examples 59500, loss = 0.790271282 (195.731 examples/sec; 0.255 sec/batch)\n",
      "2019-03-16 23:34:49.787143: step 1200, examples 60000, loss = 1.008406758 (199.978 examples/sec; 0.250 sec/batch)\n",
      "Top 1 validation accuracy: 0.5495283007621765 and top 2 validation accuracy: 0.7594339847564697\n",
      "Model Saved!\n",
      "2019-03-16 23:34:54.168521: step 1210, examples 60500, loss = 0.883812904 (194.031 examples/sec; 0.258 sec/batch)\n",
      "2019-03-16 23:34:56.803008: step 1220, examples 61000, loss = 0.873237550 (213.311 examples/sec; 0.234 sec/batch)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2019-03-16 23:34:59.384924: step 1230, examples 61500, loss = 0.886484921 (205.998 examples/sec; 0.243 sec/batch)\n",
      "2019-03-16 23:35:01.946825: step 1240, examples 62000, loss = 0.978228688 (199.977 examples/sec; 0.250 sec/batch)\n",
      "2019-03-16 23:35:04.516778: step 1250, examples 62500, loss = 0.974439025 (190.296 examples/sec; 0.263 sec/batch)\n",
      "2019-03-16 23:35:07.021651: step 1260, examples 63000, loss = 0.943195581 (188.217 examples/sec; 0.266 sec/batch)\n",
      "2019-03-16 23:35:09.531589: step 1270, examples 63500, loss = 0.878289640 (197.026 examples/sec; 0.254 sec/batch)\n",
      "2019-03-16 23:35:12.162551: step 1280, examples 64000, loss = 0.856292725 (194.986 examples/sec; 0.256 sec/batch)\n",
      "2019-03-16 23:35:14.680010: step 1290, examples 64500, loss = 0.855582356 (210.981 examples/sec; 0.237 sec/batch)\n",
      "2019-03-16 23:35:17.249359: step 1300, examples 65000, loss = 0.793148518 (191.980 examples/sec; 0.260 sec/batch)\n",
      "Top 1 validation accuracy: 0.5660377144813538 and top 2 validation accuracy: 0.7735849022865295\n",
      "Model Saved!\n",
      "2019-03-16 23:35:21.552679: step 1310, examples 65500, loss = 0.845763206 (208.792 examples/sec; 0.239 sec/batch)\n",
      "2019-03-16 23:35:24.100807: step 1320, examples 66000, loss = 1.009689808 (194.613 examples/sec; 0.257 sec/batch)\n",
      "2019-03-16 23:35:26.599584: step 1330, examples 66500, loss = 0.900996208 (201.891 examples/sec; 0.248 sec/batch)\n",
      "2019-03-16 23:35:29.164705: step 1340, examples 67000, loss = 0.812658250 (201.347 examples/sec; 0.248 sec/batch)\n",
      "2019-03-16 23:35:31.703451: step 1350, examples 67500, loss = 1.064146876 (193.807 examples/sec; 0.258 sec/batch)\n",
      "2019-03-16 23:35:34.270214: step 1360, examples 68000, loss = 0.865107954 (202.204 examples/sec; 0.247 sec/batch)\n",
      "2019-03-16 23:35:36.773042: step 1370, examples 68500, loss = 0.850655138 (213.308 examples/sec; 0.234 sec/batch)\n",
      "2019-03-16 23:35:39.291231: step 1380, examples 69000, loss = 0.704752982 (220.015 examples/sec; 0.227 sec/batch)\n",
      "2019-03-16 23:35:41.836664: step 1390, examples 69500, loss = 0.913325429 (188.214 examples/sec; 0.266 sec/batch)\n",
      "2019-03-16 23:35:44.480653: step 1400, examples 70000, loss = 0.708971858 (195.576 examples/sec; 0.256 sec/batch)\n",
      "Top 1 validation accuracy: 0.5778301954269409 and top 2 validation accuracy: 0.775943398475647\n",
      "Model Saved!\n",
      "2019-03-16 23:35:48.940389: step 1410, examples 70500, loss = 0.819350481 (199.978 examples/sec; 0.250 sec/batch)\n",
      "2019-03-16 23:35:51.461244: step 1420, examples 71000, loss = 0.760004163 (199.082 examples/sec; 0.251 sec/batch)\n",
      "2019-03-16 23:35:53.997690: step 1430, examples 71500, loss = 0.868427515 (199.976 examples/sec; 0.250 sec/batch)\n",
      "2019-03-16 23:35:56.537814: step 1440, examples 72000, loss = 0.842801213 (205.153 examples/sec; 0.244 sec/batch)\n",
      "2019-03-16 23:35:59.084545: step 1450, examples 72500, loss = 0.928931713 (183.286 examples/sec; 0.273 sec/batch)\n",
      "2019-03-16 23:36:01.650481: step 1460, examples 73000, loss = 0.828667223 (198.492 examples/sec; 0.252 sec/batch)\n",
      "2019-03-16 23:36:04.173704: step 1470, examples 73500, loss = 0.705584407 (194.393 examples/sec; 0.257 sec/batch)\n",
      "2019-03-16 23:36:06.730182: step 1480, examples 74000, loss = 0.791687489 (201.090 examples/sec; 0.249 sec/batch)\n",
      "2019-03-16 23:36:09.256579: step 1490, examples 74500, loss = 0.767199516 (213.144 examples/sec; 0.235 sec/batch)\n",
      "2019-03-16 23:36:11.803356: step 1500, examples 75000, loss = 0.916641474 (188.215 examples/sec; 0.266 sec/batch)\n",
      "Top 1 validation accuracy: 0.5330188870429993 and top 2 validation accuracy: 0.75\n",
      "Model Saved!\n",
      "2019-03-16 23:36:16.215355: step 1510, examples 75500, loss = 0.858645201 (195.264 examples/sec; 0.256 sec/batch)\n",
      "2019-03-16 23:36:18.724916: step 1520, examples 76000, loss = 0.760977805 (202.530 examples/sec; 0.247 sec/batch)\n",
      "2019-03-16 23:36:21.253412: step 1530, examples 76500, loss = 0.859328568 (215.440 examples/sec; 0.232 sec/batch)\n",
      "2019-03-16 23:36:23.758270: step 1540, examples 77000, loss = 0.809129596 (208.994 examples/sec; 0.239 sec/batch)\n",
      "2019-03-16 23:36:26.351676: step 1550, examples 77500, loss = 0.938673019 (196.204 examples/sec; 0.255 sec/batch)\n",
      "2019-03-16 23:36:28.869637: step 1560, examples 78000, loss = 0.788498104 (199.978 examples/sec; 0.250 sec/batch)\n",
      "2019-03-16 23:36:31.434819: step 1570, examples 78500, loss = 0.731810629 (182.708 examples/sec; 0.274 sec/batch)\n",
      "2019-03-16 23:36:33.997394: step 1580, examples 79000, loss = 0.827900112 (199.978 examples/sec; 0.250 sec/batch)\n",
      "2019-03-16 23:36:36.532968: step 1590, examples 79500, loss = 0.791943073 (189.013 examples/sec; 0.265 sec/batch)\n",
      "2019-03-16 23:36:39.100359: step 1600, examples 80000, loss = 0.914548457 (191.040 examples/sec; 0.262 sec/batch)\n",
      "Top 1 validation accuracy: 0.599056601524353 and top 2 validation accuracy: 0.7948113083839417\n",
      "Model Saved!\n",
      "2019-03-16 23:36:43.600111: step 1610, examples 80500, loss = 0.798635244 (189.949 examples/sec; 0.263 sec/batch)\n",
      "2019-03-16 23:36:46.071984: step 1620, examples 81000, loss = 0.832922995 (199.065 examples/sec; 0.251 sec/batch)\n",
      "2019-03-16 23:36:48.589228: step 1630, examples 81500, loss = 0.917745233 (197.848 examples/sec; 0.253 sec/batch)\n",
      "2019-03-16 23:36:51.085278: step 1640, examples 82000, loss = 0.866849542 (189.221 examples/sec; 0.264 sec/batch)\n",
      "2019-03-16 23:36:53.610488: step 1650, examples 82500, loss = 0.795279622 (209.925 examples/sec; 0.238 sec/batch)\n",
      "2019-03-16 23:36:56.146920: step 1660, examples 83000, loss = 0.788695812 (195.284 examples/sec; 0.256 sec/batch)\n",
      "2019-03-16 23:36:58.726895: step 1670, examples 83500, loss = 0.884019732 (199.978 examples/sec; 0.250 sec/batch)\n",
      "2019-03-16 23:37:01.284936: step 1680, examples 84000, loss = 1.095462799 (202.352 examples/sec; 0.247 sec/batch)\n",
      "2019-03-16 23:37:03.902213: step 1690, examples 84500, loss = 0.989070058 (213.312 examples/sec; 0.234 sec/batch)\n",
      "2019-03-16 23:37:06.460534: step 1700, examples 85000, loss = 0.921329618 (199.198 examples/sec; 0.251 sec/batch)\n",
      "Top 1 validation accuracy: 0.5589622855186462 and top 2 validation accuracy: 0.8113207817077637\n",
      "Model Saved!\n",
      "2019-03-16 23:37:10.812099: step 1710, examples 85500, loss = 0.852381110 (199.980 examples/sec; 0.250 sec/batch)\n",
      "2019-03-16 23:37:13.418036: step 1720, examples 86000, loss = 1.045121789 (183.923 examples/sec; 0.272 sec/batch)\n",
      "2019-03-16 23:37:15.932299: step 1730, examples 86500, loss = 0.846147656 (213.312 examples/sec; 0.234 sec/batch)\n",
      "2019-03-16 23:37:18.498375: step 1740, examples 87000, loss = 0.821910262 (203.684 examples/sec; 0.245 sec/batch)\n",
      "2019-03-16 23:37:21.103506: step 1750, examples 87500, loss = 0.809289098 (209.148 examples/sec; 0.239 sec/batch)\n",
      "2019-03-16 23:37:23.664979: step 1760, examples 88000, loss = 0.848388731 (194.343 examples/sec; 0.257 sec/batch)\n",
      "2019-03-16 23:37:26.247369: step 1770, examples 88500, loss = 0.810185492 (181.582 examples/sec; 0.275 sec/batch)\n",
      "2019-03-16 23:37:28.766403: step 1780, examples 89000, loss = 0.855029941 (191.047 examples/sec; 0.262 sec/batch)\n",
      "2019-03-16 23:37:31.306823: step 1790, examples 89500, loss = 0.784642160 (185.838 examples/sec; 0.269 sec/batch)\n",
      "2019-03-16 23:37:33.874698: step 1800, examples 90000, loss = 0.948954105 (188.217 examples/sec; 0.266 sec/batch)\n",
      "Top 1 validation accuracy: 0.5636792182922363 and top 2 validation accuracy: 0.7948113083839417\n",
      "Model Saved!\n",
      "2019-03-16 23:37:38.203952: step 1810, examples 90500, loss = 0.749047339 (191.407 examples/sec; 0.261 sec/batch)\n",
      "2019-03-16 23:37:40.709451: step 1820, examples 91000, loss = 0.785060406 (206.118 examples/sec; 0.243 sec/batch)\n",
      "2019-03-16 23:37:43.231086: step 1830, examples 91500, loss = 0.797057867 (186.475 examples/sec; 0.268 sec/batch)\n",
      "2019-03-16 23:37:45.802879: step 1840, examples 92000, loss = 1.001027465 (198.020 examples/sec; 0.253 sec/batch)\n",
      "2019-03-16 23:37:48.367701: step 1850, examples 92500, loss = 0.882784784 (189.001 examples/sec; 0.265 sec/batch)\n",
      "2019-03-16 23:37:50.897152: step 1860, examples 93000, loss = 0.825720608 (188.215 examples/sec; 0.266 sec/batch)\n",
      "2019-03-16 23:37:53.491992: step 1870, examples 93500, loss = 0.876783967 (196.845 examples/sec; 0.254 sec/batch)\n",
      "2019-03-16 23:37:56.025937: step 1880, examples 94000, loss = 0.807547748 (199.980 examples/sec; 0.250 sec/batch)\n",
      "2019-03-16 23:37:58.535870: step 1890, examples 94500, loss = 0.883463144 (210.570 examples/sec; 0.237 sec/batch)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2019-03-16 23:38:01.052566: step 1900, examples 95000, loss = 0.893579721 (199.977 examples/sec; 0.250 sec/batch)\n",
      "Top 1 validation accuracy: 0.525943398475647 and top 2 validation accuracy: 0.8136792182922363\n",
      "Model Saved!\n",
      "2019-03-16 23:38:05.445196: step 1910, examples 95500, loss = 0.814965010 (200.257 examples/sec; 0.250 sec/batch)\n",
      "2019-03-16 23:38:08.070365: step 1920, examples 96000, loss = 1.013068438 (176.417 examples/sec; 0.283 sec/batch)\n",
      "2019-03-16 23:38:10.599566: step 1930, examples 96500, loss = 0.805203378 (190.364 examples/sec; 0.263 sec/batch)\n",
      "2019-03-16 23:38:13.119676: step 1940, examples 97000, loss = 1.025690794 (197.177 examples/sec; 0.254 sec/batch)\n",
      "2019-03-16 23:38:15.719824: step 1950, examples 97500, loss = 0.904920459 (193.636 examples/sec; 0.258 sec/batch)\n",
      "2019-03-16 23:38:18.252809: step 1960, examples 98000, loss = 0.905232430 (194.751 examples/sec; 0.257 sec/batch)\n",
      "2019-03-16 23:38:20.818424: step 1970, examples 98500, loss = 0.911678672 (188.215 examples/sec; 0.266 sec/batch)\n",
      "2019-03-16 23:38:23.406380: step 1980, examples 99000, loss = 0.687428355 (186.900 examples/sec; 0.268 sec/batch)\n",
      "2019-03-16 23:38:26.068448: step 1990, examples 99500, loss = 0.986505628 (188.162 examples/sec; 0.266 sec/batch)\n",
      "2019-03-16 23:38:28.616057: step 2000, examples 100000, loss = 0.781330466 (203.726 examples/sec; 0.245 sec/batch)\n",
      "Top 1 validation accuracy: 0.5754716992378235 and top 2 validation accuracy: 0.7806603908538818\n",
      "Model Saved!\n",
      "2019-03-16 23:38:33.120800: step 2010, examples 100500, loss = 0.815258265 (195.531 examples/sec; 0.256 sec/batch)\n",
      "2019-03-16 23:38:35.635739: step 2020, examples 101000, loss = 0.635581613 (197.840 examples/sec; 0.253 sec/batch)\n",
      "2019-03-16 23:38:38.200225: step 2030, examples 101500, loss = 0.733971477 (196.072 examples/sec; 0.255 sec/batch)\n",
      "2019-03-16 23:38:40.777063: step 2040, examples 102000, loss = 0.895403624 (201.374 examples/sec; 0.248 sec/batch)\n",
      "2019-03-16 23:38:43.285322: step 2050, examples 102500, loss = 1.011927247 (196.499 examples/sec; 0.254 sec/batch)\n",
      "2019-03-16 23:38:45.787821: step 2060, examples 103000, loss = 0.686396301 (199.146 examples/sec; 0.251 sec/batch)\n",
      "2019-03-16 23:38:48.318740: step 2070, examples 103500, loss = 0.886585891 (210.430 examples/sec; 0.238 sec/batch)\n",
      "2019-03-16 23:38:50.817736: step 2080, examples 104000, loss = 0.786447883 (199.980 examples/sec; 0.250 sec/batch)\n",
      "2019-03-16 23:38:53.336780: step 2090, examples 104500, loss = 0.839125872 (201.253 examples/sec; 0.248 sec/batch)\n",
      "2019-03-16 23:38:55.926895: step 2100, examples 105000, loss = 0.866834760 (199.979 examples/sec; 0.250 sec/batch)\n",
      "Top 1 validation accuracy: 0.5849056839942932 and top 2 validation accuracy: 0.8066037893295288\n",
      "Model Saved!\n",
      "2019-03-16 23:39:00.254270: step 2110, examples 105500, loss = 0.803051114 (189.399 examples/sec; 0.264 sec/batch)\n",
      "2019-03-16 23:39:02.818906: step 2120, examples 106000, loss = 0.825249076 (199.974 examples/sec; 0.250 sec/batch)\n",
      "2019-03-16 23:39:05.403572: step 2130, examples 106500, loss = 0.782715201 (208.685 examples/sec; 0.240 sec/batch)\n",
      "2019-03-16 23:39:07.891331: step 2140, examples 107000, loss = 0.893469095 (213.310 examples/sec; 0.234 sec/batch)\n",
      "2019-03-16 23:39:10.445675: step 2150, examples 107500, loss = 0.600028992 (197.852 examples/sec; 0.253 sec/batch)\n",
      "2019-03-16 23:39:13.100039: step 2160, examples 108000, loss = 0.808549404 (177.541 examples/sec; 0.282 sec/batch)\n",
      "2019-03-16 23:39:15.678213: step 2170, examples 108500, loss = 0.884484053 (197.549 examples/sec; 0.253 sec/batch)\n",
      "2019-03-16 23:39:18.223873: step 2180, examples 109000, loss = 0.751535535 (190.852 examples/sec; 0.262 sec/batch)\n",
      "2019-03-16 23:39:20.756138: step 2190, examples 109500, loss = 1.050796270 (206.611 examples/sec; 0.242 sec/batch)\n",
      "2019-03-16 23:39:23.277738: step 2200, examples 110000, loss = 0.826095462 (195.569 examples/sec; 0.256 sec/batch)\n",
      "Top 1 validation accuracy: 0.5636792182922363 and top 2 validation accuracy: 0.7995283007621765\n",
      "Model Saved!\n",
      "2019-03-16 23:39:27.673096: step 2210, examples 110500, loss = 0.753314734 (189.651 examples/sec; 0.264 sec/batch)\n",
      "2019-03-16 23:39:30.216232: step 2220, examples 111000, loss = 0.875563383 (202.280 examples/sec; 0.247 sec/batch)\n",
      "2019-03-16 23:39:32.771789: step 2230, examples 111500, loss = 0.891276717 (194.592 examples/sec; 0.257 sec/batch)\n",
      "2019-03-16 23:39:35.292610: step 2240, examples 112000, loss = 0.836727440 (196.173 examples/sec; 0.255 sec/batch)\n",
      "2019-03-16 23:39:37.856479: step 2250, examples 112500, loss = 0.898574471 (199.980 examples/sec; 0.250 sec/batch)\n",
      "2019-03-16 23:39:40.385900: step 2260, examples 113000, loss = 0.901560068 (192.534 examples/sec; 0.260 sec/batch)\n",
      "2019-03-16 23:39:42.952190: step 2270, examples 113500, loss = 0.865194678 (188.217 examples/sec; 0.266 sec/batch)\n",
      "2019-03-16 23:39:45.587419: step 2280, examples 114000, loss = 0.902322352 (196.326 examples/sec; 0.255 sec/batch)\n",
      "2019-03-16 23:39:48.115524: step 2290, examples 114500, loss = 0.904843569 (188.056 examples/sec; 0.266 sec/batch)\n",
      "2019-03-16 23:39:50.639809: step 2300, examples 115000, loss = 0.922316253 (187.018 examples/sec; 0.267 sec/batch)\n",
      "Top 1 validation accuracy: 0.5919811129570007 and top 2 validation accuracy: 0.8113207817077637\n",
      "Model Saved!\n",
      "2019-03-16 23:39:55.077998: step 2310, examples 115500, loss = 0.824475110 (204.813 examples/sec; 0.244 sec/batch)\n",
      "2019-03-16 23:39:57.632282: step 2320, examples 116000, loss = 0.756452501 (206.578 examples/sec; 0.242 sec/batch)\n",
      "2019-03-16 23:40:00.217171: step 2330, examples 116500, loss = 0.660636306 (194.371 examples/sec; 0.257 sec/batch)\n",
      "2019-03-16 23:40:02.747421: step 2340, examples 117000, loss = 0.755032778 (206.873 examples/sec; 0.242 sec/batch)\n",
      "2019-03-16 23:40:05.315737: step 2350, examples 117500, loss = 0.897930324 (196.763 examples/sec; 0.254 sec/batch)\n",
      "2019-03-16 23:40:07.840624: step 2360, examples 118000, loss = 0.937016726 (199.978 examples/sec; 0.250 sec/batch)\n",
      "2019-03-16 23:40:10.367945: step 2370, examples 118500, loss = 0.901122570 (186.884 examples/sec; 0.268 sec/batch)\n",
      "2019-03-16 23:40:12.907474: step 2380, examples 119000, loss = 0.743826032 (199.978 examples/sec; 0.250 sec/batch)\n",
      "2019-03-16 23:40:15.478073: step 2390, examples 119500, loss = 0.772907734 (193.626 examples/sec; 0.258 sec/batch)\n",
      "2019-03-16 23:40:17.934898: step 2400, examples 120000, loss = 0.659093738 (207.513 examples/sec; 0.241 sec/batch)\n",
      "Top 1 validation accuracy: 0.5849056839942932 and top 2 validation accuracy: 0.7853773832321167\n",
      "Model Saved!\n",
      "2019-03-16 23:40:22.323747: step 2410, examples 120500, loss = 0.912252665 (184.941 examples/sec; 0.270 sec/batch)\n",
      "2019-03-16 23:40:24.849568: step 2420, examples 121000, loss = 0.875906944 (188.216 examples/sec; 0.266 sec/batch)\n",
      "2019-03-16 23:40:27.368000: step 2430, examples 121500, loss = 0.895785809 (193.887 examples/sec; 0.258 sec/batch)\n",
      "2019-03-16 23:40:29.899034: step 2440, examples 122000, loss = 0.786608577 (199.980 examples/sec; 0.250 sec/batch)\n",
      "2019-03-16 23:40:32.492087: step 2450, examples 122500, loss = 0.688688099 (203.223 examples/sec; 0.246 sec/batch)\n",
      "2019-03-16 23:40:35.060532: step 2460, examples 123000, loss = 0.775716066 (187.394 examples/sec; 0.267 sec/batch)\n",
      "2019-03-16 23:40:37.590588: step 2470, examples 123500, loss = 0.919566035 (192.319 examples/sec; 0.260 sec/batch)\n",
      "2019-03-16 23:40:40.112221: step 2480, examples 124000, loss = 0.867586911 (205.896 examples/sec; 0.243 sec/batch)\n",
      "2019-03-16 23:40:42.649495: step 2490, examples 124500, loss = 0.784823596 (202.756 examples/sec; 0.247 sec/batch)\n",
      "2019-03-16 23:40:45.181094: step 2500, examples 125000, loss = 0.923679590 (197.733 examples/sec; 0.253 sec/batch)\n",
      "Top 1 validation accuracy: 0.5707547068595886 and top 2 validation accuracy: 0.7995283007621765\n",
      "Model Saved!\n",
      "2019-03-16 23:40:49.541620: step 2510, examples 125500, loss = 0.893582940 (198.374 examples/sec; 0.252 sec/batch)\n",
      "2019-03-16 23:40:52.083630: step 2520, examples 126000, loss = 0.711056113 (190.178 examples/sec; 0.263 sec/batch)\n",
      "2019-03-16 23:40:54.629801: step 2530, examples 126500, loss = 0.911330342 (196.477 examples/sec; 0.254 sec/batch)\n",
      "2019-03-16 23:40:57.146234: step 2540, examples 127000, loss = 0.653169632 (212.636 examples/sec; 0.235 sec/batch)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2019-03-16 23:40:59.681685: step 2550, examples 127500, loss = 0.745278716 (190.804 examples/sec; 0.262 sec/batch)\n",
      "2019-03-16 23:41:02.218169: step 2560, examples 128000, loss = 0.547921419 (198.573 examples/sec; 0.252 sec/batch)\n",
      "2019-03-16 23:41:04.818828: step 2570, examples 128500, loss = 0.651835322 (199.978 examples/sec; 0.250 sec/batch)\n",
      "2019-03-16 23:41:07.336698: step 2580, examples 129000, loss = 0.688754916 (203.302 examples/sec; 0.246 sec/batch)\n",
      "2019-03-16 23:41:09.889781: step 2590, examples 129500, loss = 0.754289985 (199.979 examples/sec; 0.250 sec/batch)\n",
      "2019-03-16 23:41:12.440142: step 2600, examples 130000, loss = 0.863612652 (190.112 examples/sec; 0.263 sec/batch)\n",
      "Top 1 validation accuracy: 0.6108490824699402 and top 2 validation accuracy: 0.7783018946647644\n",
      "Model Saved!\n",
      "2019-03-16 23:41:16.758337: step 2610, examples 130500, loss = 0.666969836 (213.966 examples/sec; 0.234 sec/batch)\n",
      "2019-03-16 23:41:19.336242: step 2620, examples 131000, loss = 0.940357685 (176.586 examples/sec; 0.283 sec/batch)\n",
      "2019-03-16 23:41:21.969906: step 2630, examples 131500, loss = 1.011289001 (199.979 examples/sec; 0.250 sec/batch)\n",
      "2019-03-16 23:41:24.552984: step 2640, examples 132000, loss = 0.868263602 (186.891 examples/sec; 0.268 sec/batch)\n",
      "2019-03-16 23:41:27.180856: step 2650, examples 132500, loss = 0.676460505 (177.206 examples/sec; 0.282 sec/batch)\n",
      "2019-03-16 23:41:29.711339: step 2660, examples 133000, loss = 0.809512496 (199.253 examples/sec; 0.251 sec/batch)\n",
      "2019-03-16 23:41:32.262885: step 2670, examples 133500, loss = 0.752846301 (196.416 examples/sec; 0.255 sec/batch)\n",
      "2019-03-16 23:41:34.818531: step 2680, examples 134000, loss = 0.870336294 (189.831 examples/sec; 0.263 sec/batch)\n",
      "2019-03-16 23:41:37.647120: step 2690, examples 134500, loss = 0.870742381 (182.834 examples/sec; 0.273 sec/batch)\n",
      "2019-03-16 23:41:40.329991: step 2700, examples 135000, loss = 0.816673756 (192.032 examples/sec; 0.260 sec/batch)\n",
      "Top 1 validation accuracy: 0.5896226167678833 and top 2 validation accuracy: 0.801886796951294\n",
      "Model Saved!\n",
      "2019-03-16 23:41:44.837540: step 2710, examples 135500, loss = 0.817485452 (199.981 examples/sec; 0.250 sec/batch)\n",
      "2019-03-16 23:41:47.509901: step 2720, examples 136000, loss = 0.800278068 (173.753 examples/sec; 0.288 sec/batch)\n",
      "2019-03-16 23:41:50.116584: step 2730, examples 136500, loss = 0.751013398 (187.829 examples/sec; 0.266 sec/batch)\n",
      "2019-03-16 23:41:52.881845: step 2740, examples 137000, loss = 0.813178360 (187.470 examples/sec; 0.267 sec/batch)\n",
      "2019-03-16 23:41:55.660370: step 2750, examples 137500, loss = 0.726084828 (197.778 examples/sec; 0.253 sec/batch)\n",
      "2019-03-16 23:41:58.252954: step 2760, examples 138000, loss = 0.749166250 (191.777 examples/sec; 0.261 sec/batch)\n",
      "2019-03-16 23:42:00.834505: step 2770, examples 138500, loss = 0.670110643 (199.978 examples/sec; 0.250 sec/batch)\n",
      "2019-03-16 23:42:03.421633: step 2780, examples 139000, loss = 0.772678196 (192.862 examples/sec; 0.259 sec/batch)\n",
      "2019-03-16 23:42:05.985073: step 2790, examples 139500, loss = 0.753061712 (199.981 examples/sec; 0.250 sec/batch)\n",
      "2019-03-16 23:42:08.584332: step 2800, examples 140000, loss = 0.677989841 (201.848 examples/sec; 0.248 sec/batch)\n",
      "Top 1 validation accuracy: 0.5943396091461182 and top 2 validation accuracy: 0.7971698045730591\n",
      "Model Saved!\n",
      "2019-03-16 23:42:12.894162: step 2810, examples 140500, loss = 0.801402748 (213.310 examples/sec; 0.234 sec/batch)\n",
      "2019-03-16 23:42:15.442639: step 2820, examples 141000, loss = 0.833258510 (188.445 examples/sec; 0.265 sec/batch)\n",
      "2019-03-16 23:42:17.999442: step 2830, examples 141500, loss = 0.735154629 (189.609 examples/sec; 0.264 sec/batch)\n",
      "2019-03-16 23:42:20.476723: step 2840, examples 142000, loss = 0.532234609 (216.606 examples/sec; 0.231 sec/batch)\n",
      "2019-03-16 23:42:23.039419: step 2850, examples 142500, loss = 0.918140471 (188.215 examples/sec; 0.266 sec/batch)\n",
      "2019-03-16 23:42:25.648001: step 2860, examples 143000, loss = 0.744992018 (201.766 examples/sec; 0.248 sec/batch)\n",
      "2019-03-16 23:42:28.225155: step 2870, examples 143500, loss = 0.684132934 (187.458 examples/sec; 0.267 sec/batch)\n",
      "2019-03-16 23:42:30.755662: step 2880, examples 144000, loss = 0.877582669 (205.017 examples/sec; 0.244 sec/batch)\n",
      "2019-03-16 23:42:33.234383: step 2890, examples 144500, loss = 0.761441648 (195.969 examples/sec; 0.255 sec/batch)\n",
      "2019-03-16 23:42:35.836257: step 2900, examples 145000, loss = 0.736263216 (198.674 examples/sec; 0.252 sec/batch)\n",
      "Top 1 validation accuracy: 0.5825471878051758 and top 2 validation accuracy: 0.775943398475647\n",
      "Model Saved!\n",
      "2019-03-16 23:42:40.384259: step 2910, examples 145500, loss = 0.823207140 (188.935 examples/sec; 0.265 sec/batch)\n",
      "2019-03-16 23:42:42.913895: step 2920, examples 146000, loss = 0.816977620 (188.216 examples/sec; 0.266 sec/batch)\n",
      "2019-03-16 23:42:45.445614: step 2930, examples 146500, loss = 0.730387151 (201.983 examples/sec; 0.248 sec/batch)\n",
      "2019-03-16 23:42:47.946640: step 2940, examples 147000, loss = 0.777465701 (213.310 examples/sec; 0.234 sec/batch)\n",
      "2019-03-16 23:42:50.482700: step 2950, examples 147500, loss = 0.790884376 (221.153 examples/sec; 0.226 sec/batch)\n",
      "2019-03-16 23:42:53.013300: step 2960, examples 148000, loss = 0.747367501 (199.977 examples/sec; 0.250 sec/batch)\n",
      "2019-03-16 23:42:55.637744: step 2970, examples 148500, loss = 0.850516915 (197.665 examples/sec; 0.253 sec/batch)\n",
      "2019-03-16 23:42:58.195758: step 2980, examples 149000, loss = 0.714571893 (201.514 examples/sec; 0.248 sec/batch)\n",
      "2019-03-16 23:43:00.724842: step 2990, examples 149500, loss = 0.981958747 (201.392 examples/sec; 0.248 sec/batch)\n",
      "2019-03-16 23:43:03.269356: step 3000, examples 150000, loss = 0.751958966 (203.319 examples/sec; 0.246 sec/batch)\n",
      "Top 1 validation accuracy: 0.5896226167678833 and top 2 validation accuracy: 0.8066037893295288\n",
      "Model Saved!\n",
      "2019-03-16 23:43:07.700209: step 3010, examples 150500, loss = 0.630269289 (192.467 examples/sec; 0.260 sec/batch)\n",
      "2019-03-16 23:43:10.257733: step 3020, examples 151000, loss = 0.701852977 (180.382 examples/sec; 0.277 sec/batch)\n",
      "2019-03-16 23:43:12.910206: step 3030, examples 151500, loss = 0.851908445 (199.978 examples/sec; 0.250 sec/batch)\n",
      "2019-03-16 23:43:15.444949: step 3040, examples 152000, loss = 0.763069034 (189.578 examples/sec; 0.264 sec/batch)\n",
      "2019-03-16 23:43:17.965373: step 3050, examples 152500, loss = 1.015311003 (199.978 examples/sec; 0.250 sec/batch)\n",
      "2019-03-16 23:43:20.481757: step 3060, examples 153000, loss = 0.851068735 (209.836 examples/sec; 0.238 sec/batch)\n",
      "2019-03-16 23:43:23.015137: step 3070, examples 153500, loss = 0.798180819 (199.978 examples/sec; 0.250 sec/batch)\n",
      "2019-03-16 23:43:25.525283: step 3080, examples 154000, loss = 0.680416942 (191.443 examples/sec; 0.261 sec/batch)\n",
      "2019-03-16 23:43:28.085927: step 3090, examples 154500, loss = 0.703710198 (192.071 examples/sec; 0.260 sec/batch)\n",
      "2019-03-16 23:43:30.615911: step 3100, examples 155000, loss = 0.805251241 (189.622 examples/sec; 0.264 sec/batch)\n",
      "Top 1 validation accuracy: 0.5660377144813538 and top 2 validation accuracy: 0.7806603908538818\n",
      "Model Saved!\n",
      "2019-03-16 23:43:34.961216: step 3110, examples 155500, loss = 0.924306035 (199.980 examples/sec; 0.250 sec/batch)\n",
      "2019-03-16 23:43:37.537707: step 3120, examples 156000, loss = 0.620623946 (202.779 examples/sec; 0.247 sec/batch)\n",
      "2019-03-16 23:43:40.046273: step 3130, examples 156500, loss = 0.716615140 (199.979 examples/sec; 0.250 sec/batch)\n",
      "2019-03-16 23:43:42.616306: step 3140, examples 157000, loss = 0.886459947 (191.110 examples/sec; 0.262 sec/batch)\n",
      "2019-03-16 23:43:45.394301: step 3150, examples 157500, loss = 0.744160771 (193.788 examples/sec; 0.258 sec/batch)\n",
      "2019-03-16 23:43:47.897262: step 3160, examples 158000, loss = 0.688573360 (199.978 examples/sec; 0.250 sec/batch)\n",
      "2019-03-16 23:43:50.438931: step 3170, examples 158500, loss = 0.833381653 (180.345 examples/sec; 0.277 sec/batch)\n",
      "2019-03-16 23:43:52.997081: step 3180, examples 159000, loss = 0.822719812 (199.114 examples/sec; 0.251 sec/batch)\n",
      "2019-03-16 23:43:55.553389: step 3190, examples 159500, loss = 0.658067703 (186.492 examples/sec; 0.268 sec/batch)\n",
      "2019-03-16 23:43:58.115881: step 3200, examples 160000, loss = 0.775391400 (199.425 examples/sec; 0.251 sec/batch)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Top 1 validation accuracy: 0.5825471878051758 and top 2 validation accuracy: 0.8089622855186462\n",
      "Model Saved!\n",
      "2019-03-16 23:44:02.680066: step 3210, examples 160500, loss = 0.659929752 (206.219 examples/sec; 0.242 sec/batch)\n",
      "2019-03-16 23:44:05.215318: step 3220, examples 161000, loss = 0.590038657 (193.058 examples/sec; 0.259 sec/batch)\n",
      "2019-03-16 23:44:07.756986: step 3230, examples 161500, loss = 0.707694888 (194.284 examples/sec; 0.257 sec/batch)\n",
      "2019-03-16 23:44:10.290591: step 3240, examples 162000, loss = 0.821186066 (202.017 examples/sec; 0.248 sec/batch)\n",
      "2019-03-16 23:44:12.838267: step 3250, examples 162500, loss = 0.722000718 (199.976 examples/sec; 0.250 sec/batch)\n",
      "2019-03-16 23:44:15.460794: step 3260, examples 163000, loss = 0.714790344 (179.841 examples/sec; 0.278 sec/batch)\n",
      "2019-03-16 23:44:17.996900: step 3270, examples 163500, loss = 0.694438815 (199.978 examples/sec; 0.250 sec/batch)\n",
      "2019-03-16 23:44:20.477337: step 3280, examples 164000, loss = 0.615845203 (187.049 examples/sec; 0.267 sec/batch)\n",
      "2019-03-16 23:44:22.997693: step 3290, examples 164500, loss = 0.601078033 (199.979 examples/sec; 0.250 sec/batch)\n",
      "2019-03-16 23:44:25.537062: step 3300, examples 165000, loss = 0.695541620 (200.997 examples/sec; 0.249 sec/batch)\n",
      "Top 1 validation accuracy: 0.6108490824699402 and top 2 validation accuracy: 0.8066037893295288\n",
      "Model Saved!\n",
      "2019-03-16 23:44:29.882442: step 3310, examples 165500, loss = 0.753911257 (213.312 examples/sec; 0.234 sec/batch)\n",
      "2019-03-16 23:44:32.460762: step 3320, examples 166000, loss = 0.699148595 (200.909 examples/sec; 0.249 sec/batch)\n",
      "2019-03-16 23:44:35.012863: step 3330, examples 166500, loss = 0.699547887 (188.215 examples/sec; 0.266 sec/batch)\n",
      "2019-03-16 23:44:37.667749: step 3340, examples 167000, loss = 0.874134898 (186.337 examples/sec; 0.268 sec/batch)\n",
      "2019-03-16 23:44:40.272879: step 3350, examples 167500, loss = 0.702891827 (184.244 examples/sec; 0.271 sec/batch)\n",
      "2019-03-16 23:44:42.803332: step 3360, examples 168000, loss = 0.576476038 (199.982 examples/sec; 0.250 sec/batch)\n",
      "2019-03-16 23:44:45.328692: step 3370, examples 168500, loss = 0.705396295 (198.317 examples/sec; 0.252 sec/batch)\n",
      "2019-03-16 23:44:47.952165: step 3380, examples 169000, loss = 0.696591139 (199.979 examples/sec; 0.250 sec/batch)\n",
      "2019-03-16 23:44:50.492943: step 3390, examples 169500, loss = 0.675738931 (207.937 examples/sec; 0.240 sec/batch)\n",
      "2019-03-16 23:44:53.028469: step 3400, examples 170000, loss = 0.727337480 (199.980 examples/sec; 0.250 sec/batch)\n",
      "Top 1 validation accuracy: 0.6084905862808228 and top 2 validation accuracy: 0.8443396091461182\n",
      "Model Saved!\n",
      "2019-03-16 23:44:57.374029: step 3410, examples 170500, loss = 0.742878377 (189.826 examples/sec; 0.263 sec/batch)\n",
      "2019-03-16 23:44:59.920393: step 3420, examples 171000, loss = 0.743556082 (199.979 examples/sec; 0.250 sec/batch)\n",
      "2019-03-16 23:45:02.517003: step 3430, examples 171500, loss = 0.927385330 (190.813 examples/sec; 0.262 sec/batch)\n",
      "2019-03-16 23:45:05.117688: step 3440, examples 172000, loss = 0.951150715 (211.014 examples/sec; 0.237 sec/batch)\n",
      "2019-03-16 23:45:07.663944: step 3450, examples 172500, loss = 1.026564240 (196.081 examples/sec; 0.255 sec/batch)\n",
      "2019-03-16 23:45:10.217287: step 3460, examples 173000, loss = 0.645065784 (194.108 examples/sec; 0.258 sec/batch)\n",
      "2019-03-16 23:45:12.726868: step 3470, examples 173500, loss = 0.910189271 (207.375 examples/sec; 0.241 sec/batch)\n",
      "2019-03-16 23:45:15.268921: step 3480, examples 174000, loss = 0.741736054 (193.107 examples/sec; 0.259 sec/batch)\n",
      "2019-03-16 23:45:17.857008: step 3490, examples 174500, loss = 0.871709824 (188.216 examples/sec; 0.266 sec/batch)\n",
      "2019-03-16 23:45:20.444785: step 3500, examples 175000, loss = 0.711377621 (193.397 examples/sec; 0.259 sec/batch)\n",
      "Top 1 validation accuracy: 0.5943396091461182 and top 2 validation accuracy: 0.7877358198165894\n",
      "Model Saved!\n",
      "2019-03-16 23:45:24.755707: step 3510, examples 175500, loss = 0.802310705 (193.417 examples/sec; 0.259 sec/batch)\n",
      "2019-03-16 23:45:27.340009: step 3520, examples 176000, loss = 0.779165030 (203.040 examples/sec; 0.246 sec/batch)\n",
      "2019-03-16 23:45:29.900200: step 3530, examples 176500, loss = 0.864976108 (199.979 examples/sec; 0.250 sec/batch)\n",
      "2019-03-16 23:45:32.445201: step 3540, examples 177000, loss = 0.766265631 (186.491 examples/sec; 0.268 sec/batch)\n",
      "2019-03-16 23:45:35.005852: step 3550, examples 177500, loss = 0.591845155 (188.215 examples/sec; 0.266 sec/batch)\n",
      "2019-03-16 23:45:37.574188: step 3560, examples 178000, loss = 0.530683517 (204.420 examples/sec; 0.245 sec/batch)\n",
      "2019-03-16 23:45:40.146641: step 3570, examples 178500, loss = 0.771749318 (183.822 examples/sec; 0.272 sec/batch)\n",
      "2019-03-16 23:45:42.716252: step 3580, examples 179000, loss = 0.558746278 (194.773 examples/sec; 0.257 sec/batch)\n",
      "2019-03-16 23:45:45.403928: step 3590, examples 179500, loss = 0.716962576 (192.760 examples/sec; 0.259 sec/batch)\n",
      "2019-03-16 23:45:47.878714: step 3600, examples 180000, loss = 0.735396743 (199.978 examples/sec; 0.250 sec/batch)\n",
      "Top 1 validation accuracy: 0.5966981053352356 and top 2 validation accuracy: 0.7853773832321167\n",
      "Model Saved!\n",
      "2019-03-16 23:45:52.389046: step 3610, examples 180500, loss = 0.537374854 (205.952 examples/sec; 0.243 sec/batch)\n",
      "2019-03-16 23:45:54.941589: step 3620, examples 181000, loss = 0.852816343 (188.218 examples/sec; 0.266 sec/batch)\n",
      "2019-03-16 23:45:57.460391: step 3630, examples 181500, loss = 0.868586063 (212.573 examples/sec; 0.235 sec/batch)\n",
      "2019-03-16 23:46:00.012594: step 3640, examples 182000, loss = 0.653905272 (188.214 examples/sec; 0.266 sec/batch)\n",
      "2019-03-16 23:46:02.569728: step 3650, examples 182500, loss = 0.937248826 (197.336 examples/sec; 0.253 sec/batch)\n",
      "2019-03-16 23:46:05.144463: step 3660, examples 183000, loss = 0.751159132 (189.755 examples/sec; 0.263 sec/batch)\n",
      "2019-03-16 23:46:07.752894: step 3670, examples 183500, loss = 0.653598666 (192.058 examples/sec; 0.260 sec/batch)\n",
      "2019-03-16 23:46:10.284378: step 3680, examples 184000, loss = 0.743483365 (216.285 examples/sec; 0.231 sec/batch)\n",
      "2019-03-16 23:46:12.808149: step 3690, examples 184500, loss = 0.726818681 (213.310 examples/sec; 0.234 sec/batch)\n",
      "2019-03-16 23:46:15.376343: step 3700, examples 185000, loss = 0.653350294 (187.938 examples/sec; 0.266 sec/batch)\n",
      "Top 1 validation accuracy: 0.6108490824699402 and top 2 validation accuracy: 0.8066037893295288\n",
      "Model Saved!\n",
      "2019-03-16 23:46:19.731084: step 3710, examples 185500, loss = 0.735934734 (198.981 examples/sec; 0.251 sec/batch)\n",
      "2019-03-16 23:46:22.314305: step 3720, examples 186000, loss = 0.657983840 (191.734 examples/sec; 0.261 sec/batch)\n",
      "2019-03-16 23:46:24.904644: step 3730, examples 186500, loss = 0.788900077 (199.978 examples/sec; 0.250 sec/batch)\n",
      "2019-03-16 23:46:27.445305: step 3740, examples 187000, loss = 0.708531797 (198.645 examples/sec; 0.252 sec/batch)\n",
      "2019-03-16 23:46:30.050566: step 3750, examples 187500, loss = 0.633821845 (188.215 examples/sec; 0.266 sec/batch)\n",
      "2019-03-16 23:46:33.199342: step 3760, examples 188000, loss = 0.857330441 (163.364 examples/sec; 0.306 sec/batch)\n",
      "2019-03-16 23:46:36.272650: step 3770, examples 188500, loss = 0.778612256 (156.816 examples/sec; 0.319 sec/batch)\n",
      "2019-03-16 23:46:39.113859: step 3780, examples 189000, loss = 0.618839920 (174.151 examples/sec; 0.287 sec/batch)\n",
      "2019-03-16 23:46:42.114067: step 3790, examples 189500, loss = 0.734900594 (152.499 examples/sec; 0.328 sec/batch)\n",
      "2019-03-16 23:46:45.327615: step 3800, examples 190000, loss = 0.552747488 (156.813 examples/sec; 0.319 sec/batch)\n",
      "Top 1 validation accuracy: 0.6108490824699402 and top 2 validation accuracy: 0.8254716992378235\n",
      "Model Saved!\n",
      "2019-03-16 23:46:50.083469: step 3810, examples 190500, loss = 0.855623126 (168.469 examples/sec; 0.297 sec/batch)\n",
      "2019-03-16 23:46:52.864589: step 3820, examples 191000, loss = 0.651325822 (152.305 examples/sec; 0.328 sec/batch)\n",
      "2019-03-16 23:46:55.810571: step 3830, examples 191500, loss = 0.645424247 (141.668 examples/sec; 0.353 sec/batch)\n",
      "2019-03-16 23:46:58.669378: step 3840, examples 192000, loss = 0.759271860 (185.822 examples/sec; 0.269 sec/batch)\n",
      "2019-03-16 23:47:01.409361: step 3850, examples 192500, loss = 0.691472471 (167.381 examples/sec; 0.299 sec/batch)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2019-03-16 23:47:04.416899: step 3860, examples 193000, loss = 0.729459107 (148.414 examples/sec; 0.337 sec/batch)\n",
      "2019-03-16 23:47:07.516193: step 3870, examples 193500, loss = 0.601568937 (178.735 examples/sec; 0.280 sec/batch)\n",
      "2019-03-16 23:47:10.573660: step 3880, examples 194000, loss = 0.728723884 (156.323 examples/sec; 0.320 sec/batch)\n",
      "2019-03-16 23:47:13.718431: step 3890, examples 194500, loss = 0.631585598 (151.112 examples/sec; 0.331 sec/batch)\n",
      "2019-03-16 23:47:16.872818: step 3900, examples 195000, loss = 0.763440132 (143.709 examples/sec; 0.348 sec/batch)\n",
      "Top 1 validation accuracy: 0.5966981053352356 and top 2 validation accuracy: 0.8089622855186462\n",
      "Model Saved!\n",
      "2019-03-16 23:47:21.552935: step 3910, examples 195500, loss = 0.674426556 (207.519 examples/sec; 0.241 sec/batch)\n",
      "2019-03-16 23:47:24.026736: step 3920, examples 196000, loss = 0.790851712 (213.313 examples/sec; 0.234 sec/batch)\n",
      "2019-03-16 23:47:26.537550: step 3930, examples 196500, loss = 0.660151720 (204.963 examples/sec; 0.244 sec/batch)\n",
      "2019-03-16 23:47:29.039181: step 3940, examples 197000, loss = 0.890204072 (199.977 examples/sec; 0.250 sec/batch)\n",
      "2019-03-16 23:47:31.516558: step 3950, examples 197500, loss = 0.897569299 (198.576 examples/sec; 0.252 sec/batch)\n",
      "2019-03-16 23:47:33.964410: step 3960, examples 198000, loss = 0.697308183 (199.978 examples/sec; 0.250 sec/batch)\n",
      "2019-03-16 23:47:36.442345: step 3970, examples 198500, loss = 0.752756894 (200.979 examples/sec; 0.249 sec/batch)\n",
      "2019-03-16 23:47:38.900231: step 3980, examples 199000, loss = 0.748617411 (213.310 examples/sec; 0.234 sec/batch)\n",
      "2019-03-16 23:47:41.352605: step 3990, examples 199500, loss = 0.574884772 (206.217 examples/sec; 0.242 sec/batch)\n",
      "2019-03-16 23:47:43.896029: step 4000, examples 200000, loss = 0.695381224 (199.979 examples/sec; 0.250 sec/batch)\n",
      "Top 1 validation accuracy: 0.6108490824699402 and top 2 validation accuracy: 0.801886796951294\n",
      "Model Saved!\n",
      "2019-03-16 23:47:48.331001: step 4010, examples 200500, loss = 0.828253210 (188.891 examples/sec; 0.265 sec/batch)\n",
      "2019-03-16 23:47:51.101556: step 4020, examples 201000, loss = 0.487543792 (212.744 examples/sec; 0.235 sec/batch)\n",
      "2019-03-16 23:47:53.864531: step 4030, examples 201500, loss = 0.758659959 (183.128 examples/sec; 0.273 sec/batch)\n",
      "2019-03-16 23:47:56.574699: step 4040, examples 202000, loss = 0.626239955 (213.309 examples/sec; 0.234 sec/batch)\n",
      "2019-03-16 23:47:59.394287: step 4050, examples 202500, loss = 0.661556482 (167.902 examples/sec; 0.298 sec/batch)\n",
      "2019-03-16 23:48:02.270957: step 4060, examples 203000, loss = 0.737784266 (174.361 examples/sec; 0.287 sec/batch)\n",
      "2019-03-16 23:48:05.250823: step 4070, examples 203500, loss = 0.660426080 (176.209 examples/sec; 0.284 sec/batch)\n",
      "2019-03-16 23:48:08.100425: step 4080, examples 204000, loss = 0.809177399 (185.380 examples/sec; 0.270 sec/batch)\n",
      "2019-03-16 23:48:11.123549: step 4090, examples 204500, loss = 0.612915874 (158.265 examples/sec; 0.316 sec/batch)\n",
      "2019-03-16 23:48:13.964103: step 4100, examples 205000, loss = 0.866730034 (181.948 examples/sec; 0.275 sec/batch)\n",
      "Top 1 validation accuracy: 0.6108490824699402 and top 2 validation accuracy: 0.8160377144813538\n",
      "Model Saved!\n",
      "2019-03-16 23:48:18.547758: step 4110, examples 205500, loss = 0.688712358 (159.321 examples/sec; 0.314 sec/batch)\n",
      "2019-03-16 23:48:21.319232: step 4120, examples 206000, loss = 0.657431006 (194.301 examples/sec; 0.257 sec/batch)\n",
      "2019-03-16 23:48:24.070344: step 4130, examples 206500, loss = 0.882050633 (163.534 examples/sec; 0.306 sec/batch)\n",
      "2019-03-16 23:48:26.891658: step 4140, examples 207000, loss = 0.789191127 (188.018 examples/sec; 0.266 sec/batch)\n",
      "2019-03-16 23:48:29.537068: step 4150, examples 207500, loss = 0.755632162 (196.739 examples/sec; 0.254 sec/batch)\n",
      "2019-03-16 23:48:32.156949: step 4160, examples 208000, loss = 0.552873492 (197.103 examples/sec; 0.254 sec/batch)\n",
      "2019-03-16 23:48:34.823997: step 4170, examples 208500, loss = 0.684639931 (161.382 examples/sec; 0.310 sec/batch)\n",
      "2019-03-16 23:48:37.677601: step 4180, examples 209000, loss = 0.661355972 (212.042 examples/sec; 0.236 sec/batch)\n",
      "2019-03-16 23:48:40.269087: step 4190, examples 209500, loss = 0.704622507 (190.382 examples/sec; 0.263 sec/batch)\n",
      "2019-03-16 23:48:42.726042: step 4200, examples 210000, loss = 0.797166586 (214.353 examples/sec; 0.233 sec/batch)\n",
      "Top 1 validation accuracy: 0.5825471878051758 and top 2 validation accuracy: 0.8113207817077637\n",
      "Model Saved!\n",
      "2019-03-16 23:48:47.037046: step 4210, examples 210500, loss = 0.700919390 (199.977 examples/sec; 0.250 sec/batch)\n",
      "2019-03-16 23:48:49.573330: step 4220, examples 211000, loss = 0.655824363 (211.320 examples/sec; 0.237 sec/batch)\n",
      "2019-03-16 23:48:52.021443: step 4230, examples 211500, loss = 0.718117535 (213.309 examples/sec; 0.234 sec/batch)\n",
      "2019-03-16 23:48:54.460924: step 4240, examples 212000, loss = 0.706829906 (209.538 examples/sec; 0.239 sec/batch)\n",
      "2019-03-16 23:48:56.920038: step 4250, examples 212500, loss = 0.655004859 (206.331 examples/sec; 0.242 sec/batch)\n",
      "2019-03-16 23:48:59.384246: step 4260, examples 213000, loss = 0.662316561 (188.607 examples/sec; 0.265 sec/batch)\n",
      "2019-03-16 23:49:01.872315: step 4270, examples 213500, loss = 0.707465708 (199.977 examples/sec; 0.250 sec/batch)\n",
      "2019-03-16 23:49:04.399119: step 4280, examples 214000, loss = 0.792686105 (197.700 examples/sec; 0.253 sec/batch)\n",
      "2019-03-16 23:49:06.853738: step 4290, examples 214500, loss = 0.729563594 (199.979 examples/sec; 0.250 sec/batch)\n",
      "2019-03-16 23:49:09.352313: step 4300, examples 215000, loss = 0.620022953 (195.760 examples/sec; 0.255 sec/batch)\n",
      "Top 1 validation accuracy: 0.6202830076217651 and top 2 validation accuracy: 0.8254716992378235\n",
      "Model Saved!\n",
      "2019-03-16 23:49:13.567573: step 4310, examples 215500, loss = 0.776535392 (209.063 examples/sec; 0.239 sec/batch)\n",
      "2019-03-16 23:49:16.062287: step 4320, examples 216000, loss = 0.708810568 (209.570 examples/sec; 0.239 sec/batch)\n",
      "2019-03-16 23:49:18.532377: step 4330, examples 216500, loss = 0.540788114 (203.956 examples/sec; 0.245 sec/batch)\n",
      "2019-03-16 23:49:21.053158: step 4340, examples 217000, loss = 0.765341878 (199.979 examples/sec; 0.250 sec/batch)\n",
      "2019-03-16 23:49:23.570323: step 4350, examples 217500, loss = 0.670822382 (201.220 examples/sec; 0.248 sec/batch)\n",
      "2019-03-16 23:49:26.037715: step 4360, examples 218000, loss = 0.800966501 (199.978 examples/sec; 0.250 sec/batch)\n",
      "2019-03-16 23:49:28.431363: step 4370, examples 218500, loss = 0.836415529 (196.842 examples/sec; 0.254 sec/batch)\n",
      "2019-03-16 23:49:30.910358: step 4380, examples 219000, loss = 0.748383760 (199.979 examples/sec; 0.250 sec/batch)\n",
      "2019-03-16 23:49:33.368527: step 4390, examples 219500, loss = 0.739691854 (199.247 examples/sec; 0.251 sec/batch)\n",
      "2019-03-16 23:49:35.883507: step 4400, examples 220000, loss = 0.889470100 (199.977 examples/sec; 0.250 sec/batch)\n",
      "Top 1 validation accuracy: 0.6179245114326477 and top 2 validation accuracy: 0.8089622855186462\n",
      "Model Saved!\n",
      "2019-03-16 23:49:40.146832: step 4410, examples 220500, loss = 0.600511372 (206.255 examples/sec; 0.242 sec/batch)\n",
      "2019-03-16 23:49:42.599943: step 4420, examples 221000, loss = 0.640550852 (201.647 examples/sec; 0.248 sec/batch)\n",
      "2019-03-16 23:49:45.157723: step 4430, examples 221500, loss = 0.667216897 (198.037 examples/sec; 0.252 sec/batch)\n",
      "2019-03-16 23:49:47.615798: step 4440, examples 222000, loss = 0.565113783 (202.364 examples/sec; 0.247 sec/batch)\n",
      "2019-03-16 23:49:50.316582: step 4450, examples 222500, loss = 0.648676872 (186.768 examples/sec; 0.268 sec/batch)\n",
      "2019-03-16 23:49:53.005903: step 4460, examples 223000, loss = 0.636476338 (213.308 examples/sec; 0.234 sec/batch)\n",
      "2019-03-16 23:49:55.493615: step 4470, examples 223500, loss = 0.826999962 (209.458 examples/sec; 0.239 sec/batch)\n",
      "2019-03-16 23:49:58.021478: step 4480, examples 224000, loss = 0.600746632 (172.197 examples/sec; 0.290 sec/batch)\n",
      "2019-03-16 23:50:00.552850: step 4490, examples 224500, loss = 0.544619918 (206.633 examples/sec; 0.242 sec/batch)\n",
      "2019-03-16 23:50:03.236392: step 4500, examples 225000, loss = 0.576609254 (197.560 examples/sec; 0.253 sec/batch)\n",
      "Top 1 validation accuracy: 0.5943396091461182 and top 2 validation accuracy: 0.8325471878051758\n",
      "Model Saved!\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2019-03-16 23:50:07.709550: step 4510, examples 225500, loss = 0.675170422 (156.647 examples/sec; 0.319 sec/batch)\n",
      "2019-03-16 23:50:10.417510: step 4520, examples 226000, loss = 0.596472859 (184.489 examples/sec; 0.271 sec/batch)\n",
      "2019-03-16 23:50:12.861015: step 4530, examples 226500, loss = 0.729682684 (213.309 examples/sec; 0.234 sec/batch)\n",
      "2019-03-16 23:50:16.135597: step 4540, examples 227000, loss = 0.662805557 (144.124 examples/sec; 0.347 sec/batch)\n",
      "2019-03-16 23:50:18.941650: step 4550, examples 227500, loss = 0.694762349 (155.555 examples/sec; 0.321 sec/batch)\n",
      "2019-03-16 23:50:21.586912: step 4560, examples 228000, loss = 0.671226382 (181.997 examples/sec; 0.275 sec/batch)\n",
      "2019-03-16 23:50:24.611220: step 4570, examples 228500, loss = 0.700113654 (180.678 examples/sec; 0.277 sec/batch)\n",
      "2019-03-16 23:50:27.550107: step 4580, examples 229000, loss = 0.726297796 (177.464 examples/sec; 0.282 sec/batch)\n",
      "2019-03-16 23:50:30.444851: step 4590, examples 229500, loss = 0.824194551 (208.568 examples/sec; 0.240 sec/batch)\n",
      "2019-03-16 23:50:33.316519: step 4600, examples 230000, loss = 0.530164361 (205.941 examples/sec; 0.243 sec/batch)\n",
      "Top 1 validation accuracy: 0.5825471878051758 and top 2 validation accuracy: 0.8160377144813538\n",
      "Model Saved!\n",
      "2019-03-16 23:50:38.015689: step 4610, examples 230500, loss = 0.705097675 (193.345 examples/sec; 0.259 sec/batch)\n",
      "2019-03-16 23:50:40.815269: step 4620, examples 231000, loss = 0.806231916 (206.612 examples/sec; 0.242 sec/batch)\n",
      "2019-03-16 23:50:43.557454: step 4630, examples 231500, loss = 0.819216430 (179.221 examples/sec; 0.279 sec/batch)\n",
      "2019-03-16 23:50:46.439341: step 4640, examples 232000, loss = 0.719081521 (153.748 examples/sec; 0.325 sec/batch)\n",
      "2019-03-16 23:50:49.188379: step 4650, examples 232500, loss = 0.728154898 (164.093 examples/sec; 0.305 sec/batch)\n",
      "2019-03-16 23:50:51.780217: step 4660, examples 233000, loss = 0.877566814 (164.628 examples/sec; 0.304 sec/batch)\n",
      "2019-03-16 23:50:54.535615: step 4670, examples 233500, loss = 0.776063442 (199.753 examples/sec; 0.250 sec/batch)\n",
      "2019-03-16 23:50:57.415012: step 4680, examples 234000, loss = 0.748932481 (201.691 examples/sec; 0.248 sec/batch)\n",
      "2019-03-16 23:51:00.193736: step 4690, examples 234500, loss = 0.822834432 (209.173 examples/sec; 0.239 sec/batch)\n",
      "2019-03-16 23:51:03.077572: step 4700, examples 235000, loss = 0.775001645 (165.038 examples/sec; 0.303 sec/batch)\n",
      "Top 1 validation accuracy: 0.6132075190544128 and top 2 validation accuracy: 0.8183962106704712\n",
      "Model Saved!\n",
      "2019-03-16 23:51:07.712820: step 4710, examples 235500, loss = 0.621797979 (177.462 examples/sec; 0.282 sec/batch)\n",
      "2019-03-16 23:51:10.636942: step 4720, examples 236000, loss = 0.721544147 (174.971 examples/sec; 0.286 sec/batch)\n",
      "2019-03-16 23:51:13.481079: step 4730, examples 236500, loss = 0.634481072 (169.617 examples/sec; 0.295 sec/batch)\n",
      "2019-03-16 23:51:16.445195: step 4740, examples 237000, loss = 0.759891152 (165.671 examples/sec; 0.302 sec/batch)\n",
      "2019-03-16 23:51:19.237079: step 4750, examples 237500, loss = 0.730274379 (199.539 examples/sec; 0.251 sec/batch)\n",
      "2019-03-16 23:51:22.067516: step 4760, examples 238000, loss = 0.657985091 (160.104 examples/sec; 0.312 sec/batch)\n",
      "2019-03-16 23:51:25.029580: step 4770, examples 238500, loss = 0.716643155 (161.384 examples/sec; 0.310 sec/batch)\n",
      "2019-03-16 23:51:27.955805: step 4780, examples 239000, loss = 0.525599003 (161.616 examples/sec; 0.309 sec/batch)\n",
      "2019-03-16 23:51:30.778756: step 4790, examples 239500, loss = 0.723673105 (181.675 examples/sec; 0.275 sec/batch)\n",
      "2019-03-16 23:51:33.576304: step 4800, examples 240000, loss = 0.655257761 (191.867 examples/sec; 0.261 sec/batch)\n",
      "Top 1 validation accuracy: 0.6367924809455872 and top 2 validation accuracy: 0.823113203048706\n",
      "Model Saved!\n",
      "2019-03-16 23:51:38.352231: step 4810, examples 240500, loss = 0.698239088 (210.888 examples/sec; 0.237 sec/batch)\n",
      "2019-03-16 23:51:41.201851: step 4820, examples 241000, loss = 0.532107592 (153.302 examples/sec; 0.326 sec/batch)\n",
      "2019-03-16 23:51:44.075831: step 4830, examples 241500, loss = 0.848076463 (182.946 examples/sec; 0.273 sec/batch)\n",
      "2019-03-16 23:51:46.686607: step 4840, examples 242000, loss = 0.660027742 (154.565 examples/sec; 0.323 sec/batch)\n",
      "2019-03-16 23:51:49.610435: step 4850, examples 242500, loss = 0.777567506 (162.344 examples/sec; 0.308 sec/batch)\n",
      "2019-03-16 23:51:52.477056: step 4860, examples 243000, loss = 0.656628251 (192.538 examples/sec; 0.260 sec/batch)\n",
      "2019-03-16 23:51:55.310593: step 4870, examples 243500, loss = 0.630579948 (162.432 examples/sec; 0.308 sec/batch)\n",
      "2019-03-16 23:51:58.087148: step 4880, examples 244000, loss = 0.653814554 (204.944 examples/sec; 0.244 sec/batch)\n",
      "2019-03-16 23:52:00.680709: step 4890, examples 244500, loss = 0.757480562 (180.389 examples/sec; 0.277 sec/batch)\n",
      "2019-03-16 23:52:03.227794: step 4900, examples 245000, loss = 0.830241323 (184.359 examples/sec; 0.271 sec/batch)\n",
      "Top 1 validation accuracy: 0.573113203048706 and top 2 validation accuracy: 0.7995283007621765\n",
      "Model Saved!\n",
      "2019-03-16 23:52:07.662924: step 4910, examples 245500, loss = 0.719670892 (196.939 examples/sec; 0.254 sec/batch)\n",
      "2019-03-16 23:52:10.232097: step 4920, examples 246000, loss = 0.609960556 (198.458 examples/sec; 0.252 sec/batch)\n",
      "2019-03-16 23:52:12.786334: step 4930, examples 246500, loss = 0.633924842 (189.041 examples/sec; 0.264 sec/batch)\n",
      "2019-03-16 23:52:15.357911: step 4940, examples 247000, loss = 0.697593510 (176.009 examples/sec; 0.284 sec/batch)\n",
      "2019-03-16 23:52:17.928282: step 4950, examples 247500, loss = 0.716930389 (213.310 examples/sec; 0.234 sec/batch)\n",
      "2019-03-16 23:52:20.569445: step 4960, examples 248000, loss = 0.667126477 (208.874 examples/sec; 0.239 sec/batch)\n",
      "2019-03-16 23:52:23.161998: step 4970, examples 248500, loss = 0.702058017 (199.090 examples/sec; 0.251 sec/batch)\n",
      "2019-03-16 23:52:25.670683: step 4980, examples 249000, loss = 0.708064437 (203.152 examples/sec; 0.246 sec/batch)\n",
      "2019-03-16 23:52:28.162616: step 4990, examples 249500, loss = 0.731351614 (202.043 examples/sec; 0.247 sec/batch)\n",
      "Top 1 validation accuracy: 0.6108490824699402 and top 2 validation accuracy: 0.8089622855186462\n",
      "Model Saved!\n",
      "Loading datasets...\n",
      "Dataset loading completes.\n",
      "2019-03-16 23:52:35.487873: step 0, examples 0, loss = 1.419788003 (86.949 examples/sec; 0.575 sec/batch)\n",
      "Top 1 validation accuracy: 0.2641509473323822 and top 2 validation accuracy: 0.49764150381088257\n",
      "Model Saved!\n",
      "2019-03-16 23:52:39.820371: step 10, examples 500, loss = 1.439321995 (199.979 examples/sec; 0.250 sec/batch)\n",
      "2019-03-16 23:52:42.229653: step 20, examples 1000, loss = 1.450451970 (209.032 examples/sec; 0.239 sec/batch)\n",
      "2019-03-16 23:52:44.680941: step 30, examples 1500, loss = 1.416033268 (228.305 examples/sec; 0.219 sec/batch)\n",
      "2019-03-16 23:52:47.146324: step 40, examples 2000, loss = 1.409631729 (189.821 examples/sec; 0.263 sec/batch)\n",
      "2019-03-16 23:52:49.776770: step 50, examples 2500, loss = 1.397323847 (202.178 examples/sec; 0.247 sec/batch)\n",
      "2019-03-16 23:52:52.301022: step 60, examples 3000, loss = 1.399231672 (191.307 examples/sec; 0.261 sec/batch)\n",
      "2019-03-16 23:52:54.774335: step 70, examples 3500, loss = 1.396923780 (205.957 examples/sec; 0.243 sec/batch)\n",
      "2019-03-16 23:52:57.336859: step 80, examples 4000, loss = 1.324161530 (196.752 examples/sec; 0.254 sec/batch)\n",
      "2019-03-16 23:52:59.802986: step 90, examples 4500, loss = 1.334539175 (199.980 examples/sec; 0.250 sec/batch)\n",
      "2019-03-16 23:53:02.305504: step 100, examples 5000, loss = 1.410235167 (202.373 examples/sec; 0.247 sec/batch)\n",
      "Top 1 validation accuracy: 0.30896225571632385 and top 2 validation accuracy: 0.5542452931404114\n",
      "Model Saved!\n",
      "2019-03-16 23:53:06.677744: step 110, examples 5500, loss = 1.363041878 (196.061 examples/sec; 0.255 sec/batch)\n",
      "2019-03-16 23:53:09.230246: step 120, examples 6000, loss = 1.329261780 (191.377 examples/sec; 0.261 sec/batch)\n",
      "2019-03-16 23:53:11.818495: step 130, examples 6500, loss = 1.417488813 (188.215 examples/sec; 0.266 sec/batch)\n",
      "2019-03-16 23:53:14.336658: step 140, examples 7000, loss = 1.415282011 (208.246 examples/sec; 0.240 sec/batch)\n",
      "2019-03-16 23:53:16.922454: step 150, examples 7500, loss = 1.464116096 (199.979 examples/sec; 0.250 sec/batch)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2019-03-16 23:53:19.559007: step 160, examples 8000, loss = 1.355680704 (184.446 examples/sec; 0.271 sec/batch)\n",
      "2019-03-16 23:53:22.131631: step 170, examples 8500, loss = 1.377734900 (197.399 examples/sec; 0.253 sec/batch)\n",
      "2019-03-16 23:53:24.680983: step 180, examples 9000, loss = 1.306550026 (200.804 examples/sec; 0.249 sec/batch)\n",
      "2019-03-16 23:53:27.439882: step 190, examples 9500, loss = 1.327234507 (155.757 examples/sec; 0.321 sec/batch)\n",
      "2019-03-16 23:53:30.013366: step 200, examples 10000, loss = 1.345331907 (199.978 examples/sec; 0.250 sec/batch)\n",
      "Top 1 validation accuracy: 0.3207547068595886 and top 2 validation accuracy: 0.5966981053352356\n",
      "Model Saved!\n",
      "2019-03-16 23:53:34.648160: step 210, examples 10500, loss = 1.335415006 (188.669 examples/sec; 0.265 sec/batch)\n",
      "2019-03-16 23:53:37.370549: step 220, examples 11000, loss = 1.351077557 (191.980 examples/sec; 0.260 sec/batch)\n",
      "2019-03-16 23:53:40.008708: step 230, examples 11500, loss = 1.355709195 (199.980 examples/sec; 0.250 sec/batch)\n",
      "2019-03-16 23:53:42.577355: step 240, examples 12000, loss = 1.374293804 (192.217 examples/sec; 0.260 sec/batch)\n",
      "2019-03-16 23:53:45.162113: step 250, examples 12500, loss = 1.302083969 (190.872 examples/sec; 0.262 sec/batch)\n",
      "2019-03-16 23:53:47.713953: step 260, examples 13000, loss = 1.309567928 (197.819 examples/sec; 0.253 sec/batch)\n",
      "2019-03-16 23:53:50.263406: step 270, examples 13500, loss = 1.336237311 (191.792 examples/sec; 0.261 sec/batch)\n",
      "2019-03-16 23:53:52.868072: step 280, examples 14000, loss = 1.302523732 (199.977 examples/sec; 0.250 sec/batch)\n",
      "2019-03-16 23:53:55.399490: step 290, examples 14500, loss = 1.325047135 (198.484 examples/sec; 0.252 sec/batch)\n",
      "2019-03-16 23:53:57.936932: step 300, examples 15000, loss = 1.277796149 (188.216 examples/sec; 0.266 sec/batch)\n",
      "Top 1 validation accuracy: 0.36320754885673523 and top 2 validation accuracy: 0.6462264060974121\n",
      "Model Saved!\n",
      "2019-03-16 23:54:02.262171: step 310, examples 15500, loss = 1.263405085 (195.466 examples/sec; 0.256 sec/batch)\n",
      "2019-03-16 23:54:04.836868: step 320, examples 16000, loss = 1.211197019 (188.215 examples/sec; 0.266 sec/batch)\n",
      "2019-03-16 23:54:07.415670: step 330, examples 16500, loss = 1.354560614 (185.985 examples/sec; 0.269 sec/batch)\n",
      "2019-03-16 23:54:09.892163: step 340, examples 17000, loss = 1.448190689 (213.310 examples/sec; 0.234 sec/batch)\n",
      "2019-03-16 23:54:12.444747: step 350, examples 17500, loss = 1.282683611 (186.764 examples/sec; 0.268 sec/batch)\n",
      "2019-03-16 23:54:14.957873: step 360, examples 18000, loss = 1.235282660 (199.978 examples/sec; 0.250 sec/batch)\n",
      "2019-03-16 23:54:17.500817: step 370, examples 18500, loss = 1.130351782 (198.923 examples/sec; 0.251 sec/batch)\n",
      "2019-03-16 23:54:20.037244: step 380, examples 19000, loss = 1.246622086 (199.978 examples/sec; 0.250 sec/batch)\n",
      "2019-03-16 23:54:22.626910: step 390, examples 19500, loss = 1.279474139 (193.340 examples/sec; 0.259 sec/batch)\n",
      "2019-03-16 23:54:25.303784: step 400, examples 20000, loss = 1.122100830 (192.683 examples/sec; 0.259 sec/batch)\n",
      "Top 1 validation accuracy: 0.42688679695129395 and top 2 validation accuracy: 0.7146226167678833\n",
      "Model Saved!\n",
      "2019-03-16 23:54:29.787820: step 410, examples 20500, loss = 1.145193696 (199.978 examples/sec; 0.250 sec/batch)\n",
      "2019-03-16 23:54:32.320990: step 420, examples 21000, loss = 1.219469309 (202.858 examples/sec; 0.246 sec/batch)\n",
      "2019-03-16 23:54:34.883517: step 430, examples 21500, loss = 1.246717930 (199.979 examples/sec; 0.250 sec/batch)\n",
      "2019-03-16 23:54:37.460883: step 440, examples 22000, loss = 0.901279092 (187.014 examples/sec; 0.267 sec/batch)\n",
      "2019-03-16 23:54:40.101336: step 450, examples 22500, loss = 1.351833582 (199.104 examples/sec; 0.251 sec/batch)\n",
      "2019-03-16 23:54:42.678387: step 460, examples 23000, loss = 1.200667500 (204.242 examples/sec; 0.245 sec/batch)\n",
      "2019-03-16 23:54:45.268444: step 470, examples 23500, loss = 1.080259919 (195.592 examples/sec; 0.256 sec/batch)\n",
      "2019-03-16 23:54:47.828651: step 480, examples 24000, loss = 1.187258482 (199.978 examples/sec; 0.250 sec/batch)\n",
      "2019-03-16 23:54:50.368406: step 490, examples 24500, loss = 1.276937962 (184.617 examples/sec; 0.271 sec/batch)\n",
      "2019-03-16 23:54:52.948645: step 500, examples 25000, loss = 1.054806590 (188.215 examples/sec; 0.266 sec/batch)\n",
      "Top 1 validation accuracy: 0.4363207519054413 and top 2 validation accuracy: 0.7169811129570007\n",
      "Model Saved!\n",
      "2019-03-16 23:54:57.336361: step 510, examples 25500, loss = 1.185283899 (195.640 examples/sec; 0.256 sec/batch)\n",
      "2019-03-16 23:54:59.874325: step 520, examples 26000, loss = 1.125344753 (199.979 examples/sec; 0.250 sec/batch)\n",
      "2019-03-16 23:55:02.445686: step 530, examples 26500, loss = 1.310993433 (212.082 examples/sec; 0.236 sec/batch)\n",
      "2019-03-16 23:55:04.995938: step 540, examples 27000, loss = 1.126881599 (188.215 examples/sec; 0.266 sec/batch)\n",
      "2019-03-16 23:55:07.552867: step 550, examples 27500, loss = 1.275326252 (211.867 examples/sec; 0.236 sec/batch)\n",
      "2019-03-16 23:55:10.094230: step 560, examples 28000, loss = 1.104187131 (189.633 examples/sec; 0.264 sec/batch)\n",
      "2019-03-16 23:55:12.740400: step 570, examples 28500, loss = 1.170108318 (192.496 examples/sec; 0.260 sec/batch)\n",
      "2019-03-16 23:55:15.286899: step 580, examples 29000, loss = 1.131073236 (189.050 examples/sec; 0.264 sec/batch)\n",
      "2019-03-16 23:55:17.835782: step 590, examples 29500, loss = 1.004850149 (199.980 examples/sec; 0.250 sec/batch)\n",
      "2019-03-16 23:55:20.336682: step 600, examples 30000, loss = 1.065096378 (208.078 examples/sec; 0.240 sec/batch)\n",
      "Top 1 validation accuracy: 0.4716981053352356 and top 2 validation accuracy: 0.7028301954269409\n",
      "Model Saved!\n",
      "2019-03-16 23:55:24.713778: step 610, examples 30500, loss = 1.135681152 (197.469 examples/sec; 0.253 sec/batch)\n",
      "2019-03-16 23:55:27.326757: step 620, examples 31000, loss = 1.316100836 (184.926 examples/sec; 0.270 sec/batch)\n",
      "2019-03-16 23:55:29.900762: step 630, examples 31500, loss = 1.001489401 (199.979 examples/sec; 0.250 sec/batch)\n",
      "2019-03-16 23:55:32.442402: step 640, examples 32000, loss = 1.044739723 (199.974 examples/sec; 0.250 sec/batch)\n",
      "2019-03-16 23:55:34.996298: step 650, examples 32500, loss = 0.994807363 (199.979 examples/sec; 0.250 sec/batch)\n",
      "2019-03-16 23:55:37.570531: step 660, examples 33000, loss = 1.192721367 (211.724 examples/sec; 0.236 sec/batch)\n",
      "2019-03-16 23:55:40.161884: step 670, examples 33500, loss = 1.155977011 (183.576 examples/sec; 0.272 sec/batch)\n",
      "2019-03-16 23:55:42.756980: step 680, examples 34000, loss = 0.996196866 (192.009 examples/sec; 0.260 sec/batch)\n",
      "2019-03-16 23:55:45.427749: step 690, examples 34500, loss = 1.035305500 (171.856 examples/sec; 0.291 sec/batch)\n",
      "2019-03-16 23:55:47.959640: step 700, examples 35000, loss = 0.966472268 (199.978 examples/sec; 0.250 sec/batch)\n",
      "Top 1 validation accuracy: 0.5283018946647644 and top 2 validation accuracy: 0.7405660152435303\n",
      "Model Saved!\n",
      "2019-03-16 23:55:52.336997: step 710, examples 35500, loss = 1.288173199 (207.046 examples/sec; 0.241 sec/batch)\n",
      "2019-03-16 23:55:54.928072: step 720, examples 36000, loss = 1.093722463 (188.215 examples/sec; 0.266 sec/batch)\n",
      "2019-03-16 23:55:57.460845: step 730, examples 36500, loss = 1.087165236 (198.644 examples/sec; 0.252 sec/batch)\n",
      "2019-03-16 23:56:00.037182: step 740, examples 37000, loss = 1.029840589 (199.979 examples/sec; 0.250 sec/batch)\n",
      "2019-03-16 23:56:02.586122: step 750, examples 37500, loss = 1.112879992 (200.510 examples/sec; 0.249 sec/batch)\n",
      "2019-03-16 23:56:05.109463: step 760, examples 38000, loss = 1.140617371 (205.144 examples/sec; 0.244 sec/batch)\n",
      "2019-03-16 23:56:07.690269: step 770, examples 38500, loss = 1.132382035 (198.354 examples/sec; 0.252 sec/batch)\n",
      "2019-03-16 23:56:10.253915: step 780, examples 39000, loss = 1.112025023 (207.276 examples/sec; 0.241 sec/batch)\n",
      "2019-03-16 23:56:12.787873: step 790, examples 39500, loss = 0.903241873 (199.978 examples/sec; 0.250 sec/batch)\n",
      "2019-03-16 23:56:15.380205: step 800, examples 40000, loss = 1.087835073 (179.001 examples/sec; 0.279 sec/batch)\n",
      "Top 1 validation accuracy: 0.4599056541919708 and top 2 validation accuracy: 0.7405660152435303\n",
      "Model Saved!\n",
      "2019-03-16 23:56:19.727333: step 810, examples 40500, loss = 1.161088943 (187.358 examples/sec; 0.267 sec/batch)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2019-03-16 23:56:22.326324: step 820, examples 41000, loss = 1.166545391 (199.734 examples/sec; 0.250 sec/batch)\n",
      "2019-03-16 23:56:24.846866: step 830, examples 41500, loss = 1.150925875 (199.976 examples/sec; 0.250 sec/batch)\n",
      "2019-03-16 23:56:27.426131: step 840, examples 42000, loss = 1.092478156 (189.091 examples/sec; 0.264 sec/batch)\n",
      "2019-03-16 23:56:29.928400: step 850, examples 42500, loss = 1.057347775 (199.978 examples/sec; 0.250 sec/batch)\n",
      "2019-03-16 23:56:32.476420: step 860, examples 43000, loss = 1.161510944 (215.549 examples/sec; 0.232 sec/batch)\n",
      "2019-03-16 23:56:35.100017: step 870, examples 43500, loss = 0.937176228 (173.741 examples/sec; 0.288 sec/batch)\n",
      "2019-03-16 23:56:37.819153: step 880, examples 44000, loss = 1.026741982 (188.214 examples/sec; 0.266 sec/batch)\n",
      "2019-03-16 23:56:40.507620: step 890, examples 44500, loss = 0.867174029 (174.146 examples/sec; 0.287 sec/batch)\n",
      "2019-03-16 23:56:43.239131: step 900, examples 45000, loss = 1.223090887 (181.719 examples/sec; 0.275 sec/batch)\n",
      "Top 1 validation accuracy: 0.5141509175300598 and top 2 validation accuracy: 0.7216981053352356\n",
      "Model Saved!\n",
      "2019-03-16 23:56:47.711538: step 910, examples 45500, loss = 1.024033546 (199.417 examples/sec; 0.251 sec/batch)\n",
      "2019-03-16 23:56:50.258358: step 920, examples 46000, loss = 0.992335558 (193.989 examples/sec; 0.258 sec/batch)\n",
      "2019-03-16 23:56:52.849623: step 930, examples 46500, loss = 1.137635469 (188.217 examples/sec; 0.266 sec/batch)\n",
      "2019-03-16 23:56:55.423110: step 940, examples 47000, loss = 1.006789446 (191.409 examples/sec; 0.261 sec/batch)\n",
      "2019-03-16 23:56:57.976681: step 950, examples 47500, loss = 1.088420868 (188.216 examples/sec; 0.266 sec/batch)\n",
      "2019-03-16 23:57:00.552803: step 960, examples 48000, loss = 0.944808960 (204.384 examples/sec; 0.245 sec/batch)\n",
      "2019-03-16 23:57:03.139516: step 970, examples 48500, loss = 1.042535424 (182.951 examples/sec; 0.273 sec/batch)\n",
      "2019-03-16 23:57:05.740620: step 980, examples 49000, loss = 0.959759653 (200.836 examples/sec; 0.249 sec/batch)\n",
      "2019-03-16 23:57:08.277943: step 990, examples 49500, loss = 0.993403912 (195.239 examples/sec; 0.256 sec/batch)\n",
      "2019-03-16 23:57:10.787588: step 1000, examples 50000, loss = 0.974097252 (199.977 examples/sec; 0.250 sec/batch)\n",
      "Top 1 validation accuracy: 0.5330188870429993 and top 2 validation accuracy: 0.7712264060974121\n",
      "Model Saved!\n",
      "2019-03-16 23:57:15.238249: step 1010, examples 50500, loss = 1.275576115 (192.337 examples/sec; 0.260 sec/batch)\n",
      "2019-03-16 23:57:17.794655: step 1020, examples 51000, loss = 1.145951748 (209.681 examples/sec; 0.238 sec/batch)\n",
      "2019-03-16 23:57:20.445000: step 1030, examples 51500, loss = 0.867684007 (187.596 examples/sec; 0.267 sec/batch)\n",
      "2019-03-16 23:57:22.946986: step 1040, examples 52000, loss = 1.041764736 (199.979 examples/sec; 0.250 sec/batch)\n",
      "2019-03-16 23:57:25.527123: step 1050, examples 52500, loss = 0.936207533 (182.691 examples/sec; 0.274 sec/batch)\n",
      "2019-03-16 23:57:28.099086: step 1060, examples 53000, loss = 0.987046957 (192.573 examples/sec; 0.260 sec/batch)\n",
      "2019-03-16 23:57:30.663412: step 1070, examples 53500, loss = 1.053055525 (192.897 examples/sec; 0.259 sec/batch)\n",
      "2019-03-16 23:57:33.220680: step 1080, examples 54000, loss = 0.933231354 (188.157 examples/sec; 0.266 sec/batch)\n",
      "2019-03-16 23:57:35.826440: step 1090, examples 54500, loss = 1.035005808 (199.978 examples/sec; 0.250 sec/batch)\n",
      "2019-03-16 23:57:38.444811: step 1100, examples 55000, loss = 1.007144928 (203.751 examples/sec; 0.245 sec/batch)\n",
      "Top 1 validation accuracy: 0.5188679099082947 and top 2 validation accuracy: 0.75\n",
      "Model Saved!\n",
      "2019-03-16 23:57:42.756604: step 1110, examples 55500, loss = 0.829813361 (198.064 examples/sec; 0.252 sec/batch)\n",
      "2019-03-16 23:57:45.447179: step 1120, examples 56000, loss = 0.970222354 (175.304 examples/sec; 0.285 sec/batch)\n",
      "2019-03-16 23:57:47.975188: step 1130, examples 56500, loss = 0.955323458 (199.978 examples/sec; 0.250 sec/batch)\n",
      "2019-03-16 23:57:50.537708: step 1140, examples 57000, loss = 1.015011907 (204.578 examples/sec; 0.244 sec/batch)\n",
      "2019-03-16 23:57:53.147448: step 1150, examples 57500, loss = 0.954292893 (191.324 examples/sec; 0.261 sec/batch)\n",
      "2019-03-16 23:57:55.678322: step 1160, examples 58000, loss = 1.213962793 (212.107 examples/sec; 0.236 sec/batch)\n",
      "2019-03-16 23:57:58.253952: step 1170, examples 58500, loss = 1.049837232 (193.169 examples/sec; 0.259 sec/batch)\n",
      "2019-03-16 23:58:00.819037: step 1180, examples 59000, loss = 0.907877505 (188.216 examples/sec; 0.266 sec/batch)\n",
      "2019-03-16 23:58:03.352329: step 1190, examples 59500, loss = 0.865838468 (198.959 examples/sec; 0.251 sec/batch)\n",
      "2019-03-16 23:58:05.960926: step 1200, examples 60000, loss = 0.882087469 (188.216 examples/sec; 0.266 sec/batch)\n",
      "Top 1 validation accuracy: 0.5400943160057068 and top 2 validation accuracy: 0.7995283007621765\n",
      "Model Saved!\n",
      "2019-03-16 23:58:10.383923: step 1210, examples 60500, loss = 0.960768759 (199.148 examples/sec; 0.251 sec/batch)\n",
      "2019-03-16 23:58:12.950181: step 1220, examples 61000, loss = 1.131763697 (188.215 examples/sec; 0.266 sec/batch)\n",
      "2019-03-16 23:58:15.537758: step 1230, examples 61500, loss = 1.113550544 (213.498 examples/sec; 0.234 sec/batch)\n",
      "2019-03-16 23:58:18.146747: step 1240, examples 62000, loss = 1.049871325 (190.506 examples/sec; 0.262 sec/batch)\n",
      "2019-03-16 23:58:20.693234: step 1250, examples 62500, loss = 1.133321047 (201.377 examples/sec; 0.248 sec/batch)\n",
      "2019-03-16 23:58:23.294845: step 1260, examples 63000, loss = 0.949498355 (185.887 examples/sec; 0.269 sec/batch)\n",
      "2019-03-16 23:58:25.856490: step 1270, examples 63500, loss = 0.979138970 (199.978 examples/sec; 0.250 sec/batch)\n",
      "2019-03-16 23:58:28.391247: step 1280, examples 64000, loss = 1.163379669 (201.897 examples/sec; 0.248 sec/batch)\n",
      "2019-03-16 23:58:30.948033: step 1290, examples 64500, loss = 0.990075827 (199.979 examples/sec; 0.250 sec/batch)\n",
      "2019-03-16 23:58:33.635962: step 1300, examples 65000, loss = 1.008013964 (176.148 examples/sec; 0.284 sec/batch)\n",
      "Top 1 validation accuracy: 0.5448113083839417 and top 2 validation accuracy: 0.7688679099082947\n",
      "Model Saved!\n",
      "2019-03-16 23:58:38.109186: step 1310, examples 65500, loss = 0.858927369 (199.611 examples/sec; 0.250 sec/batch)\n",
      "2019-03-16 23:58:40.835568: step 1320, examples 66000, loss = 1.079163551 (188.215 examples/sec; 0.266 sec/batch)\n",
      "2019-03-16 23:58:43.367717: step 1330, examples 66500, loss = 1.079411268 (187.380 examples/sec; 0.267 sec/batch)\n",
      "2019-03-16 23:58:45.834967: step 1340, examples 67000, loss = 0.962522745 (205.200 examples/sec; 0.244 sec/batch)\n",
      "2019-03-16 23:58:48.326469: step 1350, examples 67500, loss = 0.984228730 (208.459 examples/sec; 0.240 sec/batch)\n",
      "2019-03-16 23:58:50.722624: step 1360, examples 68000, loss = 0.921952009 (213.910 examples/sec; 0.234 sec/batch)\n",
      "2019-03-16 23:58:53.179372: step 1370, examples 68500, loss = 0.920959353 (198.578 examples/sec; 0.252 sec/batch)\n",
      "2019-03-16 23:58:55.718245: step 1380, examples 69000, loss = 0.892925858 (194.243 examples/sec; 0.257 sec/batch)\n",
      "2019-03-16 23:58:58.177353: step 1390, examples 69500, loss = 0.948726416 (202.479 examples/sec; 0.247 sec/batch)\n",
      "2019-03-16 23:59:00.642643: step 1400, examples 70000, loss = 0.999205351 (191.066 examples/sec; 0.262 sec/batch)\n",
      "Top 1 validation accuracy: 0.5283018946647644 and top 2 validation accuracy: 0.7830188870429993\n",
      "Model Saved!\n",
      "2019-03-16 23:59:04.883132: step 1410, examples 70500, loss = 0.830895603 (199.977 examples/sec; 0.250 sec/batch)\n",
      "2019-03-16 23:59:07.352363: step 1420, examples 71000, loss = 1.096124411 (210.501 examples/sec; 0.238 sec/batch)\n",
      "2019-03-16 23:59:09.855874: step 1430, examples 71500, loss = 0.944233298 (188.215 examples/sec; 0.266 sec/batch)\n",
      "2019-03-16 23:59:12.336523: step 1440, examples 72000, loss = 0.948727369 (215.577 examples/sec; 0.232 sec/batch)\n",
      "2019-03-16 23:59:14.823352: step 1450, examples 72500, loss = 1.028439283 (199.978 examples/sec; 0.250 sec/batch)\n",
      "2019-03-16 23:59:17.293813: step 1460, examples 73000, loss = 0.832382441 (184.123 examples/sec; 0.272 sec/batch)\n",
      "2019-03-16 23:59:19.746303: step 1470, examples 73500, loss = 0.902076304 (214.180 examples/sec; 0.233 sec/batch)\n",
      "2019-03-16 23:59:22.237769: step 1480, examples 74000, loss = 1.063263893 (190.993 examples/sec; 0.262 sec/batch)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2019-03-16 23:59:24.706106: step 1490, examples 74500, loss = 1.040576577 (209.108 examples/sec; 0.239 sec/batch)\n",
      "2019-03-16 23:59:27.184996: step 1500, examples 75000, loss = 0.889536262 (197.867 examples/sec; 0.253 sec/batch)\n",
      "Top 1 validation accuracy: 0.5070754885673523 and top 2 validation accuracy: 0.7452830076217651\n",
      "Model Saved!\n",
      "2019-03-16 23:59:31.355877: step 1510, examples 75500, loss = 0.892614543 (205.401 examples/sec; 0.243 sec/batch)\n",
      "2019-03-16 23:59:33.834425: step 1520, examples 76000, loss = 0.997730792 (188.215 examples/sec; 0.266 sec/batch)\n",
      "2019-03-16 23:59:36.445608: step 1530, examples 76500, loss = 0.888986468 (180.646 examples/sec; 0.277 sec/batch)\n",
      "2019-03-16 23:59:39.177872: step 1540, examples 77000, loss = 1.053726435 (189.860 examples/sec; 0.263 sec/batch)\n",
      "2019-03-16 23:59:41.753160: step 1550, examples 77500, loss = 1.017059565 (211.735 examples/sec; 0.236 sec/batch)\n",
      "2019-03-16 23:59:44.278563: step 1560, examples 78000, loss = 0.971452951 (194.541 examples/sec; 0.257 sec/batch)\n",
      "2019-03-16 23:59:46.738667: step 1570, examples 78500, loss = 0.829048991 (203.967 examples/sec; 0.245 sec/batch)\n",
      "2019-03-16 23:59:49.253917: step 1580, examples 79000, loss = 1.002237797 (202.482 examples/sec; 0.247 sec/batch)\n",
      "2019-03-16 23:59:51.740984: step 1590, examples 79500, loss = 0.714188457 (204.663 examples/sec; 0.244 sec/batch)\n",
      "2019-03-16 23:59:54.223809: step 1600, examples 80000, loss = 1.071141243 (193.235 examples/sec; 0.259 sec/batch)\n",
      "Top 1 validation accuracy: 0.5778301954269409 and top 2 validation accuracy: 0.7712264060974121\n",
      "Model Saved!\n",
      "2019-03-16 23:59:58.446579: step 1610, examples 80500, loss = 0.842102766 (215.775 examples/sec; 0.232 sec/batch)\n",
      "2019-03-17 00:00:00.928590: step 1620, examples 81000, loss = 0.897592723 (199.980 examples/sec; 0.250 sec/batch)\n",
      "2019-03-17 00:00:03.515815: step 1630, examples 81500, loss = 0.829100490 (200.269 examples/sec; 0.250 sec/batch)\n",
      "2019-03-17 00:00:06.057574: step 1640, examples 82000, loss = 0.946146548 (195.557 examples/sec; 0.256 sec/batch)\n",
      "2019-03-17 00:00:08.602841: step 1650, examples 82500, loss = 1.069048762 (199.468 examples/sec; 0.251 sec/batch)\n",
      "2019-03-17 00:00:11.209774: step 1660, examples 83000, loss = 0.911313891 (188.891 examples/sec; 0.265 sec/batch)\n",
      "2019-03-17 00:00:13.776599: step 1670, examples 83500, loss = 1.005686641 (197.103 examples/sec; 0.254 sec/batch)\n",
      "2019-03-17 00:00:16.336161: step 1680, examples 84000, loss = 0.857643485 (208.773 examples/sec; 0.239 sec/batch)\n",
      "2019-03-17 00:00:18.854404: step 1690, examples 84500, loss = 0.922805607 (199.234 examples/sec; 0.251 sec/batch)\n",
      "2019-03-17 00:00:21.367296: step 1700, examples 85000, loss = 1.002813697 (214.840 examples/sec; 0.233 sec/batch)\n",
      "Top 1 validation accuracy: 0.5613207817077637 and top 2 validation accuracy: 0.7735849022865295\n",
      "Model Saved!\n",
      "2019-03-17 00:00:25.537448: step 1710, examples 85500, loss = 0.919332981 (202.552 examples/sec; 0.247 sec/batch)\n",
      "2019-03-17 00:00:27.999905: step 1720, examples 86000, loss = 1.029108763 (193.763 examples/sec; 0.258 sec/batch)\n",
      "2019-03-17 00:00:30.478191: step 1730, examples 86500, loss = 1.042358160 (209.702 examples/sec; 0.238 sec/batch)\n",
      "2019-03-17 00:00:32.996950: step 1740, examples 87000, loss = 0.897848666 (199.979 examples/sec; 0.250 sec/batch)\n",
      "2019-03-17 00:00:35.476184: step 1750, examples 87500, loss = 0.931667030 (214.075 examples/sec; 0.234 sec/batch)\n",
      "2019-03-17 00:00:37.950904: step 1760, examples 88000, loss = 0.870531797 (198.842 examples/sec; 0.251 sec/batch)\n",
      "2019-03-17 00:00:40.423791: step 1770, examples 88500, loss = 1.071249008 (190.976 examples/sec; 0.262 sec/batch)\n",
      "2019-03-17 00:00:42.865585: step 1780, examples 89000, loss = 1.187490821 (188.214 examples/sec; 0.266 sec/batch)\n",
      "2019-03-17 00:00:45.336100: step 1790, examples 89500, loss = 0.828196526 (195.324 examples/sec; 0.256 sec/batch)\n",
      "2019-03-17 00:00:47.870444: step 1800, examples 90000, loss = 0.931477308 (188.216 examples/sec; 0.266 sec/batch)\n",
      "Top 1 validation accuracy: 0.5424528121948242 and top 2 validation accuracy: 0.7523584961891174\n",
      "Model Saved!\n",
      "2019-03-17 00:00:52.052774: step 1810, examples 90500, loss = 0.880679727 (199.977 examples/sec; 0.250 sec/batch)\n",
      "2019-03-17 00:00:54.537553: step 1820, examples 91000, loss = 0.851781368 (194.022 examples/sec; 0.258 sec/batch)\n",
      "2019-03-17 00:00:57.052835: step 1830, examples 91500, loss = 0.889679372 (188.216 examples/sec; 0.266 sec/batch)\n",
      "2019-03-17 00:00:59.756305: step 1840, examples 92000, loss = 0.793048918 (182.209 examples/sec; 0.274 sec/batch)\n",
      "2019-03-17 00:01:02.374175: step 1850, examples 92500, loss = 0.740487933 (188.786 examples/sec; 0.265 sec/batch)\n",
      "2019-03-17 00:01:04.894100: step 1860, examples 93000, loss = 0.876982570 (213.310 examples/sec; 0.234 sec/batch)\n",
      "2019-03-17 00:01:07.399019: step 1870, examples 93500, loss = 0.946786344 (201.043 examples/sec; 0.249 sec/batch)\n",
      "2019-03-17 00:01:09.867561: step 1880, examples 94000, loss = 0.998481870 (213.311 examples/sec; 0.234 sec/batch)\n",
      "2019-03-17 00:01:12.287771: step 1890, examples 94500, loss = 0.814850569 (199.509 examples/sec; 0.251 sec/batch)\n",
      "2019-03-17 00:01:14.787203: step 1900, examples 95000, loss = 0.887234867 (199.976 examples/sec; 0.250 sec/batch)\n",
      "Top 1 validation accuracy: 0.5589622855186462 and top 2 validation accuracy: 0.7688679099082947\n",
      "Model Saved!\n",
      "2019-03-17 00:01:19.162428: step 1910, examples 95500, loss = 0.822620451 (189.269 examples/sec; 0.264 sec/batch)\n",
      "2019-03-17 00:01:21.693424: step 1920, examples 96000, loss = 0.871015668 (201.579 examples/sec; 0.248 sec/batch)\n",
      "2019-03-17 00:01:24.162390: step 1930, examples 96500, loss = 0.910002828 (210.419 examples/sec; 0.238 sec/batch)\n",
      "2019-03-17 00:01:26.628922: step 1940, examples 97000, loss = 0.871918082 (203.492 examples/sec; 0.246 sec/batch)\n",
      "2019-03-17 00:01:29.078993: step 1950, examples 97500, loss = 0.828449190 (201.601 examples/sec; 0.248 sec/batch)\n",
      "2019-03-17 00:01:31.529766: step 1960, examples 98000, loss = 0.856746554 (204.389 examples/sec; 0.245 sec/batch)\n",
      "2019-03-17 00:01:33.989029: step 1970, examples 98500, loss = 0.689161241 (199.674 examples/sec; 0.250 sec/batch)\n",
      "2019-03-17 00:01:36.514065: step 1980, examples 99000, loss = 0.927662134 (201.477 examples/sec; 0.248 sec/batch)\n",
      "2019-03-17 00:01:38.991368: step 1990, examples 99500, loss = 0.904191613 (199.976 examples/sec; 0.250 sec/batch)\n",
      "2019-03-17 00:01:41.443899: step 2000, examples 100000, loss = 0.853421688 (188.968 examples/sec; 0.265 sec/batch)\n",
      "Top 1 validation accuracy: 0.5377358198165894 and top 2 validation accuracy: 0.7924528121948242\n",
      "Model Saved!\n",
      "2019-03-17 00:01:45.711413: step 2010, examples 100500, loss = 0.792048693 (204.172 examples/sec; 0.245 sec/batch)\n",
      "2019-03-17 00:01:48.162100: step 2020, examples 101000, loss = 1.032657146 (198.562 examples/sec; 0.252 sec/batch)\n",
      "2019-03-17 00:01:50.633298: step 2030, examples 101500, loss = 0.886890590 (194.645 examples/sec; 0.257 sec/batch)\n",
      "2019-03-17 00:01:53.129223: step 2040, examples 102000, loss = 0.939067841 (193.435 examples/sec; 0.258 sec/batch)\n",
      "2019-03-17 00:01:55.568431: step 2050, examples 102500, loss = 0.897603810 (212.295 examples/sec; 0.236 sec/batch)\n",
      "2019-03-17 00:01:58.005921: step 2060, examples 103000, loss = 0.929053903 (199.980 examples/sec; 0.250 sec/batch)\n",
      "2019-03-17 00:02:00.440950: step 2070, examples 103500, loss = 0.890500605 (201.222 examples/sec; 0.248 sec/batch)\n",
      "2019-03-17 00:02:02.884448: step 2080, examples 104000, loss = 1.027495861 (199.981 examples/sec; 0.250 sec/batch)\n",
      "2019-03-17 00:02:05.336893: step 2090, examples 104500, loss = 0.996189177 (211.681 examples/sec; 0.236 sec/batch)\n",
      "2019-03-17 00:02:07.834073: step 2100, examples 105000, loss = 0.946914792 (213.309 examples/sec; 0.234 sec/batch)\n",
      "Top 1 validation accuracy: 0.5448113083839417 and top 2 validation accuracy: 0.7783018946647644\n",
      "Model Saved!\n",
      "2019-03-17 00:02:12.146959: step 2110, examples 105500, loss = 0.887719274 (188.452 examples/sec; 0.265 sec/batch)\n",
      "2019-03-17 00:02:14.568460: step 2120, examples 106000, loss = 0.860655546 (215.492 examples/sec; 0.232 sec/batch)\n",
      "2019-03-17 00:02:16.995134: step 2130, examples 106500, loss = 0.913914680 (213.310 examples/sec; 0.234 sec/batch)\n",
      "2019-03-17 00:02:19.484392: step 2140, examples 107000, loss = 0.825362563 (202.591 examples/sec; 0.247 sec/batch)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2019-03-17 00:02:21.996940: step 2150, examples 107500, loss = 0.978056431 (199.978 examples/sec; 0.250 sec/batch)\n",
      "2019-03-17 00:02:24.537595: step 2160, examples 108000, loss = 1.018062592 (198.036 examples/sec; 0.252 sec/batch)\n",
      "2019-03-17 00:02:27.033224: step 2170, examples 108500, loss = 0.738855720 (199.978 examples/sec; 0.250 sec/batch)\n",
      "2019-03-17 00:02:29.514192: step 2180, examples 109000, loss = 1.068460226 (193.628 examples/sec; 0.258 sec/batch)\n",
      "2019-03-17 00:02:31.965799: step 2190, examples 109500, loss = 1.008248210 (213.307 examples/sec; 0.234 sec/batch)\n",
      "2019-03-17 00:02:34.442388: step 2200, examples 110000, loss = 0.807053566 (201.164 examples/sec; 0.249 sec/batch)\n",
      "Top 1 validation accuracy: 0.5566037893295288 and top 2 validation accuracy: 0.75\n",
      "Model Saved!\n",
      "2019-03-17 00:02:38.683300: step 2210, examples 110500, loss = 0.614175498 (209.913 examples/sec; 0.238 sec/batch)\n",
      "2019-03-17 00:02:41.210165: step 2220, examples 111000, loss = 0.989982665 (187.598 examples/sec; 0.267 sec/batch)\n",
      "2019-03-17 00:02:43.704626: step 2230, examples 111500, loss = 0.866506338 (208.942 examples/sec; 0.239 sec/batch)\n",
      "2019-03-17 00:02:46.146104: step 2240, examples 112000, loss = 0.781563997 (198.184 examples/sec; 0.252 sec/batch)\n",
      "2019-03-17 00:02:48.583937: step 2250, examples 112500, loss = 0.976939321 (202.153 examples/sec; 0.247 sec/batch)\n",
      "2019-03-17 00:02:51.037787: step 2260, examples 113000, loss = 0.992046475 (213.309 examples/sec; 0.234 sec/batch)\n",
      "2019-03-17 00:02:53.531902: step 2270, examples 113500, loss = 0.852174878 (190.155 examples/sec; 0.263 sec/batch)\n",
      "2019-03-17 00:02:56.227762: step 2280, examples 114000, loss = 0.721650839 (197.885 examples/sec; 0.253 sec/batch)\n",
      "2019-03-17 00:02:58.782569: step 2290, examples 114500, loss = 1.009957314 (185.376 examples/sec; 0.270 sec/batch)\n",
      "2019-03-17 00:03:01.302771: step 2300, examples 115000, loss = 0.833068013 (196.327 examples/sec; 0.255 sec/batch)\n",
      "Top 1 validation accuracy: 0.599056601524353 and top 2 validation accuracy: 0.7900943160057068\n",
      "Model Saved!\n",
      "2019-03-17 00:03:05.634384: step 2310, examples 115500, loss = 0.734869480 (199.468 examples/sec; 0.251 sec/batch)\n",
      "2019-03-17 00:03:08.223299: step 2320, examples 116000, loss = 0.789796591 (188.890 examples/sec; 0.265 sec/batch)\n",
      "2019-03-17 00:03:10.774082: step 2330, examples 116500, loss = 0.972252488 (191.428 examples/sec; 0.261 sec/batch)\n",
      "2019-03-17 00:03:13.371989: step 2340, examples 117000, loss = 0.761386395 (195.174 examples/sec; 0.256 sec/batch)\n",
      "2019-03-17 00:03:15.919263: step 2350, examples 117500, loss = 0.913840652 (199.468 examples/sec; 0.251 sec/batch)\n",
      "2019-03-17 00:03:18.401424: step 2360, examples 118000, loss = 0.889611006 (195.811 examples/sec; 0.255 sec/batch)\n",
      "2019-03-17 00:03:20.904206: step 2370, examples 118500, loss = 1.007011056 (215.836 examples/sec; 0.232 sec/batch)\n",
      "2019-03-17 00:03:23.329943: step 2380, examples 119000, loss = 0.986793935 (213.062 examples/sec; 0.235 sec/batch)\n",
      "2019-03-17 00:03:25.789840: step 2390, examples 119500, loss = 0.838673592 (202.702 examples/sec; 0.247 sec/batch)\n",
      "2019-03-17 00:03:28.316769: step 2400, examples 120000, loss = 0.896147788 (200.269 examples/sec; 0.250 sec/batch)\n",
      "Top 1 validation accuracy: 0.5636792182922363 and top 2 validation accuracy: 0.8136792182922363\n",
      "Model Saved!\n",
      "2019-03-17 00:03:32.603918: step 2410, examples 120500, loss = 1.147068858 (203.874 examples/sec; 0.245 sec/batch)\n",
      "2019-03-17 00:03:35.037690: step 2420, examples 121000, loss = 0.929815054 (213.310 examples/sec; 0.234 sec/batch)\n",
      "2019-03-17 00:03:37.521270: step 2430, examples 121500, loss = 1.109177828 (196.219 examples/sec; 0.255 sec/batch)\n",
      "2019-03-17 00:03:40.001829: step 2440, examples 122000, loss = 0.779368043 (180.323 examples/sec; 0.277 sec/batch)\n",
      "2019-03-17 00:03:42.541515: step 2450, examples 122500, loss = 0.746397853 (194.035 examples/sec; 0.258 sec/batch)\n",
      "2019-03-17 00:03:45.309844: step 2460, examples 123000, loss = 0.757248163 (177.462 examples/sec; 0.282 sec/batch)\n",
      "2019-03-17 00:03:47.975001: step 2470, examples 123500, loss = 0.662458301 (200.270 examples/sec; 0.250 sec/batch)\n",
      "2019-03-17 00:03:50.539319: step 2480, examples 124000, loss = 0.804416537 (201.891 examples/sec; 0.248 sec/batch)\n",
      "2019-03-17 00:03:53.207439: step 2490, examples 124500, loss = 0.763165534 (201.891 examples/sec; 0.248 sec/batch)\n",
      "2019-03-17 00:03:55.729580: step 2500, examples 125000, loss = 0.995898485 (201.443 examples/sec; 0.248 sec/batch)\n",
      "Top 1 validation accuracy: 0.5070754885673523 and top 2 validation accuracy: 0.7877358198165894\n",
      "Model Saved!\n",
      "2019-03-17 00:04:00.021647: step 2510, examples 125500, loss = 0.762639582 (199.978 examples/sec; 0.250 sec/batch)\n",
      "2019-03-17 00:04:02.460914: step 2520, examples 126000, loss = 0.807362556 (212.300 examples/sec; 0.236 sec/batch)\n",
      "2019-03-17 00:04:04.944805: step 2530, examples 126500, loss = 0.942239285 (199.429 examples/sec; 0.251 sec/batch)\n",
      "2019-03-17 00:04:07.586598: step 2540, examples 127000, loss = 0.758100808 (195.557 examples/sec; 0.256 sec/batch)\n",
      "2019-03-17 00:04:10.137381: step 2550, examples 127500, loss = 0.957689166 (193.283 examples/sec; 0.259 sec/batch)\n",
      "2019-03-17 00:04:12.684669: step 2560, examples 128000, loss = 0.765784025 (195.557 examples/sec; 0.256 sec/batch)\n",
      "2019-03-17 00:04:15.234448: step 2570, examples 128500, loss = 0.725301445 (185.035 examples/sec; 0.270 sec/batch)\n",
      "2019-03-17 00:04:17.807408: step 2580, examples 129000, loss = 0.858450532 (203.857 examples/sec; 0.245 sec/batch)\n",
      "2019-03-17 00:04:20.280353: step 2590, examples 129500, loss = 0.842791855 (197.290 examples/sec; 0.253 sec/batch)\n",
      "2019-03-17 00:04:22.772126: step 2600, examples 130000, loss = 0.923469782 (208.804 examples/sec; 0.239 sec/batch)\n",
      "Top 1 validation accuracy: 0.5589622855186462 and top 2 validation accuracy: 0.7853773832321167\n",
      "Model Saved!\n",
      "2019-03-17 00:04:27.348339: step 2610, examples 130500, loss = 0.801060915 (194.466 examples/sec; 0.257 sec/batch)\n",
      "2019-03-17 00:04:29.826097: step 2620, examples 131000, loss = 0.864699364 (199.978 examples/sec; 0.250 sec/batch)\n",
      "2019-03-17 00:04:32.323082: step 2630, examples 131500, loss = 0.910159767 (207.352 examples/sec; 0.241 sec/batch)\n",
      "2019-03-17 00:04:35.184845: step 2640, examples 132000, loss = 0.843830884 (134.049 examples/sec; 0.373 sec/batch)\n",
      "2019-03-17 00:04:37.832173: step 2650, examples 132500, loss = 1.033349037 (190.111 examples/sec; 0.263 sec/batch)\n",
      "2019-03-17 00:04:40.375936: step 2660, examples 133000, loss = 0.970971406 (181.997 examples/sec; 0.275 sec/batch)\n",
      "2019-03-17 00:04:42.916351: step 2670, examples 133500, loss = 0.835878730 (202.846 examples/sec; 0.246 sec/batch)\n",
      "2019-03-17 00:04:45.387920: step 2680, examples 134000, loss = 1.102729201 (205.823 examples/sec; 0.243 sec/batch)\n",
      "2019-03-17 00:04:47.901620: step 2690, examples 134500, loss = 0.746448040 (199.979 examples/sec; 0.250 sec/batch)\n",
      "2019-03-17 00:04:50.359907: step 2700, examples 135000, loss = 0.891453743 (200.108 examples/sec; 0.250 sec/batch)\n",
      "Top 1 validation accuracy: 0.5636792182922363 and top 2 validation accuracy: 0.7924528121948242\n",
      "Model Saved!\n",
      "2019-03-17 00:04:54.653551: step 2710, examples 135500, loss = 0.924057424 (196.223 examples/sec; 0.255 sec/batch)\n",
      "2019-03-17 00:04:57.111929: step 2720, examples 136000, loss = 0.726943254 (196.251 examples/sec; 0.255 sec/batch)\n",
      "2019-03-17 00:04:59.617229: step 2730, examples 136500, loss = 0.827032447 (195.050 examples/sec; 0.256 sec/batch)\n",
      "2019-03-17 00:05:02.085131: step 2740, examples 137000, loss = 1.137700319 (191.040 examples/sec; 0.262 sec/batch)\n",
      "2019-03-17 00:05:04.630676: step 2750, examples 137500, loss = 0.716130316 (203.392 examples/sec; 0.246 sec/batch)\n",
      "2019-03-17 00:05:07.275184: step 2760, examples 138000, loss = 1.053629398 (151.351 examples/sec; 0.330 sec/batch)\n",
      "2019-03-17 00:05:09.835684: step 2770, examples 138500, loss = 0.706095159 (199.979 examples/sec; 0.250 sec/batch)\n",
      "2019-03-17 00:05:12.418745: step 2780, examples 139000, loss = 0.921632171 (202.970 examples/sec; 0.246 sec/batch)\n",
      "2019-03-17 00:05:15.214990: step 2790, examples 139500, loss = 0.856871009 (172.908 examples/sec; 0.289 sec/batch)\n",
      "2019-03-17 00:05:17.944306: step 2800, examples 140000, loss = 0.777359188 (166.780 examples/sec; 0.300 sec/batch)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Top 1 validation accuracy: 0.5566037893295288 and top 2 validation accuracy: 0.7924528121948242\n",
      "Model Saved!\n",
      "2019-03-17 00:05:22.858374: step 2810, examples 140500, loss = 0.941961408 (174.972 examples/sec; 0.286 sec/batch)\n",
      "2019-03-17 00:05:25.624731: step 2820, examples 141000, loss = 0.748861551 (166.223 examples/sec; 0.301 sec/batch)\n",
      "2019-03-17 00:05:28.639747: step 2830, examples 141500, loss = 0.720973134 (171.956 examples/sec; 0.291 sec/batch)\n",
      "2019-03-17 00:05:31.488322: step 2840, examples 142000, loss = 0.926611543 (169.616 examples/sec; 0.295 sec/batch)\n",
      "2019-03-17 00:05:34.884353: step 2850, examples 142500, loss = 0.920786977 (134.413 examples/sec; 0.372 sec/batch)\n",
      "2019-03-17 00:05:38.169088: step 2860, examples 143000, loss = 0.888668299 (132.625 examples/sec; 0.377 sec/batch)\n",
      "2019-03-17 00:05:41.228222: step 2870, examples 143500, loss = 0.732246757 (152.499 examples/sec; 0.328 sec/batch)\n",
      "2019-03-17 00:05:44.060754: step 2880, examples 144000, loss = 0.927811742 (176.208 examples/sec; 0.284 sec/batch)\n",
      "2019-03-17 00:05:47.021627: step 2890, examples 144500, loss = 0.759917796 (175.589 examples/sec; 0.285 sec/batch)\n",
      "2019-03-17 00:05:49.964452: step 2900, examples 145000, loss = 0.965933204 (150.202 examples/sec; 0.333 sec/batch)\n",
      "Top 1 validation accuracy: 0.5872641801834106 and top 2 validation accuracy: 0.8042452931404114\n",
      "Model Saved!\n",
      "2019-03-17 00:05:54.859468: step 2910, examples 145500, loss = 0.986943007 (194.036 examples/sec; 0.258 sec/batch)\n",
      "2019-03-17 00:05:57.682976: step 2920, examples 146000, loss = 0.749830842 (186.768 examples/sec; 0.268 sec/batch)\n",
      "2019-03-17 00:06:00.379147: step 2930, examples 146500, loss = 0.895795822 (184.011 examples/sec; 0.272 sec/batch)\n",
      "2019-03-17 00:06:03.054260: step 2940, examples 147000, loss = 0.957878351 (186.071 examples/sec; 0.269 sec/batch)\n",
      "2019-03-17 00:06:05.906847: step 2950, examples 147500, loss = 0.796489239 (166.223 examples/sec; 0.301 sec/batch)\n",
      "2019-03-17 00:06:08.716323: step 2960, examples 148000, loss = 0.760550618 (162.430 examples/sec; 0.308 sec/batch)\n",
      "2019-03-17 00:06:11.573914: step 2970, examples 148500, loss = 0.766271174 (165.672 examples/sec; 0.302 sec/batch)\n",
      "2019-03-17 00:06:14.794478: step 2980, examples 149000, loss = 0.788143754 (155.834 examples/sec; 0.321 sec/batch)\n",
      "2019-03-17 00:06:17.936397: step 2990, examples 149500, loss = 0.738380194 (171.653 examples/sec; 0.291 sec/batch)\n",
      "2019-03-17 00:06:21.033133: step 3000, examples 150000, loss = 0.784124136 (150.428 examples/sec; 0.332 sec/batch)\n",
      "Top 1 validation accuracy: 0.5235849022865295 and top 2 validation accuracy: 0.7617924809455872\n",
      "Model Saved!\n",
      "2019-03-17 00:06:26.421713: step 3010, examples 150500, loss = 0.750018120 (171.660 examples/sec; 0.291 sec/batch)\n",
      "2019-03-17 00:06:29.380238: step 3020, examples 151000, loss = 0.741499662 (171.646 examples/sec; 0.291 sec/batch)\n",
      "2019-03-17 00:06:32.411619: step 3030, examples 151500, loss = 0.721810937 (147.536 examples/sec; 0.339 sec/batch)\n",
      "2019-03-17 00:06:35.390844: step 3040, examples 152000, loss = 0.750460148 (170.195 examples/sec; 0.294 sec/batch)\n",
      "2019-03-17 00:06:38.216859: step 3050, examples 152500, loss = 0.687218130 (188.178 examples/sec; 0.266 sec/batch)\n",
      "2019-03-17 00:06:41.152665: step 3060, examples 153000, loss = 0.770645797 (147.974 examples/sec; 0.338 sec/batch)\n",
      "2019-03-17 00:06:44.120578: step 3070, examples 153500, loss = 0.947089255 (150.646 examples/sec; 0.332 sec/batch)\n",
      "2019-03-17 00:06:46.785740: step 3080, examples 154000, loss = 0.799189866 (214.989 examples/sec; 0.233 sec/batch)\n",
      "2019-03-17 00:06:49.399206: step 3090, examples 154500, loss = 0.743808210 (208.351 examples/sec; 0.240 sec/batch)\n",
      "2019-03-17 00:06:51.855751: step 3100, examples 155000, loss = 0.906570077 (213.977 examples/sec; 0.234 sec/batch)\n",
      "Top 1 validation accuracy: 0.5660377144813538 and top 2 validation accuracy: 0.7783018946647644\n",
      "Model Saved!\n",
      "2019-03-17 00:06:56.146603: step 3110, examples 155500, loss = 0.677094460 (189.321 examples/sec; 0.264 sec/batch)\n",
      "2019-03-17 00:06:58.644364: step 3120, examples 156000, loss = 0.831334233 (192.043 examples/sec; 0.260 sec/batch)\n",
      "2019-03-17 00:07:01.218418: step 3130, examples 156500, loss = 0.869198442 (199.074 examples/sec; 0.251 sec/batch)\n",
      "2019-03-17 00:07:03.749218: step 3140, examples 157000, loss = 0.830089271 (197.442 examples/sec; 0.253 sec/batch)\n",
      "2019-03-17 00:07:06.241381: step 3150, examples 157500, loss = 0.882480145 (199.062 examples/sec; 0.251 sec/batch)\n",
      "2019-03-17 00:07:08.735371: step 3160, examples 158000, loss = 0.645935059 (203.565 examples/sec; 0.246 sec/batch)\n",
      "2019-03-17 00:07:11.458719: step 3170, examples 158500, loss = 0.957259655 (178.242 examples/sec; 0.281 sec/batch)\n",
      "2019-03-17 00:07:14.146730: step 3180, examples 159000, loss = 0.745743454 (188.199 examples/sec; 0.266 sec/batch)\n",
      "2019-03-17 00:07:16.816699: step 3190, examples 159500, loss = 0.634931326 (174.810 examples/sec; 0.286 sec/batch)\n",
      "2019-03-17 00:07:19.564018: step 3200, examples 160000, loss = 0.854249239 (181.921 examples/sec; 0.275 sec/batch)\n",
      "Top 1 validation accuracy: 0.5566037893295288 and top 2 validation accuracy: 0.7594339847564697\n",
      "Model Saved!\n",
      "2019-03-17 00:07:24.558905: step 3210, examples 160500, loss = 0.834821761 (191.062 examples/sec; 0.262 sec/batch)\n",
      "2019-03-17 00:07:27.328271: step 3220, examples 161000, loss = 0.805253983 (156.815 examples/sec; 0.319 sec/batch)\n",
      "2019-03-17 00:07:30.310200: step 3230, examples 161500, loss = 0.849040151 (162.964 examples/sec; 0.307 sec/batch)\n",
      "2019-03-17 00:07:33.284297: step 3240, examples 162000, loss = 0.794512391 (170.667 examples/sec; 0.293 sec/batch)\n",
      "2019-03-17 00:07:35.989045: step 3250, examples 162500, loss = 0.879289150 (198.369 examples/sec; 0.252 sec/batch)\n",
      "2019-03-17 00:07:38.714467: step 3260, examples 163000, loss = 0.746123135 (180.678 examples/sec; 0.277 sec/batch)\n",
      "2019-03-17 00:07:41.263245: step 3270, examples 163500, loss = 0.720893621 (191.796 examples/sec; 0.261 sec/batch)\n",
      "2019-03-17 00:07:43.851127: step 3280, examples 164000, loss = 0.806908488 (189.608 examples/sec; 0.264 sec/batch)\n",
      "2019-03-17 00:07:46.655082: step 3290, examples 164500, loss = 0.895976841 (190.696 examples/sec; 0.262 sec/batch)\n",
      "2019-03-17 00:07:49.635080: step 3300, examples 165000, loss = 0.834984779 (156.805 examples/sec; 0.319 sec/batch)\n",
      "Top 1 validation accuracy: 0.5683962106704712 and top 2 validation accuracy: 0.7924528121948242\n",
      "Model Saved!\n",
      "2019-03-17 00:07:54.672122: step 3310, examples 165500, loss = 0.841899633 (194.793 examples/sec; 0.257 sec/batch)\n",
      "2019-03-17 00:07:57.339018: step 3320, examples 166000, loss = 0.709583282 (189.030 examples/sec; 0.265 sec/batch)\n",
      "2019-03-17 00:08:00.198622: step 3330, examples 166500, loss = 0.755865335 (183.673 examples/sec; 0.272 sec/batch)\n",
      "2019-03-17 00:08:03.073794: step 3340, examples 167000, loss = 0.952686429 (162.964 examples/sec; 0.307 sec/batch)\n",
      "2019-03-17 00:08:05.978056: step 3350, examples 167500, loss = 0.852840424 (173.753 examples/sec; 0.288 sec/batch)\n",
      "2019-03-17 00:08:08.723870: step 3360, examples 168000, loss = 0.742415786 (179.056 examples/sec; 0.279 sec/batch)\n",
      "2019-03-17 00:08:11.483207: step 3370, examples 168500, loss = 0.955371141 (165.123 examples/sec; 0.303 sec/batch)\n",
      "2019-03-17 00:08:14.251947: step 3380, examples 169000, loss = 0.698127031 (164.024 examples/sec; 0.305 sec/batch)\n",
      "2019-03-17 00:08:17.101763: step 3390, examples 169500, loss = 0.773179770 (172.749 examples/sec; 0.289 sec/batch)\n",
      "2019-03-17 00:08:19.718721: step 3400, examples 170000, loss = 0.874339461 (195.557 examples/sec; 0.256 sec/batch)\n",
      "Top 1 validation accuracy: 0.5825471878051758 and top 2 validation accuracy: 0.7971698045730591\n",
      "Model Saved!\n",
      "2019-03-17 00:08:24.475370: step 3410, examples 170500, loss = 0.789626241 (191.061 examples/sec; 0.262 sec/batch)\n",
      "2019-03-17 00:08:27.147476: step 3420, examples 171000, loss = 0.791012287 (188.890 examples/sec; 0.265 sec/batch)\n",
      "2019-03-17 00:08:29.824292: step 3430, examples 171500, loss = 0.861529469 (210.500 examples/sec; 0.238 sec/batch)\n",
      "2019-03-17 00:08:32.549736: step 3440, examples 172000, loss = 0.682518125 (170.195 examples/sec; 0.294 sec/batch)\n",
      "2019-03-17 00:08:35.235021: step 3450, examples 172500, loss = 0.834928095 (192.537 examples/sec; 0.260 sec/batch)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2019-03-17 00:08:37.952247: step 3460, examples 173000, loss = 1.042402864 (186.071 examples/sec; 0.269 sec/batch)\n",
      "2019-03-17 00:08:40.622755: step 3470, examples 173500, loss = 0.904824018 (174.722 examples/sec; 0.286 sec/batch)\n",
      "2019-03-17 00:08:43.329573: step 3480, examples 174000, loss = 0.773936033 (180.678 examples/sec; 0.277 sec/batch)\n",
      "2019-03-17 00:08:46.311183: step 3490, examples 174500, loss = 0.793661714 (147.972 examples/sec; 0.338 sec/batch)\n",
      "2019-03-17 00:08:49.556933: step 3500, examples 175000, loss = 0.915238738 (158.812 examples/sec; 0.315 sec/batch)\n",
      "Top 1 validation accuracy: 0.5707547068595886 and top 2 validation accuracy: 0.8113207817077637\n",
      "Model Saved!\n",
      "2019-03-17 00:08:54.719854: step 3510, examples 175500, loss = 0.830311418 (174.360 examples/sec; 0.287 sec/batch)\n",
      "2019-03-17 00:08:57.618562: step 3520, examples 176000, loss = 0.769705057 (185.035 examples/sec; 0.270 sec/batch)\n",
      "2019-03-17 00:09:00.497718: step 3530, examples 176500, loss = 0.804015160 (173.450 examples/sec; 0.288 sec/batch)\n",
      "2019-03-17 00:09:03.318719: step 3540, examples 177000, loss = 0.715571284 (140.867 examples/sec; 0.355 sec/batch)\n",
      "2019-03-17 00:09:06.195023: step 3550, examples 177500, loss = 0.784305215 (191.053 examples/sec; 0.262 sec/batch)\n",
      "2019-03-17 00:09:09.006679: step 3560, examples 178000, loss = 0.706213355 (176.826 examples/sec; 0.283 sec/batch)\n",
      "2019-03-17 00:09:11.652027: step 3570, examples 178500, loss = 0.777784586 (194.793 examples/sec; 0.257 sec/batch)\n",
      "2019-03-17 00:09:14.292172: step 3580, examples 179000, loss = 0.834384918 (176.833 examples/sec; 0.283 sec/batch)\n",
      "2019-03-17 00:09:16.992580: step 3590, examples 179500, loss = 0.707282066 (192.537 examples/sec; 0.260 sec/batch)\n",
      "2019-03-17 00:09:19.876263: step 3600, examples 180000, loss = 0.842246175 (149.751 examples/sec; 0.334 sec/batch)\n",
      "Top 1 validation accuracy: 0.5636792182922363 and top 2 validation accuracy: 0.801886796951294\n",
      "Model Saved!\n",
      "2019-03-17 00:09:24.846446: step 3610, examples 180500, loss = 0.980975628 (187.823 examples/sec; 0.266 sec/batch)\n",
      "2019-03-17 00:09:27.495976: step 3620, examples 181000, loss = 0.827179074 (202.419 examples/sec; 0.247 sec/batch)\n",
      "2019-03-17 00:09:29.944202: step 3630, examples 181500, loss = 0.762810707 (217.719 examples/sec; 0.230 sec/batch)\n",
      "2019-03-17 00:09:32.394592: step 3640, examples 182000, loss = 0.790837765 (198.538 examples/sec; 0.252 sec/batch)\n",
      "2019-03-17 00:09:34.843295: step 3650, examples 182500, loss = 0.696188450 (193.388 examples/sec; 0.259 sec/batch)\n",
      "2019-03-17 00:09:37.352032: step 3660, examples 183000, loss = 0.746319413 (199.929 examples/sec; 0.250 sec/batch)\n",
      "2019-03-17 00:09:39.818972: step 3670, examples 183500, loss = 0.699451566 (213.312 examples/sec; 0.234 sec/batch)\n",
      "2019-03-17 00:09:42.284206: step 3680, examples 184000, loss = 1.059954882 (202.870 examples/sec; 0.246 sec/batch)\n",
      "2019-03-17 00:09:44.832968: step 3690, examples 184500, loss = 0.630952716 (202.278 examples/sec; 0.247 sec/batch)\n",
      "2019-03-17 00:09:47.379674: step 3700, examples 185000, loss = 0.709562004 (200.931 examples/sec; 0.249 sec/batch)\n",
      "Top 1 validation accuracy: 0.5754716992378235 and top 2 validation accuracy: 0.7877358198165894\n",
      "Model Saved!\n",
      "2019-03-17 00:09:51.647240: step 3710, examples 185500, loss = 0.767969370 (205.069 examples/sec; 0.244 sec/batch)\n",
      "2019-03-17 00:09:54.018102: step 3720, examples 186000, loss = 0.865579009 (203.153 examples/sec; 0.246 sec/batch)\n",
      "2019-03-17 00:09:56.574463: step 3730, examples 186500, loss = 0.655561030 (190.436 examples/sec; 0.263 sec/batch)\n",
      "2019-03-17 00:09:59.163309: step 3740, examples 187000, loss = 0.900711536 (198.661 examples/sec; 0.252 sec/batch)\n",
      "2019-03-17 00:10:01.731787: step 3750, examples 187500, loss = 0.696625888 (207.466 examples/sec; 0.241 sec/batch)\n",
      "2019-03-17 00:10:04.393644: step 3760, examples 188000, loss = 0.740202069 (182.663 examples/sec; 0.274 sec/batch)\n",
      "2019-03-17 00:10:07.194090: step 3770, examples 188500, loss = 0.687794685 (165.671 examples/sec; 0.302 sec/batch)\n",
      "2019-03-17 00:10:09.828095: step 3780, examples 189000, loss = 0.611413419 (187.470 examples/sec; 0.267 sec/batch)\n",
      "2019-03-17 00:10:12.472124: step 3790, examples 189500, loss = 0.810662389 (205.214 examples/sec; 0.244 sec/batch)\n",
      "2019-03-17 00:10:14.966757: step 3800, examples 190000, loss = 0.798049927 (201.077 examples/sec; 0.249 sec/batch)\n",
      "Top 1 validation accuracy: 0.5825471878051758 and top 2 validation accuracy: 0.7924528121948242\n",
      "Model Saved!\n",
      "2019-03-17 00:10:19.252154: step 3810, examples 190500, loss = 0.618763089 (201.891 examples/sec; 0.248 sec/batch)\n",
      "2019-03-17 00:10:21.928270: step 3820, examples 191000, loss = 0.737167954 (196.326 examples/sec; 0.255 sec/batch)\n",
      "2019-03-17 00:10:24.477047: step 3830, examples 191500, loss = 0.920817256 (197.885 examples/sec; 0.253 sec/batch)\n",
      "2019-03-17 00:10:26.995745: step 3840, examples 192000, loss = 0.858898222 (202.711 examples/sec; 0.247 sec/batch)\n",
      "2019-03-17 00:10:29.528479: step 3850, examples 192500, loss = 0.749911427 (184.011 examples/sec; 0.272 sec/batch)\n",
      "2019-03-17 00:10:32.095305: step 3860, examples 193000, loss = 0.737467945 (203.539 examples/sec; 0.246 sec/batch)\n",
      "2019-03-17 00:10:34.567879: step 3870, examples 193500, loss = 0.817096353 (209.526 examples/sec; 0.239 sec/batch)\n",
      "2019-03-17 00:10:37.066524: step 3880, examples 194000, loss = 0.742447019 (199.469 examples/sec; 0.251 sec/batch)\n",
      "2019-03-17 00:10:39.598257: step 3890, examples 194500, loss = 0.729768157 (189.608 examples/sec; 0.264 sec/batch)\n",
      "2019-03-17 00:10:42.115951: step 3900, examples 195000, loss = 0.946813822 (198.674 examples/sec; 0.252 sec/batch)\n",
      "Top 1 validation accuracy: 0.525943398475647 and top 2 validation accuracy: 0.775943398475647\n",
      "Model Saved!\n",
      "2019-03-17 00:10:46.470530: step 3910, examples 195500, loss = 1.028694510 (203.539 examples/sec; 0.246 sec/batch)\n",
      "2019-03-17 00:10:48.991233: step 3920, examples 196000, loss = 0.591473222 (194.035 examples/sec; 0.258 sec/batch)\n",
      "2019-03-17 00:10:51.491882: step 3930, examples 196500, loss = 0.609364748 (192.537 examples/sec; 0.260 sec/batch)\n",
      "2019-03-17 00:10:54.004563: step 3940, examples 197000, loss = 0.722639680 (202.712 examples/sec; 0.247 sec/batch)\n",
      "2019-03-17 00:10:56.534291: step 3950, examples 197500, loss = 0.628271282 (200.269 examples/sec; 0.250 sec/batch)\n",
      "2019-03-17 00:10:59.029927: step 3960, examples 198000, loss = 0.734620988 (204.372 examples/sec; 0.245 sec/batch)\n",
      "2019-03-17 00:11:01.585723: step 3970, examples 198500, loss = 0.824908018 (196.327 examples/sec; 0.255 sec/batch)\n",
      "2019-03-17 00:11:04.059301: step 3980, examples 199000, loss = 0.763115585 (202.711 examples/sec; 0.247 sec/batch)\n",
      "2019-03-17 00:11:06.593038: step 3990, examples 199500, loss = 0.654479980 (189.609 examples/sec; 0.264 sec/batch)\n",
      "2019-03-17 00:11:09.128780: step 4000, examples 200000, loss = 0.777998269 (213.108 examples/sec; 0.235 sec/batch)\n",
      "Top 1 validation accuracy: 0.5424528121948242 and top 2 validation accuracy: 0.7570754885673523\n",
      "Model Saved!\n",
      "2019-03-17 00:11:13.431222: step 4010, examples 200500, loss = 0.708195567 (201.076 examples/sec; 0.249 sec/batch)\n",
      "2019-03-17 00:11:15.929671: step 4020, examples 201000, loss = 0.828778386 (188.217 examples/sec; 0.266 sec/batch)\n",
      "2019-03-17 00:11:18.422664: step 4030, examples 201500, loss = 0.902188063 (195.592 examples/sec; 0.256 sec/batch)\n",
      "2019-03-17 00:11:20.917145: step 4040, examples 202000, loss = 0.799910069 (188.215 examples/sec; 0.266 sec/batch)\n",
      "2019-03-17 00:11:23.483203: step 4050, examples 202500, loss = 0.813071370 (198.895 examples/sec; 0.251 sec/batch)\n",
      "2019-03-17 00:11:26.008815: step 4060, examples 203000, loss = 0.731429815 (213.310 examples/sec; 0.234 sec/batch)\n",
      "2019-03-17 00:11:28.557439: step 4070, examples 203500, loss = 0.809954822 (211.054 examples/sec; 0.237 sec/batch)\n",
      "2019-03-17 00:11:31.092169: step 4080, examples 204000, loss = 0.759351790 (192.536 examples/sec; 0.260 sec/batch)\n",
      "2019-03-17 00:11:33.602482: step 4090, examples 204500, loss = 0.626035988 (199.617 examples/sec; 0.250 sec/batch)\n",
      "2019-03-17 00:11:36.119031: step 4100, examples 205000, loss = 0.798297763 (196.687 examples/sec; 0.254 sec/batch)\n",
      "Top 1 validation accuracy: 0.5542452931404114 and top 2 validation accuracy: 0.7971698045730591\n",
      "Model Saved!\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2019-03-17 00:11:40.478830: step 4110, examples 205500, loss = 0.933153152 (199.543 examples/sec; 0.251 sec/batch)\n",
      "2019-03-17 00:11:43.029074: step 4120, examples 206000, loss = 0.742695093 (189.551 examples/sec; 0.264 sec/batch)\n",
      "2019-03-17 00:11:45.709838: step 4130, examples 206500, loss = 0.691643238 (206.384 examples/sec; 0.242 sec/batch)\n",
      "2019-03-17 00:11:48.298569: step 4140, examples 207000, loss = 0.639336944 (185.755 examples/sec; 0.269 sec/batch)\n",
      "2019-03-17 00:11:51.100738: step 4150, examples 207500, loss = 0.783660948 (154.387 examples/sec; 0.324 sec/batch)\n",
      "2019-03-17 00:11:53.897175: step 4160, examples 208000, loss = 0.762989163 (181.336 examples/sec; 0.276 sec/batch)\n",
      "2019-03-17 00:11:56.594348: step 4170, examples 208500, loss = 0.785650373 (159.830 examples/sec; 0.313 sec/batch)\n",
      "2019-03-17 00:11:59.327626: step 4180, examples 209000, loss = 0.782078862 (147.096 examples/sec; 0.340 sec/batch)\n",
      "2019-03-17 00:12:02.262793: step 4190, examples 209500, loss = 0.781036437 (204.900 examples/sec; 0.244 sec/batch)\n",
      "2019-03-17 00:12:05.146504: step 4200, examples 210000, loss = 0.758112311 (184.692 examples/sec; 0.271 sec/batch)\n",
      "Top 1 validation accuracy: 0.5754716992378235 and top 2 validation accuracy: 0.7783018946647644\n",
      "Model Saved!\n",
      "2019-03-17 00:12:10.034503: step 4210, examples 210500, loss = 0.625652790 (186.767 examples/sec; 0.268 sec/batch)\n",
      "2019-03-17 00:12:13.040495: step 4220, examples 211000, loss = 0.924461424 (167.339 examples/sec; 0.299 sec/batch)\n",
      "2019-03-17 00:12:15.743092: step 4230, examples 211500, loss = 0.785534143 (187.470 examples/sec; 0.267 sec/batch)\n",
      "2019-03-17 00:12:18.372082: step 4240, examples 212000, loss = 0.750109613 (188.890 examples/sec; 0.265 sec/batch)\n",
      "2019-03-17 00:12:21.016113: step 4250, examples 212500, loss = 0.823265910 (200.269 examples/sec; 0.250 sec/batch)\n",
      "2019-03-17 00:12:23.634075: step 4260, examples 213000, loss = 0.656763077 (195.557 examples/sec; 0.256 sec/batch)\n",
      "2019-03-17 00:12:26.262063: step 4270, examples 213500, loss = 0.610852599 (194.035 examples/sec; 0.258 sec/batch)\n",
      "2019-03-17 00:12:28.900077: step 4280, examples 214000, loss = 0.742369592 (188.178 examples/sec; 0.266 sec/batch)\n",
      "2019-03-17 00:12:31.578199: step 4290, examples 214500, loss = 0.879525006 (188.178 examples/sec; 0.266 sec/batch)\n",
      "2019-03-17 00:12:34.245291: step 4300, examples 215000, loss = 0.810433984 (192.538 examples/sec; 0.260 sec/batch)\n",
      "Top 1 validation accuracy: 0.551886796951294 and top 2 validation accuracy: 0.7688679099082947\n",
      "Model Saved!\n",
      "2019-03-17 00:12:38.871593: step 4310, examples 215500, loss = 0.922605753 (184.012 examples/sec; 0.272 sec/batch)\n",
      "2019-03-17 00:12:41.506600: step 4320, examples 216000, loss = 0.669072390 (184.693 examples/sec; 0.271 sec/batch)\n",
      "2019-03-17 00:12:44.118545: step 4330, examples 216500, loss = 0.781043172 (198.674 examples/sec; 0.252 sec/batch)\n",
      "2019-03-17 00:12:46.727483: step 4340, examples 217000, loss = 0.857972085 (194.794 examples/sec; 0.257 sec/batch)\n",
      "2019-03-17 00:12:49.430670: step 4350, examples 217500, loss = 0.794268727 (193.284 examples/sec; 0.259 sec/batch)\n",
      "2019-03-17 00:12:52.107790: step 4360, examples 218000, loss = 0.732566178 (191.796 examples/sec; 0.261 sec/batch)\n",
      "2019-03-17 00:12:54.787916: step 4370, examples 218500, loss = 0.572861493 (177.463 examples/sec; 0.282 sec/batch)\n",
      "2019-03-17 00:12:57.419915: step 4380, examples 219000, loss = 0.681967258 (190.332 examples/sec; 0.263 sec/batch)\n",
      "2019-03-17 00:13:00.027850: step 4390, examples 219500, loss = 0.757959545 (180.678 examples/sec; 0.277 sec/batch)\n",
      "2019-03-17 00:13:02.619742: step 4400, examples 220000, loss = 0.703040004 (195.557 examples/sec; 0.256 sec/batch)\n",
      "Top 1 validation accuracy: 0.5471698045730591 and top 2 validation accuracy: 0.7783018946647644\n",
      "Model Saved!\n",
      "2019-03-17 00:13:07.171846: step 4410, examples 220500, loss = 0.841342211 (178.735 examples/sec; 0.280 sec/batch)\n",
      "2019-03-17 00:13:09.796826: step 4420, examples 221000, loss = 0.845267892 (194.794 examples/sec; 0.257 sec/batch)\n",
      "2019-03-17 00:13:12.444868: step 4430, examples 221500, loss = 0.891891599 (192.537 examples/sec; 0.260 sec/batch)\n",
      "2019-03-17 00:13:15.097923: step 4440, examples 222000, loss = 0.604340792 (179.378 examples/sec; 0.279 sec/batch)\n",
      "2019-03-17 00:13:17.729922: step 4450, examples 222500, loss = 0.668113172 (189.609 examples/sec; 0.264 sec/batch)\n",
      "2019-03-17 00:13:20.456171: step 4460, examples 223000, loss = 0.748250604 (185.380 examples/sec; 0.270 sec/batch)\n",
      "2019-03-17 00:13:23.100202: step 4470, examples 223500, loss = 0.781628489 (186.071 examples/sec; 0.269 sec/batch)\n",
      "2019-03-17 00:13:25.781332: step 4480, examples 224000, loss = 0.787875295 (186.768 examples/sec; 0.268 sec/batch)\n",
      "2019-03-17 00:13:28.392275: step 4490, examples 224500, loss = 0.706322312 (197.885 examples/sec; 0.253 sec/batch)\n",
      "2019-03-17 00:13:30.936038: step 4500, examples 225000, loss = 0.670470178 (198.674 examples/sec; 0.252 sec/batch)\n",
      "Top 1 validation accuracy: 0.573113203048706 and top 2 validation accuracy: 0.7948113083839417\n",
      "Model Saved!\n",
      "2019-03-17 00:13:35.563342: step 4510, examples 225500, loss = 0.661444902 (169.616 examples/sec; 0.295 sec/batch)\n",
      "2019-03-17 00:13:38.239459: step 4520, examples 226000, loss = 0.775712252 (180.677 examples/sec; 0.277 sec/batch)\n",
      "2019-03-17 00:13:40.890508: step 4530, examples 226500, loss = 0.667804122 (188.178 examples/sec; 0.266 sec/batch)\n",
      "2019-03-17 00:13:43.576651: step 4540, examples 227000, loss = 0.617683530 (178.735 examples/sec; 0.280 sec/batch)\n",
      "2019-03-17 00:13:46.264799: step 4550, examples 227500, loss = 0.760039926 (197.885 examples/sec; 0.253 sec/batch)\n",
      "2019-03-17 00:13:48.875742: step 4560, examples 228000, loss = 0.666250467 (188.890 examples/sec; 0.265 sec/batch)\n",
      "2019-03-17 00:13:51.554866: step 4570, examples 228500, loss = 0.711901546 (177.464 examples/sec; 0.282 sec/batch)\n",
      "2019-03-17 00:13:54.179847: step 4580, examples 229000, loss = 0.728172183 (187.469 examples/sec; 0.267 sec/batch)\n",
      "2019-03-17 00:13:56.769733: step 4590, examples 229500, loss = 0.728130341 (196.327 examples/sec; 0.255 sec/batch)\n",
      "2019-03-17 00:13:59.401732: step 4600, examples 230000, loss = 0.720538616 (194.034 examples/sec; 0.258 sec/batch)\n",
      "Top 1 validation accuracy: 0.6037735939025879 and top 2 validation accuracy: 0.8160377144813538\n",
      "Model Saved!\n",
      "2019-03-17 00:14:03.973889: step 4610, examples 230500, loss = 0.934973001 (195.557 examples/sec; 0.256 sec/batch)\n",
      "2019-03-17 00:14:06.662038: step 4620, examples 231000, loss = 0.767229199 (181.997 examples/sec; 0.275 sec/batch)\n",
      "2019-03-17 00:14:09.322111: step 4630, examples 231500, loss = 0.756230593 (195.557 examples/sec; 0.256 sec/batch)\n",
      "2019-03-17 00:14:11.904979: step 4640, examples 232000, loss = 0.698099494 (193.283 examples/sec; 0.259 sec/batch)\n",
      "2019-03-17 00:14:14.530962: step 4650, examples 232500, loss = 0.640527725 (189.609 examples/sec; 0.264 sec/batch)\n",
      "2019-03-17 00:14:17.149926: step 4660, examples 233000, loss = 0.757942736 (196.327 examples/sec; 0.255 sec/batch)\n",
      "2019-03-17 00:14:19.777914: step 4670, examples 233500, loss = 0.734693766 (192.537 examples/sec; 0.260 sec/batch)\n",
      "2019-03-17 00:14:22.428963: step 4680, examples 234000, loss = 0.800853431 (188.178 examples/sec; 0.266 sec/batch)\n",
      "2019-03-17 00:14:25.141176: step 4690, examples 234500, loss = 0.747405887 (204.373 examples/sec; 0.245 sec/batch)\n",
      "2019-03-17 00:14:27.933601: step 4700, examples 235000, loss = 0.765737951 (179.379 examples/sec; 0.279 sec/batch)\n",
      "Top 1 validation accuracy: 0.5825471878051758 and top 2 validation accuracy: 0.8066037893295288\n",
      "Model Saved!\n",
      "2019-03-17 00:14:32.781493: step 4710, examples 235500, loss = 0.741885543 (170.194 examples/sec; 0.294 sec/batch)\n",
      "2019-03-17 00:14:35.482675: step 4720, examples 236000, loss = 0.556116939 (183.335 examples/sec; 0.273 sec/batch)\n",
      "2019-03-17 00:14:38.406450: step 4730, examples 236500, loss = 0.735030532 (179.378 examples/sec; 0.279 sec/batch)\n",
      "2019-03-17 00:14:41.234971: step 4740, examples 237000, loss = 0.776118755 (179.378 examples/sec; 0.279 sec/batch)\n",
      "2019-03-17 00:14:43.866970: step 4750, examples 237500, loss = 0.828773499 (198.674 examples/sec; 0.252 sec/batch)\n",
      "2019-03-17 00:14:46.588206: step 4760, examples 238000, loss = 0.534738421 (178.096 examples/sec; 0.281 sec/batch)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2019-03-17 00:14:49.457837: step 4770, examples 238500, loss = 0.756168783 (162.964 examples/sec; 0.307 sec/batch)\n",
      "2019-03-17 00:14:52.298390: step 4780, examples 239000, loss = 0.804214597 (181.335 examples/sec; 0.276 sec/batch)\n",
      "2019-03-17 00:14:55.220159: step 4790, examples 239500, loss = 0.836674869 (174.972 examples/sec; 0.286 sec/batch)\n",
      "2019-03-17 00:14:57.981502: step 4800, examples 240000, loss = 0.654715419 (181.334 examples/sec; 0.276 sec/batch)\n",
      "Top 1 validation accuracy: 0.5400943160057068 and top 2 validation accuracy: 0.7900943160057068\n",
      "Model Saved!\n",
      "2019-03-17 00:15:02.529596: step 4810, examples 240500, loss = 0.980502546 (189.608 examples/sec; 0.264 sec/batch)\n",
      "2019-03-17 00:15:05.133519: step 4820, examples 241000, loss = 0.643462896 (194.036 examples/sec; 0.258 sec/batch)\n",
      "2019-03-17 00:15:07.733433: step 4830, examples 241500, loss = 0.714973569 (197.885 examples/sec; 0.253 sec/batch)\n",
      "2019-03-17 00:15:10.400525: step 4840, examples 242000, loss = 0.660747528 (192.537 examples/sec; 0.260 sec/batch)\n",
      "2019-03-17 00:15:13.127778: step 4850, examples 242500, loss = 0.717187881 (193.282 examples/sec; 0.259 sec/batch)\n",
      "2019-03-17 00:15:15.789856: step 4860, examples 243000, loss = 0.847155154 (190.332 examples/sec; 0.263 sec/batch)\n",
      "2019-03-17 00:15:18.412832: step 4870, examples 243500, loss = 0.653869867 (186.071 examples/sec; 0.269 sec/batch)\n",
      "2019-03-17 00:15:21.046835: step 4880, examples 244000, loss = 0.792993665 (183.335 examples/sec; 0.273 sec/batch)\n",
      "2019-03-17 00:15:23.762056: step 4890, examples 244500, loss = 0.856951833 (190.332 examples/sec; 0.263 sec/batch)\n",
      "2019-03-17 00:15:26.403079: step 4900, examples 245000, loss = 0.725310802 (188.890 examples/sec; 0.265 sec/batch)\n",
      "Top 1 validation accuracy: 0.573113203048706 and top 2 validation accuracy: 0.801886796951294\n",
      "Model Saved!\n",
      "2019-03-17 00:15:31.001305: step 4910, examples 245500, loss = 0.813795686 (198.673 examples/sec; 0.252 sec/batch)\n",
      "2019-03-17 00:15:33.644333: step 4920, examples 246000, loss = 0.650913239 (192.537 examples/sec; 0.260 sec/batch)\n",
      "2019-03-17 00:15:36.261292: step 4930, examples 246500, loss = 0.680017352 (193.283 examples/sec; 0.259 sec/batch)\n",
      "2019-03-17 00:15:38.898304: step 4940, examples 247000, loss = 0.757045269 (201.891 examples/sec; 0.248 sec/batch)\n",
      "2019-03-17 00:15:41.508244: step 4950, examples 247500, loss = 0.640684605 (193.284 examples/sec; 0.259 sec/batch)\n",
      "2019-03-17 00:15:44.260563: step 4960, examples 248000, loss = 0.659526825 (191.062 examples/sec; 0.262 sec/batch)\n",
      "2019-03-17 00:15:46.911613: step 4970, examples 248500, loss = 0.765963912 (190.332 examples/sec; 0.263 sec/batch)\n",
      "2019-03-17 00:15:49.548625: step 4980, examples 249000, loss = 0.702254236 (190.331 examples/sec; 0.263 sec/batch)\n",
      "2019-03-17 00:15:52.183631: step 4990, examples 249500, loss = 0.771653891 (194.036 examples/sec; 0.258 sec/batch)\n",
      "Top 1 validation accuracy: 0.5613207817077637 and top 2 validation accuracy: 0.7712264060974121\n",
      "Model Saved!\n"
     ]
    }
   ],
   "source": [
    "best_val_ss_crop = {}\n",
    "\n",
    "for step_size in range(25,101,25):\n",
    "    num_cls = 4\n",
    "    mstp = 5000\n",
    "    lfrq = 10\n",
    "    bsz = 50\n",
    "    msf = 100\n",
    "    tr = './trained_model_final/DCNN_reg_ss_crop_step'+str(step_size)\n",
    "    if not os.path.exists(tr):\n",
    "        os.mkdir(tr)\n",
    "    start = 0\n",
    "    stop = 250\n",
    "    step = step_size\n",
    "    time_length = 700\n",
    "    time_bin = 350\n",
    "    fsz = 3\n",
    "    use_batchnorm = True\n",
    "    use_dropout = True\n",
    "    use_l2loss = True\n",
    "    acc = 'Accuracy_step'+str(step_size)\n",
    "    path = 'Path_step'+str(step_size)\n",
    "\n",
    "    best_val_ss_crop[acc],best_val_ss_crop[path] = train_model_ss(tr,start,stop,step,time_length,time_bin,fsz,use_batchnorm,use_dropout,use_l2loss,num_cls,mstp,lfrq,bsz,msf)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test Accuracy using cropped data for training for step size 25:\n",
      "Loading datasets...\n",
      "Dataset loading completes.\n",
      "INFO:tensorflow:Restoring parameters from ./trained_model_final/DCNN_reg_ss_crop_step25\\model.ckpt-3501\n",
      "[test  step 3501] loss: 1.27136; top_1_accuracy: 0.63883; top_5_accuracy: 0.844244 (3.742 sec/batch; 236.775 instances/sec)\n",
      "top_1_accuracy_test =  0.6388262 top_2_accuracy_test =  0.84424376\n",
      "Test Accuracy using cropped data for training for step size 50:\n",
      "Loading datasets...\n",
      "Dataset loading completes.\n",
      "INFO:tensorflow:Restoring parameters from ./trained_model_final/DCNN_reg_ss_crop_step50\\model.ckpt-4301\n",
      "[test  step 4301] loss: 1.29987; top_1_accuracy: 0.62641; top_5_accuracy: 0.847630 (2.122 sec/batch; 417.606 instances/sec)\n",
      "top_1_accuracy_test =  0.62641084 top_2_accuracy_test =  0.8476298\n",
      "Test Accuracy using cropped data for training for step size 75:\n",
      "Loading datasets...\n",
      "Dataset loading completes.\n",
      "INFO:tensorflow:Restoring parameters from ./trained_model_final/DCNN_reg_ss_crop_step75\\model.ckpt-4801\n",
      "[test  step 4801] loss: 1.40580; top_1_accuracy: 0.60158; top_5_accuracy: 0.826185 (1.444 sec/batch; 613.641 instances/sec)\n",
      "top_1_accuracy_test =  0.60158014 top_2_accuracy_test =  0.8261851\n",
      "Test Accuracy using cropped data for training for step size 100:\n",
      "Loading datasets...\n",
      "Dataset loading completes.\n",
      "INFO:tensorflow:Restoring parameters from ./trained_model_final/DCNN_reg_ss_crop_step100\\model.ckpt-4601\n",
      "[test  step 4601] loss: 1.48227; top_1_accuracy: 0.57562; top_5_accuracy: 0.812641 (1.485 sec/batch; 596.653 instances/sec)\n",
      "top_1_accuracy_test =  0.5756208 top_2_accuracy_test =  0.8126411\n",
      "The step_size 25 has the best test accuracy: 0.6388261914253235\n"
     ]
    }
   ],
   "source": [
    "# Accuracy for testSet(best)\n",
    "\n",
    "best_test_acc_ss_crop = 0\n",
    "best_test_ss_crop = 0\n",
    "for step_size in range(25,101,25):\n",
    "    path = 'Path_step'+str(step_size)\n",
    "    model_dir = best_val_ss_crop[path]\n",
    "    start = 0\n",
    "    stop = 250\n",
    "    step = step_size\n",
    "    time_length = 700\n",
    "    time_bin = 350\n",
    "    #Nb = BATCH_SIZE\n",
    "    fsz = 3\n",
    "    use_batchnorm = True\n",
    "    use_dropout = True\n",
    "    use_l2loss = True\n",
    "    print('Test Accuracy using cropped data for training for step size {}:'.format(step_size))\n",
    "    top_1_acc_test, top_2_acc_test = test_model_ss(model_dir,start,stop,step,time_length,time_bin,fsz,use_batchnorm,use_dropout,use_l2loss)\n",
    "    if top_1_acc_test > best_test_acc_ss_crop:\n",
    "        best_test_acc_ss_crop = top_1_acc_test\n",
    "        best_test_ss_crop = step_size\n",
    "\n",
    "print('The step_size {} has the best test accuracy: {}'.format(best_test_ss_crop,best_test_acc_ss_crop))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading datasets...\n",
      "Dataset loading completes.\n",
      "2019-03-17 00:42:12.546478: step 0, examples 0, loss = 1.420341611 (26.219 examples/sec; 1.907 sec/batch)\n",
      "Top 1 validation accuracy: 0.22641509771347046 and top 2 validation accuracy: 0.5\n",
      "Model Saved!\n",
      "2019-03-17 00:42:32.166555: step 10, examples 500, loss = 1.413772106 (33.512 examples/sec; 1.492 sec/batch)\n",
      "2019-03-17 00:42:47.138594: step 20, examples 1000, loss = 1.405620575 (32.350 examples/sec; 1.546 sec/batch)\n",
      "2019-03-17 00:43:02.152449: step 30, examples 1500, loss = 1.380291939 (33.591 examples/sec; 1.489 sec/batch)\n",
      "2019-03-17 00:43:17.059271: step 40, examples 2000, loss = 1.335037708 (34.142 examples/sec; 1.464 sec/batch)\n",
      "2019-03-17 00:43:31.894992: step 50, examples 2500, loss = 1.343952060 (34.417 examples/sec; 1.453 sec/batch)\n",
      "2019-03-17 00:43:46.719845: step 60, examples 3000, loss = 1.401606202 (34.282 examples/sec; 1.458 sec/batch)\n",
      "2019-03-17 00:44:01.770454: step 70, examples 3500, loss = 1.330043077 (33.146 examples/sec; 1.508 sec/batch)\n",
      "2019-03-17 00:44:16.441462: step 80, examples 4000, loss = 1.383965015 (33.704 examples/sec; 1.484 sec/batch)\n",
      "2019-03-17 00:44:31.074000: step 90, examples 4500, loss = 1.342633128 (33.723 examples/sec; 1.483 sec/batch)\n",
      "2019-03-17 00:44:46.086891: step 100, examples 5000, loss = 1.359135628 (33.159 examples/sec; 1.508 sec/batch)\n",
      "Top 1 validation accuracy: 0.349056601524353 and top 2 validation accuracy: 0.5636792182922363\n",
      "Model Saved!\n",
      "2019-03-17 00:45:06.020310: step 110, examples 5500, loss = 1.369527459 (33.721 examples/sec; 1.483 sec/batch)\n",
      "2019-03-17 00:45:20.800416: step 120, examples 6000, loss = 1.302417159 (32.872 examples/sec; 1.521 sec/batch)\n",
      "2019-03-17 00:45:35.443440: step 130, examples 6500, loss = 1.262888908 (34.009 examples/sec; 1.470 sec/batch)\n",
      "2019-03-17 00:45:50.088082: step 140, examples 7000, loss = 1.334494948 (33.525 examples/sec; 1.491 sec/batch)\n",
      "2019-03-17 00:46:04.841374: step 150, examples 7500, loss = 1.269230366 (33.931 examples/sec; 1.474 sec/batch)\n",
      "2019-03-17 00:46:19.795836: step 160, examples 8000, loss = 1.250996709 (34.404 examples/sec; 1.453 sec/batch)\n",
      "2019-03-17 00:46:34.553326: step 170, examples 8500, loss = 1.322595716 (33.649 examples/sec; 1.486 sec/batch)\n",
      "2019-03-17 00:46:49.389337: step 180, examples 9000, loss = 1.330218196 (33.864 examples/sec; 1.476 sec/batch)\n",
      "2019-03-17 00:47:04.131336: step 190, examples 9500, loss = 1.272426128 (34.394 examples/sec; 1.454 sec/batch)\n",
      "2019-03-17 00:47:19.557236: step 200, examples 10000, loss = 1.241522670 (33.954 examples/sec; 1.473 sec/batch)\n",
      "Top 1 validation accuracy: 0.4150943458080292 and top 2 validation accuracy: 0.650943398475647\n",
      "Model Saved!\n",
      "2019-03-17 00:47:39.101732: step 210, examples 10500, loss = 1.257620573 (34.351 examples/sec; 1.456 sec/batch)\n",
      "2019-03-17 00:47:53.836359: step 220, examples 11000, loss = 1.290369749 (34.414 examples/sec; 1.453 sec/batch)\n",
      "2019-03-17 00:48:08.406813: step 230, examples 11500, loss = 1.281663775 (33.463 examples/sec; 1.494 sec/batch)\n",
      "2019-03-17 00:48:23.115303: step 240, examples 12000, loss = 1.338649988 (34.410 examples/sec; 1.453 sec/batch)\n",
      "2019-03-17 00:48:37.781075: step 250, examples 12500, loss = 1.226491570 (34.466 examples/sec; 1.451 sec/batch)\n",
      "2019-03-17 00:48:52.434503: step 260, examples 13000, loss = 1.236327052 (33.861 examples/sec; 1.477 sec/batch)\n",
      "2019-03-17 00:49:07.643190: step 270, examples 13500, loss = 1.130324602 (30.436 examples/sec; 1.643 sec/batch)\n",
      "2019-03-17 00:49:23.425807: step 280, examples 14000, loss = 1.343552470 (32.423 examples/sec; 1.542 sec/batch)\n",
      "2019-03-17 00:49:38.524958: step 290, examples 14500, loss = 1.212713361 (33.134 examples/sec; 1.509 sec/batch)\n",
      "2019-03-17 00:49:53.770497: step 300, examples 15000, loss = 1.152671337 (33.223 examples/sec; 1.505 sec/batch)\n",
      "Top 1 validation accuracy: 0.4599056541919708 and top 2 validation accuracy: 0.7051886916160583\n",
      "Model Saved!\n",
      "2019-03-17 00:50:13.611256: step 310, examples 15500, loss = 1.241938233 (34.249 examples/sec; 1.460 sec/batch)\n",
      "2019-03-17 00:50:28.713414: step 320, examples 16000, loss = 1.225991964 (33.378 examples/sec; 1.498 sec/batch)\n",
      "2019-03-17 00:50:43.901802: step 330, examples 16500, loss = 1.207795143 (32.764 examples/sec; 1.526 sec/batch)\n",
      "2019-03-17 00:50:59.441510: step 340, examples 17000, loss = 1.245003462 (32.678 examples/sec; 1.530 sec/batch)\n",
      "2019-03-17 00:51:14.437388: step 350, examples 17500, loss = 1.030572891 (33.445 examples/sec; 1.495 sec/batch)\n",
      "2019-03-17 00:51:29.534532: step 360, examples 18000, loss = 1.304359317 (32.786 examples/sec; 1.525 sec/batch)\n",
      "2019-03-17 00:51:44.760017: step 370, examples 18500, loss = 1.220710158 (31.324 examples/sec; 1.596 sec/batch)\n",
      "2019-03-17 00:51:59.858166: step 380, examples 19000, loss = 1.119796991 (31.884 examples/sec; 1.568 sec/batch)\n",
      "2019-03-17 00:52:14.976367: step 390, examples 19500, loss = 1.261852980 (32.276 examples/sec; 1.549 sec/batch)\n",
      "2019-03-17 00:52:29.993299: step 400, examples 20000, loss = 1.100041151 (32.508 examples/sec; 1.538 sec/batch)\n",
      "Top 1 validation accuracy: 0.48820754885673523 and top 2 validation accuracy: 0.7617924809455872\n",
      "Model Saved!\n",
      "2019-03-17 00:52:50.366473: step 410, examples 20500, loss = 1.057238460 (33.025 examples/sec; 1.514 sec/batch)\n",
      "2019-03-17 00:53:05.465624: step 420, examples 21000, loss = 1.318955779 (33.068 examples/sec; 1.512 sec/batch)\n",
      "2019-03-17 00:53:20.421393: step 430, examples 21500, loss = 1.228788614 (32.381 examples/sec; 1.544 sec/batch)\n",
      "2019-03-17 00:53:35.346079: step 440, examples 22000, loss = 1.215213537 (33.581 examples/sec; 1.489 sec/batch)\n",
      "2019-03-17 00:53:50.605656: step 450, examples 22500, loss = 1.216803074 (32.297 examples/sec; 1.548 sec/batch)\n",
      "2019-03-17 00:54:05.790033: step 460, examples 23000, loss = 1.233028054 (33.877 examples/sec; 1.476 sec/batch)\n",
      "2019-03-17 00:54:20.950346: step 470, examples 23500, loss = 1.280304193 (33.223 examples/sec; 1.505 sec/batch)\n",
      "2019-03-17 00:54:36.092610: step 480, examples 24000, loss = 1.043491364 (33.535 examples/sec; 1.491 sec/batch)\n",
      "2019-03-17 00:54:51.180732: step 490, examples 24500, loss = 1.079080462 (33.401 examples/sec; 1.497 sec/batch)\n",
      "2019-03-17 00:55:06.629806: step 500, examples 25000, loss = 1.167480588 (31.864 examples/sec; 1.569 sec/batch)\n",
      "Top 1 validation accuracy: 0.5094339847564697 and top 2 validation accuracy: 0.7570754885673523\n",
      "Model Saved!\n",
      "2019-03-17 00:55:26.784547: step 510, examples 25500, loss = 1.240277767 (33.334 examples/sec; 1.500 sec/batch)\n",
      "2019-03-17 00:55:41.882694: step 520, examples 26000, loss = 1.075114727 (32.937 examples/sec; 1.518 sec/batch)\n",
      "2019-03-17 00:55:57.073088: step 530, examples 26500, loss = 0.974862337 (32.850 examples/sec; 1.522 sec/batch)\n",
      "2019-03-17 00:56:12.172238: step 540, examples 27000, loss = 0.985313416 (33.513 examples/sec; 1.492 sec/batch)\n",
      "2019-03-17 00:56:27.235291: step 550, examples 27500, loss = 1.064312458 (33.289 examples/sec; 1.502 sec/batch)\n",
      "2019-03-17 00:56:42.844445: step 560, examples 28000, loss = 1.089909434 (30.131 examples/sec; 1.659 sec/batch)\n",
      "2019-03-17 00:56:58.278312: step 570, examples 28500, loss = 1.084413171 (33.223 examples/sec; 1.505 sec/batch)\n",
      "2019-03-17 00:57:13.531872: step 580, examples 29000, loss = 1.189121604 (32.700 examples/sec; 1.529 sec/batch)\n",
      "2019-03-17 00:57:28.738308: step 590, examples 29500, loss = 0.879622102 (33.513 examples/sec; 1.492 sec/batch)\n",
      "2019-03-17 00:57:44.337837: step 600, examples 30000, loss = 1.085779309 (30.669 examples/sec; 1.630 sec/batch)\n",
      "Top 1 validation accuracy: 0.5094339847564697 and top 2 validation accuracy: 0.7570754885673523\n",
      "Model Saved!\n",
      "2019-03-17 00:58:04.508507: step 610, examples 30500, loss = 1.107879281 (33.762 examples/sec; 1.481 sec/batch)\n",
      "2019-03-17 00:58:19.538474: step 620, examples 31000, loss = 1.138617396 (32.764 examples/sec; 1.526 sec/batch)\n",
      "2019-03-17 00:58:34.513293: step 630, examples 31500, loss = 0.997913361 (33.603 examples/sec; 1.488 sec/batch)\n",
      "2019-03-17 00:58:49.670599: step 640, examples 32000, loss = 1.180792570 (33.068 examples/sec; 1.512 sec/batch)\n",
      "2019-03-17 00:59:04.740672: step 650, examples 32500, loss = 1.123565197 (33.223 examples/sec; 1.505 sec/batch)\n",
      "2019-03-17 00:59:19.888953: step 660, examples 33000, loss = 1.087103963 (33.513 examples/sec; 1.492 sec/batch)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2019-03-17 00:59:34.800604: step 670, examples 33500, loss = 1.122202158 (33.468 examples/sec; 1.494 sec/batch)\n",
      "2019-03-17 00:59:50.532103: step 680, examples 34000, loss = 0.875912726 (33.831 examples/sec; 1.478 sec/batch)\n",
      "2019-03-17 01:00:05.320426: step 690, examples 34500, loss = 1.025480509 (32.981 examples/sec; 1.516 sec/batch)\n",
      "2019-03-17 01:00:20.477733: step 700, examples 35000, loss = 0.919461429 (33.334 examples/sec; 1.500 sec/batch)\n",
      "Top 1 validation accuracy: 0.551886796951294 and top 2 validation accuracy: 0.7688679099082947\n",
      "Model Saved!\n",
      "2019-03-17 01:00:39.993626: step 710, examples 35500, loss = 1.060526848 (33.900 examples/sec; 1.475 sec/batch)\n",
      "2019-03-17 01:00:54.931347: step 720, examples 36000, loss = 1.170174837 (33.558 examples/sec; 1.490 sec/batch)\n",
      "2019-03-17 01:01:09.789858: step 730, examples 36500, loss = 1.015042186 (33.785 examples/sec; 1.480 sec/batch)\n",
      "2019-03-17 01:01:24.681456: step 740, examples 37000, loss = 0.968021572 (33.178 examples/sec; 1.507 sec/batch)\n",
      "2019-03-17 01:01:39.683347: step 750, examples 37500, loss = 1.025128484 (33.311 examples/sec; 1.501 sec/batch)\n",
      "2019-03-17 01:01:54.428557: step 760, examples 38000, loss = 0.938527346 (34.016 examples/sec; 1.470 sec/batch)\n",
      "2019-03-17 01:02:09.173766: step 770, examples 38500, loss = 0.946388841 (33.046 examples/sec; 1.513 sec/batch)\n",
      "2019-03-17 01:02:23.771584: step 780, examples 39000, loss = 0.957511485 (34.226 examples/sec; 1.461 sec/batch)\n",
      "2019-03-17 01:02:38.501755: step 790, examples 39500, loss = 1.131343842 (34.654 examples/sec; 1.443 sec/batch)\n",
      "2019-03-17 01:02:53.442482: step 800, examples 40000, loss = 1.049481153 (32.851 examples/sec; 1.522 sec/batch)\n",
      "Top 1 validation accuracy: 0.551886796951294 and top 2 validation accuracy: 0.7712264060974121\n",
      "Model Saved!\n",
      "2019-03-17 01:03:13.289256: step 810, examples 40500, loss = 1.050138831 (33.046 examples/sec; 1.513 sec/batch)\n",
      "2019-03-17 01:03:28.107661: step 820, examples 41000, loss = 0.829262495 (33.156 examples/sec; 1.508 sec/batch)\n",
      "2019-03-17 01:03:42.830811: step 830, examples 41500, loss = 1.043672562 (33.694 examples/sec; 1.484 sec/batch)\n",
      "2019-03-17 01:03:57.604094: step 840, examples 42000, loss = 1.245554209 (33.513 examples/sec; 1.492 sec/batch)\n",
      "2019-03-17 01:04:12.315213: step 850, examples 42500, loss = 0.913824856 (33.649 examples/sec; 1.486 sec/batch)\n",
      "2019-03-17 01:04:27.158683: step 860, examples 43000, loss = 0.875034392 (33.378 examples/sec; 1.498 sec/batch)\n",
      "2019-03-17 01:04:41.905898: step 870, examples 43500, loss = 1.013819933 (34.439 examples/sec; 1.452 sec/batch)\n",
      "2019-03-17 01:04:56.581923: step 880, examples 44000, loss = 0.895435393 (34.439 examples/sec; 1.452 sec/batch)\n",
      "2019-03-17 01:05:11.252935: step 890, examples 44500, loss = 0.982660651 (34.202 examples/sec; 1.462 sec/batch)\n",
      "2019-03-17 01:05:26.003159: step 900, examples 45000, loss = 0.945229292 (33.694 examples/sec; 1.484 sec/batch)\n",
      "Top 1 validation accuracy: 0.5471698045730591 and top 2 validation accuracy: 0.7948113083839417\n",
      "Model Saved!\n",
      "2019-03-17 01:05:45.541111: step 910, examples 45500, loss = 0.978775799 (34.415 examples/sec; 1.453 sec/batch)\n",
      "2019-03-17 01:06:00.211120: step 920, examples 46000, loss = 0.901253283 (34.486 examples/sec; 1.450 sec/batch)\n",
      "2019-03-17 01:06:15.010474: step 930, examples 46500, loss = 0.932717681 (33.267 examples/sec; 1.503 sec/batch)\n",
      "2019-03-17 01:06:29.777742: step 940, examples 47000, loss = 0.868877470 (33.717 examples/sec; 1.483 sec/batch)\n",
      "2019-03-17 01:06:44.579099: step 950, examples 47500, loss = 0.921118379 (33.969 examples/sec; 1.472 sec/batch)\n",
      "2019-03-17 01:06:59.379456: step 960, examples 48000, loss = 0.937351227 (33.626 examples/sec; 1.487 sec/batch)\n",
      "2019-03-17 01:07:14.143715: step 970, examples 48500, loss = 0.995549440 (33.717 examples/sec; 1.483 sec/batch)\n",
      "2019-03-17 01:07:28.983176: step 980, examples 49000, loss = 0.972672284 (33.090 examples/sec; 1.511 sec/batch)\n",
      "2019-03-17 01:07:43.769494: step 990, examples 49500, loss = 0.917256594 (33.178 examples/sec; 1.507 sec/batch)\n",
      "2019-03-17 01:07:58.444516: step 1000, examples 50000, loss = 0.833837152 (34.156 examples/sec; 1.464 sec/batch)\n",
      "Top 1 validation accuracy: 0.6014150977134705 and top 2 validation accuracy: 0.7971698045730591\n",
      "Model Saved!\n",
      "2019-03-17 01:08:17.936348: step 1010, examples 50500, loss = 0.985149562 (34.344 examples/sec; 1.456 sec/batch)\n",
      "2019-03-17 01:08:32.743722: step 1020, examples 51000, loss = 1.156148076 (32.593 examples/sec; 1.534 sec/batch)\n",
      "2019-03-17 01:08:47.528037: step 1030, examples 51500, loss = 0.953815460 (34.039 examples/sec; 1.469 sec/batch)\n",
      "2019-03-17 01:09:02.108807: step 1040, examples 52000, loss = 1.039998174 (34.016 examples/sec; 1.470 sec/batch)\n",
      "2019-03-17 01:09:16.682560: step 1050, examples 52500, loss = 0.913834751 (34.156 examples/sec; 1.464 sec/batch)\n",
      "2019-03-17 01:09:31.372622: step 1060, examples 53000, loss = 1.060733795 (34.179 examples/sec; 1.463 sec/batch)\n",
      "2019-03-17 01:09:46.192028: step 1070, examples 53500, loss = 0.940192401 (33.877 examples/sec; 1.476 sec/batch)\n",
      "2019-03-17 01:10:00.896129: step 1080, examples 54000, loss = 1.000312090 (34.606 examples/sec; 1.445 sec/batch)\n",
      "2019-03-17 01:10:15.690469: step 1090, examples 54500, loss = 0.863702059 (34.654 examples/sec; 1.443 sec/batch)\n",
      "2019-03-17 01:10:30.449715: step 1100, examples 55000, loss = 0.913237393 (33.558 examples/sec; 1.490 sec/batch)\n",
      "Top 1 validation accuracy: 0.5825471878051758 and top 2 validation accuracy: 0.7853773832321167\n",
      "Model Saved!\n",
      "2019-03-17 01:10:49.928511: step 1110, examples 55500, loss = 1.037819982 (33.762 examples/sec; 1.481 sec/batch)\n",
      "2019-03-17 01:11:04.552398: step 1120, examples 56000, loss = 0.847623229 (34.872 examples/sec; 1.434 sec/batch)\n",
      "2019-03-17 01:11:19.233436: step 1130, examples 56500, loss = 0.822650373 (33.808 examples/sec; 1.479 sec/batch)\n",
      "2019-03-17 01:11:33.932523: step 1140, examples 57000, loss = 0.908714831 (33.580 examples/sec; 1.489 sec/batch)\n",
      "2019-03-17 01:11:48.727507: step 1150, examples 57500, loss = 0.893245697 (33.923 examples/sec; 1.474 sec/batch)\n",
      "2019-03-17 01:12:03.481741: step 1160, examples 58000, loss = 0.897010803 (33.134 examples/sec; 1.509 sec/batch)\n",
      "2019-03-17 01:12:18.885702: step 1170, examples 58500, loss = 0.882940710 (32.444 examples/sec; 1.541 sec/batch)\n",
      "2019-03-17 01:12:34.177363: step 1180, examples 59000, loss = 1.034625530 (32.786 examples/sec; 1.525 sec/batch)\n",
      "2019-03-17 01:12:49.251447: step 1190, examples 59500, loss = 0.853484154 (32.466 examples/sec; 1.540 sec/batch)\n",
      "2019-03-17 01:13:04.309490: step 1200, examples 60000, loss = 0.946216941 (32.339 examples/sec; 1.546 sec/batch)\n",
      "Top 1 validation accuracy: 0.6132075190544128 and top 2 validation accuracy: 0.8089622855186462\n",
      "Model Saved!\n",
      "2019-03-17 01:13:24.481127: step 1210, examples 60500, loss = 0.865760028 (33.626 examples/sec; 1.487 sec/batch)\n",
      "2019-03-17 01:13:39.441910: step 1220, examples 61000, loss = 0.826095641 (33.311 examples/sec; 1.501 sec/batch)\n",
      "2019-03-17 01:13:54.626287: step 1230, examples 61500, loss = 1.185668588 (33.245 examples/sec; 1.504 sec/batch)\n",
      "2019-03-17 01:14:09.839741: step 1240, examples 62000, loss = 0.919315755 (32.700 examples/sec; 1.529 sec/batch)\n",
      "2019-03-17 01:14:24.954934: step 1250, examples 62500, loss = 0.894594550 (32.872 examples/sec; 1.521 sec/batch)\n",
      "2019-03-17 01:14:39.931760: step 1260, examples 63000, loss = 0.857770026 (32.894 examples/sec; 1.520 sec/batch)\n",
      "2019-03-17 01:14:54.967741: step 1270, examples 63500, loss = 0.970960200 (33.112 examples/sec; 1.510 sec/batch)\n",
      "2019-03-17 01:15:09.973644: step 1280, examples 64000, loss = 0.861913741 (33.626 examples/sec; 1.487 sec/batch)\n",
      "2019-03-17 01:15:25.196122: step 1290, examples 64500, loss = 1.072378278 (33.334 examples/sec; 1.500 sec/batch)\n",
      "2019-03-17 01:15:40.257171: step 1300, examples 65000, loss = 0.761692643 (33.378 examples/sec; 1.498 sec/batch)\n",
      "Top 1 validation accuracy: 0.5943396091461182 and top 2 validation accuracy: 0.8160377144813538\n",
      "Model Saved!\n",
      "2019-03-17 01:16:00.958217: step 1310, examples 65500, loss = 0.813741744 (30.858 examples/sec; 1.620 sec/batch)\n",
      "2019-03-17 01:16:16.500546: step 1320, examples 66000, loss = 0.903862596 (31.662 examples/sec; 1.579 sec/batch)\n",
      "2019-03-17 01:16:31.975697: step 1330, examples 66500, loss = 1.017051458 (32.423 examples/sec; 1.542 sec/batch)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2019-03-17 01:16:47.531060: step 1340, examples 67000, loss = 1.064348221 (31.304 examples/sec; 1.597 sec/batch)\n",
      "2019-03-17 01:17:03.195714: step 1350, examples 67500, loss = 0.792746007 (32.048 examples/sec; 1.560 sec/batch)\n",
      "2019-03-17 01:17:18.825275: step 1360, examples 68000, loss = 0.871252000 (32.276 examples/sec; 1.549 sec/batch)\n",
      "2019-03-17 01:17:34.353566: step 1370, examples 68500, loss = 0.758194983 (32.069 examples/sec; 1.559 sec/batch)\n",
      "2019-03-17 01:17:49.943020: step 1380, examples 69000, loss = 0.916087210 (32.297 examples/sec; 1.548 sec/batch)\n",
      "2019-03-17 01:18:05.570575: step 1390, examples 69500, loss = 1.002144098 (32.807 examples/sec; 1.524 sec/batch)\n",
      "2019-03-17 01:18:20.999602: step 1400, examples 70000, loss = 0.743937731 (32.297 examples/sec; 1.548 sec/batch)\n",
      "Top 1 validation accuracy: 0.6438679099082947 and top 2 validation accuracy: 0.8278301954269409\n",
      "Model Saved!\n",
      "2019-03-17 01:18:41.972372: step 1410, examples 70500, loss = 0.938104868 (31.762 examples/sec; 1.574 sec/batch)\n",
      "2019-03-17 01:18:57.529741: step 1420, examples 71000, loss = 0.943125486 (31.762 examples/sec; 1.574 sec/batch)\n",
      "2019-03-17 01:19:13.077083: step 1430, examples 71500, loss = 0.824750364 (30.954 examples/sec; 1.615 sec/batch)\n",
      "2019-03-17 01:19:28.588329: step 1440, examples 72000, loss = 0.805770159 (30.820 examples/sec; 1.622 sec/batch)\n",
      "2019-03-17 01:19:44.139682: step 1450, examples 72500, loss = 0.956549108 (31.089 examples/sec; 1.608 sec/batch)\n",
      "2019-03-17 01:19:59.530608: step 1460, examples 73000, loss = 0.986383379 (32.894 examples/sec; 1.520 sec/batch)\n",
      "2019-03-17 01:20:15.126078: step 1470, examples 73500, loss = 0.784880579 (31.864 examples/sec; 1.569 sec/batch)\n",
      "2019-03-17 01:20:30.742604: step 1480, examples 74000, loss = 0.968300223 (32.402 examples/sec; 1.543 sec/batch)\n",
      "2019-03-17 01:20:46.415279: step 1490, examples 74500, loss = 0.945350468 (32.339 examples/sec; 1.546 sec/batch)\n",
      "2019-03-17 01:21:02.087955: step 1500, examples 75000, loss = 1.023203135 (31.541 examples/sec; 1.585 sec/batch)\n",
      "Top 1 validation accuracy: 0.6297169923782349 and top 2 validation accuracy: 0.8066037893295288\n",
      "Model Saved!\n",
      "2019-03-17 01:21:22.747892: step 1510, examples 75500, loss = 0.807791710 (32.786 examples/sec; 1.525 sec/batch)\n",
      "2019-03-17 01:21:38.267160: step 1520, examples 76000, loss = 0.877065718 (31.702 examples/sec; 1.577 sec/batch)\n",
      "2019-03-17 01:21:53.865638: step 1530, examples 76500, loss = 0.942776680 (32.339 examples/sec; 1.546 sec/batch)\n",
      "2019-03-17 01:22:09.455091: step 1540, examples 77000, loss = 0.788853586 (31.089 examples/sec; 1.608 sec/batch)\n",
      "2019-03-17 01:22:25.031511: step 1550, examples 77500, loss = 0.739498734 (30.973 examples/sec; 1.614 sec/batch)\n",
      "2019-03-17 01:22:40.461541: step 1560, examples 78000, loss = 0.944216311 (31.265 examples/sec; 1.599 sec/batch)\n",
      "2019-03-17 01:22:55.906612: step 1570, examples 78500, loss = 1.083891034 (31.884 examples/sec; 1.568 sec/batch)\n",
      "2019-03-17 01:23:11.410839: step 1580, examples 79000, loss = 0.881395102 (32.235 examples/sec; 1.551 sec/batch)\n",
      "2019-03-17 01:23:27.100560: step 1590, examples 79500, loss = 0.957645059 (31.402 examples/sec; 1.592 sec/batch)\n",
      "2019-03-17 01:23:42.666953: step 1600, examples 80000, loss = 1.016397119 (32.614 examples/sec; 1.533 sec/batch)\n",
      "Top 1 validation accuracy: 0.6273584961891174 and top 2 validation accuracy: 0.8113207817077637\n",
      "Model Saved!\n",
      "2019-03-17 01:24:03.544468: step 1610, examples 80500, loss = 0.829439223 (32.572 examples/sec; 1.535 sec/batch)\n",
      "2019-03-17 01:24:18.941410: step 1620, examples 81000, loss = 0.903977931 (33.112 examples/sec; 1.510 sec/batch)\n",
      "2019-03-17 01:24:34.343366: step 1630, examples 81500, loss = 0.825749815 (32.444 examples/sec; 1.541 sec/batch)\n",
      "2019-03-17 01:24:49.861630: step 1640, examples 82000, loss = 0.985344887 (32.487 examples/sec; 1.539 sec/batch)\n",
      "2019-03-17 01:25:05.895267: step 1650, examples 82500, loss = 0.901441574 (28.626 examples/sec; 1.747 sec/batch)\n",
      "2019-03-17 01:25:21.949957: step 1660, examples 83000, loss = 0.830952883 (31.642 examples/sec; 1.580 sec/batch)\n",
      "2019-03-17 01:25:37.515347: step 1670, examples 83500, loss = 0.756603658 (31.462 examples/sec; 1.589 sec/batch)\n",
      "2019-03-17 01:25:53.288289: step 1680, examples 84000, loss = 0.939068258 (30.993 examples/sec; 1.613 sec/batch)\n",
      "2019-03-17 01:26:08.746393: step 1690, examples 84500, loss = 0.819902599 (31.844 examples/sec; 1.570 sec/batch)\n",
      "2019-03-17 01:26:24.347881: step 1700, examples 85000, loss = 1.138083100 (31.245 examples/sec; 1.600 sec/batch)\n",
      "Top 1 validation accuracy: 0.6061320900917053 and top 2 validation accuracy: 0.8066037893295288\n",
      "Model Saved!\n",
      "2019-03-17 01:26:45.362767: step 1710, examples 85500, loss = 0.879111886 (32.048 examples/sec; 1.560 sec/batch)\n",
      "2019-03-17 01:27:00.999346: step 1720, examples 86000, loss = 0.764847755 (32.423 examples/sec; 1.542 sec/batch)\n",
      "2019-03-17 01:27:16.565738: step 1730, examples 86500, loss = 0.836511374 (31.383 examples/sec; 1.593 sec/batch)\n",
      "2019-03-17 01:27:32.159204: step 1740, examples 87000, loss = 1.063494086 (32.423 examples/sec; 1.542 sec/batch)\n",
      "2019-03-17 01:27:47.687495: step 1750, examples 87500, loss = 0.898270547 (32.572 examples/sec; 1.535 sec/batch)\n",
      "2019-03-17 01:28:03.244864: step 1760, examples 88000, loss = 0.872891784 (32.214 examples/sec; 1.552 sec/batch)\n",
      "2019-03-17 01:28:18.769144: step 1770, examples 88500, loss = 0.690631330 (32.276 examples/sec; 1.549 sec/batch)\n",
      "2019-03-17 01:28:34.381660: step 1780, examples 89000, loss = 0.869935989 (32.235 examples/sec; 1.551 sec/batch)\n",
      "2019-03-17 01:28:49.838762: step 1790, examples 89500, loss = 0.780739069 (30.935 examples/sec; 1.616 sec/batch)\n",
      "2019-03-17 01:29:05.321933: step 1800, examples 90000, loss = 0.791394174 (31.642 examples/sec; 1.580 sec/batch)\n",
      "Top 1 validation accuracy: 0.6415094137191772 and top 2 validation accuracy: 0.8278301954269409\n",
      "Model Saved!\n",
      "2019-03-17 01:29:26.126255: step 1810, examples 90500, loss = 0.762969077 (32.466 examples/sec; 1.540 sec/batch)\n",
      "2019-03-17 01:29:41.821991: step 1820, examples 91000, loss = 0.865449667 (32.657 examples/sec; 1.531 sec/batch)\n",
      "2019-03-17 01:29:57.452555: step 1830, examples 91500, loss = 0.738428533 (32.048 examples/sec; 1.560 sec/batch)\n",
      "2019-03-17 01:30:12.986863: step 1840, examples 92000, loss = 0.741549492 (31.884 examples/sec; 1.568 sec/batch)\n",
      "2019-03-17 01:30:28.821969: step 1850, examples 92500, loss = 0.861557186 (31.905 examples/sec; 1.567 sec/batch)\n",
      "2019-03-17 01:30:44.348256: step 1860, examples 93000, loss = 0.856516421 (32.829 examples/sec; 1.523 sec/batch)\n",
      "2019-03-17 01:30:59.870531: step 1870, examples 93500, loss = 0.814575255 (32.487 examples/sec; 1.539 sec/batch)\n",
      "2019-03-17 01:31:15.537192: step 1880, examples 94000, loss = 0.877407789 (31.662 examples/sec; 1.579 sec/batch)\n",
      "2019-03-17 01:31:31.108596: step 1890, examples 94500, loss = 0.737937689 (32.550 examples/sec; 1.536 sec/batch)\n",
      "2019-03-17 01:31:47.440269: step 1900, examples 95000, loss = 0.683939755 (28.993 examples/sec; 1.725 sec/batch)\n",
      "Top 1 validation accuracy: 0.6226415038108826 and top 2 validation accuracy: 0.8254716992378235\n",
      "Model Saved!\n",
      "2019-03-17 01:32:08.983051: step 1910, examples 95500, loss = 0.950337172 (33.090 examples/sec; 1.511 sec/batch)\n",
      "2019-03-17 01:32:24.210542: step 1920, examples 96000, loss = 0.737482429 (32.193 examples/sec; 1.553 sec/batch)\n",
      "2019-03-17 01:32:39.549331: step 1930, examples 96500, loss = 0.858126640 (28.643 examples/sec; 1.746 sec/batch)\n",
      "2019-03-17 01:32:55.863712: step 1940, examples 97000, loss = 0.777326047 (31.621 examples/sec; 1.581 sec/batch)\n",
      "2019-03-17 01:33:11.457177: step 1950, examples 97500, loss = 0.873245239 (32.297 examples/sec; 1.548 sec/batch)\n",
      "2019-03-17 01:33:26.760871: step 1960, examples 98000, loss = 0.897520602 (33.762 examples/sec; 1.481 sec/batch)\n",
      "2019-03-17 01:33:42.027466: step 1970, examples 98500, loss = 0.915355265 (32.721 examples/sec; 1.528 sec/batch)\n",
      "2019-03-17 01:33:57.133636: step 1980, examples 99000, loss = 0.742868066 (32.959 examples/sec; 1.517 sec/batch)\n",
      "2019-03-17 01:34:12.303975: step 1990, examples 99500, loss = 0.932954371 (33.717 examples/sec; 1.483 sec/batch)\n",
      "2019-03-17 01:34:27.494368: step 2000, examples 100000, loss = 0.793941259 (33.134 examples/sec; 1.509 sec/batch)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Top 1 validation accuracy: 0.6415094137191772 and top 2 validation accuracy: 0.823113203048706\n",
      "Model Saved!\n",
      "2019-03-17 01:34:47.732183: step 2010, examples 100500, loss = 0.954817951 (33.762 examples/sec; 1.481 sec/batch)\n",
      "2019-03-17 01:35:03.020837: step 2020, examples 101000, loss = 0.787812948 (33.580 examples/sec; 1.489 sec/batch)\n",
      "2019-03-17 01:35:18.292447: step 2030, examples 101500, loss = 0.808538258 (33.223 examples/sec; 1.505 sec/batch)\n",
      "2019-03-17 01:35:33.578092: step 2040, examples 102000, loss = 0.853920341 (32.743 examples/sec; 1.527 sec/batch)\n",
      "2019-03-17 01:35:48.893819: step 2050, examples 102500, loss = 0.755886972 (33.112 examples/sec; 1.510 sec/batch)\n",
      "2019-03-17 01:36:04.415092: step 2060, examples 103000, loss = 0.978049994 (33.003 examples/sec; 1.515 sec/batch)\n",
      "2019-03-17 01:36:19.714776: step 2070, examples 103500, loss = 0.815852225 (32.593 examples/sec; 1.534 sec/batch)\n",
      "2019-03-17 01:36:35.114726: step 2080, examples 104000, loss = 0.801499128 (32.381 examples/sec; 1.544 sec/batch)\n",
      "2019-03-17 01:36:50.413407: step 2090, examples 104500, loss = 0.830718040 (33.025 examples/sec; 1.514 sec/batch)\n",
      "2019-03-17 01:37:05.666967: step 2100, examples 105000, loss = 0.905548096 (33.468 examples/sec; 1.494 sec/batch)\n",
      "Top 1 validation accuracy: 0.6320754885673523 and top 2 validation accuracy: 0.8207547068595886\n",
      "Model Saved!\n",
      "2019-03-17 01:37:26.092280: step 2110, examples 105500, loss = 0.958571255 (32.700 examples/sec; 1.529 sec/batch)\n",
      "2019-03-17 01:37:41.509276: step 2120, examples 106000, loss = 0.803952634 (32.743 examples/sec; 1.527 sec/batch)\n",
      "2019-03-17 01:37:56.911232: step 2130, examples 106500, loss = 0.737508059 (32.276 examples/sec; 1.549 sec/batch)\n",
      "2019-03-17 01:38:12.201891: step 2140, examples 107000, loss = 0.852459311 (32.786 examples/sec; 1.525 sec/batch)\n",
      "2019-03-17 01:38:27.658906: step 2150, examples 107500, loss = 0.680316627 (32.831 examples/sec; 1.523 sec/batch)\n",
      "2019-03-17 01:38:43.369582: step 2160, examples 108000, loss = 0.769954681 (33.156 examples/sec; 1.508 sec/batch)\n",
      "2019-03-17 01:38:58.859334: step 2170, examples 108500, loss = 0.846896589 (30.518 examples/sec; 1.638 sec/batch)\n",
      "2019-03-17 01:39:14.172053: step 2180, examples 109000, loss = 0.916302502 (33.581 examples/sec; 1.489 sec/batch)\n",
      "2019-03-17 01:39:29.457699: step 2190, examples 109500, loss = 0.857210398 (31.621 examples/sec; 1.581 sec/batch)\n",
      "2019-03-17 01:39:44.702236: step 2200, examples 110000, loss = 0.969046175 (31.206 examples/sec; 1.602 sec/batch)\n",
      "Top 1 validation accuracy: 0.6391509175300598 and top 2 validation accuracy: 0.8160377144813538\n",
      "Model Saved!\n",
      "2019-03-17 01:40:04.921001: step 2210, examples 110500, loss = 0.777093828 (33.245 examples/sec; 1.504 sec/batch)\n",
      "2019-03-17 01:40:20.132449: step 2220, examples 111000, loss = 0.908288002 (32.402 examples/sec; 1.543 sec/batch)\n",
      "2019-03-17 01:40:35.136346: step 2230, examples 111500, loss = 0.861223578 (34.062 examples/sec; 1.468 sec/batch)\n",
      "2019-03-17 01:40:50.222462: step 2240, examples 112000, loss = 0.793089151 (33.580 examples/sec; 1.489 sec/batch)\n",
      "2019-03-17 01:41:05.384780: step 2250, examples 112500, loss = 0.701197565 (32.152 examples/sec; 1.555 sec/batch)\n",
      "2019-03-17 01:41:20.645360: step 2260, examples 113000, loss = 0.920244932 (32.276 examples/sec; 1.549 sec/batch)\n",
      "2019-03-17 01:41:35.790642: step 2270, examples 113500, loss = 0.728998005 (31.422 examples/sec; 1.591 sec/batch)\n",
      "2019-03-17 01:41:51.436975: step 2280, examples 114000, loss = 0.717503488 (31.314 examples/sec; 1.597 sec/batch)\n",
      "2019-03-17 01:42:07.244623: step 2290, examples 114500, loss = 0.848115921 (32.529 examples/sec; 1.537 sec/batch)\n",
      "2019-03-17 01:42:22.655602: step 2300, examples 115000, loss = 0.901049972 (32.872 examples/sec; 1.521 sec/batch)\n",
      "Top 1 validation accuracy: 0.6226415038108826 and top 2 validation accuracy: 0.8443396091461182\n",
      "Model Saved!\n",
      "2019-03-17 01:42:42.750036: step 2310, examples 115500, loss = 0.728990972 (32.894 examples/sec; 1.520 sec/batch)\n",
      "2019-03-17 01:42:57.938424: step 2320, examples 116000, loss = 0.842418849 (32.786 examples/sec; 1.525 sec/batch)\n",
      "2019-03-17 01:43:13.337371: step 2330, examples 116500, loss = 0.688044250 (32.214 examples/sec; 1.552 sec/batch)\n",
      "2019-03-17 01:43:28.467603: step 2340, examples 117000, loss = 0.931433856 (33.025 examples/sec; 1.514 sec/batch)\n",
      "2019-03-17 01:43:43.577785: step 2350, examples 117500, loss = 0.750870943 (31.966 examples/sec; 1.564 sec/batch)\n",
      "2019-03-17 01:43:58.685726: step 2360, examples 118000, loss = 0.905900896 (32.110 examples/sec; 1.557 sec/batch)\n",
      "2019-03-17 01:44:14.385360: step 2370, examples 118500, loss = 0.883260310 (33.356 examples/sec; 1.499 sec/batch)\n",
      "2019-03-17 01:44:29.499552: step 2380, examples 119000, loss = 0.799079716 (33.003 examples/sec; 1.515 sec/batch)\n",
      "2019-03-17 01:44:44.749101: step 2390, examples 119500, loss = 0.836738586 (33.223 examples/sec; 1.505 sec/batch)\n",
      "2019-03-17 01:44:59.857276: step 2400, examples 120000, loss = 0.757351696 (32.700 examples/sec; 1.529 sec/batch)\n",
      "Top 1 validation accuracy: 0.6344339847564697 and top 2 validation accuracy: 0.823113203048706\n",
      "Model Saved!\n",
      "2019-03-17 01:45:19.998835: step 2410, examples 120500, loss = 0.677695215 (32.678 examples/sec; 1.530 sec/batch)\n",
      "2019-03-17 01:45:35.161154: step 2420, examples 121000, loss = 0.813993096 (33.134 examples/sec; 1.509 sec/batch)\n",
      "2019-03-17 01:45:50.190116: step 2430, examples 121500, loss = 0.867650986 (32.872 examples/sec; 1.521 sec/batch)\n",
      "2019-03-17 01:46:05.251165: step 2440, examples 122000, loss = 1.054068327 (33.156 examples/sec; 1.508 sec/batch)\n",
      "2019-03-17 01:46:20.359340: step 2450, examples 122500, loss = 0.860437334 (33.740 examples/sec; 1.482 sec/batch)\n",
      "2019-03-17 01:46:35.447461: step 2460, examples 123000, loss = 0.935387671 (34.062 examples/sec; 1.468 sec/batch)\n",
      "2019-03-17 01:46:50.545608: step 2470, examples 123500, loss = 0.681365967 (33.311 examples/sec; 1.501 sec/batch)\n",
      "2019-03-17 01:47:05.647766: step 2480, examples 124000, loss = 0.687994897 (32.529 examples/sec; 1.537 sec/batch)\n",
      "2019-03-17 01:47:20.841168: step 2490, examples 124500, loss = 0.753479600 (32.786 examples/sec; 1.525 sec/batch)\n",
      "2019-03-17 01:47:35.821001: step 2500, examples 125000, loss = 0.759163439 (33.513 examples/sec; 1.492 sec/batch)\n",
      "Top 1 validation accuracy: 0.6391509175300598 and top 2 validation accuracy: 0.8419811129570007\n",
      "Model Saved!\n",
      "2019-03-17 01:47:56.183146: step 2510, examples 125500, loss = 0.695744097 (32.550 examples/sec; 1.536 sec/batch)\n",
      "2019-03-17 01:48:11.353485: step 2520, examples 126000, loss = 0.987177432 (32.572 examples/sec; 1.535 sec/batch)\n",
      "2019-03-17 01:48:26.583986: step 2530, examples 126500, loss = 0.855747640 (32.614 examples/sec; 1.533 sec/batch)\n",
      "2019-03-17 01:48:41.633002: step 2540, examples 127000, loss = 0.782187879 (34.085 examples/sec; 1.467 sec/batch)\n",
      "2019-03-17 01:48:56.759225: step 2550, examples 127500, loss = 0.804988682 (33.401 examples/sec; 1.497 sec/batch)\n",
      "2019-03-17 01:49:12.027337: step 2560, examples 128000, loss = 0.810938418 (31.324 examples/sec; 1.596 sec/batch)\n",
      "2019-03-17 01:49:27.806724: step 2570, examples 128500, loss = 0.852512181 (33.245 examples/sec; 1.504 sec/batch)\n",
      "2019-03-17 01:49:43.011156: step 2580, examples 129000, loss = 0.882202864 (33.267 examples/sec; 1.503 sec/batch)\n",
      "2019-03-17 01:49:58.348939: step 2590, examples 129500, loss = 0.775688887 (32.981 examples/sec; 1.516 sec/batch)\n",
      "2019-03-17 01:50:13.504239: step 2600, examples 130000, loss = 0.782957017 (32.423 examples/sec; 1.542 sec/batch)\n",
      "Top 1 validation accuracy: 0.6415094137191772 and top 2 validation accuracy: 0.8042452931404114\n",
      "Model Saved!\n",
      "2019-03-17 01:50:34.283659: step 2610, examples 130500, loss = 0.722721338 (31.511 examples/sec; 1.587 sec/batch)\n",
      "2019-03-17 01:50:50.419577: step 2620, examples 131000, loss = 0.841933072 (31.393 examples/sec; 1.593 sec/batch)\n",
      "2019-03-17 01:51:06.110831: step 2630, examples 131500, loss = 0.984575808 (32.131 examples/sec; 1.556 sec/batch)\n",
      "2019-03-17 01:51:21.883773: step 2640, examples 132000, loss = 0.607624471 (32.007 examples/sec; 1.562 sec/batch)\n",
      "2019-03-17 01:51:37.830176: step 2650, examples 132500, loss = 0.740967393 (31.581 examples/sec; 1.583 sec/batch)\n",
      "2019-03-17 01:51:53.518895: step 2660, examples 133000, loss = 0.908097208 (31.641 examples/sec; 1.580 sec/batch)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2019-03-17 01:52:09.254738: step 2670, examples 133500, loss = 0.762892187 (31.642 examples/sec; 1.580 sec/batch)\n",
      "2019-03-17 01:52:24.882294: step 2680, examples 134000, loss = 0.756363690 (31.946 examples/sec; 1.565 sec/batch)\n",
      "2019-03-17 01:52:40.602094: step 2690, examples 134500, loss = 0.630979538 (32.007 examples/sec; 1.562 sec/batch)\n",
      "2019-03-17 01:52:56.172498: step 2700, examples 135000, loss = 0.733646154 (32.721 examples/sec; 1.528 sec/batch)\n",
      "Top 1 validation accuracy: 0.6155660152435303 and top 2 validation accuracy: 0.823113203048706\n",
      "Model Saved!\n",
      "2019-03-17 01:53:17.152285: step 2710, examples 135500, loss = 0.981679976 (31.128 examples/sec; 1.606 sec/batch)\n",
      "2019-03-17 01:53:32.775830: step 2720, examples 136000, loss = 0.862564802 (32.829 examples/sec; 1.523 sec/batch)\n",
      "2019-03-17 01:53:48.488613: step 2730, examples 136500, loss = 0.915446460 (31.844 examples/sec; 1.570 sec/batch)\n",
      "2019-03-17 01:54:04.109149: step 2740, examples 137000, loss = 0.864117801 (32.700 examples/sec; 1.529 sec/batch)\n",
      "2019-03-17 01:54:20.279485: step 2750, examples 137500, loss = 0.881211281 (31.089 examples/sec; 1.608 sec/batch)\n",
      "2019-03-17 01:54:36.004743: step 2760, examples 138000, loss = 0.797469079 (32.069 examples/sec; 1.559 sec/batch)\n",
      "2019-03-17 01:54:51.552084: step 2770, examples 138500, loss = 0.699137092 (32.110 examples/sec; 1.557 sec/batch)\n",
      "2019-03-17 01:55:07.190669: step 2780, examples 139000, loss = 0.837637901 (32.048 examples/sec; 1.560 sec/batch)\n",
      "2019-03-17 01:55:22.846299: step 2790, examples 139500, loss = 0.792028785 (31.823 examples/sec; 1.571 sec/batch)\n",
      "2019-03-17 01:55:38.775658: step 2800, examples 140000, loss = 0.739360809 (31.050 examples/sec; 1.610 sec/batch)\n",
      "Top 1 validation accuracy: 0.6344339847564697 and top 2 validation accuracy: 0.8419811129570007\n",
      "Model Saved!\n",
      "2019-03-17 01:55:59.932917: step 2810, examples 140500, loss = 0.838427186 (31.541 examples/sec; 1.585 sec/batch)\n",
      "2019-03-17 01:56:15.406061: step 2820, examples 141000, loss = 0.813698351 (32.529 examples/sec; 1.537 sec/batch)\n",
      "2019-03-17 01:56:30.909286: step 2830, examples 141500, loss = 0.621768177 (32.318 examples/sec; 1.547 sec/batch)\n",
      "2019-03-17 01:56:46.613558: step 2840, examples 142000, loss = 0.795315504 (32.423 examples/sec; 1.542 sec/batch)\n",
      "2019-03-17 01:57:02.204009: step 2850, examples 142500, loss = 0.709709585 (32.786 examples/sec; 1.525 sec/batch)\n",
      "2019-03-17 01:57:17.894732: step 2860, examples 143000, loss = 0.721755028 (32.089 examples/sec; 1.558 sec/batch)\n",
      "2019-03-17 01:57:33.569412: step 2870, examples 143500, loss = 0.801603377 (31.864 examples/sec; 1.569 sec/batch)\n",
      "2019-03-17 01:57:49.355389: step 2880, examples 144000, loss = 0.719013274 (31.884 examples/sec; 1.568 sec/batch)\n",
      "2019-03-17 01:58:04.865633: step 2890, examples 144500, loss = 0.590003550 (32.110 examples/sec; 1.557 sec/batch)\n",
      "2019-03-17 01:58:20.630553: step 2900, examples 145000, loss = 0.836036325 (31.662 examples/sec; 1.579 sec/batch)\n",
      "Top 1 validation accuracy: 0.6179245114326477 and top 2 validation accuracy: 0.8443396091461182\n",
      "Model Saved!\n",
      "2019-03-17 01:58:41.723642: step 2910, examples 145500, loss = 0.724215984 (30.763 examples/sec; 1.625 sec/batch)\n",
      "2019-03-17 01:58:57.314100: step 2920, examples 146000, loss = 0.869490862 (31.521 examples/sec; 1.586 sec/batch)\n",
      "2019-03-17 01:59:13.076253: step 2930, examples 146500, loss = 0.763768792 (29.295 examples/sec; 1.707 sec/batch)\n",
      "2019-03-17 01:59:29.141386: step 2940, examples 147000, loss = 0.808676958 (30.591 examples/sec; 1.634 sec/batch)\n",
      "2019-03-17 01:59:44.815689: step 2950, examples 147500, loss = 0.659314036 (30.296 examples/sec; 1.650 sec/batch)\n",
      "2019-03-17 02:00:00.357016: step 2960, examples 148000, loss = 0.716321588 (31.641 examples/sec; 1.580 sec/batch)\n",
      "2019-03-17 02:00:16.002619: step 2970, examples 148500, loss = 0.795647442 (32.721 examples/sec; 1.528 sec/batch)\n",
      "2019-03-17 02:00:31.773555: step 2980, examples 149000, loss = 0.806259692 (31.905 examples/sec; 1.567 sec/batch)\n",
      "2019-03-17 02:00:47.426176: step 2990, examples 149500, loss = 0.871784925 (32.028 examples/sec; 1.561 sec/batch)\n",
      "2019-03-17 02:01:03.085818: step 3000, examples 150000, loss = 0.822503448 (31.642 examples/sec; 1.580 sec/batch)\n",
      "Top 1 validation accuracy: 0.6367924809455872 and top 2 validation accuracy: 0.8396226167678833\n",
      "Model Saved!\n",
      "2019-03-17 02:01:24.238064: step 3010, examples 150500, loss = 0.849360049 (32.214 examples/sec; 1.552 sec/batch)\n",
      "2019-03-17 02:01:39.812478: step 3020, examples 151000, loss = 0.799300134 (31.621 examples/sec; 1.581 sec/batch)\n",
      "2019-03-17 02:01:55.464097: step 3030, examples 151500, loss = 0.742984533 (32.402 examples/sec; 1.543 sec/batch)\n",
      "2019-03-17 02:02:11.168858: step 3040, examples 152000, loss = 0.926658034 (32.048 examples/sec; 1.560 sec/batch)\n",
      "2019-03-17 02:02:27.032040: step 3050, examples 152500, loss = 0.861138344 (31.070 examples/sec; 1.609 sec/batch)\n",
      "2019-03-17 02:02:42.782923: step 3060, examples 153000, loss = 0.774439871 (32.508 examples/sec; 1.538 sec/batch)\n",
      "2019-03-17 02:02:58.417498: step 3070, examples 153500, loss = 0.700677276 (31.905 examples/sec; 1.567 sec/batch)\n",
      "2019-03-17 02:03:14.090172: step 3080, examples 154000, loss = 0.707889974 (31.147 examples/sec; 1.605 sec/batch)\n",
      "2019-03-17 02:03:29.956812: step 3090, examples 154500, loss = 0.857133269 (32.529 examples/sec; 1.537 sec/batch)\n",
      "2019-03-17 02:03:45.018865: step 3100, examples 155000, loss = 0.739205122 (31.905 examples/sec; 1.567 sec/batch)\n",
      "Top 1 validation accuracy: 0.6297169923782349 and top 2 validation accuracy: 0.8066037893295288\n",
      "Model Saved!\n",
      "2019-03-17 02:04:05.218578: step 3110, examples 155500, loss = 0.854629874 (33.311 examples/sec; 1.501 sec/batch)\n",
      "2019-03-17 02:04:20.357834: step 3120, examples 156000, loss = 0.713524640 (33.626 examples/sec; 1.487 sec/batch)\n",
      "2019-03-17 02:04:35.423897: step 3130, examples 156500, loss = 0.783091545 (32.786 examples/sec; 1.525 sec/batch)\n",
      "2019-03-17 02:04:51.163635: step 3140, examples 157000, loss = 0.861921668 (33.289 examples/sec; 1.502 sec/batch)\n",
      "2019-03-17 02:05:06.324951: step 3150, examples 157500, loss = 0.663763463 (32.193 examples/sec; 1.553 sec/batch)\n",
      "2019-03-17 02:05:21.420090: step 3160, examples 158000, loss = 0.979293883 (32.466 examples/sec; 1.540 sec/batch)\n",
      "2019-03-17 02:05:36.725789: step 3170, examples 158500, loss = 0.855117619 (32.069 examples/sec; 1.559 sec/batch)\n",
      "2019-03-17 02:05:51.981358: step 3180, examples 159000, loss = 0.783846438 (32.276 examples/sec; 1.549 sec/batch)\n",
      "2019-03-17 02:06:07.113595: step 3190, examples 159500, loss = 0.741122007 (33.046 examples/sec; 1.513 sec/batch)\n",
      "2019-03-17 02:06:22.304990: step 3200, examples 160000, loss = 0.706249774 (33.245 examples/sec; 1.504 sec/batch)\n",
      "Top 1 validation accuracy: 0.6485849022865295 and top 2 validation accuracy: 0.8561320900917053\n",
      "Model Saved!\n",
      "2019-03-17 02:06:42.342271: step 3210, examples 160500, loss = 0.730045557 (33.808 examples/sec; 1.479 sec/batch)\n",
      "2019-03-17 02:06:57.338148: step 3220, examples 161000, loss = 0.918856680 (31.987 examples/sec; 1.563 sec/batch)\n",
      "2019-03-17 02:07:12.541575: step 3230, examples 161500, loss = 0.787190378 (32.981 examples/sec; 1.516 sec/batch)\n",
      "2019-03-17 02:07:27.680833: step 3240, examples 162000, loss = 0.715466440 (32.894 examples/sec; 1.520 sec/batch)\n",
      "2019-03-17 02:07:42.806052: step 3250, examples 162500, loss = 0.651527405 (33.378 examples/sec; 1.498 sec/batch)\n",
      "2019-03-17 02:07:58.003463: step 3260, examples 163000, loss = 0.612792015 (33.831 examples/sec; 1.478 sec/batch)\n",
      "2019-03-17 02:08:13.184832: step 3270, examples 163500, loss = 0.614963531 (33.200 examples/sec; 1.506 sec/batch)\n",
      "2019-03-17 02:08:28.129572: step 3280, examples 164000, loss = 0.776110709 (33.025 examples/sec; 1.514 sec/batch)\n",
      "2019-03-17 02:08:43.255796: step 3290, examples 164500, loss = 0.787150383 (33.223 examples/sec; 1.505 sec/batch)\n",
      "2019-03-17 02:08:58.403072: step 3300, examples 165000, loss = 0.808961511 (33.289 examples/sec; 1.502 sec/batch)\n",
      "Top 1 validation accuracy: 0.6462264060974121 and top 2 validation accuracy: 0.8561320900917053\n",
      "Model Saved!\n",
      "2019-03-17 02:09:18.270904: step 3310, examples 165500, loss = 0.632167399 (33.200 examples/sec; 1.506 sec/batch)\n",
      "2019-03-17 02:09:33.421189: step 3320, examples 166000, loss = 0.749487102 (33.289 examples/sec; 1.502 sec/batch)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2019-03-17 02:09:48.905372: step 3330, examples 166500, loss = 0.740597486 (30.186 examples/sec; 1.656 sec/batch)\n",
      "2019-03-17 02:10:04.450758: step 3340, examples 167000, loss = 0.837910831 (33.854 examples/sec; 1.477 sec/batch)\n",
      "2019-03-17 02:10:19.331327: step 3350, examples 167500, loss = 0.808128595 (34.273 examples/sec; 1.459 sec/batch)\n",
      "2019-03-17 02:10:34.363299: step 3360, examples 168000, loss = 0.674990118 (33.046 examples/sec; 1.513 sec/batch)\n",
      "2019-03-17 02:10:49.353158: step 3370, examples 168500, loss = 0.764808238 (33.969 examples/sec; 1.472 sec/batch)\n",
      "2019-03-17 02:11:04.259797: step 3380, examples 169000, loss = 0.719039619 (32.829 examples/sec; 1.523 sec/batch)\n",
      "2019-03-17 02:11:19.236622: step 3390, examples 169500, loss = 0.668897212 (33.112 examples/sec; 1.510 sec/batch)\n",
      "2019-03-17 02:11:34.205427: step 3400, examples 170000, loss = 0.853322208 (33.739 examples/sec; 1.482 sec/batch)\n",
      "Top 1 validation accuracy: 0.6320754885673523 and top 2 validation accuracy: 0.8301886916160583\n",
      "Model Saved!\n",
      "2019-03-17 02:11:54.102844: step 3410, examples 170500, loss = 0.784121573 (33.581 examples/sec; 1.489 sec/batch)\n",
      "2019-03-17 02:12:09.051594: step 3420, examples 171000, loss = 0.702682078 (33.626 examples/sec; 1.487 sec/batch)\n",
      "2019-03-17 02:12:24.076548: step 3430, examples 171500, loss = 0.671660602 (33.200 examples/sec; 1.506 sec/batch)\n",
      "2019-03-17 02:12:39.153640: step 3440, examples 172000, loss = 0.779195964 (33.694 examples/sec; 1.484 sec/batch)\n",
      "2019-03-17 02:12:54.221708: step 3450, examples 172500, loss = 0.606596529 (33.808 examples/sec; 1.479 sec/batch)\n",
      "2019-03-17 02:13:09.145391: step 3460, examples 173000, loss = 0.794054806 (33.854 examples/sec; 1.477 sec/batch)\n",
      "2019-03-17 02:13:24.116200: step 3470, examples 173500, loss = 0.729354799 (33.156 examples/sec; 1.508 sec/batch)\n",
      "2019-03-17 02:13:38.985740: step 3480, examples 174000, loss = 0.796457350 (33.877 examples/sec; 1.476 sec/batch)\n",
      "2019-03-17 02:13:53.922458: step 3490, examples 174500, loss = 0.721310258 (33.558 examples/sec; 1.490 sec/batch)\n",
      "2019-03-17 02:14:09.009577: step 3500, examples 175000, loss = 0.741756260 (32.172 examples/sec; 1.554 sec/batch)\n",
      "Top 1 validation accuracy: 0.6415094137191772 and top 2 validation accuracy: 0.8325471878051758\n",
      "Model Saved!\n",
      "2019-03-17 02:14:28.821729: step 3510, examples 175500, loss = 0.686644137 (33.626 examples/sec; 1.487 sec/batch)\n",
      "2019-03-17 02:14:43.710320: step 3520, examples 176000, loss = 0.693315148 (33.558 examples/sec; 1.490 sec/batch)\n",
      "2019-03-17 02:14:59.066544: step 3530, examples 176500, loss = 0.769888699 (32.028 examples/sec; 1.561 sec/batch)\n",
      "2019-03-17 02:15:14.179863: step 3540, examples 177000, loss = 0.861929715 (31.540 examples/sec; 1.585 sec/batch)\n",
      "2019-03-17 02:15:29.615987: step 3550, examples 177500, loss = 0.799368918 (32.764 examples/sec; 1.526 sec/batch)\n",
      "2019-03-17 02:15:44.647959: step 3560, examples 178000, loss = 0.683933794 (31.783 examples/sec; 1.573 sec/batch)\n",
      "2019-03-17 02:15:59.492432: step 3570, examples 178500, loss = 0.817415178 (33.877 examples/sec; 1.476 sec/batch)\n",
      "2019-03-17 02:16:14.459230: step 3580, examples 179000, loss = 0.785050929 (33.289 examples/sec; 1.502 sec/batch)\n",
      "2019-03-17 02:16:30.292590: step 3590, examples 179500, loss = 0.682675064 (32.786 examples/sec; 1.525 sec/batch)\n",
      "2019-03-17 02:16:45.282449: step 3600, examples 180000, loss = 0.721529961 (34.109 examples/sec; 1.466 sec/batch)\n",
      "Top 1 validation accuracy: 0.6202830076217651 and top 2 validation accuracy: 0.8561320900917053\n",
      "Model Saved!\n",
      "2019-03-17 02:17:05.082099: step 3610, examples 180500, loss = 0.791065156 (32.721 examples/sec; 1.528 sec/batch)\n",
      "2019-03-17 02:17:19.985730: step 3620, examples 181000, loss = 0.654641509 (33.513 examples/sec; 1.492 sec/batch)\n",
      "2019-03-17 02:17:37.465212: step 3630, examples 181500, loss = 0.650580347 (26.315 examples/sec; 1.900 sec/batch)\n",
      "2019-03-17 02:17:53.566023: step 3640, examples 182000, loss = 0.798745930 (29.060 examples/sec; 1.721 sec/batch)\n",
      "2019-03-17 02:18:08.443584: step 3650, examples 182500, loss = 0.794428289 (32.635 examples/sec; 1.532 sec/batch)\n",
      "2019-03-17 02:18:23.319140: step 3660, examples 183000, loss = 0.680347264 (34.016 examples/sec; 1.470 sec/batch)\n",
      "2019-03-17 02:18:38.055325: step 3670, examples 183500, loss = 0.765689254 (33.603 examples/sec; 1.488 sec/batch)\n",
      "2019-03-17 02:18:52.969985: step 3680, examples 184000, loss = 0.695776224 (33.003 examples/sec; 1.515 sec/batch)\n",
      "2019-03-17 02:19:08.048080: step 3690, examples 184500, loss = 0.613241911 (33.289 examples/sec; 1.502 sec/batch)\n",
      "2019-03-17 02:19:23.388873: step 3700, examples 185000, loss = 0.686856389 (31.946 examples/sec; 1.565 sec/batch)\n",
      "Top 1 validation accuracy: 0.6485849022865295 and top 2 validation accuracy: 0.8278301954269409\n",
      "Model Saved!\n",
      "2019-03-17 02:19:43.604628: step 3710, examples 185500, loss = 0.679034173 (32.786 examples/sec; 1.525 sec/batch)\n",
      "2019-03-17 02:19:58.634594: step 3720, examples 186000, loss = 0.680174589 (33.558 examples/sec; 1.490 sec/batch)\n",
      "2019-03-17 02:20:13.858100: step 3730, examples 186500, loss = 0.763485372 (33.231 examples/sec; 1.505 sec/batch)\n",
      "2019-03-17 02:20:28.795422: step 3740, examples 187000, loss = 0.929337561 (33.603 examples/sec; 1.488 sec/batch)\n",
      "2019-03-17 02:20:43.851459: step 3750, examples 187500, loss = 0.638699055 (33.311 examples/sec; 1.501 sec/batch)\n",
      "2019-03-17 02:20:58.864380: step 3760, examples 188000, loss = 0.735228777 (34.486 examples/sec; 1.450 sec/batch)\n",
      "2019-03-17 02:21:13.797087: step 3770, examples 188500, loss = 0.673935831 (33.134 examples/sec; 1.509 sec/batch)\n",
      "2019-03-17 02:21:28.683672: step 3780, examples 189000, loss = 0.606515110 (33.025 examples/sec; 1.514 sec/batch)\n",
      "2019-03-17 02:21:43.705617: step 3790, examples 189500, loss = 0.664904296 (33.356 examples/sec; 1.499 sec/batch)\n",
      "2019-03-17 02:21:58.600223: step 3800, examples 190000, loss = 0.672005892 (33.267 examples/sec; 1.503 sec/batch)\n",
      "Top 1 validation accuracy: 0.6721698045730591 and top 2 validation accuracy: 0.849056601524353\n",
      "Model Saved!\n",
      "2019-03-17 02:22:18.782680: step 3810, examples 190500, loss = 0.598865032 (33.356 examples/sec; 1.499 sec/batch)\n",
      "2019-03-17 02:22:33.684306: step 3820, examples 191000, loss = 0.622735262 (33.762 examples/sec; 1.481 sec/batch)\n",
      "2019-03-17 02:22:48.639073: step 3830, examples 191500, loss = 0.622223675 (33.694 examples/sec; 1.484 sec/batch)\n",
      "2019-03-17 02:23:04.038374: step 3840, examples 192000, loss = 0.713958681 (33.581 examples/sec; 1.489 sec/batch)\n",
      "2019-03-17 02:23:18.830709: step 3850, examples 192500, loss = 0.747372210 (34.320 examples/sec; 1.457 sec/batch)\n",
      "2019-03-17 02:23:33.644099: step 3860, examples 193000, loss = 0.498963088 (33.808 examples/sec; 1.479 sec/batch)\n",
      "2019-03-17 02:23:48.549734: step 3870, examples 193500, loss = 0.719895303 (34.702 examples/sec; 1.441 sec/batch)\n",
      "2019-03-17 02:24:03.510517: step 3880, examples 194000, loss = 0.712002575 (33.740 examples/sec; 1.482 sec/batch)\n",
      "2019-03-17 02:24:18.509401: step 3890, examples 194500, loss = 0.750140011 (32.807 examples/sec; 1.524 sec/batch)\n",
      "2019-03-17 02:24:33.599526: step 3900, examples 195000, loss = 0.689659536 (31.324 examples/sec; 1.596 sec/batch)\n",
      "Top 1 validation accuracy: 0.6603773832321167 and top 2 validation accuracy: 0.8419811129570007\n",
      "Model Saved!\n",
      "2019-03-17 02:24:53.468360: step 3910, examples 195500, loss = 0.688439369 (32.959 examples/sec; 1.517 sec/batch)\n",
      "2019-03-17 02:25:08.245655: step 3920, examples 196000, loss = 0.661343992 (33.535 examples/sec; 1.491 sec/batch)\n",
      "2019-03-17 02:25:23.115195: step 3930, examples 196500, loss = 0.759546697 (33.603 examples/sec; 1.488 sec/batch)\n",
      "2019-03-17 02:25:37.924574: step 3940, examples 197000, loss = 0.687201083 (34.062 examples/sec; 1.468 sec/batch)\n",
      "2019-03-17 02:25:52.979606: step 3950, examples 197500, loss = 0.695335805 (32.007 examples/sec; 1.562 sec/batch)\n",
      "2019-03-17 02:26:07.943398: step 3960, examples 198000, loss = 0.659519613 (32.807 examples/sec; 1.524 sec/batch)\n",
      "2019-03-17 02:26:22.783860: step 3970, examples 198500, loss = 0.736777067 (34.630 examples/sec; 1.444 sec/batch)\n",
      "2019-03-17 02:26:37.580718: step 3980, examples 199000, loss = 0.748778760 (34.179 examples/sec; 1.463 sec/batch)\n",
      "2019-03-17 02:26:52.450258: step 3990, examples 199500, loss = 0.784494460 (34.848 examples/sec; 1.435 sec/batch)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2019-03-17 02:27:07.245600: step 4000, examples 200000, loss = 0.645375192 (33.993 examples/sec; 1.471 sec/batch)\n",
      "Top 1 validation accuracy: 0.6297169923782349 and top 2 validation accuracy: 0.8726415038108826\n",
      "Model Saved!\n",
      "2019-03-17 02:27:26.955010: step 4010, examples 200500, loss = 0.648393869 (34.726 examples/sec; 1.440 sec/batch)\n",
      "2019-03-17 02:27:41.905765: step 4020, examples 201000, loss = 0.688412845 (33.740 examples/sec; 1.482 sec/batch)\n",
      "2019-03-17 02:27:56.791348: step 4030, examples 201500, loss = 0.673482120 (34.367 examples/sec; 1.455 sec/batch)\n",
      "2019-03-17 02:28:11.593709: step 4040, examples 202000, loss = 0.692163408 (33.178 examples/sec; 1.507 sec/batch)\n",
      "2019-03-17 02:28:26.434172: step 4050, examples 202500, loss = 0.586296380 (33.468 examples/sec; 1.494 sec/batch)\n",
      "2019-03-17 02:28:41.208458: step 4060, examples 203000, loss = 0.774356782 (33.923 examples/sec; 1.474 sec/batch)\n",
      "2019-03-17 02:28:56.148184: step 4070, examples 203500, loss = 0.702969849 (33.112 examples/sec; 1.510 sec/batch)\n",
      "2019-03-17 02:29:11.056828: step 4080, examples 204000, loss = 0.876797616 (33.581 examples/sec; 1.489 sec/batch)\n",
      "2019-03-17 02:29:25.932384: step 4090, examples 204500, loss = 0.705926657 (33.993 examples/sec; 1.471 sec/batch)\n",
      "2019-03-17 02:29:40.825987: step 4100, examples 205000, loss = 0.687673330 (33.717 examples/sec; 1.483 sec/batch)\n",
      "Top 1 validation accuracy: 0.650943398475647 and top 2 validation accuracy: 0.8349056839942932\n",
      "Model Saved!\n",
      "2019-03-17 02:30:00.601573: step 4110, examples 205500, loss = 0.694087744 (33.558 examples/sec; 1.490 sec/batch)\n",
      "2019-03-17 02:30:15.697221: step 4120, examples 206000, loss = 0.739816129 (31.343 examples/sec; 1.595 sec/batch)\n",
      "2019-03-17 02:30:30.877170: step 4130, examples 206500, loss = 0.624322176 (34.109 examples/sec; 1.466 sec/batch)\n",
      "2019-03-17 02:30:45.828928: step 4140, examples 207000, loss = 0.853905082 (33.603 examples/sec; 1.488 sec/batch)\n",
      "2019-03-17 02:31:00.730554: step 4150, examples 207500, loss = 0.788279295 (34.109 examples/sec; 1.466 sec/batch)\n",
      "2019-03-17 02:31:15.558983: step 4160, examples 208000, loss = 0.704574227 (33.694 examples/sec; 1.484 sec/batch)\n",
      "2019-03-17 02:31:30.432534: step 4170, examples 208500, loss = 0.757040203 (34.179 examples/sec; 1.463 sec/batch)\n",
      "2019-03-17 02:31:45.330149: step 4180, examples 209000, loss = 0.762098312 (32.743 examples/sec; 1.527 sec/batch)\n",
      "2019-03-17 02:32:00.155571: step 4190, examples 209500, loss = 0.782290876 (33.267 examples/sec; 1.503 sec/batch)\n",
      "2019-03-17 02:32:14.997036: step 4200, examples 210000, loss = 0.834602952 (34.296 examples/sec; 1.458 sec/batch)\n",
      "Top 1 validation accuracy: 0.6179245114326477 and top 2 validation accuracy: 0.8396226167678833\n",
      "Model Saved!\n",
      "2019-03-17 02:32:34.794681: step 4210, examples 210500, loss = 0.634137094 (33.513 examples/sec; 1.492 sec/batch)\n",
      "2019-03-17 02:32:49.751452: step 4220, examples 211000, loss = 0.757676542 (32.193 examples/sec; 1.553 sec/batch)\n",
      "2019-03-17 02:33:04.622997: step 4230, examples 211500, loss = 0.695832312 (32.508 examples/sec; 1.538 sec/batch)\n",
      "2019-03-17 02:33:19.463460: step 4240, examples 212000, loss = 0.754059732 (34.156 examples/sec; 1.464 sec/batch)\n",
      "2019-03-17 02:33:34.276850: step 4250, examples 212500, loss = 0.646636307 (33.468 examples/sec; 1.494 sec/batch)\n",
      "2019-03-17 02:33:49.183489: step 4260, examples 213000, loss = 0.659294486 (32.786 examples/sec; 1.525 sec/batch)\n",
      "2019-03-17 02:34:04.113187: step 4270, examples 213500, loss = 0.738994181 (33.003 examples/sec; 1.515 sec/batch)\n",
      "2019-03-17 02:34:18.979720: step 4280, examples 214000, loss = 0.817843795 (33.068 examples/sec; 1.512 sec/batch)\n",
      "2019-03-17 02:34:33.920449: step 4290, examples 214500, loss = 0.684718192 (33.694 examples/sec; 1.484 sec/batch)\n",
      "2019-03-17 02:34:48.746874: step 4300, examples 215000, loss = 0.752067149 (33.046 examples/sec; 1.513 sec/batch)\n",
      "Top 1 validation accuracy: 0.6650943160057068 and top 2 validation accuracy: 0.8584905862808228\n",
      "Model Saved!\n",
      "2019-03-17 02:35:09.025798: step 4310, examples 215500, loss = 0.686656237 (33.289 examples/sec; 1.502 sec/batch)\n",
      "2019-03-17 02:35:24.344532: step 4320, examples 216000, loss = 0.816765010 (31.803 examples/sec; 1.572 sec/batch)\n",
      "2019-03-17 02:35:39.737464: step 4330, examples 216500, loss = 0.697634816 (33.046 examples/sec; 1.513 sec/batch)\n",
      "2019-03-17 02:35:55.337947: step 4340, examples 217000, loss = 0.701151907 (32.235 examples/sec; 1.551 sec/batch)\n",
      "2019-03-17 02:36:10.715839: step 4350, examples 217500, loss = 0.637181282 (32.339 examples/sec; 1.546 sec/batch)\n",
      "2019-03-17 02:36:26.103757: step 4360, examples 218000, loss = 0.754126191 (32.131 examples/sec; 1.556 sec/batch)\n",
      "2019-03-17 02:36:41.476635: step 4370, examples 218500, loss = 0.709558010 (32.572 examples/sec; 1.535 sec/batch)\n",
      "2019-03-17 02:36:56.888617: step 4380, examples 219000, loss = 0.858887613 (32.829 examples/sec; 1.523 sec/batch)\n",
      "2019-03-17 02:37:12.383822: step 4390, examples 219500, loss = 0.843762040 (31.803 examples/sec; 1.572 sec/batch)\n",
      "2019-03-17 02:37:27.795803: step 4400, examples 220000, loss = 0.663916469 (32.721 examples/sec; 1.528 sec/batch)\n",
      "Top 1 validation accuracy: 0.6533018946647644 and top 2 validation accuracy: 0.8419811129570007\n",
      "Model Saved!\n",
      "2019-03-17 02:37:48.277266: step 4410, examples 220500, loss = 0.835092783 (32.572 examples/sec; 1.535 sec/batch)\n",
      "2019-03-17 02:38:03.567925: step 4420, examples 221000, loss = 0.784502566 (32.981 examples/sec; 1.516 sec/batch)\n",
      "2019-03-17 02:38:18.906712: step 4430, examples 221500, loss = 0.705783069 (33.025 examples/sec; 1.514 sec/batch)\n",
      "2019-03-17 02:38:34.307665: step 4440, examples 222000, loss = 0.728119910 (33.900 examples/sec; 1.475 sec/batch)\n",
      "2019-03-17 02:38:49.728671: step 4450, examples 222500, loss = 0.647230685 (32.786 examples/sec; 1.525 sec/batch)\n",
      "2019-03-17 02:39:05.198808: step 4460, examples 223000, loss = 0.604524434 (32.318 examples/sec; 1.547 sec/batch)\n",
      "2019-03-17 02:39:20.598759: step 4470, examples 223500, loss = 0.827510059 (33.267 examples/sec; 1.503 sec/batch)\n",
      "2019-03-17 02:39:36.026783: step 4480, examples 224000, loss = 0.620901108 (32.981 examples/sec; 1.516 sec/batch)\n",
      "2019-03-17 02:39:51.406680: step 4490, examples 224500, loss = 0.543314815 (33.223 examples/sec; 1.505 sec/batch)\n",
      "2019-03-17 02:40:06.652220: step 4500, examples 225000, loss = 0.690672815 (32.529 examples/sec; 1.537 sec/batch)\n",
      "Top 1 validation accuracy: 0.6627358198165894 and top 2 validation accuracy: 0.849056601524353\n",
      "Model Saved!\n",
      "2019-03-17 02:40:27.228936: step 4510, examples 225500, loss = 0.868234456 (32.593 examples/sec; 1.534 sec/batch)\n",
      "2019-03-17 02:40:42.713110: step 4520, examples 226000, loss = 0.674405277 (32.678 examples/sec; 1.530 sec/batch)\n",
      "2019-03-17 02:40:58.152163: step 4530, examples 226500, loss = 0.740325928 (33.112 examples/sec; 1.510 sec/batch)\n",
      "2019-03-17 02:41:13.565149: step 4540, examples 227000, loss = 0.724800527 (33.046 examples/sec; 1.513 sec/batch)\n",
      "2019-03-17 02:41:28.955073: step 4550, examples 227500, loss = 0.551410854 (32.636 examples/sec; 1.532 sec/batch)\n",
      "2019-03-17 02:41:44.638282: step 4560, examples 228000, loss = 0.740740538 (32.786 examples/sec; 1.525 sec/batch)\n",
      "2019-03-17 02:42:00.056279: step 4570, examples 228500, loss = 0.580173492 (31.561 examples/sec; 1.584 sec/batch)\n",
      "2019-03-17 02:42:16.038779: step 4580, examples 229000, loss = 0.575064301 (32.657 examples/sec; 1.531 sec/batch)\n",
      "2019-03-17 02:42:31.519945: step 4590, examples 229500, loss = 0.694642007 (32.657 examples/sec; 1.531 sec/batch)\n",
      "2019-03-17 02:42:47.388436: step 4600, examples 230000, loss = 0.579968989 (31.531 examples/sec; 1.586 sec/batch)\n",
      "Top 1 validation accuracy: 0.6344339847564697 and top 2 validation accuracy: 0.8466981053352356\n",
      "Model Saved!\n",
      "2019-03-17 02:43:07.878916: step 4610, examples 230500, loss = 0.862057090 (33.025 examples/sec; 1.514 sec/batch)\n",
      "2019-03-17 02:43:23.265832: step 4620, examples 231000, loss = 0.630298674 (32.402 examples/sec; 1.543 sec/batch)\n",
      "2019-03-17 02:43:38.543457: step 4630, examples 231500, loss = 0.673777342 (33.112 examples/sec; 1.510 sec/batch)\n",
      "2019-03-17 02:43:54.023621: step 4640, examples 232000, loss = 0.670495331 (31.422 examples/sec; 1.591 sec/batch)\n",
      "2019-03-17 02:44:09.468691: step 4650, examples 232500, loss = 0.610044301 (32.593 examples/sec; 1.534 sec/batch)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2019-03-17 02:44:24.859617: step 4660, examples 233000, loss = 0.648194730 (32.110 examples/sec; 1.557 sec/batch)\n",
      "2019-03-17 02:44:40.486093: step 4670, examples 233500, loss = 0.571914017 (31.364 examples/sec; 1.594 sec/batch)\n",
      "2019-03-17 02:44:57.437706: step 4680, examples 234000, loss = 0.556474268 (30.973 examples/sec; 1.614 sec/batch)\n",
      "2019-03-17 02:45:13.804226: step 4690, examples 234500, loss = 0.711023092 (31.031 examples/sec; 1.611 sec/batch)\n",
      "2019-03-17 02:45:29.448826: step 4700, examples 235000, loss = 0.893343568 (32.402 examples/sec; 1.543 sec/batch)\n",
      "Top 1 validation accuracy: 0.6462264060974121 and top 2 validation accuracy: 0.8254716992378235\n",
      "Model Saved!\n",
      "2019-03-17 02:45:50.595520: step 4710, examples 235500, loss = 0.546377659 (32.333 examples/sec; 1.546 sec/batch)\n",
      "2019-03-17 02:46:05.876221: step 4720, examples 236000, loss = 0.565506697 (32.689 examples/sec; 1.530 sec/batch)\n",
      "2019-03-17 02:46:21.163569: step 4730, examples 236500, loss = 0.742836177 (32.664 examples/sec; 1.531 sec/batch)\n",
      "2019-03-17 02:46:36.328542: step 4740, examples 237000, loss = 0.735513449 (33.429 examples/sec; 1.496 sec/batch)\n",
      "2019-03-17 02:46:51.662703: step 4750, examples 237500, loss = 0.714907408 (29.742 examples/sec; 1.681 sec/batch)\n",
      "2019-03-17 02:47:08.090281: step 4760, examples 238000, loss = 0.686601877 (32.850 examples/sec; 1.522 sec/batch)\n",
      "2019-03-17 02:47:23.545378: step 4770, examples 238500, loss = 0.656002760 (31.905 examples/sec; 1.567 sec/batch)\n",
      "2019-03-17 02:47:39.221078: step 4780, examples 239000, loss = 0.762677133 (29.745 examples/sec; 1.681 sec/batch)\n",
      "2019-03-17 02:47:54.732708: step 4790, examples 239500, loss = 0.628875494 (33.412 examples/sec; 1.496 sec/batch)\n",
      "2019-03-17 02:48:10.185189: step 4800, examples 240000, loss = 0.670069039 (31.789 examples/sec; 1.573 sec/batch)\n",
      "Top 1 validation accuracy: 0.6462264060974121 and top 2 validation accuracy: 0.8372641801834106\n",
      "Model Saved!\n",
      "2019-03-17 02:48:30.710353: step 4810, examples 240500, loss = 0.743945897 (32.223 examples/sec; 1.552 sec/batch)\n",
      "2019-03-17 02:48:46.730181: step 4820, examples 241000, loss = 0.608013690 (32.131 examples/sec; 1.556 sec/batch)\n",
      "2019-03-17 02:49:02.362750: step 4830, examples 241500, loss = 0.698662996 (31.601 examples/sec; 1.582 sec/batch)\n",
      "2019-03-17 02:49:17.864972: step 4840, examples 242000, loss = 0.680465281 (32.069 examples/sec; 1.559 sec/batch)\n",
      "2019-03-17 02:49:33.763248: step 4850, examples 242500, loss = 0.775358558 (31.422 examples/sec; 1.591 sec/batch)\n",
      "2019-03-17 02:49:49.608382: step 4860, examples 243000, loss = 0.804307938 (31.642 examples/sec; 1.580 sec/batch)\n",
      "2019-03-17 02:50:05.221899: step 4870, examples 243500, loss = 0.573949277 (32.657 examples/sec; 1.531 sec/batch)\n",
      "2019-03-17 02:50:20.773252: step 4880, examples 244000, loss = 0.700356722 (32.193 examples/sec; 1.553 sec/batch)\n",
      "2019-03-17 02:50:36.434898: step 4890, examples 244500, loss = 0.784841001 (32.444 examples/sec; 1.541 sec/batch)\n",
      "2019-03-17 02:50:52.055434: step 4900, examples 245000, loss = 0.634225309 (32.423 examples/sec; 1.542 sec/batch)\n",
      "Top 1 validation accuracy: 0.6391509175300598 and top 2 validation accuracy: 0.8254716992378235\n",
      "Model Saved!\n",
      "2019-03-17 02:51:12.647191: step 4910, examples 245500, loss = 0.769201994 (31.884 examples/sec; 1.568 sec/batch)\n",
      "2019-03-17 02:51:28.115323: step 4920, examples 246000, loss = 0.822036326 (31.762 examples/sec; 1.574 sec/batch)\n",
      "2019-03-17 02:51:43.615540: step 4930, examples 246500, loss = 0.680851996 (31.783 examples/sec; 1.573 sec/batch)\n",
      "2019-03-17 02:51:59.049580: step 4940, examples 247000, loss = 0.814179361 (32.193 examples/sec; 1.553 sec/batch)\n",
      "2019-03-17 02:52:14.356283: step 4950, examples 247500, loss = 0.619511783 (32.423 examples/sec; 1.542 sec/batch)\n",
      "2019-03-17 02:52:29.876552: step 4960, examples 248000, loss = 0.686962068 (31.905 examples/sec; 1.567 sec/batch)\n",
      "2019-03-17 02:52:45.413867: step 4970, examples 248500, loss = 0.847228110 (32.894 examples/sec; 1.520 sec/batch)\n",
      "2019-03-17 02:53:00.980260: step 4980, examples 249000, loss = 0.713660240 (32.172 examples/sec; 1.554 sec/batch)\n",
      "2019-03-17 02:53:16.478471: step 4990, examples 249500, loss = 0.862226665 (32.007 examples/sec; 1.562 sec/batch)\n",
      "Top 1 validation accuracy: 0.6556603908538818 and top 2 validation accuracy: 0.8655660152435303\n",
      "Model Saved!\n"
     ]
    }
   ],
   "source": [
    "# Lets try also with step size 10\n",
    "for step_size in range(10,11,10):\n",
    "    num_cls = 4\n",
    "    mstp = 5000\n",
    "    lfrq = 10\n",
    "    bsz = 50\n",
    "    msf = 100\n",
    "    tr = './trained_model_final/DCNN_reg_ss_crop_step'+str(step_size)\n",
    "    if not os.path.exists(tr):\n",
    "        os.mkdir(tr)\n",
    "    start = 0\n",
    "    stop = 250\n",
    "    step = step_size\n",
    "    time_length = 700\n",
    "    time_bin = 350\n",
    "    fsz = 3\n",
    "    use_batchnorm = True\n",
    "    use_dropout = True\n",
    "    use_l2loss = True\n",
    "    acc = 'Accuracy_step'+str(step_size)\n",
    "    path = 'Path_step'+str(step_size)\n",
    "\n",
    "    best_val_ss_crop[acc],best_val_ss_crop[path] = train_model_ss(tr,start,stop,step,time_length,time_bin,fsz,use_batchnorm,use_dropout,use_l2loss,num_cls,mstp,lfrq,bsz,msf)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test Accuracy using cropped data for training for step size 10:\n",
      "Loading datasets...\n",
      "Dataset loading completes.\n",
      "INFO:tensorflow:Restoring parameters from ./trained_model_final/DCNN_reg_ss_crop_step10\\model.ckpt-3801\n",
      "[test  step 3801] loss: 1.28686; top_1_accuracy: 0.64673; top_5_accuracy: 0.844244 (7.296 sec/batch; 121.436 instances/sec)\n",
      "top_1_accuracy_test =  0.64672685 top_2_accuracy_test =  0.84424376\n",
      "Test Accuracy using cropped data for training for step size 25:\n",
      "Loading datasets...\n",
      "Dataset loading completes.\n",
      "INFO:tensorflow:Restoring parameters from ./trained_model_final/DCNN_reg_ss_crop_step25\\model.ckpt-3501\n",
      "[test  step 3501] loss: 1.28993; top_1_accuracy: 0.63205; top_5_accuracy: 0.841986 (3.615 sec/batch; 245.081 instances/sec)\n",
      "top_1_accuracy_test =  0.63205415 top_2_accuracy_test =  0.8419865\n",
      "Test Accuracy using cropped data for training for step size 50:\n",
      "Loading datasets...\n",
      "Dataset loading completes.\n",
      "INFO:tensorflow:Restoring parameters from ./trained_model_final/DCNN_reg_ss_crop_step50\\model.ckpt-4301\n",
      "[test  step 4301] loss: 1.32339; top_1_accuracy: 0.62077; top_5_accuracy: 0.840858 (2.294 sec/batch; 386.208 instances/sec)\n",
      "top_1_accuracy_test =  0.6207675 top_2_accuracy_test =  0.8408578\n",
      "Test Accuracy using cropped data for training for step size 75:\n",
      "Loading datasets...\n",
      "Dataset loading completes.\n",
      "INFO:tensorflow:Restoring parameters from ./trained_model_final/DCNN_reg_ss_crop_step75\\model.ckpt-4801\n",
      "[test  step 4801] loss: 1.37576; top_1_accuracy: 0.62528; top_5_accuracy: 0.825056 (1.511 sec/batch; 586.373 instances/sec)\n",
      "top_1_accuracy_test =  0.62528217 top_2_accuracy_test =  0.82505643\n",
      "Test Accuracy using cropped data for training for step size 100:\n",
      "Loading datasets...\n",
      "Dataset loading completes.\n",
      "INFO:tensorflow:Restoring parameters from ./trained_model_final/DCNN_reg_ss_crop_step100\\model.ckpt-4601\n",
      "[test  step 4601] loss: 1.47298; top_1_accuracy: 0.58804; top_5_accuracy: 0.812641 (1.497 sec/batch; 591.858 instances/sec)\n",
      "top_1_accuracy_test =  0.5880361 top_2_accuracy_test =  0.8126411\n",
      "The step_size 10 has the best test accuracy: 0.6467268466949463\n"
     ]
    }
   ],
   "source": [
    "# Accuracy for testSet(best)\n",
    "stp = np.arange(25,101,25)\n",
    "stp = np.insert(stp,0,10)\n",
    "best_test_acc_ss_crop = 0\n",
    "best_test_ss_crop = 0\n",
    "for step_size in stp:\n",
    "    path = 'Path_step'+str(step_size)\n",
    "    model_dir = best_val_ss_crop[path]\n",
    "    start = 0\n",
    "    stop = 250\n",
    "    step = step_size\n",
    "    time_length = 700\n",
    "    time_bin = 350\n",
    "    #Nb = BATCH_SIZE\n",
    "    fsz = 3\n",
    "    use_batchnorm = True\n",
    "    use_dropout = True\n",
    "    use_l2loss = True\n",
    "    print('Test Accuracy using cropped data for training for step size {}:'.format(step_size))\n",
    "    top_1_acc_test, top_2_acc_test = test_model_ss(model_dir,start,stop,step,time_length,time_bin,fsz,use_batchnorm,use_dropout,use_l2loss)\n",
    "    if top_1_acc_test > best_test_acc_ss_crop:\n",
    "        best_test_acc_ss_crop = top_1_acc_test\n",
    "        best_test_ss_crop = step_size\n",
    "\n",
    "print('The step_size {} has the best test accuracy: {}'.format(best_test_ss_crop,best_test_acc_ss_crop))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [],
   "source": [
    "def data_loader_ss_subject(time_bin,sub_id):\n",
    "    X_test = np.load(\"X_test.npy\")\n",
    "    X_test = X_test[:,0:22,0:time_bin]\n",
    "    y_test = np.load(\"y_test.npy\")\n",
    "    person_test = np.load(\"person_test.npy\")\n",
    "\n",
    "    X_train_valid = np.load(\"X_train_valid.npy\")\n",
    "    X_train_valid = X_train_valid[:,0:22,0:time_bin]\n",
    "    y_train_valid = np.load(\"y_train_valid.npy\")\n",
    "    person_train_valid = np.load(\"person_train_valid.npy\")\n",
    "    \n",
    "    N_train = X_train_valid.shape[0]\n",
    "    idx_train_valid = np.arange(N_train,dtype='int')\n",
    "\n",
    "    X_train, X_val, idx_train, idx_val = train_test_split(X_train_valid, idx_train_valid, test_size=0.1, random_state=21)\n",
    "\n",
    "    y_train = y_train_valid[idx_train]\n",
    "    person_train = person_train_valid[idx_train]\n",
    "    y_val = y_train_valid[idx_val]\n",
    "    person_val = person_train_valid[idx_val]\n",
    "    \n",
    "    idx11 = np.arange(0,X_test.shape[2],2,dtype=int)\n",
    "    idx21 = np.arange(1,X_test.shape[2],2,dtype=int)\n",
    "    X_test_ss1 = np.take(X_test,idx11,axis=2)\n",
    "    X_test_ss2 = np.take(X_test,idx21,axis=2)\n",
    "    X_test = np.concatenate((X_test_ss1,X_test_ss2),axis=0)\n",
    "    y_test = np.concatenate((y_test,y_test),axis=0)\n",
    "    person_test = np.concatenate((person_test,person_test),axis=0)\n",
    "    \n",
    "    idx12 = np.arange(0,X_train.shape[2],2,dtype=int)\n",
    "    idx22 = np.arange(1,X_train.shape[2],2,dtype=int)\n",
    "    X_train_ss1 = np.take(X_train,idx12,axis=2)\n",
    "    X_train_ss2 = np.take(X_train,idx22,axis=2)\n",
    "    X_train = np.concatenate((X_train_ss1,X_train_ss2),axis=0)\n",
    "    y_train = np.concatenate((y_train,y_train),axis=0)\n",
    "    person_train = np.concatenate((person_train,person_train),axis=0)\n",
    "    \n",
    "    idx13 = np.arange(0,X_val.shape[2],2,dtype=int)\n",
    "    idx23 = np.arange(1,X_val.shape[2],2,dtype=int)\n",
    "    X_val_ss1 = np.take(X_val,idx13,axis=2)\n",
    "    X_val_ss2 = np.take(X_val,idx23,axis=2)\n",
    "    X_val = np.concatenate((X_val_ss1,X_val_ss2),axis=0)\n",
    "    y_val = np.concatenate((y_val,y_val),axis=0)\n",
    "    person_val = np.concatenate((person_val,person_val),axis=0)\n",
    "\n",
    "    tl = X_train.shape[2]\n",
    "    X_test = np.reshape(X_test,(-1,22,tl,1))\n",
    "    X_train = np.reshape(X_train,(-1,22,tl,1))\n",
    "    X_val = np.reshape(X_val,(-1,22,tl,1))\n",
    "    \n",
    "    if sub_id<9:\n",
    "        subid_test = np.where(person_test==sub_id)\n",
    "        person_test = np.take(person_test,subid_test[0],axis=0)\n",
    "        X_test = np.take(X_test,subid_test[0],axis=0)\n",
    "        y_test = np.take(y_test,subid_test[0],axis=0)\n",
    "        subid_val = np.where(person_val==sub_id)\n",
    "        person_val = np.take(person_val,subid_val[0],axis=0)\n",
    "        X_val = np.take(X_val,subid_val[0],axis=0)\n",
    "        y_val = np.take(y_val,subid_val[0],axis=0)\n",
    "        subid_train = np.where(person_train==sub_id)\n",
    "        person_train = np.take(person_train,subid_train[0],axis=0)\n",
    "        X_train = np.take(X_train,subid_train[0],axis=0)\n",
    "        y_train = np.take(y_train,subid_train[0],axis=0)\n",
    "\n",
    "    label0 = 769\n",
    "    new_label0 = 0\n",
    "    for i in range(4):\n",
    "        m1 = (y_test==label0)\n",
    "        m2 = (y_train==label0)\n",
    "        m3 = (y_val==label0)\n",
    "        np.place(y_test,m1,new_label0)\n",
    "        np.place(y_train,m2,new_label0)\n",
    "        np.place(y_val,m3,new_label0)\n",
    "        label0 += 1\n",
    "        new_label0 += 1\n",
    "\n",
    "    labelNames = [0,1,2,3]\n",
    "    train_set = {'data': X_train, 'labels': y_train, 'person': person_train}\n",
    "    test_set = {'data': X_test, 'labels': y_test, 'person': person_test}\n",
    "    val_set = {'data': X_val, 'labels': y_val, 'person': person_val}\n",
    "    return train_set, test_set, val_set, labelNames\n",
    "\n",
    "def sample_batch(dataset, batch_size):\n",
    "    N = dataset['data'].shape[0]\n",
    "    indices = np.random.randint(N, size=batch_size)\n",
    "    return {key: dataset[key][indices] for key in dataset}\n",
    "\n",
    "def train_model_ss_subject(sub_id,target_dir,start,stop,step,time_length,time_bin,fsz,use_batchnorm,use_dropout,use_l2loss,num_class,max_step,log_frequency,batch_size,model_saving_freq):\n",
    "    # load data\n",
    "    print(\"Loading datasets...\")\n",
    "    trainSet, testSet, valSet, labelNames = data_loader_ss_subject(time_length,sub_id)\n",
    "    print(\"Dataset loading completes.\")\n",
    "    \n",
    "    best_val_acc = 0\n",
    "    best_val_path = target_dir\n",
    "    \n",
    "\n",
    "\n",
    "    # reset default graph\n",
    "    tf.reset_default_graph()\n",
    "\n",
    "    global_step = tf.train.get_or_create_global_step()\n",
    "    \n",
    "    model = Model(config, labelNames,start,stop,step,time_bin,fsz,use_batchnorm,use_dropout,use_l2loss)\n",
    "\n",
    "    # training setups\n",
    "    saver = tf.train.Saver(max_to_keep=100)\n",
    "\n",
    "    # Build an initialization operation to run below.\n",
    "    init = tf.global_variables_initializer()\n",
    "    \n",
    "    config_proto = tf.ConfigProto()\n",
    "\n",
    "    off = rewriter_config_pb2.RewriterConfig.OFF\n",
    "    config_proto.graph_options.rewrite_options.arithmetic_optimization = off\n",
    "    \n",
    "    sess = tf.Session(config=config_proto)\n",
    "\n",
    "    sess.run(init)\n",
    "\n",
    "    # main loop\n",
    "    for step in range(max_step):\n",
    "        start_time = time.time()\n",
    "\n",
    "        # prepare data\n",
    "        train_batch = sample_batch(trainSet, batch_size)\n",
    "        # feed dict\n",
    "        feed_dict = {\n",
    "            model.input: train_batch['data'],\n",
    "            model.fine_labels: train_batch['labels'],\n",
    "            model.is_training: True,\n",
    "        }\n",
    "        \n",
    "        fetch_list = [model.optimizer_op, model.loss, model.global_step]\n",
    "        _, loss_value, global_step_value = sess.run(fetch_list, feed_dict=feed_dict)\n",
    "        duration = time.time() - start_time\n",
    "        assert not np.isnan(loss_value), 'Model diverged with loss = NaN'\n",
    "\n",
    "        # log\n",
    "        if step % log_frequency == 0:\n",
    "            num_examples_per_step = batch_size\n",
    "            examples_per_sec = num_examples_per_step / duration\n",
    "            sec_per_batch = duration\n",
    "            format_str = (\n",
    "                '%s: step %d, examples %d, loss = %.9f (%.3f examples/sec; %.3f sec/batch)'\n",
    "            )\n",
    "            print(\n",
    "                format_str % (\n",
    "                    datetime.now(), step, batch_size * step,\n",
    "                    loss_value,\n",
    "                    examples_per_sec, sec_per_batch\n",
    "                )\n",
    "            )\n",
    "\n",
    "        # Save the model checkpoint periodically.\n",
    "        if step % model_saving_freq == 0 or (step + 1) == max_step:\n",
    "            fetch_list = [model.accuracy,model.top_2_accuracy]\n",
    "            feed_dict = {\n",
    "                model.input: valSet['data'],\n",
    "                model.fine_labels: valSet['labels'],\n",
    "                model.is_training: False,\n",
    "            }\n",
    "            val_acc_1, val_acc_2 =  sess.run(fetch_list, feed_dict=feed_dict)\n",
    "            checkpoint_path = os.path.join(target_dir, 'model.ckpt')\n",
    "            saver.save(sess, checkpoint_path, global_step=int(global_step_value))\n",
    "            print('Top 1 validation accuracy: {} and top 2 validation accuracy: {}'.format(val_acc_1,val_acc_2))\n",
    "            print('Model Saved!')\n",
    "            if val_acc_1>best_val_acc:\n",
    "                best_val_acc = val_acc_1\n",
    "                best_val_path = checkpoint_path+'-'+str(int(global_step_value))\n",
    "    return best_val_acc,best_val_path\n",
    "\n",
    "\n",
    "def test_model_ss_subject(sub_id,model_dir,start,stop,step,time_length,time_bin,fsz,use_batchnorm,use_dropout,use_l2loss):\n",
    "    print(\"Loading datasets...\")\n",
    "    trainSet, testSet, valSet, labelNames = data_loader_ss_subject(time_length,sub_id)\n",
    "    print(\"Dataset loading completes.\")\n",
    "    \n",
    "    # reset default graph\n",
    "    tf.reset_default_graph()\n",
    "    \n",
    "    # create model\n",
    "    \n",
    "    model = Model(config, labelNames,start,stop,step,time_bin,fsz,use_batchnorm,use_dropout,use_l2loss)\n",
    "    # training setups\n",
    "    saver = tf.train.Saver(max_to_keep=100)\n",
    "    test_accuracy = [0, 0]\n",
    "    \n",
    "    config_proto = tf.ConfigProto()\n",
    "\n",
    "    off = rewriter_config_pb2.RewriterConfig.OFF\n",
    "    config_proto.graph_options.rewrite_options.arithmetic_optimization = off\n",
    "\n",
    "    with tf.Session(config=config_proto) as session:\n",
    "        session.run(tf.global_variables_initializer())\n",
    "        saver.restore(session, model_dir)\n",
    "        # test model\n",
    "        exp_results = run_single_step(session, model, testSet, mode='test')\n",
    "        test_accuracy[0] = exp_results['top_1_accuracy']\n",
    "        test_accuracy[1] = exp_results['top_2_accuracy']\n",
    "        print('top_1_accuracy_test = ', test_accuracy[0], 'top_2_accuracy_test = ', test_accuracy[1])\n",
    "        \n",
    "    top1_acc = test_accuracy[0]\n",
    "    top2_acc = test_accuracy[1]\n",
    "    return top1_acc,top2_acc\n",
    "\n",
    "\n",
    "def run_single_step(\n",
    "        session,\n",
    "        model,\n",
    "        batch,\n",
    "        mode='test',\n",
    "        log=True,\n",
    "):\n",
    "    # construct feed dict\n",
    "    feed_dict = {\n",
    "        model.input: batch['data'],\n",
    "        # model.coarse_labels: batch['coarse_labels'],\n",
    "        model.fine_labels: batch['labels'],\n",
    "        # model.label_mapping: label_mapping,\n",
    "        model.is_training: mode == 'train'\n",
    "    }\n",
    "    \n",
    "    # select proper summary op\n",
    "    if mode == 'train':\n",
    "        summary_op = model.train_summary_op\n",
    "    elif mode == 'val':\n",
    "        summary_op = model.val_summary_op\n",
    "    else:\n",
    "        summary_op = model.test_summary_op\n",
    "    \n",
    "    # construct fetch list\n",
    "    fetch_list = [model.global_step, summary_op, model.loss, model.accuracy, model.top_2_accuracy]\n",
    "\n",
    "    # run single step\n",
    "    _start_time = time.time()\n",
    "    _step, _summary, _loss, _top_1, _top_2 = session.run(fetch_list, feed_dict=feed_dict)[:5]\n",
    "    _end_time = time.time()\n",
    "    \n",
    "    # collect step statistics\n",
    "    step_time = _end_time - _start_time\n",
    "    batch_size = batch['data'].shape[0]\n",
    "    \n",
    "    # log in console\n",
    "    if log:\n",
    "        print(('[{:5s} step {:4d}] loss: {:.5f}; top_1_accuracy: {:.5f}; top_5_accuracy: {:5f} ' +\n",
    "              '({:.3f} sec/batch; {:.3f} instances/sec)'\n",
    "              ).format(mode, _step, _loss, _top_1, _top_2, \n",
    "                       step_time, batch_size / step_time))\n",
    "    \n",
    "    # log results to file and return statistics\n",
    "    if mode == 'test':\n",
    "        test_fetch_list = [model.per_class_accuracy,\n",
    "                model.top_2_per_class_accuracy,\n",
    "                model.confusion_matrix, \n",
    "                model.pred, model.probs]\n",
    "        _top_1_c,  _top_2_c, _cm, _pred, _probs = \\\n",
    "                session.run(test_fetch_list, feed_dict=feed_dict)\n",
    "        \n",
    "        \n",
    "        # Log detailed test results in pickle format\n",
    "        stats = {\n",
    "            \"loss\": _loss,\n",
    "            \"top_1_accuracy\": _top_1,\n",
    "            \"top_2_accuracy\": _top_2,\n",
    "            \"top_1_perclass_accuracy\": _top_1_c,\n",
    "            \"top_2_perclass_accuracy\": _top_2_c,\n",
    "            \"confusion_matrix\": _cm,\n",
    "            \"pred\": _pred,\n",
    "            \"probs\": _probs\n",
    "        }\n",
    "    else:\n",
    "        stats = {\n",
    "            \"step\": _step,\n",
    "            \"loss\": _loss,\n",
    "            \"top_1_accuracy\": _top_1,\n",
    "            \"top_2_accuracy\": _top_2\n",
    "        }\n",
    "        \n",
    "    return stats\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test Accuracy for subject 0:\n",
      "Loading datasets...\n",
      "Dataset loading completes.\n",
      "INFO:tensorflow:Restoring parameters from ./trained_model_final/DCNN_reg_ss_crop_step10\\model.ckpt-3801\n",
      "[test  step 3801] loss: 1.35630; top_1_accuracy: 0.56000; top_5_accuracy: 0.870000 (0.935 sec/batch; 106.900 instances/sec)\n",
      "top_1_accuracy_test =  0.56 top_2_accuracy_test =  0.87\n",
      "Test Accuracy for subject 1:\n",
      "Loading datasets...\n",
      "Dataset loading completes.\n",
      "INFO:tensorflow:Restoring parameters from ./trained_model_final/DCNN_reg_ss_crop_step10\\model.ckpt-3801\n",
      "[test  step 3801] loss: 1.65400; top_1_accuracy: 0.46000; top_5_accuracy: 0.700000 (0.963 sec/batch; 103.890 instances/sec)\n",
      "top_1_accuracy_test =  0.46 top_2_accuracy_test =  0.7\n",
      "Test Accuracy for subject 2:\n",
      "Loading datasets...\n",
      "Dataset loading completes.\n",
      "INFO:tensorflow:Restoring parameters from ./trained_model_final/DCNN_reg_ss_crop_step10\\model.ckpt-3801\n",
      "[test  step 3801] loss: 1.08566; top_1_accuracy: 0.75000; top_5_accuracy: 0.850000 (0.922 sec/batch; 108.410 instances/sec)\n",
      "top_1_accuracy_test =  0.75 top_2_accuracy_test =  0.85\n",
      "Test Accuracy for subject 3:\n",
      "Loading datasets...\n",
      "Dataset loading completes.\n",
      "INFO:tensorflow:Restoring parameters from ./trained_model_final/DCNN_reg_ss_crop_step10\\model.ckpt-3801\n",
      "[test  step 3801] loss: 1.18673; top_1_accuracy: 0.67000; top_5_accuracy: 0.860000 (0.975 sec/batch; 102.611 instances/sec)\n",
      "top_1_accuracy_test =  0.67 top_2_accuracy_test =  0.86\n",
      "Test Accuracy for subject 4:\n",
      "Loading datasets...\n",
      "Dataset loading completes.\n",
      "INFO:tensorflow:Restoring parameters from ./trained_model_final/DCNN_reg_ss_crop_step10\\model.ckpt-3801\n",
      "[test  step 3801] loss: 1.21394; top_1_accuracy: 0.65957; top_5_accuracy: 0.872340 (0.870 sec/batch; 108.007 instances/sec)\n",
      "top_1_accuracy_test =  0.65957445 top_2_accuracy_test =  0.87234044\n",
      "Test Accuracy for subject 5:\n",
      "Loading datasets...\n",
      "Dataset loading completes.\n",
      "INFO:tensorflow:Restoring parameters from ./trained_model_final/DCNN_reg_ss_crop_step10\\model.ckpt-3801\n",
      "[test  step 3801] loss: 1.55872; top_1_accuracy: 0.50000; top_5_accuracy: 0.765306 (0.898 sec/batch; 109.084 instances/sec)\n",
      "top_1_accuracy_test =  0.5 top_2_accuracy_test =  0.7653061\n",
      "Test Accuracy for subject 6:\n",
      "Loading datasets...\n",
      "Dataset loading completes.\n",
      "INFO:tensorflow:Restoring parameters from ./trained_model_final/DCNN_reg_ss_crop_step10\\model.ckpt-3801\n",
      "[test  step 3801] loss: 1.09949; top_1_accuracy: 0.73000; top_5_accuracy: 0.890000 (0.919 sec/batch; 108.772 instances/sec)\n",
      "top_1_accuracy_test =  0.73 top_2_accuracy_test =  0.89\n",
      "Test Accuracy for subject 7:\n",
      "Loading datasets...\n",
      "Dataset loading completes.\n",
      "INFO:tensorflow:Restoring parameters from ./trained_model_final/DCNN_reg_ss_crop_step10\\model.ckpt-3801\n",
      "[test  step 3801] loss: 1.18511; top_1_accuracy: 0.71000; top_5_accuracy: 0.880000 (0.923 sec/batch; 108.289 instances/sec)\n",
      "top_1_accuracy_test =  0.71 top_2_accuracy_test =  0.88\n",
      "Test Accuracy for subject 8:\n",
      "Loading datasets...\n",
      "Dataset loading completes.\n",
      "INFO:tensorflow:Restoring parameters from ./trained_model_final/DCNN_reg_ss_crop_step10\\model.ckpt-3801\n",
      "[test  step 3801] loss: 1.11018; top_1_accuracy: 0.76596; top_5_accuracy: 0.893617 (0.874 sec/batch; 107.512 instances/sec)\n",
      "top_1_accuracy_test =  0.7659575 top_2_accuracy_test =  0.89361703\n",
      "Test Accuracy for all subjects:\n",
      "Loading datasets...\n",
      "Dataset loading completes.\n",
      "INFO:tensorflow:Restoring parameters from ./trained_model_final/DCNN_reg_ss_crop_step10\\model.ckpt-3801\n",
      "[test  step 3801] loss: 1.28553; top_1_accuracy: 0.64447; top_5_accuracy: 0.844244 (7.852 sec/batch; 112.840 instances/sec)\n",
      "top_1_accuracy_test =  0.6444695 top_2_accuracy_test =  0.84424376\n"
     ]
    }
   ],
   "source": [
    "# Test model accuracy on each subject\n",
    "subject_id = np.arange(10)\n",
    "start = 0\n",
    "stop = 250\n",
    "step = 10\n",
    "time_length = 700\n",
    "time_bin = 350\n",
    "#Nb = BATCH_SIZE\n",
    "fsz = 3\n",
    "use_batchnorm = True\n",
    "use_dropout = True\n",
    "use_l2loss = True\n",
    "path = 'Path_step10' \n",
    "model_dir = best_val_ss_crop[path]\n",
    "\n",
    "for sub_id in subject_id:\n",
    "    if sub_id < 9:\n",
    "        print('Test Accuracy for subject {}:'.format(sub_id))\n",
    "    else:\n",
    "        print('Test Accuracy for all subjects:')\n",
    "    top_1_acc_test, top_2_acc_test = test_model_ss_subject(sub_id,model_dir,start,stop,step,time_length,time_bin,fsz,use_batchnorm,use_dropout,use_l2loss)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading datasets...\n",
      "Dataset loading completes.\n",
      "2019-03-17 04:50:24.442240: step 0, examples 0, loss = 1.417763352 (26.709 examples/sec; 1.872 sec/batch)\n",
      "Top 1 validation accuracy: 0.1964285671710968 and top 2 validation accuracy: 0.5357142686843872\n",
      "Model Saved!\n",
      "2019-03-17 04:50:40.734476: step 10, examples 500, loss = 1.403492093 (33.738 examples/sec; 1.482 sec/batch)\n",
      "2019-03-17 04:50:55.044546: step 20, examples 1000, loss = 1.447151184 (35.359 examples/sec; 1.414 sec/batch)\n",
      "2019-03-17 04:51:09.668339: step 30, examples 1500, loss = 1.395545840 (35.337 examples/sec; 1.415 sec/batch)\n",
      "2019-03-17 04:51:24.234086: step 40, examples 2000, loss = 1.442118406 (33.865 examples/sec; 1.476 sec/batch)\n",
      "2019-03-17 04:51:39.238335: step 50, examples 2500, loss = 1.332412839 (33.684 examples/sec; 1.484 sec/batch)\n",
      "2019-03-17 04:51:54.017830: step 60, examples 3000, loss = 1.306838751 (34.138 examples/sec; 1.465 sec/batch)\n",
      "2019-03-17 04:52:08.792676: step 70, examples 3500, loss = 1.207140923 (34.329 examples/sec; 1.457 sec/batch)\n",
      "2019-03-17 04:52:23.383362: step 80, examples 4000, loss = 1.232868552 (34.650 examples/sec; 1.443 sec/batch)\n",
      "2019-03-17 04:52:38.041123: step 90, examples 4500, loss = 0.985755503 (34.249 examples/sec; 1.460 sec/batch)\n",
      "2019-03-17 04:52:53.010257: step 100, examples 5000, loss = 1.046241641 (32.604 examples/sec; 1.534 sec/batch)\n",
      "Top 1 validation accuracy: 0.3928571343421936 and top 2 validation accuracy: 0.8392857313156128\n",
      "Model Saved!\n",
      "2019-03-17 04:53:09.634944: step 110, examples 5500, loss = 0.990117013 (34.027 examples/sec; 1.469 sec/batch)\n",
      "2019-03-17 04:53:24.147225: step 120, examples 6000, loss = 0.944806516 (34.019 examples/sec; 1.470 sec/batch)\n",
      "2019-03-17 04:53:38.788739: step 130, examples 6500, loss = 0.896915436 (34.432 examples/sec; 1.452 sec/batch)\n",
      "2019-03-17 04:53:53.289242: step 140, examples 7000, loss = 1.006244540 (33.969 examples/sec; 1.472 sec/batch)\n",
      "2019-03-17 04:54:07.799240: step 150, examples 7500, loss = 0.814481378 (34.184 examples/sec; 1.463 sec/batch)\n",
      "2019-03-17 04:54:23.578134: step 160, examples 8000, loss = 0.719059467 (30.973 examples/sec; 1.614 sec/batch)\n",
      "2019-03-17 04:54:39.537312: step 170, examples 8500, loss = 0.833521307 (34.307 examples/sec; 1.457 sec/batch)\n",
      "2019-03-17 04:54:55.629233: step 180, examples 9000, loss = 0.916602314 (33.372 examples/sec; 1.498 sec/batch)\n",
      "2019-03-17 04:55:11.318535: step 190, examples 9500, loss = 0.815290987 (31.884 examples/sec; 1.568 sec/batch)\n",
      "2019-03-17 04:55:27.467478: step 200, examples 10000, loss = 0.786097527 (33.671 examples/sec; 1.485 sec/batch)\n",
      "Top 1 validation accuracy: 0.6785714030265808 and top 2 validation accuracy: 0.9464285969734192\n",
      "Model Saved!\n",
      "2019-03-17 04:55:44.704312: step 210, examples 10500, loss = 0.526097298 (31.682 examples/sec; 1.578 sec/batch)\n",
      "2019-03-17 04:55:59.521713: step 220, examples 11000, loss = 0.595694482 (33.923 examples/sec; 1.474 sec/batch)\n",
      "2019-03-17 04:56:14.912639: step 230, examples 11500, loss = 0.574033022 (31.702 examples/sec; 1.577 sec/batch)\n",
      "2019-03-17 04:56:30.365178: step 240, examples 12000, loss = 0.710857093 (29.447 examples/sec; 1.698 sec/batch)\n",
      "2019-03-17 04:56:46.391805: step 250, examples 12500, loss = 0.632040203 (32.318 examples/sec; 1.547 sec/batch)\n",
      "2019-03-17 04:57:01.825846: step 260, examples 13000, loss = 0.505988955 (32.508 examples/sec; 1.538 sec/batch)\n",
      "2019-03-17 04:57:16.800665: step 270, examples 13500, loss = 0.633464158 (34.156 examples/sec; 1.464 sec/batch)\n",
      "2019-03-17 04:57:31.724350: step 280, examples 14000, loss = 0.458034813 (33.993 examples/sec; 1.471 sec/batch)\n",
      "2019-03-17 04:57:46.655051: step 290, examples 14500, loss = 0.490551859 (33.626 examples/sec; 1.487 sec/batch)\n",
      "2019-03-17 04:58:02.040965: step 300, examples 15000, loss = 0.512877703 (31.966 examples/sec; 1.564 sec/batch)\n",
      "Top 1 validation accuracy: 0.8392857313156128 and top 2 validation accuracy: 1.0\n",
      "Model Saved!\n",
      "2019-03-17 04:58:19.904906: step 310, examples 15500, loss = 0.416767091 (31.070 examples/sec; 1.609 sec/batch)\n",
      "2019-03-17 04:58:36.125039: step 320, examples 16000, loss = 0.487121195 (27.384 examples/sec; 1.826 sec/batch)\n",
      "2019-03-17 04:58:52.623909: step 330, examples 16500, loss = 0.589962602 (28.110 examples/sec; 1.779 sec/batch)\n",
      "2019-03-17 04:59:10.192626: step 340, examples 17000, loss = 0.489184201 (31.245 examples/sec; 1.600 sec/batch)\n",
      "2019-03-17 04:59:27.200703: step 350, examples 17500, loss = 0.463493645 (28.709 examples/sec; 1.742 sec/batch)\n",
      "2019-03-17 04:59:43.905123: step 360, examples 18000, loss = 0.451400846 (30.186 examples/sec; 1.656 sec/batch)\n",
      "2019-03-17 05:00:00.743262: step 370, examples 18500, loss = 0.398424178 (27.859 examples/sec; 1.795 sec/batch)\n",
      "2019-03-17 05:00:17.493803: step 380, examples 19000, loss = 0.477906406 (29.878 examples/sec; 1.673 sec/batch)\n",
      "2019-03-17 05:00:34.199159: step 390, examples 19500, loss = 0.401342839 (32.063 examples/sec; 1.559 sec/batch)\n",
      "2019-03-17 05:00:52.093099: step 400, examples 20000, loss = 0.357063264 (28.414 examples/sec; 1.760 sec/batch)\n",
      "Top 1 validation accuracy: 0.7321428656578064 and top 2 validation accuracy: 1.0\n",
      "Model Saved!\n",
      "2019-03-17 05:01:09.627045: step 410, examples 20500, loss = 0.329515487 (32.609 examples/sec; 1.533 sec/batch)\n",
      "2019-03-17 05:01:25.782566: step 420, examples 21000, loss = 0.299191594 (32.684 examples/sec; 1.530 sec/batch)\n",
      "2019-03-17 05:01:41.727886: step 430, examples 21500, loss = 0.380106479 (31.462 examples/sec; 1.589 sec/batch)\n",
      "2019-03-17 05:01:57.517873: step 440, examples 22000, loss = 0.301350296 (32.636 examples/sec; 1.532 sec/batch)\n",
      "2019-03-17 05:02:13.185536: step 450, examples 22500, loss = 0.253353298 (32.444 examples/sec; 1.541 sec/batch)\n",
      "2019-03-17 05:02:28.826126: step 460, examples 23000, loss = 0.247102976 (31.722 examples/sec; 1.576 sec/batch)\n",
      "2019-03-17 05:02:44.566983: step 470, examples 23500, loss = 0.404722124 (31.844 examples/sec; 1.570 sec/batch)\n",
      "2019-03-17 05:03:00.169471: step 480, examples 24000, loss = 0.310305238 (32.152 examples/sec; 1.555 sec/batch)\n",
      "2019-03-17 05:03:15.774968: step 490, examples 24500, loss = 0.558866978 (32.089 examples/sec; 1.558 sec/batch)\n",
      "2019-03-17 05:03:31.472710: step 500, examples 25000, loss = 0.224665165 (32.028 examples/sec; 1.561 sec/batch)\n",
      "Top 1 validation accuracy: 0.7321428656578064 and top 2 validation accuracy: 1.0\n",
      "Model Saved!\n",
      "2019-03-17 05:03:48.911275: step 510, examples 25500, loss = 0.342687994 (32.339 examples/sec; 1.546 sec/batch)\n",
      "2019-03-17 05:04:04.797519: step 520, examples 26000, loss = 0.305263311 (32.764 examples/sec; 1.526 sec/batch)\n",
      "2019-03-17 05:04:20.410034: step 530, examples 26500, loss = 0.259785563 (32.614 examples/sec; 1.533 sec/batch)\n",
      "2019-03-17 05:04:36.471195: step 540, examples 27000, loss = 0.247451603 (32.069 examples/sec; 1.559 sec/batch)\n",
      "2019-03-17 05:04:52.045607: step 550, examples 27500, loss = 0.239382654 (31.147 examples/sec; 1.605 sec/batch)\n",
      "2019-03-17 05:05:07.674167: step 560, examples 28000, loss = 0.264365435 (32.089 examples/sec; 1.558 sec/batch)\n",
      "2019-03-17 05:05:23.671410: step 570, examples 28500, loss = 0.185632691 (30.556 examples/sec; 1.636 sec/batch)\n",
      "2019-03-17 05:05:39.735751: step 580, examples 29000, loss = 0.227791369 (32.048 examples/sec; 1.560 sec/batch)\n",
      "2019-03-17 05:05:55.658095: step 590, examples 29500, loss = 0.186555848 (30.556 examples/sec; 1.636 sec/batch)\n",
      "2019-03-17 05:06:12.396216: step 600, examples 30000, loss = 0.268457979 (30.744 examples/sec; 1.626 sec/batch)\n",
      "Top 1 validation accuracy: 0.8392857313156128 and top 2 validation accuracy: 0.9642857313156128\n",
      "Model Saved!\n",
      "2019-03-17 05:06:30.006042: step 610, examples 30500, loss = 0.343852311 (32.360 examples/sec; 1.545 sec/batch)\n",
      "2019-03-17 05:06:47.131581: step 620, examples 31000, loss = 0.279764384 (28.189 examples/sec; 1.774 sec/batch)\n",
      "2019-03-17 05:07:03.910198: step 630, examples 31500, loss = 0.282516360 (29.162 examples/sec; 1.715 sec/batch)\n",
      "2019-03-17 05:07:20.787075: step 640, examples 32000, loss = 0.166403040 (30.935 examples/sec; 1.616 sec/batch)\n",
      "2019-03-17 05:07:37.716091: step 650, examples 32500, loss = 0.181006193 (30.820 examples/sec; 1.622 sec/batch)\n",
      "2019-03-17 05:07:54.050526: step 660, examples 33000, loss = 0.232036218 (32.256 examples/sec; 1.550 sec/batch)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2019-03-17 05:08:10.512300: step 670, examples 33500, loss = 0.260676026 (30.954 examples/sec; 1.615 sec/batch)\n",
      "2019-03-17 05:08:27.190650: step 680, examples 34000, loss = 0.198391914 (28.992 examples/sec; 1.725 sec/batch)\n",
      "2019-03-17 05:08:44.920800: step 690, examples 34500, loss = 0.186069474 (29.043 examples/sec; 1.722 sec/batch)\n",
      "2019-03-17 05:09:01.343468: step 700, examples 35000, loss = 0.195424736 (31.343 examples/sec; 1.595 sec/batch)\n",
      "Top 1 validation accuracy: 0.875 and top 2 validation accuracy: 0.9821428656578064\n",
      "Model Saved!\n",
      "2019-03-17 05:09:19.478689: step 710, examples 35500, loss = 0.147241458 (31.186 examples/sec; 1.603 sec/batch)\n",
      "2019-03-17 05:09:35.621615: step 720, examples 36000, loss = 0.142259017 (30.518 examples/sec; 1.638 sec/batch)\n",
      "2019-03-17 05:09:52.041276: step 730, examples 36500, loss = 0.168194547 (31.884 examples/sec; 1.568 sec/batch)\n",
      "2019-03-17 05:10:08.106997: step 740, examples 37000, loss = 0.142008677 (32.981 examples/sec; 1.516 sec/batch)\n",
      "2019-03-17 05:10:23.954136: step 750, examples 37500, loss = 0.196170673 (31.070 examples/sec; 1.609 sec/batch)\n",
      "2019-03-17 05:10:39.657894: step 760, examples 38000, loss = 0.128009856 (32.131 examples/sec; 1.556 sec/batch)\n",
      "2019-03-17 05:10:55.326559: step 770, examples 38500, loss = 0.167130306 (31.702 examples/sec; 1.577 sec/batch)\n",
      "2019-03-17 05:11:13.382574: step 780, examples 39000, loss = 0.125713393 (26.218 examples/sec; 1.907 sec/batch)\n",
      "2019-03-17 05:11:31.311246: step 790, examples 39500, loss = 0.132269755 (28.301 examples/sec; 1.767 sec/batch)\n",
      "2019-03-17 05:11:48.670912: step 800, examples 40000, loss = 0.128582776 (32.466 examples/sec; 1.540 sec/batch)\n",
      "Top 1 validation accuracy: 0.8392857313156128 and top 2 validation accuracy: 0.9821428656578064\n",
      "Model Saved!\n",
      "2019-03-17 05:12:06.461219: step 810, examples 40500, loss = 0.158625394 (28.626 examples/sec; 1.747 sec/batch)\n",
      "2019-03-17 05:12:23.583750: step 820, examples 41000, loss = 0.131887212 (30.575 examples/sec; 1.635 sec/batch)\n",
      "2019-03-17 05:12:40.452606: step 830, examples 41500, loss = 0.125098005 (32.152 examples/sec; 1.555 sec/batch)\n",
      "2019-03-17 05:12:57.952140: step 840, examples 42000, loss = 0.112471625 (29.771 examples/sec; 1.679 sec/batch)\n",
      "2019-03-17 05:13:14.909231: step 850, examples 42500, loss = 0.138618484 (31.502 examples/sec; 1.587 sec/batch)\n",
      "2019-03-17 05:13:31.887377: step 860, examples 43000, loss = 0.143954158 (31.245 examples/sec; 1.600 sec/batch)\n",
      "2019-03-17 05:13:48.942729: step 870, examples 43500, loss = 0.121335194 (31.304 examples/sec; 1.597 sec/batch)\n",
      "2019-03-17 05:14:05.001432: step 880, examples 44000, loss = 0.155080542 (30.763 examples/sec; 1.625 sec/batch)\n",
      "2019-03-17 05:14:22.307450: step 890, examples 44500, loss = 0.146917745 (28.825 examples/sec; 1.735 sec/batch)\n",
      "2019-03-17 05:14:38.934663: step 900, examples 45000, loss = 0.111793868 (31.284 examples/sec; 1.598 sec/batch)\n",
      "Top 1 validation accuracy: 0.8214285969734192 and top 2 validation accuracy: 0.9821428656578064\n",
      "Model Saved!\n",
      "2019-03-17 05:14:56.727981: step 910, examples 45500, loss = 0.139844000 (28.841 examples/sec; 1.734 sec/batch)\n",
      "2019-03-17 05:15:13.755256: step 920, examples 46000, loss = 0.167259902 (26.067 examples/sec; 1.918 sec/batch)\n",
      "2019-03-17 05:15:29.981402: step 930, examples 46500, loss = 0.133465663 (29.145 examples/sec; 1.716 sec/batch)\n",
      "2019-03-17 05:15:46.551463: step 940, examples 47000, loss = 0.139355749 (31.031 examples/sec; 1.611 sec/batch)\n",
      "2019-03-17 05:16:02.689376: step 950, examples 47500, loss = 0.139571175 (29.968 examples/sec; 1.668 sec/batch)\n",
      "2019-03-17 05:16:19.803886: step 960, examples 48000, loss = 0.119510442 (29.334 examples/sec; 1.705 sec/batch)\n",
      "2019-03-17 05:16:37.992252: step 970, examples 48500, loss = 0.133581668 (27.505 examples/sec; 1.818 sec/batch)\n",
      "2019-03-17 05:16:54.994461: step 980, examples 49000, loss = 0.166823596 (30.241 examples/sec; 1.653 sec/batch)\n",
      "2019-03-17 05:17:11.433174: step 990, examples 49500, loss = 0.153385207 (30.801 examples/sec; 1.623 sec/batch)\n",
      "Top 1 validation accuracy: 0.8928571343421936 and top 2 validation accuracy: 0.9821428656578064\n",
      "Model Saved!\n",
      "Loading datasets...\n",
      "Dataset loading completes.\n",
      "2019-03-17 05:17:32.959414: step 0, examples 0, loss = 1.414331198 (25.731 examples/sec; 1.943 sec/batch)\n",
      "Top 1 validation accuracy: 0.38461539149284363 and top 2 validation accuracy: 0.6538461446762085\n",
      "Model Saved!\n",
      "2019-03-17 05:17:50.727662: step 10, examples 500, loss = 1.417460322 (32.214 examples/sec; 1.552 sec/batch)\n",
      "2019-03-17 05:18:06.636966: step 20, examples 1000, loss = 1.411609769 (30.954 examples/sec; 1.615 sec/batch)\n",
      "2019-03-17 05:18:23.695327: step 30, examples 1500, loss = 1.417130113 (26.469 examples/sec; 1.889 sec/batch)\n",
      "2019-03-17 05:18:40.492993: step 40, examples 2000, loss = 1.405558825 (29.179 examples/sec; 1.714 sec/batch)\n",
      "2019-03-17 05:18:56.827428: step 50, examples 2500, loss = 1.411407948 (30.241 examples/sec; 1.653 sec/batch)\n",
      "2019-03-17 05:19:13.549896: step 60, examples 3000, loss = 1.317083955 (31.324 examples/sec; 1.596 sec/batch)\n",
      "2019-03-17 05:19:30.508992: step 70, examples 3500, loss = 1.447931409 (31.050 examples/sec; 1.610 sec/batch)\n",
      "2019-03-17 05:19:47.635534: step 80, examples 4000, loss = 1.289845228 (27.235 examples/sec; 1.836 sec/batch)\n",
      "2019-03-17 05:20:05.224234: step 90, examples 4500, loss = 1.304041386 (28.883 examples/sec; 1.731 sec/batch)\n",
      "2019-03-17 05:20:21.737263: step 100, examples 5000, loss = 1.225678205 (30.131 examples/sec; 1.659 sec/batch)\n",
      "Top 1 validation accuracy: 0.3461538553237915 and top 2 validation accuracy: 0.6153846383094788\n",
      "Model Saved!\n",
      "2019-03-17 05:20:40.172284: step 110, examples 5500, loss = 1.304832578 (27.673 examples/sec; 1.807 sec/batch)\n",
      "2019-03-17 05:20:56.964938: step 120, examples 6000, loss = 1.301205635 (31.541 examples/sec; 1.585 sec/batch)\n",
      "2019-03-17 05:21:14.462466: step 130, examples 6500, loss = 1.391546249 (29.542 examples/sec; 1.693 sec/batch)\n",
      "2019-03-17 05:21:30.966352: step 140, examples 7000, loss = 1.145474553 (30.095 examples/sec; 1.661 sec/batch)\n",
      "2019-03-17 05:21:47.620637: step 150, examples 7500, loss = 1.102753758 (29.843 examples/sec; 1.675 sec/batch)\n",
      "2019-03-17 05:22:04.281942: step 160, examples 8000, loss = 1.159978151 (30.481 examples/sec; 1.640 sec/batch)\n",
      "2019-03-17 05:22:20.985358: step 170, examples 8500, loss = 1.186574101 (29.077 examples/sec; 1.720 sec/batch)\n",
      "2019-03-17 05:22:36.994928: step 180, examples 9000, loss = 1.135522962 (31.343 examples/sec; 1.595 sec/batch)\n",
      "2019-03-17 05:22:52.779902: step 190, examples 9500, loss = 1.114385843 (31.621 examples/sec; 1.581 sec/batch)\n",
      "2019-03-17 05:23:08.760397: step 200, examples 10000, loss = 1.138400078 (31.722 examples/sec; 1.576 sec/batch)\n",
      "Top 1 validation accuracy: 0.36538460850715637 and top 2 validation accuracy: 0.6346153616905212\n",
      "Model Saved!\n",
      "2019-03-17 05:23:26.274970: step 210, examples 10500, loss = 1.135251522 (32.423 examples/sec; 1.542 sec/batch)\n",
      "2019-03-17 05:23:42.044904: step 220, examples 11000, loss = 1.109042406 (32.048 examples/sec; 1.560 sec/batch)\n",
      "2019-03-17 05:23:57.974262: step 230, examples 11500, loss = 1.146969914 (32.339 examples/sec; 1.546 sec/batch)\n",
      "2019-03-17 05:24:13.474479: step 240, examples 12000, loss = 1.027957797 (32.172 examples/sec; 1.554 sec/batch)\n",
      "2019-03-17 05:24:30.043537: step 250, examples 12500, loss = 1.011260509 (31.662 examples/sec; 1.579 sec/batch)\n",
      "2019-03-17 05:24:45.861317: step 260, examples 13000, loss = 1.146266460 (32.256 examples/sec; 1.550 sec/batch)\n",
      "2019-03-17 05:25:01.792681: step 270, examples 13500, loss = 0.907866657 (32.508 examples/sec; 1.538 sec/batch)\n",
      "2019-03-17 05:25:17.537104: step 280, examples 14000, loss = 0.898009837 (32.796 examples/sec; 1.525 sec/batch)\n",
      "2019-03-17 05:25:33.281894: step 290, examples 14500, loss = 0.919709563 (31.682 examples/sec; 1.578 sec/batch)\n",
      "2019-03-17 05:25:49.138056: step 300, examples 15000, loss = 0.830986381 (31.502 examples/sec; 1.587 sec/batch)\n",
      "Top 1 validation accuracy: 0.38461539149284363 and top 2 validation accuracy: 0.692307710647583\n",
      "Model Saved!\n",
      "2019-03-17 05:26:06.198423: step 310, examples 15500, loss = 0.915716112 (31.803 examples/sec; 1.572 sec/batch)\n",
      "2019-03-17 05:26:21.737743: step 320, examples 16000, loss = 0.753050447 (31.905 examples/sec; 1.567 sec/batch)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2019-03-17 05:26:37.621987: step 330, examples 16500, loss = 0.760827601 (31.245 examples/sec; 1.600 sec/batch)\n",
      "2019-03-17 05:26:53.476146: step 340, examples 17000, loss = 0.693723857 (32.256 examples/sec; 1.550 sec/batch)\n",
      "2019-03-17 05:27:10.169537: step 350, examples 17500, loss = 0.793175459 (28.610 examples/sec; 1.748 sec/batch)\n",
      "2019-03-17 05:27:25.788757: step 360, examples 18000, loss = 0.592938900 (33.849 examples/sec; 1.477 sec/batch)\n",
      "2019-03-17 05:27:41.035116: step 370, examples 18500, loss = 0.752324879 (34.337 examples/sec; 1.456 sec/batch)\n",
      "2019-03-17 05:27:56.297102: step 380, examples 19000, loss = 0.631281078 (33.376 examples/sec; 1.498 sec/batch)\n",
      "2019-03-17 05:28:11.294026: step 390, examples 19500, loss = 0.838423550 (33.732 examples/sec; 1.482 sec/batch)\n",
      "2019-03-17 05:28:26.628588: step 400, examples 20000, loss = 0.686273873 (32.999 examples/sec; 1.515 sec/batch)\n",
      "Top 1 validation accuracy: 0.5192307829856873 and top 2 validation accuracy: 0.7884615659713745\n",
      "Model Saved!\n",
      "2019-03-17 05:28:43.460743: step 410, examples 20500, loss = 0.536100626 (33.621 examples/sec; 1.487 sec/batch)\n",
      "2019-03-17 05:28:58.461318: step 420, examples 21000, loss = 0.726888776 (32.920 examples/sec; 1.519 sec/batch)\n",
      "2019-03-17 05:29:13.534199: step 430, examples 21500, loss = 0.537685096 (33.658 examples/sec; 1.486 sec/batch)\n",
      "2019-03-17 05:29:28.537540: step 440, examples 22000, loss = 0.570460379 (33.635 examples/sec; 1.487 sec/batch)\n",
      "2019-03-17 05:29:43.524281: step 450, examples 22500, loss = 0.568790138 (32.551 examples/sec; 1.536 sec/batch)\n",
      "2019-03-17 05:29:58.855502: step 460, examples 23000, loss = 0.744492531 (32.643 examples/sec; 1.532 sec/batch)\n",
      "2019-03-17 05:30:14.004885: step 470, examples 23500, loss = 0.485779285 (33.674 examples/sec; 1.485 sec/batch)\n",
      "2019-03-17 05:30:29.082350: step 480, examples 24000, loss = 0.568952560 (33.393 examples/sec; 1.497 sec/batch)\n",
      "2019-03-17 05:30:44.180550: step 490, examples 24500, loss = 0.399682164 (34.220 examples/sec; 1.461 sec/batch)\n",
      "2019-03-17 05:30:59.114903: step 500, examples 25000, loss = 0.417930722 (33.758 examples/sec; 1.481 sec/batch)\n",
      "Top 1 validation accuracy: 0.5192307829856873 and top 2 validation accuracy: 0.75\n",
      "Model Saved!\n",
      "2019-03-17 05:31:15.871303: step 510, examples 25500, loss = 0.439852029 (33.413 examples/sec; 1.496 sec/batch)\n",
      "2019-03-17 05:31:30.916920: step 520, examples 26000, loss = 0.479128569 (33.730 examples/sec; 1.482 sec/batch)\n",
      "2019-03-17 05:31:46.061420: step 530, examples 26500, loss = 0.410372764 (32.597 examples/sec; 1.534 sec/batch)\n",
      "2019-03-17 05:32:01.134873: step 540, examples 27000, loss = 0.465876013 (32.888 examples/sec; 1.520 sec/batch)\n",
      "2019-03-17 05:32:16.131765: step 550, examples 27500, loss = 0.484544873 (33.648 examples/sec; 1.486 sec/batch)\n",
      "2019-03-17 05:32:31.123991: step 560, examples 28000, loss = 0.413481712 (32.856 examples/sec; 1.522 sec/batch)\n",
      "2019-03-17 05:32:46.428311: step 570, examples 28500, loss = 0.427847564 (33.742 examples/sec; 1.482 sec/batch)\n",
      "2019-03-17 05:33:01.377818: step 580, examples 29000, loss = 0.284969777 (33.480 examples/sec; 1.493 sec/batch)\n",
      "2019-03-17 05:33:16.514999: step 590, examples 29500, loss = 0.358963311 (33.739 examples/sec; 1.482 sec/batch)\n",
      "2019-03-17 05:33:31.888866: step 600, examples 30000, loss = 0.320097417 (30.861 examples/sec; 1.620 sec/batch)\n",
      "Top 1 validation accuracy: 0.48076921701431274 and top 2 validation accuracy: 0.8846153616905212\n",
      "Model Saved!\n",
      "2019-03-17 05:33:48.948854: step 610, examples 30500, loss = 0.350798786 (33.239 examples/sec; 1.504 sec/batch)\n",
      "2019-03-17 05:34:03.968956: step 620, examples 31000, loss = 0.346788585 (33.219 examples/sec; 1.505 sec/batch)\n",
      "2019-03-17 05:34:19.517437: step 630, examples 31500, loss = 0.391913503 (31.827 examples/sec; 1.571 sec/batch)\n",
      "2019-03-17 05:34:34.735144: step 640, examples 32000, loss = 0.311505288 (31.885 examples/sec; 1.568 sec/batch)\n",
      "2019-03-17 05:34:49.445150: step 650, examples 32500, loss = 0.342222214 (34.078 examples/sec; 1.467 sec/batch)\n",
      "2019-03-17 05:35:04.139814: step 660, examples 33000, loss = 0.237753570 (33.846 examples/sec; 1.477 sec/batch)\n",
      "2019-03-17 05:35:18.880238: step 670, examples 33500, loss = 0.297251672 (33.932 examples/sec; 1.474 sec/batch)\n",
      "2019-03-17 05:35:33.445544: step 680, examples 34000, loss = 0.277579546 (34.681 examples/sec; 1.442 sec/batch)\n",
      "2019-03-17 05:35:48.003608: step 690, examples 34500, loss = 0.288408548 (34.226 examples/sec; 1.461 sec/batch)\n",
      "2019-03-17 05:36:02.628718: step 700, examples 35000, loss = 0.293090999 (33.736 examples/sec; 1.482 sec/batch)\n",
      "Top 1 validation accuracy: 0.4615384638309479 and top 2 validation accuracy: 0.8653846383094788\n",
      "Model Saved!\n",
      "2019-03-17 05:36:18.990044: step 710, examples 35500, loss = 0.319367796 (34.907 examples/sec; 1.432 sec/batch)\n",
      "2019-03-17 05:36:33.664046: step 720, examples 36000, loss = 0.285314173 (33.488 examples/sec; 1.493 sec/batch)\n",
      "2019-03-17 05:36:48.213605: step 730, examples 36500, loss = 0.259726286 (34.047 examples/sec; 1.469 sec/batch)\n",
      "2019-03-17 05:37:02.833773: step 740, examples 37000, loss = 0.243607998 (34.547 examples/sec; 1.447 sec/batch)\n",
      "2019-03-17 05:37:17.329674: step 750, examples 37500, loss = 0.247596487 (34.369 examples/sec; 1.455 sec/batch)\n",
      "2019-03-17 05:37:31.895117: step 760, examples 38000, loss = 0.206460610 (34.289 examples/sec; 1.458 sec/batch)\n",
      "2019-03-17 05:37:46.734635: step 770, examples 38500, loss = 0.211530983 (33.219 examples/sec; 1.505 sec/batch)\n",
      "2019-03-17 05:38:01.232190: step 780, examples 39000, loss = 0.252258092 (33.575 examples/sec; 1.489 sec/batch)\n",
      "2019-03-17 05:38:15.826567: step 790, examples 39500, loss = 0.208667934 (34.930 examples/sec; 1.431 sec/batch)\n",
      "2019-03-17 05:38:30.462434: step 800, examples 40000, loss = 0.206571624 (33.812 examples/sec; 1.479 sec/batch)\n",
      "Top 1 validation accuracy: 0.5192307829856873 and top 2 validation accuracy: 0.8461538553237915\n",
      "Model Saved!\n",
      "2019-03-17 05:38:46.581073: step 810, examples 40500, loss = 0.193871647 (34.532 examples/sec; 1.448 sec/batch)\n",
      "2019-03-17 05:39:01.225153: step 820, examples 41000, loss = 0.197984949 (34.548 examples/sec; 1.447 sec/batch)\n",
      "2019-03-17 05:39:15.874530: step 830, examples 41500, loss = 0.218762353 (33.657 examples/sec; 1.486 sec/batch)\n",
      "2019-03-17 05:39:30.432627: step 840, examples 42000, loss = 0.222772300 (34.590 examples/sec; 1.446 sec/batch)\n",
      "2019-03-17 05:39:45.118291: step 850, examples 42500, loss = 0.250250667 (33.102 examples/sec; 1.510 sec/batch)\n",
      "2019-03-17 05:40:00.096261: step 860, examples 43000, loss = 0.263165742 (33.024 examples/sec; 1.514 sec/batch)\n",
      "2019-03-17 05:40:14.593189: step 870, examples 43500, loss = 0.200153068 (34.535 examples/sec; 1.448 sec/batch)\n",
      "2019-03-17 05:40:29.198891: step 880, examples 44000, loss = 0.183271989 (34.802 examples/sec; 1.437 sec/batch)\n",
      "2019-03-17 05:40:43.899263: step 890, examples 44500, loss = 0.271840841 (33.738 examples/sec; 1.482 sec/batch)\n",
      "2019-03-17 05:40:58.273552: step 900, examples 45000, loss = 0.248898163 (34.813 examples/sec; 1.436 sec/batch)\n",
      "Top 1 validation accuracy: 0.5192307829856873 and top 2 validation accuracy: 0.8653846383094788\n",
      "Model Saved!\n",
      "2019-03-17 05:41:15.069248: step 910, examples 45500, loss = 0.213301644 (30.485 examples/sec; 1.640 sec/batch)\n",
      "2019-03-17 05:41:29.815020: step 920, examples 46000, loss = 0.291814327 (35.893 examples/sec; 1.393 sec/batch)\n",
      "2019-03-17 05:41:44.857795: step 930, examples 46500, loss = 0.246220842 (32.205 examples/sec; 1.553 sec/batch)\n",
      "2019-03-17 05:41:59.405139: step 940, examples 47000, loss = 0.175137654 (34.694 examples/sec; 1.441 sec/batch)\n",
      "2019-03-17 05:42:14.622373: step 950, examples 47500, loss = 0.165943086 (32.706 examples/sec; 1.529 sec/batch)\n",
      "2019-03-17 05:42:29.563103: step 960, examples 48000, loss = 0.179268211 (33.468 examples/sec; 1.494 sec/batch)\n",
      "2019-03-17 05:42:44.464728: step 970, examples 48500, loss = 0.206301600 (33.808 examples/sec; 1.479 sec/batch)\n",
      "2019-03-17 05:42:59.338279: step 980, examples 49000, loss = 0.175459459 (34.062 examples/sec; 1.468 sec/batch)\n",
      "2019-03-17 05:43:14.100532: step 990, examples 49500, loss = 0.189344406 (33.762 examples/sec; 1.481 sec/batch)\n",
      "Top 1 validation accuracy: 0.48076921701431274 and top 2 validation accuracy: 0.8846153616905212\n",
      "Model Saved!\n",
      "Loading datasets...\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dataset loading completes.\n",
      "2019-03-17 05:43:33.313042: step 0, examples 0, loss = 1.418010473 (28.513 examples/sec; 1.754 sec/batch)\n",
      "Top 1 validation accuracy: 0.1315789520740509 and top 2 validation accuracy: 0.42105263471603394\n",
      "Model Saved!\n",
      "2019-03-17 05:43:50.200381: step 10, examples 500, loss = 1.432673931 (33.965 examples/sec; 1.472 sec/batch)\n",
      "2019-03-17 05:44:05.294719: step 20, examples 1000, loss = 1.379699707 (32.944 examples/sec; 1.518 sec/batch)\n",
      "2019-03-17 05:44:20.336285: step 30, examples 1500, loss = 1.392725825 (33.435 examples/sec; 1.495 sec/batch)\n",
      "2019-03-17 05:44:35.515121: step 40, examples 2000, loss = 1.366487861 (32.823 examples/sec; 1.523 sec/batch)\n",
      "2019-03-17 05:44:50.561916: step 50, examples 2500, loss = 1.368790507 (33.000 examples/sec; 1.515 sec/batch)\n",
      "2019-03-17 05:45:05.631634: step 60, examples 3000, loss = 1.259562373 (32.490 examples/sec; 1.539 sec/batch)\n",
      "2019-03-17 05:45:20.726678: step 70, examples 3500, loss = 1.276532531 (32.404 examples/sec; 1.543 sec/batch)\n",
      "2019-03-17 05:45:36.004481: step 80, examples 4000, loss = 1.182771802 (32.729 examples/sec; 1.528 sec/batch)\n",
      "2019-03-17 05:45:51.228059: step 90, examples 4500, loss = 1.268613338 (32.582 examples/sec; 1.535 sec/batch)\n",
      "2019-03-17 05:46:06.254361: step 100, examples 5000, loss = 1.214753270 (33.382 examples/sec; 1.498 sec/batch)\n",
      "Top 1 validation accuracy: 0.34210526943206787 and top 2 validation accuracy: 0.5263158082962036\n",
      "Model Saved!\n",
      "2019-03-17 05:46:22.801495: step 110, examples 5500, loss = 1.099845767 (32.752 examples/sec; 1.527 sec/batch)\n",
      "2019-03-17 05:46:37.462725: step 120, examples 6000, loss = 1.070517421 (34.650 examples/sec; 1.443 sec/batch)\n",
      "2019-03-17 05:46:52.113276: step 130, examples 6500, loss = 1.189853668 (34.449 examples/sec; 1.451 sec/batch)\n",
      "2019-03-17 05:47:06.788194: step 140, examples 7000, loss = 1.057272077 (35.071 examples/sec; 1.426 sec/batch)\n",
      "2019-03-17 05:47:21.352561: step 150, examples 7500, loss = 0.980208158 (35.451 examples/sec; 1.410 sec/batch)\n",
      "2019-03-17 05:47:35.988772: step 160, examples 8000, loss = 0.897498906 (32.751 examples/sec; 1.527 sec/batch)\n",
      "2019-03-17 05:47:50.742318: step 170, examples 8500, loss = 0.946375608 (33.601 examples/sec; 1.488 sec/batch)\n",
      "2019-03-17 05:48:05.364298: step 180, examples 9000, loss = 0.900614202 (34.540 examples/sec; 1.448 sec/batch)\n",
      "2019-03-17 05:48:20.004247: step 190, examples 9500, loss = 0.956916809 (34.594 examples/sec; 1.445 sec/batch)\n",
      "2019-03-17 05:48:34.587442: step 200, examples 10000, loss = 0.877336919 (34.511 examples/sec; 1.449 sec/batch)\n",
      "Top 1 validation accuracy: 0.7368420958518982 and top 2 validation accuracy: 0.8157894611358643\n",
      "Model Saved!\n",
      "2019-03-17 05:48:50.605326: step 210, examples 10500, loss = 0.811089754 (33.495 examples/sec; 1.493 sec/batch)\n",
      "2019-03-17 05:49:05.161798: step 220, examples 11000, loss = 0.656764984 (33.330 examples/sec; 1.500 sec/batch)\n",
      "2019-03-17 05:49:19.670546: step 230, examples 11500, loss = 0.654864371 (34.527 examples/sec; 1.448 sec/batch)\n",
      "2019-03-17 05:49:34.098399: step 240, examples 12000, loss = 0.753434718 (34.431 examples/sec; 1.452 sec/batch)\n",
      "2019-03-17 05:49:48.693597: step 250, examples 12500, loss = 0.768211722 (34.143 examples/sec; 1.464 sec/batch)\n",
      "2019-03-17 05:50:03.321378: step 260, examples 13000, loss = 0.575408340 (35.248 examples/sec; 1.419 sec/batch)\n",
      "2019-03-17 05:50:17.977901: step 270, examples 13500, loss = 0.729695678 (33.206 examples/sec; 1.506 sec/batch)\n",
      "2019-03-17 05:50:32.701730: step 280, examples 14000, loss = 0.546486855 (35.237 examples/sec; 1.419 sec/batch)\n",
      "2019-03-17 05:50:47.445380: step 290, examples 14500, loss = 0.469939619 (34.653 examples/sec; 1.443 sec/batch)\n",
      "2019-03-17 05:51:01.814177: step 300, examples 15000, loss = 0.563806117 (35.124 examples/sec; 1.424 sec/batch)\n",
      "Top 1 validation accuracy: 0.7368420958518982 and top 2 validation accuracy: 0.9473684430122375\n",
      "Model Saved!\n",
      "2019-03-17 05:51:17.907834: step 310, examples 15500, loss = 0.576281488 (35.004 examples/sec; 1.428 sec/batch)\n",
      "2019-03-17 05:51:32.987269: step 320, examples 16000, loss = 0.493274033 (32.293 examples/sec; 1.548 sec/batch)\n",
      "2019-03-17 05:51:47.747010: step 330, examples 16500, loss = 0.444363624 (34.559 examples/sec; 1.447 sec/batch)\n",
      "2019-03-17 05:52:02.227997: step 340, examples 17000, loss = 0.483010799 (34.895 examples/sec; 1.433 sec/batch)\n",
      "2019-03-17 05:52:16.801571: step 350, examples 17500, loss = 0.503729522 (33.570 examples/sec; 1.489 sec/batch)\n",
      "2019-03-17 05:52:31.313915: step 360, examples 18000, loss = 0.371966064 (34.358 examples/sec; 1.455 sec/batch)\n",
      "2019-03-17 05:52:45.824553: step 370, examples 18500, loss = 0.293921113 (33.564 examples/sec; 1.490 sec/batch)\n",
      "2019-03-17 05:53:00.389370: step 380, examples 19000, loss = 0.266591281 (34.604 examples/sec; 1.445 sec/batch)\n",
      "2019-03-17 05:53:14.988675: step 390, examples 19500, loss = 0.332343340 (33.061 examples/sec; 1.512 sec/batch)\n",
      "2019-03-17 05:53:29.566448: step 400, examples 20000, loss = 0.261689335 (33.938 examples/sec; 1.473 sec/batch)\n",
      "Top 1 validation accuracy: 0.7631579041481018 and top 2 validation accuracy: 0.9473684430122375\n",
      "Model Saved!\n",
      "2019-03-17 05:53:45.559175: step 410, examples 20500, loss = 0.250913739 (34.810 examples/sec; 1.436 sec/batch)\n",
      "2019-03-17 05:53:59.973821: step 420, examples 21000, loss = 0.227828279 (35.695 examples/sec; 1.401 sec/batch)\n",
      "2019-03-17 05:54:14.431907: step 430, examples 21500, loss = 0.239306673 (34.645 examples/sec; 1.443 sec/batch)\n",
      "2019-03-17 05:54:28.946136: step 440, examples 22000, loss = 0.315656155 (34.495 examples/sec; 1.449 sec/batch)\n",
      "2019-03-17 05:54:43.408714: step 450, examples 22500, loss = 0.338826925 (33.094 examples/sec; 1.511 sec/batch)\n",
      "2019-03-17 05:54:58.053904: step 460, examples 23000, loss = 0.276325345 (33.332 examples/sec; 1.500 sec/batch)\n",
      "2019-03-17 05:55:12.512170: step 470, examples 23500, loss = 0.293686688 (33.500 examples/sec; 1.493 sec/batch)\n",
      "2019-03-17 05:55:27.020322: step 480, examples 24000, loss = 0.221015707 (35.241 examples/sec; 1.419 sec/batch)\n",
      "2019-03-17 05:55:41.493880: step 490, examples 24500, loss = 0.240659863 (34.655 examples/sec; 1.443 sec/batch)\n",
      "2019-03-17 05:55:56.179423: step 500, examples 25000, loss = 0.251711190 (34.381 examples/sec; 1.454 sec/batch)\n",
      "Top 1 validation accuracy: 0.7368420958518982 and top 2 validation accuracy: 0.8947368264198303\n",
      "Model Saved!\n",
      "2019-03-17 05:56:12.199771: step 510, examples 25500, loss = 0.175776973 (34.206 examples/sec; 1.462 sec/batch)\n",
      "2019-03-17 05:56:26.801047: step 520, examples 26000, loss = 0.241079956 (33.735 examples/sec; 1.482 sec/batch)\n",
      "2019-03-17 05:56:41.445427: step 530, examples 26500, loss = 0.228245512 (33.972 examples/sec; 1.472 sec/batch)\n",
      "2019-03-17 05:56:56.344245: step 540, examples 27000, loss = 0.197682053 (29.609 examples/sec; 1.689 sec/batch)\n",
      "2019-03-17 05:57:12.268415: step 550, examples 27500, loss = 0.212438241 (34.556 examples/sec; 1.447 sec/batch)\n",
      "2019-03-17 05:57:26.931132: step 560, examples 28000, loss = 0.200065315 (34.047 examples/sec; 1.469 sec/batch)\n",
      "2019-03-17 05:57:41.564351: step 570, examples 28500, loss = 0.205762148 (35.139 examples/sec; 1.423 sec/batch)\n",
      "2019-03-17 05:57:56.170848: step 580, examples 29000, loss = 0.140782714 (34.899 examples/sec; 1.433 sec/batch)\n",
      "2019-03-17 05:58:10.744018: step 590, examples 29500, loss = 0.179168865 (34.123 examples/sec; 1.465 sec/batch)\n",
      "2019-03-17 05:58:25.347292: step 600, examples 30000, loss = 0.177534401 (33.927 examples/sec; 1.474 sec/batch)\n",
      "Top 1 validation accuracy: 0.7894737124443054 and top 2 validation accuracy: 0.9210526347160339\n",
      "Model Saved!\n",
      "2019-03-17 05:58:41.646515: step 610, examples 30500, loss = 0.177935243 (33.062 examples/sec; 1.512 sec/batch)\n",
      "2019-03-17 05:58:56.213227: step 620, examples 31000, loss = 0.161615878 (33.983 examples/sec; 1.471 sec/batch)\n",
      "2019-03-17 05:59:10.729071: step 630, examples 31500, loss = 0.141810164 (34.459 examples/sec; 1.451 sec/batch)\n",
      "2019-03-17 05:59:25.282413: step 640, examples 32000, loss = 0.122323543 (34.941 examples/sec; 1.431 sec/batch)\n",
      "2019-03-17 05:59:39.934486: step 650, examples 32500, loss = 0.151432037 (34.748 examples/sec; 1.439 sec/batch)\n",
      "2019-03-17 05:59:54.622405: step 660, examples 33000, loss = 0.148804322 (34.371 examples/sec; 1.455 sec/batch)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2019-03-17 06:00:09.145718: step 670, examples 33500, loss = 0.208801553 (35.040 examples/sec; 1.427 sec/batch)\n",
      "2019-03-17 06:00:23.759183: step 680, examples 34000, loss = 0.142767638 (33.957 examples/sec; 1.472 sec/batch)\n",
      "2019-03-17 06:00:38.389274: step 690, examples 34500, loss = 0.144345030 (34.432 examples/sec; 1.452 sec/batch)\n",
      "2019-03-17 06:00:52.915850: step 700, examples 35000, loss = 0.142970651 (34.357 examples/sec; 1.455 sec/batch)\n",
      "Top 1 validation accuracy: 0.7631579041481018 and top 2 validation accuracy: 0.9736841917037964\n",
      "Model Saved!\n",
      "2019-03-17 06:01:09.133530: step 710, examples 35500, loss = 0.119792417 (32.810 examples/sec; 1.524 sec/batch)\n",
      "2019-03-17 06:01:23.873935: step 720, examples 36000, loss = 0.121464707 (34.521 examples/sec; 1.448 sec/batch)\n",
      "2019-03-17 06:01:38.354915: step 730, examples 36500, loss = 0.181981415 (34.118 examples/sec; 1.466 sec/batch)\n",
      "2019-03-17 06:01:53.003995: step 740, examples 37000, loss = 0.135681972 (33.571 examples/sec; 1.489 sec/batch)\n",
      "2019-03-17 06:02:07.781195: step 750, examples 37500, loss = 0.126599208 (32.244 examples/sec; 1.551 sec/batch)\n",
      "2019-03-17 06:02:22.745991: step 760, examples 38000, loss = 0.121037930 (34.507 examples/sec; 1.449 sec/batch)\n",
      "2019-03-17 06:02:37.281720: step 770, examples 38500, loss = 0.145609766 (35.122 examples/sec; 1.424 sec/batch)\n",
      "2019-03-17 06:02:51.845314: step 780, examples 39000, loss = 0.124489740 (33.978 examples/sec; 1.472 sec/batch)\n",
      "2019-03-17 06:03:06.358877: step 790, examples 39500, loss = 0.112156600 (34.458 examples/sec; 1.451 sec/batch)\n",
      "2019-03-17 06:03:20.950385: step 800, examples 40000, loss = 0.123916984 (34.944 examples/sec; 1.431 sec/batch)\n",
      "Top 1 validation accuracy: 0.7105262875556946 and top 2 validation accuracy: 0.9210526347160339\n",
      "Model Saved!\n",
      "2019-03-17 06:03:37.043955: step 810, examples 40500, loss = 0.092569202 (33.715 examples/sec; 1.483 sec/batch)\n",
      "2019-03-17 06:03:51.564871: step 820, examples 41000, loss = 0.171734944 (34.087 examples/sec; 1.467 sec/batch)\n",
      "2019-03-17 06:04:06.078704: step 830, examples 41500, loss = 0.184029624 (35.372 examples/sec; 1.414 sec/batch)\n",
      "2019-03-17 06:04:20.677820: step 840, examples 42000, loss = 0.127130762 (35.153 examples/sec; 1.422 sec/batch)\n",
      "2019-03-17 06:04:35.127902: step 850, examples 42500, loss = 0.132301897 (34.818 examples/sec; 1.436 sec/batch)\n",
      "2019-03-17 06:04:49.537392: step 860, examples 43000, loss = 0.120783404 (33.487 examples/sec; 1.493 sec/batch)\n",
      "2019-03-17 06:05:04.152256: step 870, examples 43500, loss = 0.132580295 (34.945 examples/sec; 1.431 sec/batch)\n",
      "2019-03-17 06:05:18.681028: step 880, examples 44000, loss = 0.132158324 (33.602 examples/sec; 1.488 sec/batch)\n",
      "2019-03-17 06:05:33.566744: step 890, examples 44500, loss = 0.109730490 (34.930 examples/sec; 1.431 sec/batch)\n",
      "2019-03-17 06:05:48.251034: step 900, examples 45000, loss = 0.091818549 (33.751 examples/sec; 1.481 sec/batch)\n",
      "Top 1 validation accuracy: 0.7105262875556946 and top 2 validation accuracy: 0.9736841917037964\n",
      "Model Saved!\n",
      "2019-03-17 06:06:04.208461: step 910, examples 45500, loss = 0.113387257 (34.372 examples/sec; 1.455 sec/batch)\n",
      "2019-03-17 06:06:18.643340: step 920, examples 46000, loss = 0.128351822 (34.105 examples/sec; 1.466 sec/batch)\n",
      "2019-03-17 06:06:33.145078: step 930, examples 46500, loss = 0.171988621 (33.802 examples/sec; 1.479 sec/batch)\n",
      "2019-03-17 06:06:47.627809: step 940, examples 47000, loss = 0.116104513 (34.527 examples/sec; 1.448 sec/batch)\n",
      "2019-03-17 06:07:02.191587: step 950, examples 47500, loss = 0.091799997 (34.488 examples/sec; 1.450 sec/batch)\n",
      "2019-03-17 06:07:16.726482: step 960, examples 48000, loss = 0.123596191 (34.383 examples/sec; 1.454 sec/batch)\n",
      "2019-03-17 06:07:31.143942: step 970, examples 48500, loss = 0.120280907 (33.738 examples/sec; 1.482 sec/batch)\n",
      "2019-03-17 06:07:46.237915: step 980, examples 49000, loss = 0.139428481 (34.059 examples/sec; 1.468 sec/batch)\n",
      "2019-03-17 06:08:00.715113: step 990, examples 49500, loss = 0.102273919 (33.706 examples/sec; 1.483 sec/batch)\n",
      "Top 1 validation accuracy: 0.6842105388641357 and top 2 validation accuracy: 0.8947368264198303\n",
      "Model Saved!\n",
      "Loading datasets...\n",
      "Dataset loading completes.\n",
      "2019-03-17 06:08:19.639444: step 0, examples 0, loss = 1.419677258 (28.478 examples/sec; 1.756 sec/batch)\n",
      "Top 1 validation accuracy: 0.2750000059604645 and top 2 validation accuracy: 0.5\n",
      "Model Saved!\n",
      "2019-03-17 06:08:35.677656: step 10, examples 500, loss = 1.445638776 (35.124 examples/sec; 1.424 sec/batch)\n",
      "2019-03-17 06:08:50.170497: step 20, examples 1000, loss = 1.418799281 (34.423 examples/sec; 1.453 sec/batch)\n",
      "2019-03-17 06:09:04.728166: step 30, examples 1500, loss = 1.404553652 (34.305 examples/sec; 1.457 sec/batch)\n",
      "2019-03-17 06:09:19.219235: step 40, examples 2000, loss = 1.392123699 (34.149 examples/sec; 1.464 sec/batch)\n",
      "2019-03-17 06:09:33.839190: step 50, examples 2500, loss = 1.346282959 (33.757 examples/sec; 1.481 sec/batch)\n",
      "2019-03-17 06:09:48.387152: step 60, examples 3000, loss = 1.349925160 (34.842 examples/sec; 1.435 sec/batch)\n",
      "2019-03-17 06:10:02.915005: step 70, examples 3500, loss = 1.378321052 (34.395 examples/sec; 1.454 sec/batch)\n",
      "2019-03-17 06:10:17.493897: step 80, examples 4000, loss = 1.291389227 (33.890 examples/sec; 1.475 sec/batch)\n",
      "2019-03-17 06:10:31.934958: step 90, examples 4500, loss = 1.376257896 (35.207 examples/sec; 1.420 sec/batch)\n",
      "2019-03-17 06:10:46.318378: step 100, examples 5000, loss = 1.083527565 (34.020 examples/sec; 1.470 sec/batch)\n",
      "Top 1 validation accuracy: 0.15000000596046448 and top 2 validation accuracy: 0.6000000238418579\n",
      "Model Saved!\n",
      "2019-03-17 06:11:02.162460: step 110, examples 5500, loss = 1.205926180 (34.452 examples/sec; 1.451 sec/batch)\n",
      "2019-03-17 06:11:16.661925: step 120, examples 6000, loss = 1.084040523 (35.725 examples/sec; 1.400 sec/batch)\n",
      "2019-03-17 06:11:31.240763: step 130, examples 6500, loss = 1.176062346 (33.990 examples/sec; 1.471 sec/batch)\n",
      "2019-03-17 06:11:45.847947: step 140, examples 7000, loss = 1.074426293 (34.195 examples/sec; 1.462 sec/batch)\n",
      "2019-03-17 06:12:00.314759: step 150, examples 7500, loss = 0.913745701 (34.110 examples/sec; 1.466 sec/batch)\n",
      "2019-03-17 06:12:14.858835: step 160, examples 8000, loss = 0.921603739 (32.852 examples/sec; 1.522 sec/batch)\n",
      "2019-03-17 06:12:29.815854: step 170, examples 8500, loss = 0.875408113 (35.493 examples/sec; 1.409 sec/batch)\n",
      "2019-03-17 06:12:44.296668: step 180, examples 9000, loss = 1.034302115 (34.737 examples/sec; 1.439 sec/batch)\n",
      "2019-03-17 06:12:58.819916: step 190, examples 9500, loss = 0.862849832 (35.431 examples/sec; 1.411 sec/batch)\n",
      "2019-03-17 06:13:13.196097: step 200, examples 10000, loss = 0.919234335 (35.530 examples/sec; 1.407 sec/batch)\n",
      "Top 1 validation accuracy: 0.3499999940395355 and top 2 validation accuracy: 0.6000000238418579\n",
      "Model Saved!\n",
      "2019-03-17 06:13:29.293876: step 210, examples 10500, loss = 0.985544026 (34.943 examples/sec; 1.431 sec/batch)\n",
      "2019-03-17 06:13:43.704890: step 220, examples 11000, loss = 0.863750100 (33.767 examples/sec; 1.481 sec/batch)\n",
      "2019-03-17 06:13:58.318798: step 230, examples 11500, loss = 0.995986879 (34.336 examples/sec; 1.456 sec/batch)\n",
      "2019-03-17 06:14:12.929699: step 240, examples 12000, loss = 0.988170087 (34.571 examples/sec; 1.446 sec/batch)\n",
      "2019-03-17 06:14:27.381395: step 250, examples 12500, loss = 1.232344508 (33.944 examples/sec; 1.473 sec/batch)\n",
      "2019-03-17 06:14:41.935043: step 260, examples 13000, loss = 0.759667933 (33.951 examples/sec; 1.473 sec/batch)\n",
      "2019-03-17 06:14:56.462143: step 270, examples 13500, loss = 0.542399764 (33.927 examples/sec; 1.474 sec/batch)\n",
      "2019-03-17 06:15:10.753445: step 280, examples 14000, loss = 0.658411443 (35.289 examples/sec; 1.417 sec/batch)\n",
      "2019-03-17 06:15:25.262541: step 290, examples 14500, loss = 0.772105813 (34.295 examples/sec; 1.458 sec/batch)\n",
      "2019-03-17 06:15:39.527552: step 300, examples 15000, loss = 0.756260812 (34.712 examples/sec; 1.440 sec/batch)\n",
      "Top 1 validation accuracy: 0.4000000059604645 and top 2 validation accuracy: 0.675000011920929\n",
      "Model Saved!\n",
      "2019-03-17 06:15:55.641190: step 310, examples 15500, loss = 0.762439549 (34.016 examples/sec; 1.470 sec/batch)\n",
      "2019-03-17 06:16:10.111349: step 320, examples 16000, loss = 0.674700320 (34.545 examples/sec; 1.447 sec/batch)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2019-03-17 06:16:24.565125: step 330, examples 16500, loss = 0.594646633 (34.329 examples/sec; 1.456 sec/batch)\n",
      "2019-03-17 06:16:39.053195: step 340, examples 17000, loss = 0.634353220 (34.740 examples/sec; 1.439 sec/batch)\n",
      "2019-03-17 06:16:53.608034: step 350, examples 17500, loss = 0.634532034 (34.190 examples/sec; 1.462 sec/batch)\n",
      "2019-03-17 06:17:08.544874: step 360, examples 18000, loss = 0.705592453 (33.952 examples/sec; 1.473 sec/batch)\n",
      "2019-03-17 06:17:23.366132: step 370, examples 18500, loss = 0.519808173 (35.850 examples/sec; 1.395 sec/batch)\n",
      "2019-03-17 06:17:37.988570: step 380, examples 19000, loss = 0.703158915 (34.464 examples/sec; 1.451 sec/batch)\n",
      "2019-03-17 06:17:52.520679: step 390, examples 19500, loss = 0.664602041 (32.623 examples/sec; 1.533 sec/batch)\n",
      "2019-03-17 06:18:07.035521: step 400, examples 20000, loss = 0.660885096 (34.407 examples/sec; 1.453 sec/batch)\n",
      "Top 1 validation accuracy: 0.4749999940395355 and top 2 validation accuracy: 0.675000011920929\n",
      "Model Saved!\n",
      "2019-03-17 06:18:22.903860: step 410, examples 20500, loss = 0.622940719 (34.857 examples/sec; 1.434 sec/batch)\n",
      "2019-03-17 06:18:37.319410: step 420, examples 21000, loss = 0.478047460 (35.275 examples/sec; 1.417 sec/batch)\n",
      "2019-03-17 06:18:52.019951: step 430, examples 21500, loss = 0.492697150 (33.717 examples/sec; 1.483 sec/batch)\n",
      "2019-03-17 06:19:06.498281: step 440, examples 22000, loss = 0.428351015 (35.042 examples/sec; 1.427 sec/batch)\n",
      "2019-03-17 06:19:21.050092: step 450, examples 22500, loss = 0.456860930 (33.765 examples/sec; 1.481 sec/batch)\n",
      "2019-03-17 06:19:35.537387: step 460, examples 23000, loss = 0.473161042 (34.387 examples/sec; 1.454 sec/batch)\n",
      "2019-03-17 06:19:50.020393: step 470, examples 23500, loss = 0.472521037 (35.956 examples/sec; 1.391 sec/batch)\n",
      "2019-03-17 06:20:04.464390: step 480, examples 24000, loss = 0.381035805 (34.666 examples/sec; 1.442 sec/batch)\n",
      "2019-03-17 06:20:19.139109: step 490, examples 24500, loss = 0.442428887 (33.351 examples/sec; 1.499 sec/batch)\n",
      "2019-03-17 06:20:33.722642: step 500, examples 25000, loss = 0.395959109 (32.221 examples/sec; 1.552 sec/batch)\n",
      "Top 1 validation accuracy: 0.44999998807907104 and top 2 validation accuracy: 0.6499999761581421\n",
      "Model Saved!\n",
      "2019-03-17 06:20:49.627368: step 510, examples 25500, loss = 0.516358554 (33.754 examples/sec; 1.481 sec/batch)\n",
      "2019-03-17 06:21:04.130964: step 520, examples 26000, loss = 0.434272259 (34.780 examples/sec; 1.438 sec/batch)\n",
      "2019-03-17 06:21:18.624876: step 530, examples 26500, loss = 0.451625168 (34.385 examples/sec; 1.454 sec/batch)\n",
      "2019-03-17 06:21:33.036422: step 540, examples 27000, loss = 0.340331674 (35.523 examples/sec; 1.408 sec/batch)\n",
      "2019-03-17 06:21:47.694577: step 550, examples 27500, loss = 0.295724303 (34.273 examples/sec; 1.459 sec/batch)\n",
      "2019-03-17 06:22:02.319156: step 560, examples 28000, loss = 0.330025554 (34.938 examples/sec; 1.431 sec/batch)\n",
      "2019-03-17 06:22:17.007842: step 570, examples 28500, loss = 0.290840834 (35.025 examples/sec; 1.428 sec/batch)\n",
      "2019-03-17 06:22:31.537210: step 580, examples 29000, loss = 0.332738727 (35.125 examples/sec; 1.423 sec/batch)\n",
      "2019-03-17 06:22:46.075226: step 590, examples 29500, loss = 0.308981389 (34.787 examples/sec; 1.437 sec/batch)\n",
      "2019-03-17 06:23:00.476907: step 600, examples 30000, loss = 0.304449826 (34.643 examples/sec; 1.443 sec/batch)\n",
      "Top 1 validation accuracy: 0.42500001192092896 and top 2 validation accuracy: 0.675000011920929\n",
      "Model Saved!\n",
      "2019-03-17 06:23:16.430153: step 610, examples 30500, loss = 0.271008313 (33.477 examples/sec; 1.494 sec/batch)\n",
      "2019-03-17 06:23:30.919561: step 620, examples 31000, loss = 0.289338082 (33.844 examples/sec; 1.477 sec/batch)\n",
      "2019-03-17 06:23:45.444735: step 630, examples 31500, loss = 0.275233060 (32.455 examples/sec; 1.541 sec/batch)\n",
      "2019-03-17 06:23:59.973598: step 640, examples 32000, loss = 0.246377125 (34.806 examples/sec; 1.437 sec/batch)\n",
      "2019-03-17 06:24:14.473841: step 650, examples 32500, loss = 0.280509233 (34.733 examples/sec; 1.440 sec/batch)\n",
      "2019-03-17 06:24:28.889318: step 660, examples 33000, loss = 0.265104055 (35.380 examples/sec; 1.413 sec/batch)\n",
      "2019-03-17 06:24:43.431982: step 670, examples 33500, loss = 0.288882166 (35.399 examples/sec; 1.412 sec/batch)\n",
      "2019-03-17 06:24:58.052503: step 680, examples 34000, loss = 0.270785630 (34.996 examples/sec; 1.429 sec/batch)\n",
      "2019-03-17 06:25:12.525395: step 690, examples 34500, loss = 0.247407392 (35.526 examples/sec; 1.407 sec/batch)\n",
      "2019-03-17 06:25:27.118661: step 700, examples 35000, loss = 0.223798230 (34.530 examples/sec; 1.448 sec/batch)\n",
      "Top 1 validation accuracy: 0.44999998807907104 and top 2 validation accuracy: 0.800000011920929\n",
      "Model Saved!\n",
      "2019-03-17 06:25:43.237631: step 710, examples 35500, loss = 0.252260596 (34.606 examples/sec; 1.445 sec/batch)\n",
      "2019-03-17 06:25:57.726307: step 720, examples 36000, loss = 0.234316826 (34.628 examples/sec; 1.444 sec/batch)\n",
      "2019-03-17 06:26:12.165095: step 730, examples 36500, loss = 0.218111575 (35.032 examples/sec; 1.427 sec/batch)\n",
      "2019-03-17 06:26:26.678736: step 740, examples 37000, loss = 0.224706188 (34.866 examples/sec; 1.434 sec/batch)\n",
      "2019-03-17 06:26:41.231574: step 750, examples 37500, loss = 0.214032844 (33.223 examples/sec; 1.505 sec/batch)\n",
      "2019-03-17 06:26:55.742233: step 760, examples 38000, loss = 0.252155244 (34.449 examples/sec; 1.451 sec/batch)\n",
      "2019-03-17 06:27:10.300446: step 770, examples 38500, loss = 0.220888227 (34.073 examples/sec; 1.467 sec/batch)\n",
      "2019-03-17 06:27:24.993281: step 780, examples 39000, loss = 0.205396369 (35.020 examples/sec; 1.428 sec/batch)\n",
      "2019-03-17 06:27:39.324829: step 790, examples 39500, loss = 0.195296705 (36.027 examples/sec; 1.388 sec/batch)\n",
      "2019-03-17 06:27:53.834848: step 800, examples 40000, loss = 0.194519565 (34.228 examples/sec; 1.461 sec/batch)\n",
      "Top 1 validation accuracy: 0.4000000059604645 and top 2 validation accuracy: 0.675000011920929\n",
      "Model Saved!\n",
      "2019-03-17 06:28:09.818836: step 810, examples 40500, loss = 0.176478475 (34.992 examples/sec; 1.429 sec/batch)\n",
      "2019-03-17 06:28:24.321851: step 820, examples 41000, loss = 0.214937598 (34.908 examples/sec; 1.432 sec/batch)\n",
      "2019-03-17 06:28:38.901197: step 830, examples 41500, loss = 0.225708306 (34.284 examples/sec; 1.458 sec/batch)\n",
      "2019-03-17 06:28:53.336185: step 840, examples 42000, loss = 0.188218057 (34.635 examples/sec; 1.444 sec/batch)\n",
      "2019-03-17 06:29:07.726456: step 850, examples 42500, loss = 0.160693407 (34.812 examples/sec; 1.436 sec/batch)\n",
      "2019-03-17 06:29:22.269295: step 860, examples 43000, loss = 0.225456044 (33.741 examples/sec; 1.482 sec/batch)\n",
      "2019-03-17 06:29:36.662288: step 870, examples 43500, loss = 0.153425455 (34.828 examples/sec; 1.436 sec/batch)\n",
      "2019-03-17 06:29:51.250099: step 880, examples 44000, loss = 0.166360915 (33.535 examples/sec; 1.491 sec/batch)\n",
      "2019-03-17 06:30:05.737778: step 890, examples 44500, loss = 0.222607091 (34.451 examples/sec; 1.451 sec/batch)\n",
      "2019-03-17 06:30:20.115883: step 900, examples 45000, loss = 0.150189534 (34.031 examples/sec; 1.469 sec/batch)\n",
      "Top 1 validation accuracy: 0.4000000059604645 and top 2 validation accuracy: 0.7749999761581421\n",
      "Model Saved!\n",
      "2019-03-17 06:30:36.112775: step 910, examples 45500, loss = 0.140694335 (34.611 examples/sec; 1.445 sec/batch)\n",
      "2019-03-17 06:30:50.655891: step 920, examples 46000, loss = 0.197502464 (35.470 examples/sec; 1.410 sec/batch)\n",
      "2019-03-17 06:31:05.336601: step 930, examples 46500, loss = 0.250913203 (33.918 examples/sec; 1.474 sec/batch)\n",
      "2019-03-17 06:31:19.858143: step 940, examples 47000, loss = 0.166918278 (34.064 examples/sec; 1.468 sec/batch)\n",
      "2019-03-17 06:31:34.399329: step 950, examples 47500, loss = 0.166165337 (34.685 examples/sec; 1.442 sec/batch)\n",
      "2019-03-17 06:31:48.962512: step 960, examples 48000, loss = 0.194866404 (35.102 examples/sec; 1.424 sec/batch)\n",
      "2019-03-17 06:32:03.418789: step 970, examples 48500, loss = 0.172230855 (34.945 examples/sec; 1.431 sec/batch)\n",
      "2019-03-17 06:32:17.901975: step 980, examples 49000, loss = 0.167111889 (33.548 examples/sec; 1.490 sec/batch)\n",
      "2019-03-17 06:32:32.387738: step 990, examples 49500, loss = 0.138947308 (34.962 examples/sec; 1.430 sec/batch)\n",
      "Top 1 validation accuracy: 0.375 and top 2 validation accuracy: 0.824999988079071\n",
      "Model Saved!\n",
      "Loading datasets...\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dataset loading completes.\n",
      "2019-03-17 06:32:51.336758: step 0, examples 0, loss = 1.420453191 (27.786 examples/sec; 1.799 sec/batch)\n",
      "Top 1 validation accuracy: 0.25 and top 2 validation accuracy: 0.5\n",
      "Model Saved!\n",
      "2019-03-17 06:33:07.677897: step 10, examples 500, loss = 1.412018299 (34.654 examples/sec; 1.443 sec/batch)\n",
      "2019-03-17 06:33:22.088621: step 20, examples 1000, loss = 1.401161432 (33.573 examples/sec; 1.489 sec/batch)\n",
      "2019-03-17 06:33:36.522690: step 30, examples 1500, loss = 1.272984862 (34.570 examples/sec; 1.446 sec/batch)\n",
      "2019-03-17 06:33:51.126636: step 40, examples 2000, loss = 1.326489568 (35.402 examples/sec; 1.412 sec/batch)\n",
      "2019-03-17 06:34:05.769596: step 50, examples 2500, loss = 1.133008957 (33.333 examples/sec; 1.500 sec/batch)\n",
      "2019-03-17 06:34:20.262469: step 60, examples 3000, loss = 1.189159513 (34.697 examples/sec; 1.441 sec/batch)\n",
      "2019-03-17 06:34:34.800141: step 70, examples 3500, loss = 1.069894671 (35.211 examples/sec; 1.420 sec/batch)\n",
      "2019-03-17 06:34:49.336409: step 80, examples 4000, loss = 1.231672168 (34.691 examples/sec; 1.441 sec/batch)\n",
      "2019-03-17 06:35:03.818731: step 90, examples 4500, loss = 0.933240533 (34.230 examples/sec; 1.461 sec/batch)\n",
      "2019-03-17 06:35:18.268977: step 100, examples 5000, loss = 0.959928334 (35.446 examples/sec; 1.411 sec/batch)\n",
      "Top 1 validation accuracy: 0.5208333134651184 and top 2 validation accuracy: 0.8333333134651184\n",
      "Model Saved!\n",
      "2019-03-17 06:35:34.445361: step 110, examples 5500, loss = 0.827079356 (33.618 examples/sec; 1.487 sec/batch)\n",
      "2019-03-17 06:35:49.106338: step 120, examples 6000, loss = 0.911001027 (34.252 examples/sec; 1.460 sec/batch)\n",
      "2019-03-17 06:36:03.723064: step 130, examples 6500, loss = 0.891877770 (34.205 examples/sec; 1.462 sec/batch)\n",
      "2019-03-17 06:36:18.289352: step 140, examples 7000, loss = 0.851325631 (34.942 examples/sec; 1.431 sec/batch)\n",
      "2019-03-17 06:36:32.693393: step 150, examples 7500, loss = 0.818228304 (34.384 examples/sec; 1.454 sec/batch)\n",
      "2019-03-17 06:36:47.004670: step 160, examples 8000, loss = 0.861997962 (34.072 examples/sec; 1.467 sec/batch)\n",
      "2019-03-17 06:37:01.579699: step 170, examples 8500, loss = 0.856257975 (34.511 examples/sec; 1.449 sec/batch)\n",
      "2019-03-17 06:37:16.166728: step 180, examples 9000, loss = 0.948699415 (33.930 examples/sec; 1.474 sec/batch)\n",
      "2019-03-17 06:37:30.745322: step 190, examples 9500, loss = 0.729537785 (34.875 examples/sec; 1.434 sec/batch)\n",
      "2019-03-17 06:37:45.442436: step 200, examples 10000, loss = 0.812630415 (34.206 examples/sec; 1.462 sec/batch)\n",
      "Top 1 validation accuracy: 0.6041666865348816 and top 2 validation accuracy: 0.9166666865348816\n",
      "Model Saved!\n",
      "2019-03-17 06:38:01.560908: step 210, examples 10500, loss = 0.776693881 (34.903 examples/sec; 1.433 sec/batch)\n",
      "2019-03-17 06:38:16.093045: step 220, examples 11000, loss = 0.749556959 (34.097 examples/sec; 1.466 sec/batch)\n",
      "2019-03-17 06:38:30.719104: step 230, examples 11500, loss = 0.878550470 (34.509 examples/sec; 1.449 sec/batch)\n",
      "2019-03-17 06:38:45.313378: step 240, examples 12000, loss = 0.715770662 (33.761 examples/sec; 1.481 sec/batch)\n",
      "2019-03-17 06:38:59.935450: step 250, examples 12500, loss = 0.739104509 (33.951 examples/sec; 1.473 sec/batch)\n",
      "2019-03-17 06:39:14.571431: step 260, examples 13000, loss = 0.602212787 (34.338 examples/sec; 1.456 sec/batch)\n",
      "2019-03-17 06:39:28.901562: step 270, examples 13500, loss = 0.764393270 (34.323 examples/sec; 1.457 sec/batch)\n",
      "2019-03-17 06:39:43.384853: step 280, examples 14000, loss = 0.667363465 (33.346 examples/sec; 1.499 sec/batch)\n",
      "2019-03-17 06:39:58.086228: step 290, examples 14500, loss = 0.673043787 (33.829 examples/sec; 1.478 sec/batch)\n",
      "2019-03-17 06:40:12.641675: step 300, examples 15000, loss = 0.669997454 (34.235 examples/sec; 1.461 sec/batch)\n",
      "Top 1 validation accuracy: 0.7083333134651184 and top 2 validation accuracy: 0.875\n",
      "Model Saved!\n",
      "2019-03-17 06:40:28.785881: step 310, examples 15500, loss = 0.742408812 (35.150 examples/sec; 1.422 sec/batch)\n",
      "2019-03-17 06:40:43.284960: step 320, examples 16000, loss = 0.689308941 (34.799 examples/sec; 1.437 sec/batch)\n",
      "2019-03-17 06:40:57.693321: step 330, examples 16500, loss = 0.731704533 (34.949 examples/sec; 1.431 sec/batch)\n",
      "2019-03-17 06:41:12.165122: step 340, examples 17000, loss = 0.696724296 (34.708 examples/sec; 1.441 sec/batch)\n",
      "2019-03-17 06:41:26.677799: step 350, examples 17500, loss = 0.550156832 (34.438 examples/sec; 1.452 sec/batch)\n",
      "2019-03-17 06:41:41.692385: step 360, examples 18000, loss = 0.647264600 (34.495 examples/sec; 1.449 sec/batch)\n",
      "2019-03-17 06:41:56.314471: step 370, examples 18500, loss = 0.440488517 (34.427 examples/sec; 1.452 sec/batch)\n",
      "2019-03-17 06:42:11.129634: step 380, examples 19000, loss = 0.594439149 (32.466 examples/sec; 1.540 sec/batch)\n",
      "2019-03-17 06:42:26.402849: step 390, examples 19500, loss = 0.586229563 (32.635 examples/sec; 1.532 sec/batch)\n",
      "2019-03-17 06:42:40.902404: step 400, examples 20000, loss = 0.558888674 (33.740 examples/sec; 1.482 sec/batch)\n",
      "Top 1 validation accuracy: 0.6666666865348816 and top 2 validation accuracy: 0.8333333134651184\n",
      "Model Saved!\n",
      "2019-03-17 06:42:57.218792: step 410, examples 20500, loss = 0.480074286 (33.267 examples/sec; 1.503 sec/batch)\n",
      "2019-03-17 06:43:11.952972: step 420, examples 21000, loss = 0.397596717 (33.626 examples/sec; 1.487 sec/batch)\n",
      "2019-03-17 06:43:26.623983: step 430, examples 21500, loss = 0.502296805 (34.678 examples/sec; 1.442 sec/batch)\n",
      "2019-03-17 06:43:41.304019: step 440, examples 22000, loss = 0.587794721 (34.848 examples/sec; 1.435 sec/batch)\n",
      "2019-03-17 06:43:56.066274: step 450, examples 22500, loss = 0.565989912 (33.558 examples/sec; 1.490 sec/batch)\n",
      "2019-03-17 06:44:10.659078: step 460, examples 23000, loss = 0.514066756 (35.317 examples/sec; 1.416 sec/batch)\n",
      "2019-03-17 06:44:25.110277: step 470, examples 23500, loss = 0.407322198 (34.913 examples/sec; 1.432 sec/batch)\n",
      "2019-03-17 06:44:39.646079: step 480, examples 24000, loss = 0.335256964 (35.682 examples/sec; 1.401 sec/batch)\n",
      "2019-03-17 06:44:54.213299: step 490, examples 24500, loss = 0.307781547 (34.077 examples/sec; 1.467 sec/batch)\n",
      "2019-03-17 06:45:08.904541: step 500, examples 25000, loss = 0.380540162 (33.775 examples/sec; 1.480 sec/batch)\n",
      "Top 1 validation accuracy: 0.7083333134651184 and top 2 validation accuracy: 0.9166666865348816\n",
      "Model Saved!\n",
      "2019-03-17 06:45:25.019447: step 510, examples 25500, loss = 0.383015364 (35.216 examples/sec; 1.420 sec/batch)\n",
      "2019-03-17 06:45:39.455755: step 520, examples 26000, loss = 0.354433060 (34.068 examples/sec; 1.468 sec/batch)\n",
      "2019-03-17 06:45:54.034861: step 530, examples 26500, loss = 0.372015566 (33.942 examples/sec; 1.473 sec/batch)\n",
      "2019-03-17 06:46:08.607070: step 540, examples 27000, loss = 0.411129832 (34.184 examples/sec; 1.463 sec/batch)\n",
      "2019-03-17 06:46:23.108189: step 550, examples 27500, loss = 0.275111467 (34.644 examples/sec; 1.443 sec/batch)\n",
      "2019-03-17 06:46:37.774869: step 560, examples 28000, loss = 0.235775709 (33.916 examples/sec; 1.474 sec/batch)\n",
      "2019-03-17 06:46:52.336064: step 570, examples 28500, loss = 0.327545613 (34.727 examples/sec; 1.440 sec/batch)\n",
      "2019-03-17 06:47:06.873662: step 580, examples 29000, loss = 0.331682771 (33.972 examples/sec; 1.472 sec/batch)\n",
      "2019-03-17 06:47:21.262964: step 590, examples 29500, loss = 0.279323697 (34.743 examples/sec; 1.439 sec/batch)\n",
      "2019-03-17 06:47:35.500832: step 600, examples 30000, loss = 0.305772513 (36.534 examples/sec; 1.369 sec/batch)\n",
      "Top 1 validation accuracy: 0.6041666865348816 and top 2 validation accuracy: 0.8541666865348816\n",
      "Model Saved!\n",
      "2019-03-17 06:47:52.054009: step 610, examples 30500, loss = 0.312623709 (34.270 examples/sec; 1.459 sec/batch)\n",
      "2019-03-17 06:48:07.104391: step 620, examples 31000, loss = 0.271804839 (32.498 examples/sec; 1.539 sec/batch)\n",
      "2019-03-17 06:48:22.117964: step 630, examples 31500, loss = 0.285212398 (33.441 examples/sec; 1.495 sec/batch)\n",
      "2019-03-17 06:48:37.056086: step 640, examples 32000, loss = 0.228321552 (33.719 examples/sec; 1.483 sec/batch)\n",
      "2019-03-17 06:48:52.083900: step 650, examples 32500, loss = 0.302060038 (34.384 examples/sec; 1.454 sec/batch)\n",
      "2019-03-17 06:49:07.004760: step 660, examples 33000, loss = 0.229709715 (33.451 examples/sec; 1.495 sec/batch)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2019-03-17 06:49:22.240289: step 670, examples 33500, loss = 0.242959976 (32.264 examples/sec; 1.550 sec/batch)\n",
      "2019-03-17 06:49:37.178794: step 680, examples 34000, loss = 0.252812088 (32.356 examples/sec; 1.545 sec/batch)\n",
      "2019-03-17 06:49:52.072707: step 690, examples 34500, loss = 0.276137441 (34.283 examples/sec; 1.458 sec/batch)\n",
      "2019-03-17 06:50:07.108048: step 700, examples 35000, loss = 0.247387931 (33.334 examples/sec; 1.500 sec/batch)\n",
      "Top 1 validation accuracy: 0.7291666865348816 and top 2 validation accuracy: 0.875\n",
      "Model Saved!\n",
      "2019-03-17 06:50:23.607533: step 710, examples 35500, loss = 0.185040861 (33.989 examples/sec; 1.471 sec/batch)\n",
      "2019-03-17 06:50:38.589069: step 720, examples 36000, loss = 0.241190761 (33.349 examples/sec; 1.499 sec/batch)\n",
      "2019-03-17 06:50:53.738680: step 730, examples 36500, loss = 0.263960570 (32.864 examples/sec; 1.521 sec/batch)\n",
      "2019-03-17 06:51:08.732868: step 740, examples 37000, loss = 0.246166095 (33.923 examples/sec; 1.474 sec/batch)\n",
      "2019-03-17 06:51:23.734569: step 750, examples 37500, loss = 0.238298222 (33.464 examples/sec; 1.494 sec/batch)\n",
      "2019-03-17 06:51:38.834950: step 760, examples 38000, loss = 0.269041121 (33.368 examples/sec; 1.498 sec/batch)\n",
      "2019-03-17 06:51:53.931131: step 770, examples 38500, loss = 0.186310947 (33.618 examples/sec; 1.487 sec/batch)\n",
      "2019-03-17 06:52:08.971704: step 780, examples 39000, loss = 0.166283950 (33.083 examples/sec; 1.511 sec/batch)\n",
      "2019-03-17 06:52:24.020045: step 790, examples 39500, loss = 0.203111261 (33.657 examples/sec; 1.486 sec/batch)\n",
      "2019-03-17 06:52:38.955913: step 800, examples 40000, loss = 0.201049045 (33.290 examples/sec; 1.502 sec/batch)\n",
      "Top 1 validation accuracy: 0.6041666865348816 and top 2 validation accuracy: 0.8541666865348816\n",
      "Model Saved!\n",
      "2019-03-17 06:52:55.709983: step 810, examples 40500, loss = 0.226120248 (33.539 examples/sec; 1.491 sec/batch)\n",
      "2019-03-17 06:53:10.729816: step 820, examples 41000, loss = 0.166146263 (32.626 examples/sec; 1.533 sec/batch)\n",
      "2019-03-17 06:53:25.662045: step 830, examples 41500, loss = 0.162806764 (33.400 examples/sec; 1.497 sec/batch)\n",
      "2019-03-17 06:53:40.742556: step 840, examples 42000, loss = 0.151121438 (33.362 examples/sec; 1.499 sec/batch)\n",
      "2019-03-17 06:53:55.753839: step 850, examples 42500, loss = 0.148216099 (33.042 examples/sec; 1.513 sec/batch)\n",
      "2019-03-17 06:54:10.732032: step 860, examples 43000, loss = 0.172258079 (33.991 examples/sec; 1.471 sec/batch)\n",
      "2019-03-17 06:54:25.818705: step 870, examples 43500, loss = 0.161366001 (31.957 examples/sec; 1.565 sec/batch)\n",
      "2019-03-17 06:54:40.726243: step 880, examples 44000, loss = 0.180689901 (32.465 examples/sec; 1.540 sec/batch)\n",
      "2019-03-17 06:54:55.615815: step 890, examples 44500, loss = 0.178467050 (33.784 examples/sec; 1.480 sec/batch)\n",
      "2019-03-17 06:55:10.563756: step 900, examples 45000, loss = 0.148901507 (32.972 examples/sec; 1.516 sec/batch)\n",
      "Top 1 validation accuracy: 0.6666666865348816 and top 2 validation accuracy: 0.8541666865348816\n",
      "Model Saved!\n",
      "2019-03-17 06:55:27.004040: step 910, examples 45500, loss = 0.175196514 (33.368 examples/sec; 1.498 sec/batch)\n",
      "2019-03-17 06:55:42.043580: step 920, examples 46000, loss = 0.154519022 (33.208 examples/sec; 1.506 sec/batch)\n",
      "2019-03-17 06:55:56.997774: step 930, examples 46500, loss = 0.153864965 (34.249 examples/sec; 1.460 sec/batch)\n",
      "2019-03-17 06:56:11.950714: step 940, examples 47000, loss = 0.158602029 (33.220 examples/sec; 1.505 sec/batch)\n",
      "2019-03-17 06:56:27.017335: step 950, examples 47500, loss = 0.148426175 (32.473 examples/sec; 1.540 sec/batch)\n",
      "2019-03-17 06:56:41.889217: step 960, examples 48000, loss = 0.144565821 (34.149 examples/sec; 1.464 sec/batch)\n",
      "2019-03-17 06:56:56.939161: step 970, examples 48500, loss = 0.160744578 (33.314 examples/sec; 1.501 sec/batch)\n",
      "2019-03-17 06:57:11.972646: step 980, examples 49000, loss = 0.140493438 (33.804 examples/sec; 1.479 sec/batch)\n",
      "2019-03-17 06:57:27.050463: step 990, examples 49500, loss = 0.159839302 (33.506 examples/sec; 1.492 sec/batch)\n",
      "Top 1 validation accuracy: 0.5625 and top 2 validation accuracy: 0.7916666865348816\n",
      "Model Saved!\n",
      "Loading datasets...\n",
      "Dataset loading completes.\n",
      "2019-03-17 06:57:46.577591: step 0, examples 0, loss = 1.416238904 (26.554 examples/sec; 1.883 sec/batch)\n",
      "Top 1 validation accuracy: 0.1964285671710968 and top 2 validation accuracy: 0.4285714328289032\n",
      "Model Saved!\n",
      "2019-03-17 06:58:03.232085: step 10, examples 500, loss = 1.393511891 (34.279 examples/sec; 1.459 sec/batch)\n",
      "2019-03-17 06:58:18.219179: step 20, examples 1000, loss = 1.421739101 (33.768 examples/sec; 1.481 sec/batch)\n",
      "2019-03-17 06:58:33.296720: step 30, examples 1500, loss = 1.352700472 (33.170 examples/sec; 1.507 sec/batch)\n",
      "2019-03-17 06:58:48.133882: step 40, examples 2000, loss = 1.339504719 (34.718 examples/sec; 1.440 sec/batch)\n",
      "2019-03-17 06:59:03.133282: step 50, examples 2500, loss = 1.338238120 (32.751 examples/sec; 1.527 sec/batch)\n",
      "2019-03-17 06:59:18.066271: step 60, examples 3000, loss = 1.291669369 (33.749 examples/sec; 1.482 sec/batch)\n",
      "2019-03-17 06:59:33.021577: step 70, examples 3500, loss = 1.218904853 (33.359 examples/sec; 1.499 sec/batch)\n",
      "2019-03-17 06:59:47.989075: step 80, examples 4000, loss = 1.163584590 (34.340 examples/sec; 1.456 sec/batch)\n",
      "2019-03-17 07:00:02.951203: step 90, examples 4500, loss = 1.303445578 (33.030 examples/sec; 1.514 sec/batch)\n",
      "2019-03-17 07:00:17.988513: step 100, examples 5000, loss = 1.119309545 (32.140 examples/sec; 1.556 sec/batch)\n",
      "Top 1 validation accuracy: 0.375 and top 2 validation accuracy: 0.7321428656578064\n",
      "Model Saved!\n",
      "2019-03-17 07:00:34.727014: step 110, examples 5500, loss = 0.802437186 (34.107 examples/sec; 1.466 sec/batch)\n",
      "2019-03-17 07:00:49.644875: step 120, examples 6000, loss = 1.001259804 (33.263 examples/sec; 1.503 sec/batch)\n",
      "2019-03-17 07:01:04.520384: step 130, examples 6500, loss = 1.063803434 (32.645 examples/sec; 1.532 sec/batch)\n",
      "2019-03-17 07:01:19.492390: step 140, examples 7000, loss = 1.128669262 (33.320 examples/sec; 1.501 sec/batch)\n",
      "2019-03-17 07:01:34.553797: step 150, examples 7500, loss = 1.022627831 (33.106 examples/sec; 1.510 sec/batch)\n",
      "2019-03-17 07:01:49.627796: step 160, examples 8000, loss = 1.065900087 (33.567 examples/sec; 1.490 sec/batch)\n",
      "2019-03-17 07:02:04.669446: step 170, examples 8500, loss = 0.981363833 (33.165 examples/sec; 1.508 sec/batch)\n",
      "2019-03-17 07:02:19.625441: step 180, examples 9000, loss = 0.890521467 (33.809 examples/sec; 1.479 sec/batch)\n",
      "2019-03-17 07:02:34.445008: step 190, examples 9500, loss = 0.895284832 (34.000 examples/sec; 1.471 sec/batch)\n",
      "2019-03-17 07:02:49.445805: step 200, examples 10000, loss = 0.983267367 (33.279 examples/sec; 1.502 sec/batch)\n",
      "Top 1 validation accuracy: 0.4285714328289032 and top 2 validation accuracy: 0.7321428656578064\n",
      "Model Saved!\n",
      "2019-03-17 07:03:06.141275: step 210, examples 10500, loss = 0.936379790 (32.992 examples/sec; 1.516 sec/batch)\n",
      "2019-03-17 07:03:21.162531: step 220, examples 11000, loss = 1.184777141 (33.678 examples/sec; 1.485 sec/batch)\n",
      "2019-03-17 07:03:36.208919: step 230, examples 11500, loss = 1.046908379 (33.202 examples/sec; 1.506 sec/batch)\n",
      "2019-03-17 07:03:51.191690: step 240, examples 12000, loss = 0.648125291 (34.487 examples/sec; 1.450 sec/batch)\n",
      "2019-03-17 07:04:06.178013: step 250, examples 12500, loss = 1.034559727 (33.631 examples/sec; 1.487 sec/batch)\n",
      "2019-03-17 07:04:21.049159: step 260, examples 13000, loss = 0.772348046 (33.625 examples/sec; 1.487 sec/batch)\n",
      "2019-03-17 07:04:35.966665: step 270, examples 13500, loss = 0.866838038 (34.126 examples/sec; 1.465 sec/batch)\n",
      "2019-03-17 07:04:51.130300: step 280, examples 14000, loss = 0.677780867 (33.215 examples/sec; 1.505 sec/batch)\n",
      "2019-03-17 07:05:06.084138: step 290, examples 14500, loss = 0.738191664 (32.336 examples/sec; 1.546 sec/batch)\n",
      "2019-03-17 07:05:21.057647: step 300, examples 15000, loss = 0.841058016 (32.620 examples/sec; 1.533 sec/batch)\n",
      "Top 1 validation accuracy: 0.4464285671710968 and top 2 validation accuracy: 0.625\n",
      "Model Saved!\n",
      "2019-03-17 07:05:37.693033: step 310, examples 15500, loss = 0.678754747 (32.655 examples/sec; 1.531 sec/batch)\n",
      "2019-03-17 07:05:52.661880: step 320, examples 16000, loss = 0.775759637 (32.604 examples/sec; 1.534 sec/batch)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2019-03-17 07:06:07.570052: step 330, examples 16500, loss = 0.706148207 (33.813 examples/sec; 1.479 sec/batch)\n",
      "2019-03-17 07:06:22.588403: step 340, examples 17000, loss = 0.608687639 (33.690 examples/sec; 1.484 sec/batch)\n",
      "2019-03-17 07:06:37.495761: step 350, examples 17500, loss = 0.688454628 (33.788 examples/sec; 1.480 sec/batch)\n",
      "2019-03-17 07:06:52.465139: step 360, examples 18000, loss = 0.633916020 (33.510 examples/sec; 1.492 sec/batch)\n",
      "2019-03-17 07:07:07.443179: step 370, examples 18500, loss = 0.474327087 (33.249 examples/sec; 1.504 sec/batch)\n",
      "2019-03-17 07:07:22.358866: step 380, examples 19000, loss = 0.534408748 (34.389 examples/sec; 1.454 sec/batch)\n",
      "2019-03-17 07:07:37.281890: step 390, examples 19500, loss = 0.633835554 (34.000 examples/sec; 1.471 sec/batch)\n",
      "2019-03-17 07:07:52.378121: step 400, examples 20000, loss = 0.538189232 (33.685 examples/sec; 1.484 sec/batch)\n",
      "Top 1 validation accuracy: 0.5892857313156128 and top 2 validation accuracy: 0.7142857313156128\n",
      "Model Saved!\n",
      "2019-03-17 07:08:09.171127: step 410, examples 20500, loss = 0.508733034 (33.136 examples/sec; 1.509 sec/batch)\n",
      "2019-03-17 07:08:24.146805: step 420, examples 21000, loss = 0.501688361 (33.324 examples/sec; 1.500 sec/batch)\n",
      "2019-03-17 07:08:39.129478: step 430, examples 21500, loss = 0.610717297 (33.028 examples/sec; 1.514 sec/batch)\n",
      "2019-03-17 07:08:54.178720: step 440, examples 22000, loss = 0.472899914 (33.413 examples/sec; 1.496 sec/batch)\n",
      "2019-03-17 07:09:11.007825: step 450, examples 22500, loss = 0.559513986 (32.325 examples/sec; 1.547 sec/batch)\n",
      "2019-03-17 07:09:26.103584: step 460, examples 23000, loss = 0.521201491 (34.265 examples/sec; 1.459 sec/batch)\n",
      "2019-03-17 07:09:40.575829: step 470, examples 23500, loss = 0.406829655 (34.438 examples/sec; 1.452 sec/batch)\n",
      "2019-03-17 07:09:55.182686: step 480, examples 24000, loss = 0.384753674 (34.334 examples/sec; 1.456 sec/batch)\n",
      "2019-03-17 07:10:09.934727: step 490, examples 24500, loss = 0.353446275 (33.564 examples/sec; 1.490 sec/batch)\n",
      "2019-03-17 07:10:24.374560: step 500, examples 25000, loss = 0.486464053 (34.438 examples/sec; 1.452 sec/batch)\n",
      "Top 1 validation accuracy: 0.6071428656578064 and top 2 validation accuracy: 0.7857142686843872\n",
      "Model Saved!\n",
      "2019-03-17 07:10:40.357974: step 510, examples 25500, loss = 0.347757012 (34.024 examples/sec; 1.470 sec/batch)\n",
      "2019-03-17 07:10:54.819640: step 520, examples 26000, loss = 0.398414224 (34.700 examples/sec; 1.441 sec/batch)\n",
      "2019-03-17 07:11:09.468621: step 530, examples 26500, loss = 0.310376197 (34.166 examples/sec; 1.463 sec/batch)\n",
      "2019-03-17 07:11:24.050591: step 540, examples 27000, loss = 0.391873956 (34.585 examples/sec; 1.446 sec/batch)\n",
      "2019-03-17 07:11:38.560908: step 550, examples 27500, loss = 0.296900630 (35.560 examples/sec; 1.406 sec/batch)\n",
      "2019-03-17 07:11:53.217799: step 560, examples 28000, loss = 0.341317683 (33.536 examples/sec; 1.491 sec/batch)\n",
      "2019-03-17 07:12:07.646623: step 570, examples 28500, loss = 0.300682545 (35.193 examples/sec; 1.421 sec/batch)\n",
      "2019-03-17 07:12:22.287055: step 580, examples 29000, loss = 0.322008997 (34.996 examples/sec; 1.429 sec/batch)\n",
      "2019-03-17 07:12:36.905311: step 590, examples 29500, loss = 0.249765724 (35.714 examples/sec; 1.400 sec/batch)\n",
      "2019-03-17 07:12:51.498140: step 600, examples 30000, loss = 0.247894287 (35.303 examples/sec; 1.416 sec/batch)\n",
      "Top 1 validation accuracy: 0.5714285969734192 and top 2 validation accuracy: 0.8035714030265808\n",
      "Model Saved!\n",
      "2019-03-17 07:13:07.693027: step 610, examples 30500, loss = 0.300364524 (34.408 examples/sec; 1.453 sec/batch)\n",
      "2019-03-17 07:13:22.162261: step 620, examples 31000, loss = 0.271833360 (34.034 examples/sec; 1.469 sec/batch)\n",
      "2019-03-17 07:13:36.692456: step 630, examples 31500, loss = 0.178179100 (34.513 examples/sec; 1.449 sec/batch)\n",
      "2019-03-17 07:13:51.233437: step 640, examples 32000, loss = 0.255216569 (34.875 examples/sec; 1.434 sec/batch)\n",
      "2019-03-17 07:14:05.857011: step 650, examples 32500, loss = 0.186864376 (34.067 examples/sec; 1.468 sec/batch)\n",
      "2019-03-17 07:14:20.537109: step 660, examples 33000, loss = 0.240807921 (34.742 examples/sec; 1.439 sec/batch)\n",
      "2019-03-17 07:14:35.743656: step 670, examples 33500, loss = 0.207509190 (35.037 examples/sec; 1.427 sec/batch)\n",
      "2019-03-17 07:14:50.263038: step 680, examples 34000, loss = 0.191535085 (34.588 examples/sec; 1.446 sec/batch)\n",
      "2019-03-17 07:15:04.694445: step 690, examples 34500, loss = 0.230983406 (34.363 examples/sec; 1.455 sec/batch)\n",
      "2019-03-17 07:15:19.208961: step 700, examples 35000, loss = 0.201402947 (33.735 examples/sec; 1.482 sec/batch)\n",
      "Top 1 validation accuracy: 0.5178571343421936 and top 2 validation accuracy: 0.7678571343421936\n",
      "Model Saved!\n",
      "2019-03-17 07:15:35.409587: step 710, examples 35500, loss = 0.194998458 (34.075 examples/sec; 1.467 sec/batch)\n",
      "2019-03-17 07:15:50.004013: step 720, examples 36000, loss = 0.201826751 (35.247 examples/sec; 1.419 sec/batch)\n",
      "2019-03-17 07:16:04.530994: step 730, examples 36500, loss = 0.216269165 (35.005 examples/sec; 1.428 sec/batch)\n",
      "2019-03-17 07:16:19.054563: step 740, examples 37000, loss = 0.233960286 (34.610 examples/sec; 1.445 sec/batch)\n",
      "2019-03-17 07:16:33.478097: step 750, examples 37500, loss = 0.195184991 (33.923 examples/sec; 1.474 sec/batch)\n",
      "2019-03-17 07:16:47.835713: step 760, examples 38000, loss = 0.226974398 (35.229 examples/sec; 1.419 sec/batch)\n",
      "2019-03-17 07:17:02.400090: step 770, examples 38500, loss = 0.201056480 (34.234 examples/sec; 1.461 sec/batch)\n",
      "2019-03-17 07:17:16.948721: step 780, examples 39000, loss = 0.160515860 (34.064 examples/sec; 1.468 sec/batch)\n",
      "2019-03-17 07:17:31.336960: step 790, examples 39500, loss = 0.190431133 (34.171 examples/sec; 1.463 sec/batch)\n",
      "2019-03-17 07:17:45.769951: step 800, examples 40000, loss = 0.150469348 (34.417 examples/sec; 1.453 sec/batch)\n",
      "Top 1 validation accuracy: 0.5892857313156128 and top 2 validation accuracy: 0.8571428656578064\n",
      "Model Saved!\n",
      "2019-03-17 07:18:02.470647: step 810, examples 40500, loss = 0.196203664 (33.117 examples/sec; 1.510 sec/batch)\n",
      "2019-03-17 07:18:17.406325: step 820, examples 41000, loss = 0.162671641 (33.391 examples/sec; 1.497 sec/batch)\n",
      "2019-03-17 07:18:32.491731: step 830, examples 41500, loss = 0.180782184 (33.280 examples/sec; 1.502 sec/batch)\n",
      "2019-03-17 07:18:47.354468: step 840, examples 42000, loss = 0.219349995 (33.317 examples/sec; 1.501 sec/batch)\n",
      "2019-03-17 07:19:02.294045: step 850, examples 42500, loss = 0.184709057 (33.441 examples/sec; 1.495 sec/batch)\n",
      "2019-03-17 07:19:17.200150: step 860, examples 43000, loss = 0.199473724 (34.293 examples/sec; 1.458 sec/batch)\n",
      "2019-03-17 07:19:32.146347: step 870, examples 43500, loss = 0.207551822 (34.422 examples/sec; 1.453 sec/batch)\n",
      "2019-03-17 07:19:47.161844: step 880, examples 44000, loss = 0.140830383 (33.793 examples/sec; 1.480 sec/batch)\n",
      "2019-03-17 07:20:02.143542: step 890, examples 44500, loss = 0.169121042 (32.144 examples/sec; 1.556 sec/batch)\n",
      "2019-03-17 07:20:17.145988: step 900, examples 45000, loss = 0.154197216 (32.881 examples/sec; 1.521 sec/batch)\n",
      "Top 1 validation accuracy: 0.6071428656578064 and top 2 validation accuracy: 0.8035714030265808\n",
      "Model Saved!\n",
      "2019-03-17 07:20:33.848584: step 910, examples 45500, loss = 0.115212195 (31.550 examples/sec; 1.585 sec/batch)\n",
      "2019-03-17 07:20:48.727191: step 920, examples 46000, loss = 0.157993689 (33.015 examples/sec; 1.514 sec/batch)\n",
      "2019-03-17 07:21:03.693744: step 930, examples 46500, loss = 0.114943199 (34.350 examples/sec; 1.456 sec/batch)\n",
      "2019-03-17 07:21:18.696472: step 940, examples 47000, loss = 0.162806258 (34.124 examples/sec; 1.465 sec/batch)\n",
      "2019-03-17 07:21:33.639875: step 950, examples 47500, loss = 0.212009802 (32.886 examples/sec; 1.520 sec/batch)\n",
      "2019-03-17 07:21:48.662551: step 960, examples 48000, loss = 0.151118532 (34.462 examples/sec; 1.451 sec/batch)\n",
      "2019-03-17 07:22:03.717275: step 970, examples 48500, loss = 0.129417360 (33.704 examples/sec; 1.484 sec/batch)\n",
      "2019-03-17 07:22:18.646381: step 980, examples 49000, loss = 0.122520596 (33.328 examples/sec; 1.500 sec/batch)\n",
      "2019-03-17 07:22:33.460544: step 990, examples 49500, loss = 0.127206281 (33.313 examples/sec; 1.501 sec/batch)\n",
      "Top 1 validation accuracy: 0.6428571343421936 and top 2 validation accuracy: 0.8214285969734192\n",
      "Model Saved!\n",
      "Loading datasets...\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dataset loading completes.\n",
      "2019-03-17 07:22:52.873883: step 0, examples 0, loss = 1.425220609 (27.999 examples/sec; 1.786 sec/batch)\n",
      "Top 1 validation accuracy: 0.4117647111415863 and top 2 validation accuracy: 0.529411792755127\n",
      "Model Saved!\n",
      "2019-03-17 07:23:09.724368: step 10, examples 500, loss = 1.404115200 (33.112 examples/sec; 1.510 sec/batch)\n",
      "2019-03-17 07:23:24.688683: step 20, examples 1000, loss = 1.418889284 (33.577 examples/sec; 1.489 sec/batch)\n",
      "2019-03-17 07:23:39.537293: step 30, examples 1500, loss = 1.303700686 (34.582 examples/sec; 1.446 sec/batch)\n",
      "2019-03-17 07:23:54.576433: step 40, examples 2000, loss = 1.239197731 (33.607 examples/sec; 1.488 sec/batch)\n",
      "2019-03-17 07:24:09.612953: step 50, examples 2500, loss = 1.316057682 (33.338 examples/sec; 1.500 sec/batch)\n",
      "2019-03-17 07:24:24.571138: step 60, examples 3000, loss = 1.217170358 (33.125 examples/sec; 1.509 sec/batch)\n",
      "2019-03-17 07:24:39.608076: step 70, examples 3500, loss = 1.043883801 (33.453 examples/sec; 1.495 sec/batch)\n",
      "2019-03-17 07:24:54.638617: step 80, examples 4000, loss = 1.015676737 (33.088 examples/sec; 1.511 sec/batch)\n",
      "2019-03-17 07:25:09.537153: step 90, examples 4500, loss = 1.000586033 (33.264 examples/sec; 1.503 sec/batch)\n",
      "2019-03-17 07:25:24.537733: step 100, examples 5000, loss = 1.013653636 (32.910 examples/sec; 1.519 sec/batch)\n",
      "Top 1 validation accuracy: 0.529411792755127 and top 2 validation accuracy: 0.8235294222831726\n",
      "Model Saved!\n",
      "2019-03-17 07:25:40.957843: step 110, examples 5500, loss = 0.924862325 (33.393 examples/sec; 1.497 sec/batch)\n",
      "2019-03-17 07:25:55.847100: step 120, examples 6000, loss = 0.894834161 (33.575 examples/sec; 1.489 sec/batch)\n",
      "2019-03-17 07:26:10.833688: step 130, examples 6500, loss = 0.934945464 (33.851 examples/sec; 1.477 sec/batch)\n",
      "2019-03-17 07:26:25.827067: step 140, examples 7000, loss = 0.818927765 (33.461 examples/sec; 1.494 sec/batch)\n",
      "2019-03-17 07:26:40.801620: step 150, examples 7500, loss = 0.703827620 (33.156 examples/sec; 1.508 sec/batch)\n",
      "2019-03-17 07:26:55.925097: step 160, examples 8000, loss = 0.758833170 (32.234 examples/sec; 1.551 sec/batch)\n",
      "2019-03-17 07:27:10.879645: step 170, examples 8500, loss = 0.766571283 (33.829 examples/sec; 1.478 sec/batch)\n",
      "2019-03-17 07:27:26.333179: step 180, examples 9000, loss = 0.660106897 (33.527 examples/sec; 1.491 sec/batch)\n",
      "2019-03-17 07:27:41.120642: step 190, examples 9500, loss = 0.665326297 (33.911 examples/sec; 1.474 sec/batch)\n",
      "2019-03-17 07:27:56.156405: step 200, examples 10000, loss = 0.843407631 (33.547 examples/sec; 1.490 sec/batch)\n",
      "Top 1 validation accuracy: 0.6764705777168274 and top 2 validation accuracy: 0.8529411554336548\n",
      "Model Saved!\n",
      "2019-03-17 07:28:12.616522: step 210, examples 10500, loss = 0.666246057 (33.830 examples/sec; 1.478 sec/batch)\n",
      "2019-03-17 07:28:27.575418: step 220, examples 11000, loss = 0.625687659 (34.131 examples/sec; 1.465 sec/batch)\n",
      "2019-03-17 07:28:42.677677: step 230, examples 11500, loss = 0.714133024 (32.653 examples/sec; 1.531 sec/batch)\n",
      "2019-03-17 07:28:57.592658: step 240, examples 12000, loss = 0.561943293 (33.879 examples/sec; 1.476 sec/batch)\n",
      "2019-03-17 07:29:12.492562: step 250, examples 12500, loss = 0.520695269 (33.994 examples/sec; 1.471 sec/batch)\n",
      "2019-03-17 07:29:27.537362: step 260, examples 13000, loss = 0.572434068 (34.531 examples/sec; 1.448 sec/batch)\n",
      "2019-03-17 07:29:42.494592: step 270, examples 13500, loss = 0.633067310 (32.873 examples/sec; 1.521 sec/batch)\n",
      "2019-03-17 07:29:57.599388: step 280, examples 14000, loss = 0.578197002 (33.527 examples/sec; 1.491 sec/batch)\n",
      "2019-03-17 07:30:12.646423: step 290, examples 14500, loss = 0.692283988 (33.196 examples/sec; 1.506 sec/batch)\n",
      "2019-03-17 07:30:27.537578: step 300, examples 15000, loss = 0.510095835 (34.055 examples/sec; 1.468 sec/batch)\n",
      "Top 1 validation accuracy: 0.7352941036224365 and top 2 validation accuracy: 0.970588207244873\n",
      "Model Saved!\n",
      "2019-03-17 07:30:43.710051: step 310, examples 15500, loss = 0.365433872 (34.695 examples/sec; 1.441 sec/batch)\n",
      "2019-03-17 07:30:58.636034: step 320, examples 16000, loss = 0.445694566 (33.942 examples/sec; 1.473 sec/batch)\n",
      "2019-03-17 07:31:13.702825: step 330, examples 16500, loss = 0.328798026 (31.970 examples/sec; 1.564 sec/batch)\n",
      "2019-03-17 07:31:28.730456: step 340, examples 17000, loss = 0.408485532 (32.297 examples/sec; 1.548 sec/batch)\n",
      "2019-03-17 07:31:43.755618: step 350, examples 17500, loss = 0.434788018 (33.374 examples/sec; 1.498 sec/batch)\n",
      "2019-03-17 07:31:58.663135: step 360, examples 18000, loss = 0.336603254 (33.708 examples/sec; 1.483 sec/batch)\n",
      "2019-03-17 07:32:13.614790: step 370, examples 18500, loss = 0.406418204 (33.305 examples/sec; 1.501 sec/batch)\n",
      "2019-03-17 07:32:28.678060: step 380, examples 19000, loss = 0.344454020 (33.915 examples/sec; 1.474 sec/batch)\n",
      "2019-03-17 07:32:43.694171: step 390, examples 19500, loss = 0.360222995 (33.334 examples/sec; 1.500 sec/batch)\n",
      "2019-03-17 07:32:58.608127: step 400, examples 20000, loss = 0.350889713 (33.790 examples/sec; 1.480 sec/batch)\n",
      "Top 1 validation accuracy: 0.5882353186607361 and top 2 validation accuracy: 0.8823529481887817\n",
      "Model Saved!\n",
      "2019-03-17 07:33:15.078927: step 410, examples 20500, loss = 0.375320822 (34.503 examples/sec; 1.449 sec/batch)\n",
      "2019-03-17 07:33:30.035610: step 420, examples 21000, loss = 0.254638880 (34.500 examples/sec; 1.449 sec/batch)\n",
      "2019-03-17 07:33:45.041079: step 430, examples 21500, loss = 0.412224561 (32.517 examples/sec; 1.538 sec/batch)\n",
      "2019-03-17 07:34:00.087189: step 440, examples 22000, loss = 0.261364907 (33.414 examples/sec; 1.496 sec/batch)\n",
      "2019-03-17 07:34:15.093980: step 450, examples 22500, loss = 0.285570234 (32.569 examples/sec; 1.535 sec/batch)\n",
      "2019-03-17 07:34:29.988051: step 460, examples 23000, loss = 0.222938582 (33.430 examples/sec; 1.496 sec/batch)\n",
      "2019-03-17 07:34:45.012712: step 470, examples 23500, loss = 0.257137746 (33.618 examples/sec; 1.487 sec/batch)\n",
      "2019-03-17 07:34:59.904028: step 480, examples 24000, loss = 0.270801902 (33.803 examples/sec; 1.479 sec/batch)\n",
      "2019-03-17 07:35:14.817638: step 490, examples 24500, loss = 0.357404232 (33.760 examples/sec; 1.481 sec/batch)\n",
      "2019-03-17 07:35:29.752459: step 500, examples 25000, loss = 0.304385185 (32.023 examples/sec; 1.561 sec/batch)\n",
      "Top 1 validation accuracy: 0.6176470518112183 and top 2 validation accuracy: 0.8823529481887817\n",
      "Model Saved!\n",
      "2019-03-17 07:35:46.184451: step 510, examples 25500, loss = 0.285068154 (32.503 examples/sec; 1.538 sec/batch)\n",
      "2019-03-17 07:36:00.767042: step 520, examples 26000, loss = 0.204069048 (33.867 examples/sec; 1.476 sec/batch)\n",
      "2019-03-17 07:36:15.333717: step 530, examples 26500, loss = 0.178143173 (34.423 examples/sec; 1.453 sec/batch)\n",
      "2019-03-17 07:36:29.818979: step 540, examples 27000, loss = 0.218578473 (35.311 examples/sec; 1.416 sec/batch)\n",
      "2019-03-17 07:36:44.259066: step 550, examples 27500, loss = 0.148360565 (34.037 examples/sec; 1.469 sec/batch)\n",
      "2019-03-17 07:36:58.756302: step 560, examples 28000, loss = 0.193392426 (35.090 examples/sec; 1.425 sec/batch)\n",
      "2019-03-17 07:37:13.318120: step 570, examples 28500, loss = 0.192822546 (34.248 examples/sec; 1.460 sec/batch)\n",
      "2019-03-17 07:37:27.962487: step 580, examples 29000, loss = 0.176344737 (34.628 examples/sec; 1.444 sec/batch)\n",
      "2019-03-17 07:37:42.442753: step 590, examples 29500, loss = 0.178821534 (35.155 examples/sec; 1.422 sec/batch)\n",
      "2019-03-17 07:37:57.116226: step 600, examples 30000, loss = 0.173488036 (35.236 examples/sec; 1.419 sec/batch)\n",
      "Top 1 validation accuracy: 0.7647058963775635 and top 2 validation accuracy: 0.9411764740943909\n",
      "Model Saved!\n",
      "2019-03-17 07:38:13.461156: step 610, examples 30500, loss = 0.211416706 (33.459 examples/sec; 1.494 sec/batch)\n",
      "2019-03-17 07:38:28.460693: step 620, examples 31000, loss = 0.223566309 (32.902 examples/sec; 1.520 sec/batch)\n",
      "2019-03-17 07:38:43.463110: step 630, examples 31500, loss = 0.183007374 (33.914 examples/sec; 1.474 sec/batch)\n",
      "2019-03-17 07:38:58.518438: step 640, examples 32000, loss = 0.181051716 (33.225 examples/sec; 1.505 sec/batch)\n",
      "2019-03-17 07:39:13.567538: step 650, examples 32500, loss = 0.232274577 (31.843 examples/sec; 1.570 sec/batch)\n",
      "2019-03-17 07:39:28.824561: step 660, examples 33000, loss = 0.139544874 (31.373 examples/sec; 1.594 sec/batch)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2019-03-17 07:39:44.060038: step 670, examples 33500, loss = 0.167407289 (32.602 examples/sec; 1.534 sec/batch)\n",
      "2019-03-17 07:39:59.086485: step 680, examples 34000, loss = 0.153026521 (32.275 examples/sec; 1.549 sec/batch)\n",
      "2019-03-17 07:40:14.146055: step 690, examples 34500, loss = 0.156714767 (32.910 examples/sec; 1.519 sec/batch)\n",
      "2019-03-17 07:40:29.259264: step 700, examples 35000, loss = 0.186934531 (33.365 examples/sec; 1.499 sec/batch)\n",
      "Top 1 validation accuracy: 0.7352941036224365 and top 2 validation accuracy: 0.9411764740943909\n",
      "Model Saved!\n",
      "2019-03-17 07:40:45.809144: step 710, examples 35500, loss = 0.174202695 (33.956 examples/sec; 1.472 sec/batch)\n",
      "2019-03-17 07:41:00.699057: step 720, examples 36000, loss = 0.162357569 (33.829 examples/sec; 1.478 sec/batch)\n",
      "2019-03-17 07:41:15.677369: step 730, examples 36500, loss = 0.154429421 (34.486 examples/sec; 1.450 sec/batch)\n",
      "2019-03-17 07:41:30.620043: step 740, examples 37000, loss = 0.121656634 (33.669 examples/sec; 1.485 sec/batch)\n",
      "2019-03-17 07:41:46.045053: step 750, examples 37500, loss = 0.167947650 (33.036 examples/sec; 1.513 sec/batch)\n",
      "2019-03-17 07:42:01.110046: step 760, examples 38000, loss = 0.110741876 (33.193 examples/sec; 1.506 sec/batch)\n",
      "2019-03-17 07:42:16.487789: step 770, examples 38500, loss = 0.128238693 (32.250 examples/sec; 1.550 sec/batch)\n",
      "2019-03-17 07:42:31.991012: step 780, examples 39000, loss = 0.118249461 (33.267 examples/sec; 1.503 sec/batch)\n",
      "2019-03-17 07:42:46.947464: step 790, examples 39500, loss = 0.117637068 (34.062 examples/sec; 1.468 sec/batch)\n",
      "2019-03-17 07:43:01.988460: step 800, examples 40000, loss = 0.141474336 (34.016 examples/sec; 1.470 sec/batch)\n",
      "Top 1 validation accuracy: 0.7941176295280457 and top 2 validation accuracy: 0.970588207244873\n",
      "Model Saved!\n",
      "2019-03-17 07:43:18.599630: step 810, examples 40500, loss = 0.120817564 (33.245 examples/sec; 1.504 sec/batch)\n",
      "2019-03-17 07:43:33.571788: step 820, examples 41000, loss = 0.140272200 (34.189 examples/sec; 1.462 sec/batch)\n",
      "2019-03-17 07:43:48.636059: step 830, examples 41500, loss = 0.132244736 (33.567 examples/sec; 1.490 sec/batch)\n",
      "2019-03-17 07:44:03.469400: step 840, examples 42000, loss = 0.100644179 (33.622 examples/sec; 1.487 sec/batch)\n",
      "2019-03-17 07:44:18.436725: step 850, examples 42500, loss = 0.125185519 (33.466 examples/sec; 1.494 sec/batch)\n",
      "2019-03-17 07:44:33.376778: step 860, examples 43000, loss = 0.123408444 (32.380 examples/sec; 1.544 sec/batch)\n",
      "2019-03-17 07:44:48.325930: step 870, examples 43500, loss = 0.100608423 (32.463 examples/sec; 1.540 sec/batch)\n",
      "2019-03-17 07:45:03.257575: step 880, examples 44000, loss = 0.130664378 (33.060 examples/sec; 1.512 sec/batch)\n",
      "2019-03-17 07:45:18.269892: step 890, examples 44500, loss = 0.124172419 (33.977 examples/sec; 1.472 sec/batch)\n",
      "2019-03-17 07:45:33.240448: step 900, examples 45000, loss = 0.123489022 (33.440 examples/sec; 1.495 sec/batch)\n",
      "Top 1 validation accuracy: 0.8235294222831726 and top 2 validation accuracy: 0.9411764740943909\n",
      "Model Saved!\n",
      "2019-03-17 07:45:49.611682: step 910, examples 45500, loss = 0.128901184 (33.253 examples/sec; 1.504 sec/batch)\n",
      "2019-03-17 07:46:04.626232: step 920, examples 46000, loss = 0.112909406 (33.466 examples/sec; 1.494 sec/batch)\n",
      "2019-03-17 07:46:19.681854: step 930, examples 46500, loss = 0.097449467 (33.680 examples/sec; 1.485 sec/batch)\n",
      "2019-03-17 07:46:34.754301: step 940, examples 47000, loss = 0.095837973 (33.119 examples/sec; 1.510 sec/batch)\n",
      "2019-03-17 07:46:49.798369: step 950, examples 47500, loss = 0.090390034 (33.088 examples/sec; 1.511 sec/batch)\n",
      "2019-03-17 07:47:04.855694: step 960, examples 48000, loss = 0.127430573 (32.908 examples/sec; 1.519 sec/batch)\n",
      "2019-03-17 07:47:19.735934: step 970, examples 48500, loss = 0.092890047 (33.370 examples/sec; 1.498 sec/batch)\n",
      "2019-03-17 07:47:34.602563: step 980, examples 49000, loss = 0.097500019 (33.630 examples/sec; 1.487 sec/batch)\n",
      "2019-03-17 07:47:49.726971: step 990, examples 49500, loss = 0.144983679 (33.630 examples/sec; 1.487 sec/batch)\n",
      "Top 1 validation accuracy: 0.7941176295280457 and top 2 validation accuracy: 0.9411764740943909\n",
      "Model Saved!\n",
      "Loading datasets...\n",
      "Dataset loading completes.\n",
      "2019-03-17 07:48:09.146448: step 0, examples 0, loss = 1.421012521 (27.485 examples/sec; 1.819 sec/batch)\n",
      "Top 1 validation accuracy: 0.3214285671710968 and top 2 validation accuracy: 0.5535714030265808\n",
      "Model Saved!\n",
      "2019-03-17 07:48:25.915631: step 10, examples 500, loss = 1.403410077 (34.015 examples/sec; 1.470 sec/batch)\n",
      "2019-03-17 07:48:40.964483: step 20, examples 1000, loss = 1.410974622 (34.108 examples/sec; 1.466 sec/batch)\n",
      "2019-03-17 07:48:55.787350: step 30, examples 1500, loss = 1.361674786 (33.328 examples/sec; 1.500 sec/batch)\n",
      "2019-03-17 07:49:10.695521: step 40, examples 2000, loss = 1.360348344 (34.369 examples/sec; 1.455 sec/batch)\n",
      "2019-03-17 07:49:25.629467: step 50, examples 2500, loss = 1.319094777 (33.365 examples/sec; 1.499 sec/batch)\n",
      "2019-03-17 07:49:40.590111: step 60, examples 3000, loss = 1.137332797 (34.300 examples/sec; 1.458 sec/batch)\n",
      "2019-03-17 07:49:55.626424: step 70, examples 3500, loss = 1.178804755 (33.781 examples/sec; 1.480 sec/batch)\n",
      "2019-03-17 07:50:10.693970: step 80, examples 4000, loss = 1.087280750 (33.770 examples/sec; 1.481 sec/batch)\n",
      "2019-03-17 07:50:25.621653: step 90, examples 4500, loss = 0.736968040 (32.438 examples/sec; 1.541 sec/batch)\n",
      "2019-03-17 07:50:40.373843: step 100, examples 5000, loss = 0.989620566 (34.320 examples/sec; 1.457 sec/batch)\n",
      "Top 1 validation accuracy: 0.6964285969734192 and top 2 validation accuracy: 0.9107142686843872\n",
      "Model Saved!\n",
      "2019-03-17 07:50:56.937246: step 110, examples 5500, loss = 0.680856645 (32.257 examples/sec; 1.550 sec/batch)\n",
      "2019-03-17 07:51:11.872931: step 120, examples 6000, loss = 0.707186639 (34.066 examples/sec; 1.468 sec/batch)\n",
      "2019-03-17 07:51:26.769685: step 130, examples 6500, loss = 0.675988793 (33.832 examples/sec; 1.478 sec/batch)\n",
      "2019-03-17 07:51:41.782619: step 140, examples 7000, loss = 0.688329160 (34.553 examples/sec; 1.447 sec/batch)\n",
      "2019-03-17 07:51:56.817446: step 150, examples 7500, loss = 0.719506919 (33.762 examples/sec; 1.481 sec/batch)\n",
      "2019-03-17 07:52:11.769714: step 160, examples 8000, loss = 0.629387259 (33.701 examples/sec; 1.484 sec/batch)\n",
      "2019-03-17 07:52:26.855757: step 170, examples 8500, loss = 0.506935060 (32.918 examples/sec; 1.519 sec/batch)\n",
      "2019-03-17 07:52:41.859049: step 180, examples 9000, loss = 0.518060744 (34.104 examples/sec; 1.466 sec/batch)\n",
      "2019-03-17 07:52:56.796698: step 190, examples 9500, loss = 0.433972478 (33.111 examples/sec; 1.510 sec/batch)\n",
      "2019-03-17 07:53:11.720241: step 200, examples 10000, loss = 0.451569527 (32.749 examples/sec; 1.527 sec/batch)\n",
      "Top 1 validation accuracy: 0.75 and top 2 validation accuracy: 0.8571428656578064\n",
      "Model Saved!\n",
      "2019-03-17 07:53:28.321142: step 210, examples 10500, loss = 0.404107183 (33.554 examples/sec; 1.490 sec/batch)\n",
      "2019-03-17 07:53:43.226686: step 220, examples 11000, loss = 0.337616235 (32.616 examples/sec; 1.533 sec/batch)\n",
      "2019-03-17 07:53:58.146792: step 230, examples 11500, loss = 0.341079116 (34.397 examples/sec; 1.454 sec/batch)\n",
      "2019-03-17 07:54:13.161872: step 240, examples 12000, loss = 0.266938716 (32.937 examples/sec; 1.518 sec/batch)\n",
      "2019-03-17 07:54:28.146136: step 250, examples 12500, loss = 0.318456560 (33.778 examples/sec; 1.480 sec/batch)\n",
      "2019-03-17 07:54:43.108169: step 260, examples 13000, loss = 0.331495553 (33.185 examples/sec; 1.507 sec/batch)\n",
      "2019-03-17 07:54:58.102586: step 270, examples 13500, loss = 0.297929257 (33.607 examples/sec; 1.488 sec/batch)\n",
      "2019-03-17 07:55:13.024478: step 280, examples 14000, loss = 0.332957774 (33.532 examples/sec; 1.491 sec/batch)\n",
      "2019-03-17 07:55:27.809855: step 290, examples 14500, loss = 0.302412599 (33.738 examples/sec; 1.482 sec/batch)\n",
      "2019-03-17 07:55:42.646216: step 300, examples 15000, loss = 0.269294053 (34.096 examples/sec; 1.466 sec/batch)\n",
      "Top 1 validation accuracy: 0.7857142686843872 and top 2 validation accuracy: 0.8928571343421936\n",
      "Model Saved!\n",
      "2019-03-17 07:55:59.143357: step 310, examples 15500, loss = 0.322255820 (32.567 examples/sec; 1.535 sec/batch)\n",
      "2019-03-17 07:56:14.162779: step 320, examples 16000, loss = 0.300545663 (32.980 examples/sec; 1.516 sec/batch)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2019-03-17 07:56:29.241427: step 330, examples 16500, loss = 0.259639621 (33.611 examples/sec; 1.488 sec/batch)\n",
      "2019-03-17 07:56:44.239653: step 340, examples 17000, loss = 0.202803373 (33.047 examples/sec; 1.513 sec/batch)\n",
      "2019-03-17 07:56:59.042305: step 350, examples 17500, loss = 0.238309920 (33.220 examples/sec; 1.505 sec/batch)\n",
      "2019-03-17 07:57:13.971188: step 360, examples 18000, loss = 0.245376348 (32.765 examples/sec; 1.526 sec/batch)\n",
      "2019-03-17 07:57:29.102005: step 370, examples 18500, loss = 0.189432397 (33.770 examples/sec; 1.481 sec/batch)\n",
      "2019-03-17 07:57:44.198161: step 380, examples 19000, loss = 0.250453055 (32.222 examples/sec; 1.552 sec/batch)\n",
      "2019-03-17 07:57:59.366965: step 390, examples 19500, loss = 0.137046039 (32.342 examples/sec; 1.546 sec/batch)\n",
      "2019-03-17 07:58:14.389396: step 400, examples 20000, loss = 0.202372655 (33.088 examples/sec; 1.511 sec/batch)\n",
      "Top 1 validation accuracy: 0.7142857313156128 and top 2 validation accuracy: 0.8928571343421936\n",
      "Model Saved!\n",
      "2019-03-17 07:58:31.068969: step 410, examples 20500, loss = 0.203076318 (32.638 examples/sec; 1.532 sec/batch)\n",
      "2019-03-17 07:58:45.952006: step 420, examples 21000, loss = 0.188966647 (34.304 examples/sec; 1.458 sec/batch)\n",
      "2019-03-17 07:59:00.993349: step 430, examples 21500, loss = 0.187761366 (33.312 examples/sec; 1.501 sec/batch)\n",
      "2019-03-17 07:59:16.096188: step 440, examples 22000, loss = 0.153002769 (33.448 examples/sec; 1.495 sec/batch)\n",
      "2019-03-17 07:59:31.146687: step 450, examples 22500, loss = 0.173344359 (33.333 examples/sec; 1.500 sec/batch)\n",
      "2019-03-17 07:59:46.214681: step 460, examples 23000, loss = 0.189026743 (31.782 examples/sec; 1.573 sec/batch)\n",
      "2019-03-17 08:00:01.297883: step 470, examples 23500, loss = 0.202862605 (31.235 examples/sec; 1.601 sec/batch)\n",
      "2019-03-17 08:00:16.689641: step 480, examples 24000, loss = 0.164070964 (32.513 examples/sec; 1.538 sec/batch)\n",
      "2019-03-17 08:00:31.736107: step 490, examples 24500, loss = 0.150703862 (33.099 examples/sec; 1.511 sec/batch)\n",
      "2019-03-17 08:00:46.643659: step 500, examples 25000, loss = 0.144669190 (34.423 examples/sec; 1.453 sec/batch)\n",
      "Top 1 validation accuracy: 0.7142857313156128 and top 2 validation accuracy: 0.8928571343421936\n",
      "Model Saved!\n",
      "2019-03-17 08:01:02.616260: step 510, examples 25500, loss = 0.167516395 (35.166 examples/sec; 1.422 sec/batch)\n",
      "2019-03-17 08:01:17.146391: step 520, examples 26000, loss = 0.230158895 (34.081 examples/sec; 1.467 sec/batch)\n",
      "2019-03-17 08:01:31.720047: step 530, examples 26500, loss = 0.138977706 (34.459 examples/sec; 1.451 sec/batch)\n",
      "2019-03-17 08:01:46.353615: step 540, examples 27000, loss = 0.153113320 (33.218 examples/sec; 1.505 sec/batch)\n",
      "2019-03-17 08:02:00.817437: step 550, examples 27500, loss = 0.153088689 (34.737 examples/sec; 1.439 sec/batch)\n",
      "2019-03-17 08:02:15.363591: step 560, examples 28000, loss = 0.109232634 (33.535 examples/sec; 1.491 sec/batch)\n",
      "2019-03-17 08:02:29.939054: step 570, examples 28500, loss = 0.164508000 (35.674 examples/sec; 1.402 sec/batch)\n",
      "2019-03-17 08:02:44.494990: step 580, examples 29000, loss = 0.133919179 (35.075 examples/sec; 1.426 sec/batch)\n",
      "2019-03-17 08:02:59.357044: step 590, examples 29500, loss = 0.123227902 (33.854 examples/sec; 1.477 sec/batch)\n",
      "2019-03-17 08:03:14.102493: step 600, examples 30000, loss = 0.107948370 (33.828 examples/sec; 1.478 sec/batch)\n",
      "Top 1 validation accuracy: 0.8392857313156128 and top 2 validation accuracy: 0.9285714030265808\n",
      "Model Saved!\n",
      "2019-03-17 08:03:30.146635: step 610, examples 30500, loss = 0.106919959 (34.041 examples/sec; 1.469 sec/batch)\n",
      "2019-03-17 08:03:44.741791: step 620, examples 31000, loss = 0.100635864 (33.623 examples/sec; 1.487 sec/batch)\n",
      "2019-03-17 08:03:59.336874: step 630, examples 31500, loss = 0.128466353 (33.413 examples/sec; 1.496 sec/batch)\n",
      "2019-03-17 08:04:13.935446: step 640, examples 32000, loss = 0.154733643 (34.834 examples/sec; 1.435 sec/batch)\n",
      "2019-03-17 08:04:28.437384: step 650, examples 32500, loss = 0.105965406 (34.892 examples/sec; 1.433 sec/batch)\n",
      "2019-03-17 08:04:42.760255: step 660, examples 33000, loss = 0.125217363 (35.124 examples/sec; 1.424 sec/batch)\n",
      "2019-03-17 08:04:57.262680: step 670, examples 33500, loss = 0.108572289 (35.599 examples/sec; 1.405 sec/batch)\n",
      "2019-03-17 08:05:11.804644: step 680, examples 34000, loss = 0.117025249 (34.063 examples/sec; 1.468 sec/batch)\n",
      "2019-03-17 08:05:26.330061: step 690, examples 34500, loss = 0.116218187 (34.447 examples/sec; 1.452 sec/batch)\n",
      "2019-03-17 08:05:40.817633: step 700, examples 35000, loss = 0.090799935 (33.957 examples/sec; 1.472 sec/batch)\n",
      "Top 1 validation accuracy: 0.75 and top 2 validation accuracy: 0.9107142686843872\n",
      "Model Saved!\n",
      "2019-03-17 08:05:57.020594: step 710, examples 35500, loss = 0.098725207 (35.026 examples/sec; 1.428 sec/batch)\n",
      "2019-03-17 08:06:11.513591: step 720, examples 36000, loss = 0.104985707 (35.384 examples/sec; 1.413 sec/batch)\n",
      "2019-03-17 08:06:26.024796: step 730, examples 36500, loss = 0.108366944 (33.609 examples/sec; 1.488 sec/batch)\n",
      "2019-03-17 08:06:40.943119: step 740, examples 37000, loss = 0.135608271 (31.874 examples/sec; 1.569 sec/batch)\n",
      "2019-03-17 08:06:55.742501: step 750, examples 37500, loss = 0.118433625 (34.510 examples/sec; 1.449 sec/batch)\n",
      "2019-03-17 08:07:10.315732: step 760, examples 38000, loss = 0.095779926 (34.225 examples/sec; 1.461 sec/batch)\n",
      "2019-03-17 08:07:24.887488: step 770, examples 38500, loss = 0.081505232 (34.673 examples/sec; 1.442 sec/batch)\n",
      "2019-03-17 08:07:39.385895: step 780, examples 39000, loss = 0.087270185 (34.201 examples/sec; 1.462 sec/batch)\n",
      "2019-03-17 08:07:53.879427: step 790, examples 39500, loss = 0.085240796 (34.449 examples/sec; 1.451 sec/batch)\n",
      "2019-03-17 08:08:08.537582: step 800, examples 40000, loss = 0.088588931 (33.643 examples/sec; 1.486 sec/batch)\n",
      "Top 1 validation accuracy: 0.8035714030265808 and top 2 validation accuracy: 0.9107142686843872\n",
      "Model Saved!\n",
      "2019-03-17 08:08:24.869098: step 810, examples 40500, loss = 0.126895592 (34.259 examples/sec; 1.459 sec/batch)\n",
      "2019-03-17 08:08:39.385735: step 820, examples 41000, loss = 0.106248334 (35.025 examples/sec; 1.428 sec/batch)\n",
      "2019-03-17 08:08:54.039208: step 830, examples 41500, loss = 0.075475983 (35.117 examples/sec; 1.424 sec/batch)\n",
      "2019-03-17 08:09:08.818672: step 840, examples 42000, loss = 0.121723004 (33.946 examples/sec; 1.473 sec/batch)\n",
      "2019-03-17 08:09:23.532849: step 850, examples 42500, loss = 0.108889528 (33.540 examples/sec; 1.491 sec/batch)\n",
      "2019-03-17 08:09:38.146623: step 860, examples 43000, loss = 0.123846486 (32.854 examples/sec; 1.522 sec/batch)\n",
      "2019-03-17 08:09:52.727733: step 870, examples 43500, loss = 0.101418465 (33.366 examples/sec; 1.499 sec/batch)\n",
      "2019-03-17 08:10:07.336532: step 880, examples 44000, loss = 0.102766626 (33.827 examples/sec; 1.478 sec/batch)\n",
      "2019-03-17 08:10:22.038403: step 890, examples 44500, loss = 0.089731507 (33.320 examples/sec; 1.501 sec/batch)\n",
      "2019-03-17 08:10:36.425349: step 900, examples 45000, loss = 0.154552415 (34.806 examples/sec; 1.437 sec/batch)\n",
      "Top 1 validation accuracy: 0.8392857313156128 and top 2 validation accuracy: 0.9285714030265808\n",
      "Model Saved!\n",
      "2019-03-17 08:10:52.513876: step 910, examples 45500, loss = 0.091542721 (34.089 examples/sec; 1.467 sec/batch)\n",
      "2019-03-17 08:11:07.068137: step 920, examples 46000, loss = 0.104394719 (33.919 examples/sec; 1.474 sec/batch)\n",
      "2019-03-17 08:11:21.624409: step 930, examples 46500, loss = 0.089871973 (33.888 examples/sec; 1.475 sec/batch)\n",
      "2019-03-17 08:11:36.196215: step 940, examples 47000, loss = 0.082688734 (33.656 examples/sec; 1.486 sec/batch)\n",
      "2019-03-17 08:11:50.726248: step 950, examples 47500, loss = 0.091039151 (35.448 examples/sec; 1.411 sec/batch)\n",
      "2019-03-17 08:12:05.179342: step 960, examples 48000, loss = 0.076808281 (34.780 examples/sec; 1.438 sec/batch)\n",
      "2019-03-17 08:12:19.729875: step 970, examples 48500, loss = 0.084445253 (34.212 examples/sec; 1.461 sec/batch)\n",
      "2019-03-17 08:12:34.161613: step 980, examples 49000, loss = 0.093714885 (34.216 examples/sec; 1.461 sec/batch)\n",
      "2019-03-17 08:12:48.753499: step 990, examples 49500, loss = 0.072152138 (33.897 examples/sec; 1.475 sec/batch)\n",
      "Top 1 validation accuracy: 0.75 and top 2 validation accuracy: 0.8928571343421936\n",
      "Model Saved!\n",
      "Loading datasets...\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dataset loading completes.\n",
      "2019-03-17 08:13:07.873882: step 0, examples 0, loss = 1.419539928 (28.156 examples/sec; 1.776 sec/batch)\n",
      "Top 1 validation accuracy: 0.13636364042758942 and top 2 validation accuracy: 0.5454545617103577\n",
      "Model Saved!\n",
      "2019-03-17 08:13:24.006452: step 10, examples 500, loss = 1.388378739 (35.063 examples/sec; 1.426 sec/batch)\n",
      "2019-03-17 08:13:38.591436: step 20, examples 1000, loss = 1.290118456 (34.583 examples/sec; 1.446 sec/batch)\n",
      "2019-03-17 08:13:53.089177: step 30, examples 1500, loss = 1.138007998 (34.181 examples/sec; 1.463 sec/batch)\n",
      "2019-03-17 08:14:07.632903: step 40, examples 2000, loss = 0.982105255 (35.184 examples/sec; 1.421 sec/batch)\n",
      "2019-03-17 08:14:22.261975: step 50, examples 2500, loss = 1.073893666 (33.603 examples/sec; 1.488 sec/batch)\n",
      "2019-03-17 08:14:36.923100: step 60, examples 3000, loss = 1.077718973 (33.693 examples/sec; 1.484 sec/batch)\n",
      "2019-03-17 08:14:51.336340: step 70, examples 3500, loss = 0.965257883 (35.768 examples/sec; 1.398 sec/batch)\n",
      "2019-03-17 08:15:05.903729: step 80, examples 4000, loss = 0.865301549 (33.360 examples/sec; 1.499 sec/batch)\n",
      "2019-03-17 08:15:21.073986: step 90, examples 4500, loss = 0.715590537 (32.343 examples/sec; 1.546 sec/batch)\n",
      "2019-03-17 08:15:35.888136: step 100, examples 5000, loss = 0.645943880 (36.382 examples/sec; 1.374 sec/batch)\n",
      "Top 1 validation accuracy: 0.5909090638160706 and top 2 validation accuracy: 0.8636363744735718\n",
      "Model Saved!\n",
      "2019-03-17 08:15:51.993510: step 110, examples 5500, loss = 0.555722296 (34.871 examples/sec; 1.434 sec/batch)\n",
      "2019-03-17 08:16:06.585423: step 120, examples 6000, loss = 0.753068864 (34.408 examples/sec; 1.453 sec/batch)\n",
      "2019-03-17 08:16:21.509571: step 130, examples 6500, loss = 0.592685759 (33.434 examples/sec; 1.495 sec/batch)\n",
      "2019-03-17 08:16:36.336612: step 140, examples 7000, loss = 0.465370923 (34.252 examples/sec; 1.460 sec/batch)\n",
      "2019-03-17 08:16:51.035339: step 150, examples 7500, loss = 0.438817412 (33.857 examples/sec; 1.477 sec/batch)\n",
      "2019-03-17 08:17:05.535610: step 160, examples 8000, loss = 0.395165324 (34.028 examples/sec; 1.469 sec/batch)\n",
      "2019-03-17 08:17:19.988148: step 170, examples 8500, loss = 0.366916388 (34.465 examples/sec; 1.451 sec/batch)\n",
      "2019-03-17 08:17:34.460955: step 180, examples 9000, loss = 0.519222081 (34.697 examples/sec; 1.441 sec/batch)\n",
      "2019-03-17 08:17:49.146026: step 190, examples 9500, loss = 0.332000375 (33.971 examples/sec; 1.472 sec/batch)\n",
      "2019-03-17 08:18:03.726810: step 200, examples 10000, loss = 0.385814667 (34.906 examples/sec; 1.432 sec/batch)\n",
      "Top 1 validation accuracy: 0.6818181872367859 and top 2 validation accuracy: 0.9090909361839294\n",
      "Model Saved!\n",
      "2019-03-17 08:18:19.757265: step 210, examples 10500, loss = 0.290837079 (34.417 examples/sec; 1.453 sec/batch)\n",
      "2019-03-17 08:18:34.181136: step 220, examples 11000, loss = 0.322096109 (34.649 examples/sec; 1.443 sec/batch)\n",
      "2019-03-17 08:18:48.756542: step 230, examples 11500, loss = 0.269325614 (34.178 examples/sec; 1.463 sec/batch)\n",
      "2019-03-17 08:19:03.365043: step 240, examples 12000, loss = 0.339698106 (34.323 examples/sec; 1.457 sec/batch)\n",
      "2019-03-17 08:19:18.035734: step 250, examples 12500, loss = 0.305859327 (35.014 examples/sec; 1.428 sec/batch)\n",
      "2019-03-17 08:19:32.526983: step 260, examples 13000, loss = 0.230498806 (35.082 examples/sec; 1.425 sec/batch)\n",
      "2019-03-17 08:19:47.038459: step 270, examples 13500, loss = 0.291036338 (35.401 examples/sec; 1.412 sec/batch)\n",
      "2019-03-17 08:20:01.569682: step 280, examples 14000, loss = 0.194843039 (33.509 examples/sec; 1.492 sec/batch)\n",
      "2019-03-17 08:20:16.094921: step 290, examples 14500, loss = 0.292819291 (33.595 examples/sec; 1.488 sec/batch)\n",
      "2019-03-17 08:20:30.976162: step 300, examples 15000, loss = 0.274869949 (35.253 examples/sec; 1.418 sec/batch)\n",
      "Top 1 validation accuracy: 0.7045454382896423 and top 2 validation accuracy: 0.8409090638160706\n",
      "Model Saved!\n",
      "2019-03-17 08:20:47.072135: step 310, examples 15500, loss = 0.209344640 (33.568 examples/sec; 1.490 sec/batch)\n",
      "2019-03-17 08:21:01.668933: step 320, examples 16000, loss = 0.187289909 (34.194 examples/sec; 1.462 sec/batch)\n",
      "2019-03-17 08:21:16.354669: step 330, examples 16500, loss = 0.147092178 (32.948 examples/sec; 1.518 sec/batch)\n",
      "2019-03-17 08:21:31.215586: step 340, examples 17000, loss = 0.169596553 (33.959 examples/sec; 1.472 sec/batch)\n",
      "2019-03-17 08:21:45.878201: step 350, examples 17500, loss = 0.183960855 (34.569 examples/sec; 1.446 sec/batch)\n",
      "2019-03-17 08:22:00.546302: step 360, examples 18000, loss = 0.145424634 (33.443 examples/sec; 1.495 sec/batch)\n",
      "2019-03-17 08:22:15.117150: step 370, examples 18500, loss = 0.135773987 (34.726 examples/sec; 1.440 sec/batch)\n",
      "2019-03-17 08:22:29.762230: step 380, examples 19000, loss = 0.170756012 (34.848 examples/sec; 1.435 sec/batch)\n",
      "2019-03-17 08:22:44.223392: step 390, examples 19500, loss = 0.133204028 (34.908 examples/sec; 1.432 sec/batch)\n",
      "2019-03-17 08:22:58.575287: step 400, examples 20000, loss = 0.130722657 (34.345 examples/sec; 1.456 sec/batch)\n",
      "Top 1 validation accuracy: 0.7954545617103577 and top 2 validation accuracy: 0.8181818127632141\n",
      "Model Saved!\n",
      "2019-03-17 08:23:14.672044: step 410, examples 20500, loss = 0.114302762 (32.207 examples/sec; 1.552 sec/batch)\n",
      "2019-03-17 08:23:29.675726: step 420, examples 21000, loss = 0.144483984 (32.742 examples/sec; 1.527 sec/batch)\n",
      "2019-03-17 08:23:44.419853: step 430, examples 21500, loss = 0.115481287 (32.111 examples/sec; 1.557 sec/batch)\n",
      "2019-03-17 08:23:59.062820: step 440, examples 22000, loss = 0.133709684 (34.446 examples/sec; 1.452 sec/batch)\n",
      "2019-03-17 08:24:13.679504: step 450, examples 22500, loss = 0.151859388 (34.192 examples/sec; 1.462 sec/batch)\n",
      "2019-03-17 08:24:28.241961: step 460, examples 23000, loss = 0.117427461 (34.377 examples/sec; 1.454 sec/batch)\n",
      "2019-03-17 08:24:42.622972: step 470, examples 23500, loss = 0.139806733 (34.664 examples/sec; 1.442 sec/batch)\n",
      "2019-03-17 08:24:57.262270: step 480, examples 24000, loss = 0.108471967 (34.791 examples/sec; 1.437 sec/batch)\n",
      "2019-03-17 08:25:11.865779: step 490, examples 24500, loss = 0.113091089 (34.378 examples/sec; 1.454 sec/batch)\n",
      "2019-03-17 08:25:26.443599: step 500, examples 25000, loss = 0.107446715 (33.846 examples/sec; 1.477 sec/batch)\n",
      "Top 1 validation accuracy: 0.7727272510528564 and top 2 validation accuracy: 0.9090909361839294\n",
      "Model Saved!\n",
      "2019-03-17 08:25:42.535204: step 510, examples 25500, loss = 0.099043749 (34.243 examples/sec; 1.460 sec/batch)\n",
      "2019-03-17 08:25:57.076705: step 520, examples 26000, loss = 0.097189695 (34.507 examples/sec; 1.449 sec/batch)\n",
      "2019-03-17 08:26:11.629809: step 530, examples 26500, loss = 0.113754161 (34.820 examples/sec; 1.436 sec/batch)\n",
      "2019-03-17 08:26:26.072704: step 540, examples 27000, loss = 0.154058784 (33.509 examples/sec; 1.492 sec/batch)\n",
      "2019-03-17 08:26:40.595134: step 550, examples 27500, loss = 0.094797678 (34.168 examples/sec; 1.463 sec/batch)\n",
      "2019-03-17 08:26:55.334303: step 560, examples 28000, loss = 0.089094520 (32.603 examples/sec; 1.534 sec/batch)\n",
      "2019-03-17 08:27:10.252919: step 570, examples 28500, loss = 0.090277068 (34.304 examples/sec; 1.458 sec/batch)\n",
      "2019-03-17 08:27:25.193573: step 580, examples 29000, loss = 0.124346860 (34.357 examples/sec; 1.455 sec/batch)\n",
      "2019-03-17 08:27:39.661645: step 590, examples 29500, loss = 0.103644088 (34.526 examples/sec; 1.448 sec/batch)\n",
      "2019-03-17 08:27:54.162619: step 600, examples 30000, loss = 0.090032473 (34.291 examples/sec; 1.458 sec/batch)\n",
      "Top 1 validation accuracy: 0.7954545617103577 and top 2 validation accuracy: 0.8863636255264282\n",
      "Model Saved!\n",
      "2019-03-17 08:28:10.322299: step 610, examples 30500, loss = 0.101385713 (34.148 examples/sec; 1.464 sec/batch)\n",
      "2019-03-17 08:28:24.770147: step 620, examples 31000, loss = 0.084512956 (35.362 examples/sec; 1.414 sec/batch)\n",
      "2019-03-17 08:28:39.263020: step 630, examples 31500, loss = 0.076734409 (34.253 examples/sec; 1.460 sec/batch)\n",
      "2019-03-17 08:28:53.738498: step 640, examples 32000, loss = 0.102053232 (34.026 examples/sec; 1.469 sec/batch)\n",
      "2019-03-17 08:29:08.259672: step 650, examples 32500, loss = 0.076679111 (34.290 examples/sec; 1.458 sec/batch)\n",
      "2019-03-17 08:29:22.677540: step 660, examples 33000, loss = 0.094462611 (34.508 examples/sec; 1.449 sec/batch)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2019-03-17 08:29:37.278588: step 670, examples 33500, loss = 0.074115947 (33.609 examples/sec; 1.488 sec/batch)\n",
      "2019-03-17 08:29:51.913184: step 680, examples 34000, loss = 0.087055780 (34.085 examples/sec; 1.467 sec/batch)\n",
      "2019-03-17 08:30:06.445518: step 690, examples 34500, loss = 0.081723005 (34.841 examples/sec; 1.435 sec/batch)\n",
      "2019-03-17 08:30:20.966914: step 700, examples 35000, loss = 0.089398652 (34.985 examples/sec; 1.429 sec/batch)\n",
      "Top 1 validation accuracy: 0.7727272510528564 and top 2 validation accuracy: 0.8863636255264282\n",
      "Model Saved!\n",
      "2019-03-17 08:30:37.739148: step 710, examples 35500, loss = 0.087923691 (33.046 examples/sec; 1.513 sec/batch)\n",
      "2019-03-17 08:30:53.044910: step 720, examples 36000, loss = 0.082441367 (33.090 examples/sec; 1.511 sec/batch)\n",
      "2019-03-17 08:31:08.654524: step 730, examples 36500, loss = 0.073451526 (32.381 examples/sec; 1.544 sec/batch)\n",
      "2019-03-17 08:31:23.988951: step 740, examples 37000, loss = 0.078754276 (33.082 examples/sec; 1.511 sec/batch)\n",
      "2019-03-17 08:31:39.110540: step 750, examples 37500, loss = 0.064721674 (33.065 examples/sec; 1.512 sec/batch)\n",
      "2019-03-17 08:31:54.162419: step 760, examples 38000, loss = 0.081515625 (33.328 examples/sec; 1.500 sec/batch)\n",
      "2019-03-17 08:32:09.082082: step 770, examples 38500, loss = 0.072766513 (33.284 examples/sec; 1.502 sec/batch)\n",
      "2019-03-17 08:32:23.904921: step 780, examples 39000, loss = 0.075874120 (33.982 examples/sec; 1.471 sec/batch)\n",
      "2019-03-17 08:32:38.872885: step 790, examples 39500, loss = 0.072239637 (34.951 examples/sec; 1.431 sec/batch)\n",
      "2019-03-17 08:32:53.903328: step 800, examples 40000, loss = 0.070367426 (33.342 examples/sec; 1.500 sec/batch)\n",
      "Top 1 validation accuracy: 0.8181818127632141 and top 2 validation accuracy: 0.9090909361839294\n",
      "Model Saved!\n",
      "2019-03-17 08:33:10.421049: step 810, examples 40500, loss = 0.066572882 (33.033 examples/sec; 1.514 sec/batch)\n",
      "2019-03-17 08:33:25.431407: step 820, examples 41000, loss = 0.059746157 (33.146 examples/sec; 1.508 sec/batch)\n",
      "2019-03-17 08:33:40.386230: step 830, examples 41500, loss = 0.065701015 (33.186 examples/sec; 1.507 sec/batch)\n",
      "2019-03-17 08:33:55.336494: step 840, examples 42000, loss = 0.068633653 (34.162 examples/sec; 1.464 sec/batch)\n",
      "2019-03-17 08:34:10.444836: step 850, examples 42500, loss = 0.084125139 (33.278 examples/sec; 1.503 sec/batch)\n",
      "2019-03-17 08:34:25.512938: step 860, examples 43000, loss = 0.069711551 (32.293 examples/sec; 1.548 sec/batch)\n",
      "2019-03-17 08:34:40.346924: step 870, examples 43500, loss = 0.066164300 (34.313 examples/sec; 1.457 sec/batch)\n",
      "2019-03-17 08:34:55.240808: step 880, examples 44000, loss = 0.075941183 (34.772 examples/sec; 1.438 sec/batch)\n",
      "2019-03-17 08:35:10.355794: step 890, examples 44500, loss = 0.061686281 (32.502 examples/sec; 1.538 sec/batch)\n",
      "2019-03-17 08:35:25.336267: step 900, examples 45000, loss = 0.081159301 (34.203 examples/sec; 1.462 sec/batch)\n",
      "Top 1 validation accuracy: 0.8863636255264282 and top 2 validation accuracy: 0.9090909361839294\n",
      "Model Saved!\n",
      "2019-03-17 08:35:41.901538: step 910, examples 45500, loss = 0.068459123 (32.889 examples/sec; 1.520 sec/batch)\n",
      "2019-03-17 08:35:56.962642: step 920, examples 46000, loss = 0.083874866 (33.646 examples/sec; 1.486 sec/batch)\n",
      "2019-03-17 08:36:11.889386: step 930, examples 46500, loss = 0.069588803 (33.625 examples/sec; 1.487 sec/batch)\n",
      "2019-03-17 08:36:26.894345: step 940, examples 47000, loss = 0.079697698 (33.153 examples/sec; 1.508 sec/batch)\n",
      "2019-03-17 08:36:41.901600: step 950, examples 47500, loss = 0.057290707 (33.167 examples/sec; 1.508 sec/batch)\n",
      "2019-03-17 08:36:56.726710: step 960, examples 48000, loss = 0.064924091 (33.860 examples/sec; 1.477 sec/batch)\n",
      "2019-03-17 08:37:11.773405: step 970, examples 48500, loss = 0.066990010 (33.024 examples/sec; 1.514 sec/batch)\n",
      "2019-03-17 08:37:26.668915: step 980, examples 49000, loss = 0.053143896 (33.889 examples/sec; 1.475 sec/batch)\n",
      "2019-03-17 08:37:41.646754: step 990, examples 49500, loss = 0.065799721 (33.201 examples/sec; 1.506 sec/batch)\n",
      "Top 1 validation accuracy: 0.8181818127632141 and top 2 validation accuracy: 0.9090909361839294\n",
      "Model Saved!\n"
     ]
    }
   ],
   "source": [
    "best_val_ss_crop_subject = {}\n",
    "\n",
    "for sub_id in range(9):\n",
    "    num_cls = 4\n",
    "    mstp = 1000\n",
    "    lfrq = 10\n",
    "    bsz = 50\n",
    "    msf = 100\n",
    "    tr = './trained_model_final/DCNN_reg_ss_crop_subject'+str(sub_id)\n",
    "    if not os.path.exists(tr):\n",
    "        os.mkdir(tr)\n",
    "    start = 0\n",
    "    stop = 250\n",
    "    step = 10\n",
    "    time_length = 700\n",
    "    time_bin = 350\n",
    "    fsz = 3\n",
    "    use_batchnorm = True\n",
    "    use_dropout = True\n",
    "    use_l2loss = True\n",
    "    acc = 'Accuracy_subject'+str(sub_id)\n",
    "    path = 'Path_subject'+str(sub_id)\n",
    "\n",
    "    best_val_ss_crop_subject[acc],best_val_ss_crop_subject[path] = train_model_ss_subject(sub_id,tr,start,stop,step,time_length,time_bin,fsz,use_batchnorm,use_dropout,use_l2loss,num_cls,mstp,lfrq,bsz,msf)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test Accuracy for subject 0 trained on subject 0:\n",
      "Loading datasets...\n",
      "Dataset loading completes.\n",
      "INFO:tensorflow:Restoring parameters from ./trained_model_final/DCNN_reg_ss_crop_subject0\\model.ckpt-1000\n",
      "[test  step 1000] loss: 1.49412; top_1_accuracy: 0.71000; top_5_accuracy: 0.970000 (0.967 sec/batch; 103.451 instances/sec)\n",
      "top_1_accuracy_test =  0.71 top_2_accuracy_test =  0.97\n",
      "Test Accuracy for subject 1 trained on subject 0:\n",
      "Loading datasets...\n",
      "Dataset loading completes.\n",
      "INFO:tensorflow:Restoring parameters from ./trained_model_final/DCNN_reg_ss_crop_subject0\\model.ckpt-1000\n",
      "[test  step 1000] loss: 5.15868; top_1_accuracy: 0.41000; top_5_accuracy: 0.570000 (0.939 sec/batch; 106.487 instances/sec)\n",
      "top_1_accuracy_test =  0.41 top_2_accuracy_test =  0.57\n",
      "Test Accuracy for subject 2 trained on subject 0:\n",
      "Loading datasets...\n",
      "Dataset loading completes.\n",
      "INFO:tensorflow:Restoring parameters from ./trained_model_final/DCNN_reg_ss_crop_subject0\\model.ckpt-1000\n",
      "[test  step 1000] loss: 1.86477; top_1_accuracy: 0.61000; top_5_accuracy: 0.920000 (0.935 sec/batch; 106.944 instances/sec)\n",
      "top_1_accuracy_test =  0.61 top_2_accuracy_test =  0.92\n",
      "Test Accuracy for subject 3 trained on subject 0:\n",
      "Loading datasets...\n",
      "Dataset loading completes.\n",
      "INFO:tensorflow:Restoring parameters from ./trained_model_final/DCNN_reg_ss_crop_subject0\\model.ckpt-1000\n",
      "[test  step 1000] loss: 5.91666; top_1_accuracy: 0.38000; top_5_accuracy: 0.540000 (0.936 sec/batch; 106.828 instances/sec)\n",
      "top_1_accuracy_test =  0.38 top_2_accuracy_test =  0.54\n",
      "Test Accuracy for subject 4 trained on subject 0:\n",
      "Loading datasets...\n",
      "Dataset loading completes.\n",
      "INFO:tensorflow:Restoring parameters from ./trained_model_final/DCNN_reg_ss_crop_subject0\\model.ckpt-1000\n",
      "[test  step 1000] loss: 10.75781; top_1_accuracy: 0.29787; top_5_accuracy: 0.595745 (0.880 sec/batch; 106.778 instances/sec)\n",
      "top_1_accuracy_test =  0.29787233 top_2_accuracy_test =  0.59574467\n",
      "Test Accuracy for subject 5 trained on subject 0:\n",
      "Loading datasets...\n",
      "Dataset loading completes.\n",
      "INFO:tensorflow:Restoring parameters from ./trained_model_final/DCNN_reg_ss_crop_subject0\\model.ckpt-1000\n",
      "[test  step 1000] loss: 8.75736; top_1_accuracy: 0.21429; top_5_accuracy: 0.459184 (0.961 sec/batch; 101.933 instances/sec)\n",
      "top_1_accuracy_test =  0.21428572 top_2_accuracy_test =  0.45918366\n",
      "Test Accuracy for subject 6 trained on subject 0:\n",
      "Loading datasets...\n",
      "Dataset loading completes.\n",
      "INFO:tensorflow:Restoring parameters from ./trained_model_final/DCNN_reg_ss_crop_subject0\\model.ckpt-1000\n",
      "[test  step 1000] loss: 5.35029; top_1_accuracy: 0.43000; top_5_accuracy: 0.650000 (0.904 sec/batch; 110.605 instances/sec)\n",
      "top_1_accuracy_test =  0.43 top_2_accuracy_test =  0.65\n",
      "Test Accuracy for subject 7 trained on subject 0:\n",
      "Loading datasets...\n",
      "Dataset loading completes.\n",
      "INFO:tensorflow:Restoring parameters from ./trained_model_final/DCNN_reg_ss_crop_subject0\\model.ckpt-1000\n",
      "[test  step 1000] loss: 6.76560; top_1_accuracy: 0.42000; top_5_accuracy: 0.580000 (0.937 sec/batch; 106.678 instances/sec)\n",
      "top_1_accuracy_test =  0.42 top_2_accuracy_test =  0.58\n",
      "Test Accuracy for subject 8 trained on subject 0:\n",
      "Loading datasets...\n",
      "Dataset loading completes.\n",
      "INFO:tensorflow:Restoring parameters from ./trained_model_final/DCNN_reg_ss_crop_subject0\\model.ckpt-1000\n",
      "[test  step 1000] loss: 8.56599; top_1_accuracy: 0.30851; top_5_accuracy: 0.531915 (0.862 sec/batch; 109.077 instances/sec)\n",
      "top_1_accuracy_test =  0.30851063 top_2_accuracy_test =  0.5319149\n",
      "Test Accuracy for all subjects trained on subject 0:\n",
      "Loading datasets...\n",
      "Dataset loading completes.\n",
      "INFO:tensorflow:Restoring parameters from ./trained_model_final/DCNN_reg_ss_crop_subject0\\model.ckpt-1000\n",
      "[test  step 1000] loss: 6.02429; top_1_accuracy: 0.42664; top_5_accuracy: 0.647856 (7.319 sec/batch; 121.057 instances/sec)\n",
      "top_1_accuracy_test =  0.42663658 top_2_accuracy_test =  0.6478555\n",
      "Test Accuracy for subject 0 trained on subject 1:\n",
      "Loading datasets...\n",
      "Dataset loading completes.\n",
      "INFO:tensorflow:Restoring parameters from ./trained_model_final/DCNN_reg_ss_crop_subject1\\model.ckpt-401\n",
      "[test  step  401] loss: 2.42408; top_1_accuracy: 0.30000; top_5_accuracy: 0.550000 (0.913 sec/batch; 109.553 instances/sec)\n",
      "top_1_accuracy_test =  0.3 top_2_accuracy_test =  0.55\n",
      "Test Accuracy for subject 1 trained on subject 1:\n",
      "Loading datasets...\n",
      "Dataset loading completes.\n",
      "INFO:tensorflow:Restoring parameters from ./trained_model_final/DCNN_reg_ss_crop_subject1\\model.ckpt-401\n",
      "[test  step  401] loss: 1.96075; top_1_accuracy: 0.35000; top_5_accuracy: 0.700000 (0.908 sec/batch; 110.132 instances/sec)\n",
      "top_1_accuracy_test =  0.35 top_2_accuracy_test =  0.7\n",
      "Test Accuracy for subject 2 trained on subject 1:\n",
      "Loading datasets...\n",
      "Dataset loading completes.\n",
      "INFO:tensorflow:Restoring parameters from ./trained_model_final/DCNN_reg_ss_crop_subject1\\model.ckpt-401\n",
      "[test  step  401] loss: 1.74125; top_1_accuracy: 0.48000; top_5_accuracy: 0.780000 (0.890 sec/batch; 112.422 instances/sec)\n",
      "top_1_accuracy_test =  0.48 top_2_accuracy_test =  0.78\n",
      "Test Accuracy for subject 3 trained on subject 1:\n",
      "Loading datasets...\n",
      "Dataset loading completes.\n",
      "INFO:tensorflow:Restoring parameters from ./trained_model_final/DCNN_reg_ss_crop_subject1\\model.ckpt-401\n",
      "[test  step  401] loss: 2.36189; top_1_accuracy: 0.24000; top_5_accuracy: 0.670000 (0.885 sec/batch; 113.027 instances/sec)\n",
      "top_1_accuracy_test =  0.24 top_2_accuracy_test =  0.67\n",
      "Test Accuracy for subject 4 trained on subject 1:\n",
      "Loading datasets...\n",
      "Dataset loading completes.\n",
      "INFO:tensorflow:Restoring parameters from ./trained_model_final/DCNN_reg_ss_crop_subject1\\model.ckpt-401\n",
      "[test  step  401] loss: 2.07280; top_1_accuracy: 0.34043; top_5_accuracy: 0.627660 (0.884 sec/batch; 106.319 instances/sec)\n",
      "top_1_accuracy_test =  0.34042552 top_2_accuracy_test =  0.62765956\n",
      "Test Accuracy for subject 5 trained on subject 1:\n",
      "Loading datasets...\n",
      "Dataset loading completes.\n",
      "INFO:tensorflow:Restoring parameters from ./trained_model_final/DCNN_reg_ss_crop_subject1\\model.ckpt-401\n",
      "[test  step  401] loss: 2.34766; top_1_accuracy: 0.30612; top_5_accuracy: 0.581633 (0.911 sec/batch; 107.535 instances/sec)\n",
      "top_1_accuracy_test =  0.30612245 top_2_accuracy_test =  0.5816327\n",
      "Test Accuracy for subject 6 trained on subject 1:\n",
      "Loading datasets...\n",
      "Dataset loading completes.\n",
      "INFO:tensorflow:Restoring parameters from ./trained_model_final/DCNN_reg_ss_crop_subject1\\model.ckpt-401\n",
      "[test  step  401] loss: 2.07845; top_1_accuracy: 0.29000; top_5_accuracy: 0.710000 (0.887 sec/batch; 112.786 instances/sec)\n",
      "top_1_accuracy_test =  0.29 top_2_accuracy_test =  0.71\n",
      "Test Accuracy for subject 7 trained on subject 1:\n",
      "Loading datasets...\n",
      "Dataset loading completes.\n",
      "INFO:tensorflow:Restoring parameters from ./trained_model_final/DCNN_reg_ss_crop_subject1\\model.ckpt-401\n",
      "[test  step  401] loss: 2.91848; top_1_accuracy: 0.24000; top_5_accuracy: 0.450000 (0.896 sec/batch; 111.627 instances/sec)\n",
      "top_1_accuracy_test =  0.24 top_2_accuracy_test =  0.45\n",
      "Test Accuracy for subject 8 trained on subject 1:\n",
      "Loading datasets...\n",
      "Dataset loading completes.\n",
      "INFO:tensorflow:Restoring parameters from ./trained_model_final/DCNN_reg_ss_crop_subject1\\model.ckpt-401\n",
      "[test  step  401] loss: 2.36235; top_1_accuracy: 0.39362; top_5_accuracy: 0.574468 (0.982 sec/batch; 95.676 instances/sec)\n",
      "top_1_accuracy_test =  0.39361703 top_2_accuracy_test =  0.5744681\n",
      "Test Accuracy for all subjects trained on subject 1:\n",
      "Loading datasets...\n",
      "Dataset loading completes.\n",
      "INFO:tensorflow:Restoring parameters from ./trained_model_final/DCNN_reg_ss_crop_subject1\\model.ckpt-401\n",
      "[test  step  401] loss: 2.24767; top_1_accuracy: 0.34312; top_5_accuracy: 0.633183 (7.897 sec/batch; 112.197 instances/sec)\n",
      "top_1_accuracy_test =  0.34311512 top_2_accuracy_test =  0.6331828\n",
      "Test Accuracy for subject 0 trained on subject 2:\n",
      "Loading datasets...\n",
      "Dataset loading completes.\n",
      "INFO:tensorflow:Restoring parameters from ./trained_model_final/DCNN_reg_ss_crop_subject2\\model.ckpt-601\n",
      "[test  step  601] loss: 2.27814; top_1_accuracy: 0.63000; top_5_accuracy: 0.830000 (1.266 sec/batch; 78.972 instances/sec)\n",
      "top_1_accuracy_test =  0.63 top_2_accuracy_test =  0.83\n",
      "Test Accuracy for subject 1 trained on subject 2:\n",
      "Loading datasets...\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dataset loading completes.\n",
      "INFO:tensorflow:Restoring parameters from ./trained_model_final/DCNN_reg_ss_crop_subject2\\model.ckpt-601\n",
      "[test  step  601] loss: 4.70516; top_1_accuracy: 0.39000; top_5_accuracy: 0.560000 (1.072 sec/batch; 93.251 instances/sec)\n",
      "top_1_accuracy_test =  0.39 top_2_accuracy_test =  0.56\n",
      "Test Accuracy for subject 2 trained on subject 2:\n",
      "Loading datasets...\n",
      "Dataset loading completes.\n",
      "INFO:tensorflow:Restoring parameters from ./trained_model_final/DCNN_reg_ss_crop_subject2\\model.ckpt-601\n",
      "[test  step  601] loss: 1.15686; top_1_accuracy: 0.80000; top_5_accuracy: 0.950000 (1.034 sec/batch; 96.741 instances/sec)\n",
      "top_1_accuracy_test =  0.8 top_2_accuracy_test =  0.95\n",
      "Test Accuracy for subject 3 trained on subject 2:\n",
      "Loading datasets...\n",
      "Dataset loading completes.\n",
      "INFO:tensorflow:Restoring parameters from ./trained_model_final/DCNN_reg_ss_crop_subject2\\model.ckpt-601\n",
      "[test  step  601] loss: 5.06216; top_1_accuracy: 0.34000; top_5_accuracy: 0.560000 (1.034 sec/batch; 96.722 instances/sec)\n",
      "top_1_accuracy_test =  0.34 top_2_accuracy_test =  0.56\n",
      "Test Accuracy for subject 4 trained on subject 2:\n",
      "Loading datasets...\n",
      "Dataset loading completes.\n",
      "INFO:tensorflow:Restoring parameters from ./trained_model_final/DCNN_reg_ss_crop_subject2\\model.ckpt-601\n",
      "[test  step  601] loss: 4.77143; top_1_accuracy: 0.31915; top_5_accuracy: 0.638298 (1.000 sec/batch; 94.009 instances/sec)\n",
      "top_1_accuracy_test =  0.31914893 top_2_accuracy_test =  0.63829786\n",
      "Test Accuracy for subject 5 trained on subject 2:\n",
      "Loading datasets...\n",
      "Dataset loading completes.\n",
      "INFO:tensorflow:Restoring parameters from ./trained_model_final/DCNN_reg_ss_crop_subject2\\model.ckpt-601\n",
      "[test  step  601] loss: 5.34814; top_1_accuracy: 0.34694; top_5_accuracy: 0.561224 (1.008 sec/batch; 97.176 instances/sec)\n",
      "top_1_accuracy_test =  0.3469388 top_2_accuracy_test =  0.56122446\n",
      "Test Accuracy for subject 6 trained on subject 2:\n",
      "Loading datasets...\n",
      "Dataset loading completes.\n",
      "INFO:tensorflow:Restoring parameters from ./trained_model_final/DCNN_reg_ss_crop_subject2\\model.ckpt-601\n",
      "[test  step  601] loss: 3.98425; top_1_accuracy: 0.37000; top_5_accuracy: 0.700000 (1.020 sec/batch; 98.035 instances/sec)\n",
      "top_1_accuracy_test =  0.37 top_2_accuracy_test =  0.7\n",
      "Test Accuracy for subject 7 trained on subject 2:\n",
      "Loading datasets...\n",
      "Dataset loading completes.\n",
      "INFO:tensorflow:Restoring parameters from ./trained_model_final/DCNN_reg_ss_crop_subject2\\model.ckpt-601\n",
      "[test  step  601] loss: 3.37251; top_1_accuracy: 0.53000; top_5_accuracy: 0.740000 (0.999 sec/batch; 100.128 instances/sec)\n",
      "top_1_accuracy_test =  0.53 top_2_accuracy_test =  0.74\n",
      "Test Accuracy for subject 8 trained on subject 2:\n",
      "Loading datasets...\n",
      "Dataset loading completes.\n",
      "INFO:tensorflow:Restoring parameters from ./trained_model_final/DCNN_reg_ss_crop_subject2\\model.ckpt-601\n",
      "[test  step  601] loss: 3.83706; top_1_accuracy: 0.44681; top_5_accuracy: 0.670213 (0.910 sec/batch; 103.269 instances/sec)\n",
      "top_1_accuracy_test =  0.44680852 top_2_accuracy_test =  0.67021275\n",
      "Test Accuracy for all subjects trained on subject 2:\n",
      "Loading datasets...\n",
      "Dataset loading completes.\n",
      "INFO:tensorflow:Restoring parameters from ./trained_model_final/DCNN_reg_ss_crop_subject2\\model.ckpt-601\n",
      "[test  step  601] loss: 3.87106; top_1_accuracy: 0.44582; top_5_accuracy: 0.693002 (7.896 sec/batch; 112.205 instances/sec)\n",
      "top_1_accuracy_test =  0.44582394 top_2_accuracy_test =  0.6930023\n",
      "Test Accuracy for subject 0 trained on subject 3:\n",
      "Loading datasets...\n",
      "Dataset loading completes.\n",
      "INFO:tensorflow:Restoring parameters from ./trained_model_final/DCNN_reg_ss_crop_subject3\\model.ckpt-401\n",
      "[test  step  401] loss: 3.10036; top_1_accuracy: 0.22000; top_5_accuracy: 0.510000 (0.964 sec/batch; 103.690 instances/sec)\n",
      "top_1_accuracy_test =  0.22 top_2_accuracy_test =  0.51\n",
      "Test Accuracy for subject 1 trained on subject 3:\n",
      "Loading datasets...\n",
      "Dataset loading completes.\n",
      "INFO:tensorflow:Restoring parameters from ./trained_model_final/DCNN_reg_ss_crop_subject3\\model.ckpt-401\n",
      "[test  step  401] loss: 2.58323; top_1_accuracy: 0.28000; top_5_accuracy: 0.550000 (0.974 sec/batch; 102.712 instances/sec)\n",
      "top_1_accuracy_test =  0.28 top_2_accuracy_test =  0.55\n",
      "Test Accuracy for subject 2 trained on subject 3:\n",
      "Loading datasets...\n",
      "Dataset loading completes.\n",
      "INFO:tensorflow:Restoring parameters from ./trained_model_final/DCNN_reg_ss_crop_subject3\\model.ckpt-401\n",
      "[test  step  401] loss: 2.52607; top_1_accuracy: 0.31000; top_5_accuracy: 0.630000 (0.983 sec/batch; 101.757 instances/sec)\n",
      "top_1_accuracy_test =  0.31 top_2_accuracy_test =  0.63\n",
      "Test Accuracy for subject 3 trained on subject 3:\n",
      "Loading datasets...\n",
      "Dataset loading completes.\n",
      "INFO:tensorflow:Restoring parameters from ./trained_model_final/DCNN_reg_ss_crop_subject3\\model.ckpt-401\n",
      "[test  step  401] loss: 1.72374; top_1_accuracy: 0.53000; top_5_accuracy: 0.700000 (0.966 sec/batch; 103.536 instances/sec)\n",
      "top_1_accuracy_test =  0.53 top_2_accuracy_test =  0.7\n",
      "Test Accuracy for subject 4 trained on subject 3:\n",
      "Loading datasets...\n",
      "Dataset loading completes.\n",
      "INFO:tensorflow:Restoring parameters from ./trained_model_final/DCNN_reg_ss_crop_subject3\\model.ckpt-401\n",
      "[test  step  401] loss: 2.01548; top_1_accuracy: 0.41489; top_5_accuracy: 0.659574 (0.936 sec/batch; 100.429 instances/sec)\n",
      "top_1_accuracy_test =  0.41489363 top_2_accuracy_test =  0.65957445\n",
      "Test Accuracy for subject 5 trained on subject 3:\n",
      "Loading datasets...\n",
      "Dataset loading completes.\n",
      "INFO:tensorflow:Restoring parameters from ./trained_model_final/DCNN_reg_ss_crop_subject3\\model.ckpt-401\n",
      "[test  step  401] loss: 2.76591; top_1_accuracy: 0.23469; top_5_accuracy: 0.469388 (0.886 sec/batch; 110.640 instances/sec)\n",
      "top_1_accuracy_test =  0.23469388 top_2_accuracy_test =  0.46938777\n",
      "Test Accuracy for subject 6 trained on subject 3:\n",
      "Loading datasets...\n",
      "Dataset loading completes.\n",
      "INFO:tensorflow:Restoring parameters from ./trained_model_final/DCNN_reg_ss_crop_subject3\\model.ckpt-401\n",
      "[test  step  401] loss: 2.12776; top_1_accuracy: 0.35000; top_5_accuracy: 0.630000 (0.908 sec/batch; 110.145 instances/sec)\n",
      "top_1_accuracy_test =  0.35 top_2_accuracy_test =  0.63\n",
      "Test Accuracy for subject 7 trained on subject 3:\n",
      "Loading datasets...\n",
      "Dataset loading completes.\n",
      "INFO:tensorflow:Restoring parameters from ./trained_model_final/DCNN_reg_ss_crop_subject3\\model.ckpt-401\n",
      "[test  step  401] loss: 2.35322; top_1_accuracy: 0.41000; top_5_accuracy: 0.590000 (0.915 sec/batch; 109.322 instances/sec)\n",
      "top_1_accuracy_test =  0.41 top_2_accuracy_test =  0.59\n",
      "Test Accuracy for subject 8 trained on subject 3:\n",
      "Loading datasets...\n",
      "Dataset loading completes.\n",
      "INFO:tensorflow:Restoring parameters from ./trained_model_final/DCNN_reg_ss_crop_subject3\\model.ckpt-401\n",
      "[test  step  401] loss: 3.65649; top_1_accuracy: 0.32979; top_5_accuracy: 0.563830 (0.838 sec/batch; 112.211 instances/sec)\n",
      "top_1_accuracy_test =  0.32978722 top_2_accuracy_test =  0.5638298\n",
      "Test Accuracy for all subjects trained on subject 3:\n",
      "Loading datasets...\n",
      "Dataset loading completes.\n",
      "INFO:tensorflow:Restoring parameters from ./trained_model_final/DCNN_reg_ss_crop_subject3\\model.ckpt-401\n",
      "[test  step  401] loss: 2.52470; top_1_accuracy: 0.33747; top_5_accuracy: 0.585779 (7.188 sec/batch; 123.263 instances/sec)\n",
      "top_1_accuracy_test =  0.33747178 top_2_accuracy_test =  0.5857788\n",
      "Test Accuracy for subject 0 trained on subject 4:\n",
      "Loading datasets...\n",
      "Dataset loading completes.\n",
      "INFO:tensorflow:Restoring parameters from ./trained_model_final/DCNN_reg_ss_crop_subject4\\model.ckpt-701\n",
      "[test  step  701] loss: 4.02659; top_1_accuracy: 0.27000; top_5_accuracy: 0.630000 (1.041 sec/batch; 96.087 instances/sec)\n",
      "top_1_accuracy_test =  0.27 top_2_accuracy_test =  0.63\n",
      "Test Accuracy for subject 1 trained on subject 4:\n",
      "Loading datasets...\n",
      "Dataset loading completes.\n",
      "INFO:tensorflow:Restoring parameters from ./trained_model_final/DCNN_reg_ss_crop_subject4\\model.ckpt-701\n",
      "[test  step  701] loss: 3.84274; top_1_accuracy: 0.30000; top_5_accuracy: 0.660000 (1.032 sec/batch; 96.885 instances/sec)\n",
      "top_1_accuracy_test =  0.3 top_2_accuracy_test =  0.66\n",
      "Test Accuracy for subject 2 trained on subject 4:\n",
      "Loading datasets...\n",
      "Dataset loading completes.\n",
      "INFO:tensorflow:Restoring parameters from ./trained_model_final/DCNN_reg_ss_crop_subject4\\model.ckpt-701\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[test  step  701] loss: 5.09005; top_1_accuracy: 0.29000; top_5_accuracy: 0.490000 (1.021 sec/batch; 97.911 instances/sec)\n",
      "top_1_accuracy_test =  0.29 top_2_accuracy_test =  0.49\n",
      "Test Accuracy for subject 3 trained on subject 4:\n",
      "Loading datasets...\n",
      "Dataset loading completes.\n",
      "INFO:tensorflow:Restoring parameters from ./trained_model_final/DCNN_reg_ss_crop_subject4\\model.ckpt-701\n",
      "[test  step  701] loss: 2.40200; top_1_accuracy: 0.49000; top_5_accuracy: 0.780000 (1.061 sec/batch; 94.279 instances/sec)\n",
      "top_1_accuracy_test =  0.49 top_2_accuracy_test =  0.78\n",
      "Test Accuracy for subject 4 trained on subject 4:\n",
      "Loading datasets...\n",
      "Dataset loading completes.\n",
      "INFO:tensorflow:Restoring parameters from ./trained_model_final/DCNN_reg_ss_crop_subject4\\model.ckpt-701\n",
      "[test  step  701] loss: 1.77874; top_1_accuracy: 0.64894; top_5_accuracy: 0.829787 (0.970 sec/batch; 96.909 instances/sec)\n",
      "top_1_accuracy_test =  0.64893615 top_2_accuracy_test =  0.82978725\n",
      "Test Accuracy for subject 5 trained on subject 4:\n",
      "Loading datasets...\n",
      "Dataset loading completes.\n",
      "INFO:tensorflow:Restoring parameters from ./trained_model_final/DCNN_reg_ss_crop_subject4\\model.ckpt-701\n",
      "[test  step  701] loss: 4.44557; top_1_accuracy: 0.22449; top_5_accuracy: 0.540816 (1.011 sec/batch; 96.951 instances/sec)\n",
      "top_1_accuracy_test =  0.2244898 top_2_accuracy_test =  0.5408163\n",
      "Test Accuracy for subject 6 trained on subject 4:\n",
      "Loading datasets...\n",
      "Dataset loading completes.\n",
      "INFO:tensorflow:Restoring parameters from ./trained_model_final/DCNN_reg_ss_crop_subject4\\model.ckpt-701\n",
      "[test  step  701] loss: 1.98438; top_1_accuracy: 0.55000; top_5_accuracy: 0.880000 (1.020 sec/batch; 98.054 instances/sec)\n",
      "top_1_accuracy_test =  0.55 top_2_accuracy_test =  0.88\n",
      "Test Accuracy for subject 7 trained on subject 4:\n",
      "Loading datasets...\n",
      "Dataset loading completes.\n",
      "INFO:tensorflow:Restoring parameters from ./trained_model_final/DCNN_reg_ss_crop_subject4\\model.ckpt-701\n",
      "[test  step  701] loss: 3.80113; top_1_accuracy: 0.35000; top_5_accuracy: 0.610000 (0.996 sec/batch; 100.437 instances/sec)\n",
      "top_1_accuracy_test =  0.35 top_2_accuracy_test =  0.61\n",
      "Test Accuracy for subject 8 trained on subject 4:\n",
      "Loading datasets...\n",
      "Dataset loading completes.\n",
      "INFO:tensorflow:Restoring parameters from ./trained_model_final/DCNN_reg_ss_crop_subject4\\model.ckpt-701\n",
      "[test  step  701] loss: 5.16058; top_1_accuracy: 0.29787; top_5_accuracy: 0.510638 (0.929 sec/batch; 101.144 instances/sec)\n",
      "top_1_accuracy_test =  0.29787233 top_2_accuracy_test =  0.5106383\n",
      "Test Accuracy for all subjects trained on subject 4:\n",
      "Loading datasets...\n",
      "Dataset loading completes.\n",
      "INFO:tensorflow:Restoring parameters from ./trained_model_final/DCNN_reg_ss_crop_subject4\\model.ckpt-701\n",
      "[test  step  701] loss: 3.60272; top_1_accuracy: 0.38149; top_5_accuracy: 0.651242 (7.938 sec/batch; 111.609 instances/sec)\n",
      "top_1_accuracy_test =  0.38148984 top_2_accuracy_test =  0.65124154\n",
      "Test Accuracy for subject 0 trained on subject 5:\n",
      "Loading datasets...\n",
      "Dataset loading completes.\n",
      "INFO:tensorflow:Restoring parameters from ./trained_model_final/DCNN_reg_ss_crop_subject5\\model.ckpt-1000\n",
      "[test  step 1000] loss: 4.53367; top_1_accuracy: 0.27000; top_5_accuracy: 0.590000 (0.973 sec/batch; 102.734 instances/sec)\n",
      "top_1_accuracy_test =  0.27 top_2_accuracy_test =  0.59\n",
      "Test Accuracy for subject 1 trained on subject 5:\n",
      "Loading datasets...\n",
      "Dataset loading completes.\n",
      "INFO:tensorflow:Restoring parameters from ./trained_model_final/DCNN_reg_ss_crop_subject5\\model.ckpt-1000\n",
      "[test  step 1000] loss: 4.94267; top_1_accuracy: 0.22000; top_5_accuracy: 0.480000 (0.960 sec/batch; 104.193 instances/sec)\n",
      "top_1_accuracy_test =  0.22 top_2_accuracy_test =  0.48\n",
      "Test Accuracy for subject 2 trained on subject 5:\n",
      "Loading datasets...\n",
      "Dataset loading completes.\n",
      "INFO:tensorflow:Restoring parameters from ./trained_model_final/DCNN_reg_ss_crop_subject5\\model.ckpt-1000\n",
      "[test  step 1000] loss: 3.89114; top_1_accuracy: 0.36000; top_5_accuracy: 0.640000 (0.884 sec/batch; 113.097 instances/sec)\n",
      "top_1_accuracy_test =  0.36 top_2_accuracy_test =  0.64\n",
      "Test Accuracy for subject 3 trained on subject 5:\n",
      "Loading datasets...\n",
      "Dataset loading completes.\n",
      "INFO:tensorflow:Restoring parameters from ./trained_model_final/DCNN_reg_ss_crop_subject5\\model.ckpt-1000\n",
      "[test  step 1000] loss: 3.34466; top_1_accuracy: 0.29000; top_5_accuracy: 0.580000 (0.879 sec/batch; 113.754 instances/sec)\n",
      "top_1_accuracy_test =  0.29 top_2_accuracy_test =  0.58\n",
      "Test Accuracy for subject 4 trained on subject 5:\n",
      "Loading datasets...\n",
      "Dataset loading completes.\n",
      "INFO:tensorflow:Restoring parameters from ./trained_model_final/DCNN_reg_ss_crop_subject5\\model.ckpt-1000\n",
      "[test  step 1000] loss: 3.85864; top_1_accuracy: 0.39362; top_5_accuracy: 0.648936 (0.862 sec/batch; 109.036 instances/sec)\n",
      "top_1_accuracy_test =  0.39361703 top_2_accuracy_test =  0.64893615\n",
      "Test Accuracy for subject 5 trained on subject 5:\n",
      "Loading datasets...\n",
      "Dataset loading completes.\n",
      "INFO:tensorflow:Restoring parameters from ./trained_model_final/DCNN_reg_ss_crop_subject5\\model.ckpt-1000\n",
      "[test  step 1000] loss: 2.83683; top_1_accuracy: 0.47959; top_5_accuracy: 0.785714 (0.878 sec/batch; 111.587 instances/sec)\n",
      "top_1_accuracy_test =  0.47959185 top_2_accuracy_test =  0.78571427\n",
      "Test Accuracy for subject 6 trained on subject 5:\n",
      "Loading datasets...\n",
      "Dataset loading completes.\n",
      "INFO:tensorflow:Restoring parameters from ./trained_model_final/DCNN_reg_ss_crop_subject5\\model.ckpt-1000\n",
      "[test  step 1000] loss: 4.45319; top_1_accuracy: 0.27000; top_5_accuracy: 0.670000 (0.899 sec/batch; 111.190 instances/sec)\n",
      "top_1_accuracy_test =  0.27 top_2_accuracy_test =  0.67\n",
      "Test Accuracy for subject 7 trained on subject 5:\n",
      "Loading datasets...\n",
      "Dataset loading completes.\n",
      "INFO:tensorflow:Restoring parameters from ./trained_model_final/DCNN_reg_ss_crop_subject5\\model.ckpt-1000\n",
      "[test  step 1000] loss: 3.82666; top_1_accuracy: 0.31000; top_5_accuracy: 0.620000 (0.892 sec/batch; 112.114 instances/sec)\n",
      "top_1_accuracy_test =  0.31 top_2_accuracy_test =  0.62\n",
      "Test Accuracy for subject 8 trained on subject 5:\n",
      "Loading datasets...\n",
      "Dataset loading completes.\n",
      "INFO:tensorflow:Restoring parameters from ./trained_model_final/DCNN_reg_ss_crop_subject5\\model.ckpt-1000\n",
      "[test  step 1000] loss: 4.93020; top_1_accuracy: 0.31915; top_5_accuracy: 0.585106 (0.847 sec/batch; 110.959 instances/sec)\n",
      "top_1_accuracy_test =  0.31914893 top_2_accuracy_test =  0.5851064\n",
      "Test Accuracy for all subjects trained on subject 5:\n",
      "Loading datasets...\n",
      "Dataset loading completes.\n",
      "INFO:tensorflow:Restoring parameters from ./trained_model_final/DCNN_reg_ss_crop_subject5\\model.ckpt-1000\n",
      "[test  step 1000] loss: 4.03716; top_1_accuracy: 0.32280; top_5_accuracy: 0.632054 (7.210 sec/batch; 122.876 instances/sec)\n",
      "top_1_accuracy_test =  0.3227991 top_2_accuracy_test =  0.63205415\n",
      "Test Accuracy for subject 0 trained on subject 6:\n",
      "Loading datasets...\n",
      "Dataset loading completes.\n",
      "INFO:tensorflow:Restoring parameters from ./trained_model_final/DCNN_reg_ss_crop_subject6\\model.ckpt-901\n",
      "[test  step  901] loss: 4.58300; top_1_accuracy: 0.35000; top_5_accuracy: 0.660000 (0.940 sec/batch; 106.335 instances/sec)\n",
      "top_1_accuracy_test =  0.35 top_2_accuracy_test =  0.66\n",
      "Test Accuracy for subject 1 trained on subject 6:\n",
      "Loading datasets...\n",
      "Dataset loading completes.\n",
      "INFO:tensorflow:Restoring parameters from ./trained_model_final/DCNN_reg_ss_crop_subject6\\model.ckpt-901\n",
      "[test  step  901] loss: 5.38838; top_1_accuracy: 0.24000; top_5_accuracy: 0.550000 (0.952 sec/batch; 105.046 instances/sec)\n",
      "top_1_accuracy_test =  0.24 top_2_accuracy_test =  0.55\n",
      "Test Accuracy for subject 2 trained on subject 6:\n",
      "Loading datasets...\n",
      "Dataset loading completes.\n",
      "INFO:tensorflow:Restoring parameters from ./trained_model_final/DCNN_reg_ss_crop_subject6\\model.ckpt-901\n",
      "[test  step  901] loss: 7.18485; top_1_accuracy: 0.28000; top_5_accuracy: 0.550000 (0.938 sec/batch; 106.635 instances/sec)\n",
      "top_1_accuracy_test =  0.28 top_2_accuracy_test =  0.55\n",
      "Test Accuracy for subject 3 trained on subject 6:\n",
      "Loading datasets...\n",
      "Dataset loading completes.\n",
      "INFO:tensorflow:Restoring parameters from ./trained_model_final/DCNN_reg_ss_crop_subject6\\model.ckpt-901\n",
      "[test  step  901] loss: 2.87247; top_1_accuracy: 0.62000; top_5_accuracy: 0.750000 (0.939 sec/batch; 106.550 instances/sec)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "top_1_accuracy_test =  0.62 top_2_accuracy_test =  0.75\n",
      "Test Accuracy for subject 4 trained on subject 6:\n",
      "Loading datasets...\n",
      "Dataset loading completes.\n",
      "INFO:tensorflow:Restoring parameters from ./trained_model_final/DCNN_reg_ss_crop_subject6\\model.ckpt-901\n",
      "[test  step  901] loss: 3.16881; top_1_accuracy: 0.60638; top_5_accuracy: 0.723404 (0.882 sec/batch; 106.542 instances/sec)\n",
      "top_1_accuracy_test =  0.60638297 top_2_accuracy_test =  0.7234042\n",
      "Test Accuracy for subject 5 trained on subject 6:\n",
      "Loading datasets...\n",
      "Dataset loading completes.\n",
      "INFO:tensorflow:Restoring parameters from ./trained_model_final/DCNN_reg_ss_crop_subject6\\model.ckpt-901\n",
      "[test  step  901] loss: 5.00401; top_1_accuracy: 0.28571; top_5_accuracy: 0.540816 (1.007 sec/batch; 97.361 instances/sec)\n",
      "top_1_accuracy_test =  0.2857143 top_2_accuracy_test =  0.5408163\n",
      "Test Accuracy for subject 6 trained on subject 6:\n",
      "Loading datasets...\n",
      "Dataset loading completes.\n",
      "INFO:tensorflow:Restoring parameters from ./trained_model_final/DCNN_reg_ss_crop_subject6\\model.ckpt-901\n",
      "[test  step  901] loss: 1.55956; top_1_accuracy: 0.78000; top_5_accuracy: 0.910000 (1.019 sec/batch; 98.144 instances/sec)\n",
      "top_1_accuracy_test =  0.78 top_2_accuracy_test =  0.91\n",
      "Test Accuracy for subject 7 trained on subject 6:\n",
      "Loading datasets...\n",
      "Dataset loading completes.\n",
      "INFO:tensorflow:Restoring parameters from ./trained_model_final/DCNN_reg_ss_crop_subject6\\model.ckpt-901\n",
      "[test  step  901] loss: 4.39656; top_1_accuracy: 0.46000; top_5_accuracy: 0.660000 (1.021 sec/batch; 97.988 instances/sec)\n",
      "top_1_accuracy_test =  0.46 top_2_accuracy_test =  0.66\n",
      "Test Accuracy for subject 8 trained on subject 6:\n",
      "Loading datasets...\n",
      "Dataset loading completes.\n",
      "INFO:tensorflow:Restoring parameters from ./trained_model_final/DCNN_reg_ss_crop_subject6\\model.ckpt-901\n",
      "[test  step  901] loss: 5.94499; top_1_accuracy: 0.37234; top_5_accuracy: 0.617021 (0.933 sec/batch; 100.766 instances/sec)\n",
      "top_1_accuracy_test =  0.3723404 top_2_accuracy_test =  0.61702126\n",
      "Test Accuracy for all subjects trained on subject 6:\n",
      "Loading datasets...\n",
      "Dataset loading completes.\n",
      "INFO:tensorflow:Restoring parameters from ./trained_model_final/DCNN_reg_ss_crop_subject6\\model.ckpt-901\n",
      "[test  step  901] loss: 4.48243; top_1_accuracy: 0.44582; top_5_accuracy: 0.674944 (7.842 sec/batch; 112.977 instances/sec)\n",
      "top_1_accuracy_test =  0.44582394 top_2_accuracy_test =  0.67494357\n",
      "Test Accuracy for subject 0 trained on subject 7:\n",
      "Loading datasets...\n",
      "Dataset loading completes.\n",
      "INFO:tensorflow:Restoring parameters from ./trained_model_final/DCNN_reg_ss_crop_subject7\\model.ckpt-601\n",
      "[test  step  601] loss: 4.35772; top_1_accuracy: 0.35000; top_5_accuracy: 0.560000 (0.896 sec/batch; 111.664 instances/sec)\n",
      "top_1_accuracy_test =  0.35 top_2_accuracy_test =  0.56\n",
      "Test Accuracy for subject 1 trained on subject 7:\n",
      "Loading datasets...\n",
      "Dataset loading completes.\n",
      "INFO:tensorflow:Restoring parameters from ./trained_model_final/DCNN_reg_ss_crop_subject7\\model.ckpt-601\n",
      "[test  step  601] loss: 8.24120; top_1_accuracy: 0.27000; top_5_accuracy: 0.470000 (0.916 sec/batch; 109.213 instances/sec)\n",
      "top_1_accuracy_test =  0.27 top_2_accuracy_test =  0.47\n",
      "Test Accuracy for subject 2 trained on subject 7:\n",
      "Loading datasets...\n",
      "Dataset loading completes.\n",
      "INFO:tensorflow:Restoring parameters from ./trained_model_final/DCNN_reg_ss_crop_subject7\\model.ckpt-601\n",
      "[test  step  601] loss: 3.67331; top_1_accuracy: 0.47000; top_5_accuracy: 0.660000 (0.901 sec/batch; 110.953 instances/sec)\n",
      "top_1_accuracy_test =  0.47 top_2_accuracy_test =  0.66\n",
      "Test Accuracy for subject 3 trained on subject 7:\n",
      "Loading datasets...\n",
      "Dataset loading completes.\n",
      "INFO:tensorflow:Restoring parameters from ./trained_model_final/DCNN_reg_ss_crop_subject7\\model.ckpt-601\n",
      "[test  step  601] loss: 4.93729; top_1_accuracy: 0.27000; top_5_accuracy: 0.470000 (0.925 sec/batch; 108.156 instances/sec)\n",
      "top_1_accuracy_test =  0.27 top_2_accuracy_test =  0.47\n",
      "Test Accuracy for subject 4 trained on subject 7:\n",
      "Loading datasets...\n",
      "Dataset loading completes.\n",
      "INFO:tensorflow:Restoring parameters from ./trained_model_final/DCNN_reg_ss_crop_subject7\\model.ckpt-601\n",
      "[test  step  601] loss: 5.76231; top_1_accuracy: 0.38298; top_5_accuracy: 0.553191 (0.851 sec/batch; 110.518 instances/sec)\n",
      "top_1_accuracy_test =  0.38297874 top_2_accuracy_test =  0.5531915\n",
      "Test Accuracy for subject 5 trained on subject 7:\n",
      "Loading datasets...\n",
      "Dataset loading completes.\n",
      "INFO:tensorflow:Restoring parameters from ./trained_model_final/DCNN_reg_ss_crop_subject7\\model.ckpt-601\n",
      "[test  step  601] loss: 4.32438; top_1_accuracy: 0.32653; top_5_accuracy: 0.591837 (0.901 sec/batch; 108.795 instances/sec)\n",
      "top_1_accuracy_test =  0.3265306 top_2_accuracy_test =  0.59183675\n",
      "Test Accuracy for subject 6 trained on subject 7:\n",
      "Loading datasets...\n",
      "Dataset loading completes.\n",
      "INFO:tensorflow:Restoring parameters from ./trained_model_final/DCNN_reg_ss_crop_subject7\\model.ckpt-601\n",
      "[test  step  601] loss: 5.67440; top_1_accuracy: 0.23000; top_5_accuracy: 0.480000 (0.916 sec/batch; 109.176 instances/sec)\n",
      "top_1_accuracy_test =  0.23 top_2_accuracy_test =  0.48\n",
      "Test Accuracy for subject 7 trained on subject 7:\n",
      "Loading datasets...\n",
      "Dataset loading completes.\n",
      "INFO:tensorflow:Restoring parameters from ./trained_model_final/DCNN_reg_ss_crop_subject7\\model.ckpt-601\n",
      "[test  step  601] loss: 1.69147; top_1_accuracy: 0.70000; top_5_accuracy: 0.900000 (0.924 sec/batch; 108.213 instances/sec)\n",
      "top_1_accuracy_test =  0.7 top_2_accuracy_test =  0.9\n",
      "Test Accuracy for subject 8 trained on subject 7:\n",
      "Loading datasets...\n",
      "Dataset loading completes.\n",
      "INFO:tensorflow:Restoring parameters from ./trained_model_final/DCNN_reg_ss_crop_subject7\\model.ckpt-601\n",
      "[test  step  601] loss: 2.52370; top_1_accuracy: 0.61702; top_5_accuracy: 0.851064 (0.852 sec/batch; 110.284 instances/sec)\n",
      "top_1_accuracy_test =  0.61702126 top_2_accuracy_test =  0.85106385\n",
      "Test Accuracy for all subjects trained on subject 7:\n",
      "Loading datasets...\n",
      "Dataset loading completes.\n",
      "INFO:tensorflow:Restoring parameters from ./trained_model_final/DCNN_reg_ss_crop_subject7\\model.ckpt-601\n",
      "[test  step  601] loss: 4.57923; top_1_accuracy: 0.40181; top_5_accuracy: 0.615124 (7.241 sec/batch; 122.362 instances/sec)\n",
      "top_1_accuracy_test =  0.40180588 top_2_accuracy_test =  0.61512417\n",
      "Test Accuracy for subject 0 trained on subject 8:\n",
      "Loading datasets...\n",
      "Dataset loading completes.\n",
      "INFO:tensorflow:Restoring parameters from ./trained_model_final/DCNN_reg_ss_crop_subject8\\model.ckpt-901\n",
      "[test  step  901] loss: 3.86321; top_1_accuracy: 0.43000; top_5_accuracy: 0.630000 (0.901 sec/batch; 111.008 instances/sec)\n",
      "top_1_accuracy_test =  0.43 top_2_accuracy_test =  0.63\n",
      "Test Accuracy for subject 1 trained on subject 8:\n",
      "Loading datasets...\n",
      "Dataset loading completes.\n",
      "INFO:tensorflow:Restoring parameters from ./trained_model_final/DCNN_reg_ss_crop_subject8\\model.ckpt-901\n",
      "[test  step  901] loss: 7.17457; top_1_accuracy: 0.28000; top_5_accuracy: 0.550000 (0.957 sec/batch; 104.450 instances/sec)\n",
      "top_1_accuracy_test =  0.28 top_2_accuracy_test =  0.55\n",
      "Test Accuracy for subject 2 trained on subject 8:\n",
      "Loading datasets...\n",
      "Dataset loading completes.\n",
      "INFO:tensorflow:Restoring parameters from ./trained_model_final/DCNN_reg_ss_crop_subject8\\model.ckpt-901\n",
      "[test  step  901] loss: 3.13960; top_1_accuracy: 0.47000; top_5_accuracy: 0.680000 (0.954 sec/batch; 104.777 instances/sec)\n",
      "top_1_accuracy_test =  0.47 top_2_accuracy_test =  0.68\n",
      "Test Accuracy for subject 3 trained on subject 8:\n",
      "Loading datasets...\n",
      "Dataset loading completes.\n",
      "INFO:tensorflow:Restoring parameters from ./trained_model_final/DCNN_reg_ss_crop_subject8\\model.ckpt-901\n",
      "[test  step  901] loss: 6.67757; top_1_accuracy: 0.19000; top_5_accuracy: 0.440000 (0.949 sec/batch; 105.349 instances/sec)\n",
      "top_1_accuracy_test =  0.19 top_2_accuracy_test =  0.44\n",
      "Test Accuracy for subject 4 trained on subject 8:\n",
      "Loading datasets...\n",
      "Dataset loading completes.\n",
      "INFO:tensorflow:Restoring parameters from ./trained_model_final/DCNN_reg_ss_crop_subject8\\model.ckpt-901\n",
      "[test  step  901] loss: 5.92560; top_1_accuracy: 0.39362; top_5_accuracy: 0.563830 (0.890 sec/batch; 105.621 instances/sec)\n",
      "top_1_accuracy_test =  0.39361703 top_2_accuracy_test =  0.5638298\n",
      "Test Accuracy for subject 5 trained on subject 8:\n",
      "Loading datasets...\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dataset loading completes.\n",
      "INFO:tensorflow:Restoring parameters from ./trained_model_final/DCNN_reg_ss_crop_subject8\\model.ckpt-901\n",
      "[test  step  901] loss: 3.96138; top_1_accuracy: 0.30612; top_5_accuracy: 0.561224 (0.921 sec/batch; 106.407 instances/sec)\n",
      "top_1_accuracy_test =  0.30612245 top_2_accuracy_test =  0.56122446\n",
      "Test Accuracy for subject 6 trained on subject 8:\n",
      "Loading datasets...\n",
      "Dataset loading completes.\n",
      "INFO:tensorflow:Restoring parameters from ./trained_model_final/DCNN_reg_ss_crop_subject8\\model.ckpt-901\n",
      "[test  step  901] loss: 5.37648; top_1_accuracy: 0.31000; top_5_accuracy: 0.610000 (0.926 sec/batch; 107.967 instances/sec)\n",
      "top_1_accuracy_test =  0.31 top_2_accuracy_test =  0.61\n",
      "Test Accuracy for subject 7 trained on subject 8:\n",
      "Loading datasets...\n",
      "Dataset loading completes.\n",
      "INFO:tensorflow:Restoring parameters from ./trained_model_final/DCNN_reg_ss_crop_subject8\\model.ckpt-901\n",
      "[test  step  901] loss: 2.89209; top_1_accuracy: 0.49000; top_5_accuracy: 0.790000 (0.929 sec/batch; 107.588 instances/sec)\n",
      "top_1_accuracy_test =  0.49 top_2_accuracy_test =  0.79\n",
      "Test Accuracy for subject 8 trained on subject 8:\n",
      "Loading datasets...\n",
      "Dataset loading completes.\n",
      "INFO:tensorflow:Restoring parameters from ./trained_model_final/DCNN_reg_ss_crop_subject8\\model.ckpt-901\n",
      "[test  step  901] loss: 1.03931; top_1_accuracy: 0.85106; top_5_accuracy: 0.957447 (0.975 sec/batch; 96.429 instances/sec)\n",
      "top_1_accuracy_test =  0.85106385 top_2_accuracy_test =  0.9574468\n",
      "Test Accuracy for all subjects trained on subject 8:\n",
      "Loading datasets...\n",
      "Dataset loading completes.\n",
      "INFO:tensorflow:Restoring parameters from ./trained_model_final/DCNN_reg_ss_crop_subject8\\model.ckpt-901\n",
      "[test  step  901] loss: 4.49945; top_1_accuracy: 0.40632; top_5_accuracy: 0.642212 (7.954 sec/batch; 111.388 instances/sec)\n",
      "top_1_accuracy_test =  0.40632054 top_2_accuracy_test =  0.6422122\n"
     ]
    }
   ],
   "source": [
    "# Test model accuracy on each subject\n",
    "subject_id1 = np.arange(9)\n",
    "subject_id2 = np.arange(10)\n",
    "start = 0\n",
    "stop = 250\n",
    "step = 10\n",
    "time_length = 700\n",
    "time_bin = 350\n",
    "#Nb = BATCH_SIZE\n",
    "fsz = 3\n",
    "use_batchnorm = True\n",
    "use_dropout = True\n",
    "use_l2loss = True\n",
    "\n",
    "for sub_id1 in subject_id1:\n",
    "    path = 'Path_subject'+str(sub_id1) \n",
    "    model_dir = best_val_ss_crop_subject[path]\n",
    "\n",
    "    for sub_id2 in subject_id2:\n",
    "        if sub_id2 < 9:\n",
    "            print('Test Accuracy for subject {} trained on subject {}:'.format(sub_id2,sub_id1))\n",
    "        else:\n",
    "            print('Test Accuracy for all subjects trained on subject {}:'.format(sub_id1))\n",
    "        top_1_acc_test, top_2_acc_test = test_model_ss_subject(sub_id2,model_dir,start,stop,step,time_length,time_bin,fsz,use_batchnorm,use_dropout,use_l2loss)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of trials of subject 0 : 418\n",
      "Number of trials of subject 1 : 420\n",
      "Number of trials of subject 2 : 434\n",
      "Number of trials of subject 3 : 428\n",
      "Number of trials of subject 4 : 422\n",
      "Number of trials of subject 5 : 416\n",
      "Number of trials of subject 6 : 442\n",
      "Number of trials of subject 7 : 408\n",
      "Number of trials of subject 8 : 418\n"
     ]
    }
   ],
   "source": [
    "for sub_id in range(9):\n",
    "    trainSet,_,_,_ = data_loader_ss_subject(700,sub_id)\n",
    "    num_sub = trainSet['data'].shape[0]\n",
    "    print('Number of trials of subject {} : {}'.format(sub_id,num_sub))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
