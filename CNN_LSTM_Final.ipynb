{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from __future__ import absolute_import\n",
    "from __future__ import division\n",
    "from __future__ import print_function\n",
    "\n",
    "import tensorflow as tf\n",
    "import numpy as np\n",
    "import time\n",
    "import os\n",
    "from datetime import datetime\n",
    "\n",
    "from model_final_rnn import Model\n",
    "from configs_final_rnn import config\n",
    "from tensorflow.core.protobuf import rewriter_config_pb2\n",
    "from sklearn.model_selection import train_test_split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "def data_loader_ss_subject(time_bin,sub_id):\n",
    "    X_test = np.load(\"X_test.npy\")\n",
    "    X_test = X_test[:,0:22,0:time_bin]\n",
    "    y_test = np.load(\"y_test.npy\")\n",
    "    person_test = np.load(\"person_test.npy\")\n",
    "\n",
    "    X_train_valid = np.load(\"X_train_valid.npy\")\n",
    "    X_train_valid = X_train_valid[:,0:22,0:time_bin]\n",
    "    y_train_valid = np.load(\"y_train_valid.npy\")\n",
    "    person_train_valid = np.load(\"person_train_valid.npy\")\n",
    "    \n",
    "    N_train = X_train_valid.shape[0]\n",
    "    idx_train_valid = np.arange(N_train,dtype='int')\n",
    "\n",
    "    X_train, X_val, idx_train, idx_val = train_test_split(X_train_valid, idx_train_valid, test_size=0.1, random_state=21)\n",
    "\n",
    "    y_train = y_train_valid[idx_train]\n",
    "    person_train = person_train_valid[idx_train]\n",
    "    y_val = y_train_valid[idx_val]\n",
    "    person_val = person_train_valid[idx_val]\n",
    "    \n",
    "    idx11 = np.arange(0,X_test.shape[2],2,dtype=int)\n",
    "    idx21 = np.arange(1,X_test.shape[2],2,dtype=int)\n",
    "    X_test_ss1 = np.take(X_test,idx11,axis=2)\n",
    "    X_test_ss2 = np.take(X_test,idx21,axis=2)\n",
    "    X_test = np.concatenate((X_test_ss1,X_test_ss2),axis=0)\n",
    "    y_test = np.concatenate((y_test,y_test),axis=0)\n",
    "    person_test = np.concatenate((person_test,person_test),axis=0)\n",
    "    \n",
    "    idx12 = np.arange(0,X_train.shape[2],2,dtype=int)\n",
    "    idx22 = np.arange(1,X_train.shape[2],2,dtype=int)\n",
    "    X_train_ss1 = np.take(X_train,idx12,axis=2)\n",
    "    X_train_ss2 = np.take(X_train,idx22,axis=2)\n",
    "    X_train = np.concatenate((X_train_ss1,X_train_ss2),axis=0)\n",
    "    y_train = np.concatenate((y_train,y_train),axis=0)\n",
    "    person_train = np.concatenate((person_train,person_train),axis=0)\n",
    "    \n",
    "    idx13 = np.arange(0,X_val.shape[2],2,dtype=int)\n",
    "    idx23 = np.arange(1,X_val.shape[2],2,dtype=int)\n",
    "    X_val_ss1 = np.take(X_val,idx13,axis=2)\n",
    "    X_val_ss2 = np.take(X_val,idx23,axis=2)\n",
    "    X_val = np.concatenate((X_val_ss1,X_val_ss2),axis=0)\n",
    "    y_val = np.concatenate((y_val,y_val),axis=0)\n",
    "    person_val = np.concatenate((person_val,person_val),axis=0)\n",
    "\n",
    "    tl = X_train.shape[2]\n",
    "    X_test = np.reshape(X_test,(-1,22,tl,1))\n",
    "    X_train = np.reshape(X_train,(-1,22,tl,1))\n",
    "    X_val = np.reshape(X_val,(-1,22,tl,1))\n",
    "    \n",
    "    if sub_id<9:\n",
    "        subid_test = np.where(person_test==sub_id)\n",
    "        person_test = np.take(person_test,subid_test[0],axis=0)\n",
    "        X_test = np.take(X_test,subid_test[0],axis=0)\n",
    "        y_test = np.take(y_test,subid_test[0],axis=0)\n",
    "        subid_val = np.where(person_val==sub_id)\n",
    "        person_val = np.take(person_val,subid_val[0],axis=0)\n",
    "        X_val = np.take(X_val,subid_val[0],axis=0)\n",
    "        y_val = np.take(y_val,subid_val[0],axis=0)\n",
    "        subid_train = np.where(person_train==sub_id)\n",
    "        person_train = np.take(person_train,subid_train[0],axis=0)\n",
    "        X_train = np.take(X_train,subid_train[0],axis=0)\n",
    "        y_train = np.take(y_train,subid_train[0],axis=0)\n",
    "\n",
    "    label0 = 769\n",
    "    new_label0 = 0\n",
    "    for i in range(4):\n",
    "        m1 = (y_test==label0)\n",
    "        m2 = (y_train==label0)\n",
    "        m3 = (y_val==label0)\n",
    "        np.place(y_test,m1,new_label0)\n",
    "        np.place(y_train,m2,new_label0)\n",
    "        np.place(y_val,m3,new_label0)\n",
    "        label0 += 1\n",
    "        new_label0 += 1\n",
    "\n",
    "    labelNames = [0,1,2,3]\n",
    "    train_set = {'data': X_train, 'labels': y_train, 'person': person_train}\n",
    "    test_set = {'data': X_test, 'labels': y_test, 'person': person_test}\n",
    "    val_set = {'data': X_val, 'labels': y_val, 'person': person_val}\n",
    "    return train_set, test_set, val_set, labelNames\n",
    "\n",
    "def sample_batch(dataset, batch_size):\n",
    "    N = dataset['data'].shape[0]\n",
    "    indices = np.random.randint(N, size=batch_size)\n",
    "    return {key: dataset[key][indices] for key in dataset}\n",
    "\n",
    "def train_model_ss_subject(sub_id,target_dir,start,stop,step,time_length,time_bin,fsz,use_batchnorm,use_dropout,use_l2loss,num_class,max_step,log_frequency,batch_size,model_saving_freq):\n",
    "    # load data\n",
    "    print(\"Loading datasets...\")\n",
    "    trainSet, testSet, valSet, labelNames = data_loader_ss_subject(time_length,sub_id)\n",
    "    print(\"Dataset loading completes.\")\n",
    "    \n",
    "    best_val_acc = 0\n",
    "    best_val_path = target_dir\n",
    "    \n",
    "\n",
    "\n",
    "    # reset default graph\n",
    "    tf.reset_default_graph()\n",
    "\n",
    "    global_step = tf.train.get_or_create_global_step()\n",
    "    \n",
    "    model = Model(config, labelNames,start,stop,step,time_bin,fsz,use_batchnorm,use_dropout,use_l2loss)\n",
    "\n",
    "    # training setups\n",
    "    saver = tf.train.Saver(max_to_keep=100)\n",
    "\n",
    "    # Build an initialization operation to run below.\n",
    "    init = tf.global_variables_initializer()\n",
    "    \n",
    "    config_proto = tf.ConfigProto()\n",
    "\n",
    "    off = rewriter_config_pb2.RewriterConfig.OFF\n",
    "    config_proto.graph_options.rewrite_options.arithmetic_optimization = off\n",
    "    \n",
    "    sess = tf.Session(config=config_proto)\n",
    "\n",
    "    sess.run(init)\n",
    "\n",
    "    # main loop\n",
    "    for step in range(max_step):\n",
    "        start_time = time.time()\n",
    "\n",
    "        # prepare data\n",
    "        train_batch = sample_batch(trainSet, batch_size)\n",
    "        # feed dict\n",
    "        feed_dict = {\n",
    "            model.input: train_batch['data'],\n",
    "            model.fine_labels: train_batch['labels'],\n",
    "            model.is_training: True,\n",
    "        }\n",
    "        \n",
    "        fetch_list = [model.optimizer_op, model.loss, model.global_step]\n",
    "        _, loss_value, global_step_value = sess.run(fetch_list, feed_dict=feed_dict)\n",
    "        duration = time.time() - start_time\n",
    "        assert not np.isnan(loss_value), 'Model diverged with loss = NaN'\n",
    "\n",
    "        # log\n",
    "        if step % log_frequency == 0:\n",
    "            num_examples_per_step = batch_size\n",
    "            examples_per_sec = num_examples_per_step / duration\n",
    "            sec_per_batch = duration\n",
    "            format_str = (\n",
    "                '%s: step %d, examples %d, loss = %.9f (%.3f examples/sec; %.3f sec/batch)'\n",
    "            )\n",
    "            print(\n",
    "                format_str % (\n",
    "                    datetime.now(), step, batch_size * step,\n",
    "                    loss_value,\n",
    "                    examples_per_sec, sec_per_batch\n",
    "                )\n",
    "            )\n",
    "\n",
    "        # Save the model checkpoint periodically.\n",
    "        if step % model_saving_freq == 0 or (step + 1) == max_step:\n",
    "            fetch_list = [model.accuracy,model.top_2_accuracy]\n",
    "            feed_dict = {\n",
    "                model.input: valSet['data'],\n",
    "                model.fine_labels: valSet['labels'],\n",
    "                model.is_training: False,\n",
    "            }\n",
    "            val_acc_1, val_acc_2 =  sess.run(fetch_list, feed_dict=feed_dict)\n",
    "            checkpoint_path = os.path.join(target_dir, 'model.ckpt')\n",
    "            saver.save(sess, checkpoint_path, global_step=int(global_step_value))\n",
    "            print('Top 1 validation accuracy: {} and top 2 validation accuracy: {}'.format(val_acc_1,val_acc_2))\n",
    "            print('Model Saved!')\n",
    "            if val_acc_1>best_val_acc:\n",
    "                best_val_acc = val_acc_1\n",
    "                best_val_path = checkpoint_path+'-'+str(int(global_step_value))\n",
    "    return best_val_acc,best_val_path\n",
    "\n",
    "\n",
    "def test_model_ss_subject(sub_id,model_dir,start,stop,step,time_length,time_bin,fsz,use_batchnorm,use_dropout,use_l2loss):\n",
    "    print(\"Loading datasets...\")\n",
    "    trainSet, testSet, valSet, labelNames = data_loader_ss_subject(time_length,sub_id)\n",
    "    print(\"Dataset loading completes.\")\n",
    "    \n",
    "    # reset default graph\n",
    "    tf.reset_default_graph()\n",
    "    \n",
    "    # create model\n",
    "    \n",
    "    model = Model(config, labelNames,start,stop,step,time_bin,fsz,use_batchnorm,use_dropout,use_l2loss)\n",
    "    # training setups\n",
    "    saver = tf.train.Saver(max_to_keep=100)\n",
    "    test_accuracy = [0, 0]\n",
    "    \n",
    "    config_proto = tf.ConfigProto()\n",
    "\n",
    "    off = rewriter_config_pb2.RewriterConfig.OFF\n",
    "    config_proto.graph_options.rewrite_options.arithmetic_optimization = off\n",
    "\n",
    "    with tf.Session(config=config_proto) as session:\n",
    "        session.run(tf.global_variables_initializer())\n",
    "        saver.restore(session, model_dir)\n",
    "        # test model\n",
    "        exp_results = run_single_step(session, model, testSet, mode='test')\n",
    "        test_accuracy[0] = exp_results['top_1_accuracy']\n",
    "        test_accuracy[1] = exp_results['top_2_accuracy']\n",
    "        print('top_1_accuracy_test = ', test_accuracy[0], 'top_2_accuracy_test = ', test_accuracy[1])\n",
    "        \n",
    "    top1_acc = test_accuracy[0]\n",
    "    top2_acc = test_accuracy[1]\n",
    "    return top1_acc,top2_acc\n",
    "\n",
    "\n",
    "def run_single_step(\n",
    "        session,\n",
    "        model,\n",
    "        batch,\n",
    "        mode='test',\n",
    "        log=True,\n",
    "):\n",
    "    # construct feed dict\n",
    "    feed_dict = {\n",
    "        model.input: batch['data'],\n",
    "        # model.coarse_labels: batch['coarse_labels'],\n",
    "        model.fine_labels: batch['labels'],\n",
    "        # model.label_mapping: label_mapping,\n",
    "        model.is_training: mode == 'train'\n",
    "    }\n",
    "    \n",
    "    # select proper summary op\n",
    "    if mode == 'train':\n",
    "        summary_op = model.train_summary_op\n",
    "    elif mode == 'val':\n",
    "        summary_op = model.val_summary_op\n",
    "    else:\n",
    "        summary_op = model.test_summary_op\n",
    "    \n",
    "    # construct fetch list\n",
    "    fetch_list = [model.global_step, summary_op, model.loss, model.accuracy, model.top_2_accuracy]\n",
    "\n",
    "    # run single step\n",
    "    _start_time = time.time()\n",
    "    _step, _summary, _loss, _top_1, _top_2 = session.run(fetch_list, feed_dict=feed_dict)[:5]\n",
    "    _end_time = time.time()\n",
    "    \n",
    "    # collect step statistics\n",
    "    step_time = _end_time - _start_time\n",
    "    batch_size = batch['data'].shape[0]\n",
    "    \n",
    "    # log in console\n",
    "    if log:\n",
    "        print(('[{:5s} step {:4d}] loss: {:.5f}; top_1_accuracy: {:.5f}; top_5_accuracy: {:5f} ' +\n",
    "              '({:.3f} sec/batch; {:.3f} instances/sec)'\n",
    "              ).format(mode, _step, _loss, _top_1, _top_2, \n",
    "                       step_time, batch_size / step_time))\n",
    "    \n",
    "    # log results to file and return statistics\n",
    "    if mode == 'test':\n",
    "        test_fetch_list = [model.per_class_accuracy,\n",
    "                model.top_2_per_class_accuracy,\n",
    "                model.confusion_matrix, \n",
    "                model.pred, model.probs]\n",
    "        _top_1_c,  _top_2_c, _cm, _pred, _probs = \\\n",
    "                session.run(test_fetch_list, feed_dict=feed_dict)\n",
    "        \n",
    "        \n",
    "        # Log detailed test results in pickle format\n",
    "        stats = {\n",
    "            \"loss\": _loss,\n",
    "            \"top_1_accuracy\": _top_1,\n",
    "            \"top_2_accuracy\": _top_2,\n",
    "            \"top_1_perclass_accuracy\": _top_1_c,\n",
    "            \"top_2_perclass_accuracy\": _top_2_c,\n",
    "            \"confusion_matrix\": _cm,\n",
    "            \"pred\": _pred,\n",
    "            \"probs\": _probs\n",
    "        }\n",
    "    else:\n",
    "        stats = {\n",
    "            \"step\": _step,\n",
    "            \"loss\": _loss,\n",
    "            \"top_1_accuracy\": _top_1,\n",
    "            \"top_2_accuracy\": _top_2\n",
    "        }\n",
    "        \n",
    "    return stats\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading datasets...\n",
      "Dataset loading completes.\n",
      "2019-03-17 16:39:15.977533: step 0, examples 0, loss = 1.418847442 (24.822 examples/sec; 2.014 sec/batch)\n",
      "Top 1 validation accuracy: 0.23349057137966156 and top 2 validation accuracy: 0.5094339847564697\n",
      "Model Saved!\n",
      "2019-03-17 16:39:36.293556: step 10, examples 500, loss = 1.409201741 (33.740 examples/sec; 1.482 sec/batch)\n",
      "2019-03-17 16:39:51.847917: step 20, examples 1000, loss = 1.401433945 (30.518 examples/sec; 1.638 sec/batch)\n",
      "2019-03-17 16:40:07.143590: step 30, examples 1500, loss = 1.395565629 (33.580 examples/sec; 1.489 sec/batch)\n",
      "2019-03-17 16:40:22.439263: step 40, examples 2000, loss = 1.405897260 (30.993 examples/sec; 1.613 sec/batch)\n",
      "2019-03-17 16:40:37.713879: step 50, examples 2500, loss = 1.393693447 (32.807 examples/sec; 1.524 sec/batch)\n",
      "2019-03-17 16:40:52.804006: step 60, examples 3000, loss = 1.382494569 (33.717 examples/sec; 1.483 sec/batch)\n",
      "2019-03-17 16:41:08.102687: step 70, examples 3500, loss = 1.375700831 (33.025 examples/sec; 1.514 sec/batch)\n",
      "2019-03-17 16:41:23.183789: step 80, examples 4000, loss = 1.379624248 (33.245 examples/sec; 1.504 sec/batch)\n",
      "2019-03-17 16:41:38.516567: step 90, examples 4500, loss = 1.357895017 (30.935 examples/sec; 1.616 sec/batch)\n",
      "2019-03-17 16:41:53.799210: step 100, examples 5000, loss = 1.342302799 (32.529 examples/sec; 1.537 sec/batch)\n",
      "Top 1 validation accuracy: 0.2995283007621765 and top 2 validation accuracy: 0.5636792182922363\n",
      "Model Saved!\n",
      "2019-03-17 16:42:14.231543: step 110, examples 5500, loss = 1.373204708 (33.581 examples/sec; 1.489 sec/batch)\n",
      "2019-03-17 16:42:29.222406: step 120, examples 6000, loss = 1.339745641 (33.490 examples/sec; 1.493 sec/batch)\n",
      "2019-03-17 16:42:44.333588: step 130, examples 6500, loss = 1.361711860 (32.678 examples/sec; 1.530 sec/batch)\n",
      "2019-03-17 16:42:59.488887: step 140, examples 7000, loss = 1.251469731 (32.572 examples/sec; 1.535 sec/batch)\n",
      "2019-03-17 16:43:14.685296: step 150, examples 7500, loss = 1.252744794 (32.214 examples/sec; 1.552 sec/batch)\n",
      "2019-03-17 16:43:29.817534: step 160, examples 8000, loss = 1.301630735 (32.851 examples/sec; 1.522 sec/batch)\n",
      "2019-03-17 16:43:44.820429: step 170, examples 8500, loss = 1.257258058 (33.068 examples/sec; 1.512 sec/batch)\n",
      "2019-03-17 16:43:59.792241: step 180, examples 9000, loss = 1.362066150 (33.200 examples/sec; 1.506 sec/batch)\n",
      "2019-03-17 16:44:14.836244: step 190, examples 9500, loss = 1.254638195 (32.937 examples/sec; 1.518 sec/batch)\n",
      "2019-03-17 16:44:29.945422: step 200, examples 10000, loss = 1.273250103 (32.572 examples/sec; 1.535 sec/batch)\n",
      "Top 1 validation accuracy: 0.37735849618911743 and top 2 validation accuracy: 0.6485849022865295\n",
      "Model Saved!\n",
      "2019-03-17 16:44:50.532164: step 210, examples 10500, loss = 1.403704643 (32.508 examples/sec; 1.538 sec/batch)\n",
      "2019-03-17 16:45:05.651367: step 220, examples 11000, loss = 1.237886071 (32.700 examples/sec; 1.529 sec/batch)\n",
      "2019-03-17 16:45:20.585079: step 230, examples 11500, loss = 1.270987749 (33.993 examples/sec; 1.471 sec/batch)\n",
      "2019-03-17 16:45:35.642116: step 240, examples 12000, loss = 1.317481995 (33.468 examples/sec; 1.494 sec/batch)\n",
      "2019-03-17 16:45:50.763325: step 250, examples 12500, loss = 1.346114278 (33.267 examples/sec; 1.503 sec/batch)\n",
      "2019-03-17 16:46:05.893558: step 260, examples 13000, loss = 1.221130967 (33.090 examples/sec; 1.511 sec/batch)\n",
      "2019-03-17 16:46:20.931546: step 270, examples 13500, loss = 1.370050907 (33.468 examples/sec; 1.494 sec/batch)\n",
      "2019-03-17 16:46:35.981565: step 280, examples 14000, loss = 1.219685435 (33.785 examples/sec; 1.480 sec/batch)\n",
      "2019-03-17 16:46:50.963404: step 290, examples 14500, loss = 1.278901577 (33.648 examples/sec; 1.486 sec/batch)\n",
      "2019-03-17 16:47:06.083610: step 300, examples 15000, loss = 1.240712404 (33.245 examples/sec; 1.504 sec/batch)\n",
      "Top 1 validation accuracy: 0.3561320900917053 and top 2 validation accuracy: 0.6155660152435303\n",
      "Model Saved!\n",
      "2019-03-17 16:47:26.635259: step 310, examples 15500, loss = 1.280924439 (33.112 examples/sec; 1.510 sec/batch)\n",
      "2019-03-17 16:47:41.911882: step 320, examples 16000, loss = 1.348801136 (33.785 examples/sec; 1.480 sec/batch)\n",
      "2019-03-17 16:47:57.067182: step 330, examples 16500, loss = 1.267449856 (33.378 examples/sec; 1.498 sec/batch)\n",
      "2019-03-17 16:48:12.110182: step 340, examples 17000, loss = 1.352380276 (33.401 examples/sec; 1.497 sec/batch)\n",
      "2019-03-17 16:48:27.366554: step 350, examples 17500, loss = 1.261052370 (31.762 examples/sec; 1.574 sec/batch)\n",
      "2019-03-17 16:48:42.984561: step 360, examples 18000, loss = 1.206520557 (33.671 examples/sec; 1.485 sec/batch)\n",
      "2019-03-17 16:48:58.518658: step 370, examples 18500, loss = 1.291128516 (30.351 examples/sec; 1.647 sec/batch)\n",
      "2019-03-17 16:49:13.959821: step 380, examples 19000, loss = 1.122525811 (32.614 examples/sec; 1.533 sec/batch)\n",
      "2019-03-17 16:49:29.117126: step 390, examples 19500, loss = 1.262752533 (32.959 examples/sec; 1.517 sec/batch)\n",
      "2019-03-17 16:49:44.357652: step 400, examples 20000, loss = 1.336917996 (32.402 examples/sec; 1.543 sec/batch)\n",
      "Top 1 validation accuracy: 0.3891509473323822 and top 2 validation accuracy: 0.6391509175300598\n",
      "Model Saved!\n",
      "2019-03-17 16:50:05.127883: step 410, examples 20500, loss = 1.045403838 (33.046 examples/sec; 1.513 sec/batch)\n",
      "2019-03-17 16:50:20.440600: step 420, examples 21000, loss = 1.231887579 (32.007 examples/sec; 1.562 sec/batch)\n",
      "2019-03-17 16:50:35.964882: step 430, examples 21500, loss = 1.206061959 (32.069 examples/sec; 1.559 sec/batch)\n",
      "2019-03-17 16:50:51.923870: step 440, examples 22000, loss = 1.226397276 (33.223 examples/sec; 1.505 sec/batch)\n",
      "2019-03-17 16:51:07.416071: step 450, examples 22500, loss = 1.305421472 (32.593 examples/sec; 1.534 sec/batch)\n",
      "2019-03-17 16:51:22.560336: step 460, examples 23000, loss = 1.116248965 (31.987 examples/sec; 1.563 sec/batch)\n",
      "2019-03-17 16:51:38.574921: step 470, examples 23500, loss = 1.237330675 (31.422 examples/sec; 1.591 sec/batch)\n",
      "2019-03-17 16:51:54.211500: step 480, examples 24000, loss = 1.175971031 (33.558 examples/sec; 1.490 sec/batch)\n",
      "2019-03-17 16:52:09.689658: step 490, examples 24500, loss = 1.282664418 (32.636 examples/sec; 1.532 sec/batch)\n",
      "2019-03-17 16:52:25.203912: step 500, examples 25000, loss = 1.312310457 (30.204 examples/sec; 1.655 sec/batch)\n",
      "Top 1 validation accuracy: 0.3820754587650299 and top 2 validation accuracy: 0.6792452931404114\n",
      "Model Saved!\n",
      "2019-03-17 16:52:46.282963: step 510, examples 25500, loss = 1.089067817 (29.789 examples/sec; 1.678 sec/batch)\n",
      "2019-03-17 16:53:01.382114: step 520, examples 26000, loss = 1.342567801 (33.401 examples/sec; 1.497 sec/batch)\n",
      "2019-03-17 16:53:16.961090: step 530, examples 26500, loss = 1.139127731 (33.558 examples/sec; 1.490 sec/batch)\n",
      "2019-03-17 16:53:32.109371: step 540, examples 27000, loss = 1.156962872 (33.245 examples/sec; 1.504 sec/batch)\n",
      "2019-03-17 16:53:47.228575: step 550, examples 27500, loss = 1.257922649 (33.267 examples/sec; 1.503 sec/batch)\n",
      "2019-03-17 16:54:02.437016: step 560, examples 28000, loss = 1.160179973 (32.614 examples/sec; 1.533 sec/batch)\n",
      "2019-03-17 16:54:17.924198: step 570, examples 28500, loss = 1.165802479 (31.987 examples/sec; 1.563 sec/batch)\n",
      "2019-03-17 16:54:32.976223: step 580, examples 29000, loss = 1.262717724 (32.850 examples/sec; 1.522 sec/batch)\n",
      "2019-03-17 16:54:48.403245: step 590, examples 29500, loss = 1.132275105 (32.466 examples/sec; 1.540 sec/batch)\n",
      "2019-03-17 16:55:04.689552: step 600, examples 30000, loss = 1.280000567 (30.388 examples/sec; 1.645 sec/batch)\n",
      "Top 1 validation accuracy: 0.41981130838394165 and top 2 validation accuracy: 0.6863207817077637\n",
      "Model Saved!\n",
      "2019-03-17 16:55:25.914993: step 610, examples 30500, loss = 1.148138881 (33.156 examples/sec; 1.508 sec/batch)\n",
      "2019-03-17 16:55:42.084977: step 620, examples 31000, loss = 1.186975837 (30.935 examples/sec; 1.616 sec/batch)\n",
      "2019-03-17 16:55:58.288731: step 630, examples 31500, loss = 1.275007367 (26.218 examples/sec; 1.907 sec/batch)\n",
      "2019-03-17 16:56:14.989138: step 640, examples 32000, loss = 1.253887296 (30.916 examples/sec; 1.617 sec/batch)\n",
      "2019-03-17 16:56:31.065888: step 650, examples 32500, loss = 1.199451923 (32.423 examples/sec; 1.542 sec/batch)\n",
      "2019-03-17 16:56:48.141298: step 660, examples 33000, loss = 0.985689938 (24.196 examples/sec; 2.066 sec/batch)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2019-03-17 16:57:04.512830: step 670, examples 33500, loss = 1.266569495 (30.744 examples/sec; 1.626 sec/batch)\n",
      "2019-03-17 16:57:21.017719: step 680, examples 34000, loss = 1.220920801 (31.225 examples/sec; 1.601 sec/batch)\n",
      "2019-03-17 16:57:37.620868: step 690, examples 34500, loss = 1.232403636 (31.109 examples/sec; 1.607 sec/batch)\n",
      "2019-03-17 16:57:53.789864: step 700, examples 35000, loss = 1.289508462 (32.829 examples/sec; 1.523 sec/batch)\n",
      "Top 1 validation accuracy: 0.44811320304870605 and top 2 validation accuracy: 0.698113203048706\n",
      "Model Saved!\n",
      "2019-03-17 16:58:14.921057: step 710, examples 35500, loss = 1.095586896 (28.301 examples/sec; 1.767 sec/batch)\n",
      "2019-03-17 16:58:31.320662: step 720, examples 36000, loss = 1.177868605 (31.402 examples/sec; 1.592 sec/batch)\n",
      "2019-03-17 16:58:47.134713: step 730, examples 36500, loss = 0.987768590 (33.946 examples/sec; 1.473 sec/batch)\n",
      "2019-03-17 16:59:02.750237: step 740, examples 37000, loss = 1.063945770 (31.363 examples/sec; 1.594 sec/batch)\n",
      "2019-03-17 16:59:18.666560: step 750, examples 37500, loss = 1.039507985 (33.289 examples/sec; 1.502 sec/batch)\n",
      "2019-03-17 16:59:35.131342: step 760, examples 38000, loss = 1.170183897 (32.048 examples/sec; 1.560 sec/batch)\n",
      "2019-03-17 16:59:51.911963: step 770, examples 38500, loss = 1.121583343 (32.089 examples/sec; 1.558 sec/batch)\n",
      "2019-03-17 17:00:08.347667: step 780, examples 39000, loss = 1.211632967 (27.415 examples/sec; 1.824 sec/batch)\n",
      "2019-03-17 17:00:25.143329: step 790, examples 39500, loss = 1.211359501 (32.276 examples/sec; 1.549 sec/batch)\n",
      "2019-03-17 17:00:40.955376: step 800, examples 40000, loss = 1.129025340 (33.200 examples/sec; 1.506 sec/batch)\n",
      "Top 1 validation accuracy: 0.4811320900917053 and top 2 validation accuracy: 0.7405660152435303\n",
      "Model Saved!\n",
      "2019-03-17 17:01:01.868987: step 810, examples 40500, loss = 1.157948256 (32.508 examples/sec; 1.538 sec/batch)\n",
      "2019-03-17 17:01:17.345139: step 820, examples 41000, loss = 1.121929646 (32.193 examples/sec; 1.553 sec/batch)\n",
      "2019-03-17 17:01:33.026839: step 830, examples 41500, loss = 1.106204152 (31.304 examples/sec; 1.597 sec/batch)\n",
      "2019-03-17 17:01:48.714554: step 840, examples 42000, loss = 1.215406179 (33.178 examples/sec; 1.507 sec/batch)\n",
      "2019-03-17 17:02:04.383219: step 850, examples 42500, loss = 1.146441579 (32.172 examples/sec; 1.554 sec/batch)\n",
      "2019-03-17 17:02:19.956631: step 860, examples 43000, loss = 1.160593748 (32.235 examples/sec; 1.551 sec/batch)\n",
      "2019-03-17 17:02:35.728570: step 870, examples 43500, loss = 1.116968632 (31.946 examples/sec; 1.565 sec/batch)\n",
      "2019-03-17 17:02:51.267890: step 880, examples 44000, loss = 1.140744448 (32.529 examples/sec; 1.537 sec/batch)\n",
      "2019-03-17 17:03:06.843308: step 890, examples 44500, loss = 1.123620868 (31.844 examples/sec; 1.570 sec/batch)\n",
      "2019-03-17 17:03:22.582159: step 900, examples 45000, loss = 0.993659258 (32.048 examples/sec; 1.560 sec/batch)\n",
      "Top 1 validation accuracy: 0.4858490526676178 and top 2 validation accuracy: 0.7452830076217651\n",
      "Model Saved!\n",
      "2019-03-17 17:03:43.636144: step 910, examples 45500, loss = 1.010841131 (32.894 examples/sec; 1.520 sec/batch)\n",
      "2019-03-17 17:03:59.186494: step 920, examples 46000, loss = 1.111311078 (31.966 examples/sec; 1.564 sec/batch)\n",
      "2019-03-17 17:04:14.781964: step 930, examples 46500, loss = 1.286568284 (32.007 examples/sec; 1.562 sec/batch)\n",
      "2019-03-17 17:04:30.408517: step 940, examples 47000, loss = 1.197254419 (31.089 examples/sec; 1.608 sec/batch)\n",
      "2019-03-17 17:04:46.407058: step 950, examples 47500, loss = 1.262110472 (32.402 examples/sec; 1.543 sec/batch)\n",
      "2019-03-17 17:05:02.061686: step 960, examples 48000, loss = 1.215595603 (32.550 examples/sec; 1.536 sec/batch)\n",
      "2019-03-17 17:05:17.727343: step 970, examples 48500, loss = 1.091276646 (31.884 examples/sec; 1.568 sec/batch)\n",
      "2019-03-17 17:05:33.329534: step 980, examples 49000, loss = 1.015198231 (30.444 examples/sec; 1.642 sec/batch)\n",
      "2019-03-17 17:05:49.156688: step 990, examples 49500, loss = 1.330935001 (32.786 examples/sec; 1.525 sec/batch)\n",
      "2019-03-17 17:06:04.708040: step 1000, examples 50000, loss = 1.012436390 (31.925 examples/sec; 1.566 sec/batch)\n",
      "Top 1 validation accuracy: 0.5165094137191772 and top 2 validation accuracy: 0.7570754885673523\n",
      "Model Saved!\n",
      "2019-03-17 17:06:25.799123: step 1010, examples 50500, loss = 1.088883758 (30.916 examples/sec; 1.617 sec/batch)\n",
      "2019-03-17 17:06:41.249208: step 1020, examples 51000, loss = 1.187528014 (32.318 examples/sec; 1.547 sec/batch)\n",
      "2019-03-17 17:06:56.803568: step 1030, examples 51500, loss = 1.254949093 (33.178 examples/sec; 1.507 sec/batch)\n",
      "2019-03-17 17:07:12.310804: step 1040, examples 52000, loss = 1.063567758 (32.172 examples/sec; 1.554 sec/batch)\n",
      "2019-03-17 17:07:27.962423: step 1050, examples 52500, loss = 1.084811807 (31.284 examples/sec; 1.598 sec/batch)\n",
      "2019-03-17 17:07:43.667184: step 1060, examples 53000, loss = 0.973347306 (32.894 examples/sec; 1.520 sec/batch)\n",
      "2019-03-17 17:07:59.157374: step 1070, examples 53500, loss = 1.001862407 (32.131 examples/sec; 1.556 sec/batch)\n",
      "2019-03-17 17:08:14.718754: step 1080, examples 54000, loss = 1.190217733 (32.402 examples/sec; 1.543 sec/batch)\n",
      "2019-03-17 17:08:30.281136: step 1090, examples 54500, loss = 0.986034214 (32.339 examples/sec; 1.546 sec/batch)\n",
      "2019-03-17 17:08:45.801406: step 1100, examples 55000, loss = 0.936379492 (32.381 examples/sec; 1.544 sec/batch)\n",
      "Top 1 validation accuracy: 0.49056604504585266 and top 2 validation accuracy: 0.7075471878051758\n",
      "Model Saved!\n",
      "2019-03-17 17:09:06.745097: step 1110, examples 55500, loss = 1.109990358 (31.245 examples/sec; 1.600 sec/batch)\n",
      "2019-03-17 17:09:22.169112: step 1120, examples 56000, loss = 1.208422184 (31.682 examples/sec; 1.578 sec/batch)\n",
      "2019-03-17 17:09:37.718459: step 1130, examples 56500, loss = 1.061182022 (30.706 examples/sec; 1.628 sec/batch)\n",
      "2019-03-17 17:09:53.023156: step 1140, examples 57000, loss = 1.036777377 (32.235 examples/sec; 1.551 sec/batch)\n",
      "2019-03-17 17:10:08.438146: step 1150, examples 57500, loss = 1.051402688 (32.466 examples/sec; 1.540 sec/batch)\n",
      "2019-03-17 17:10:24.012560: step 1160, examples 58000, loss = 1.005740523 (32.152 examples/sec; 1.555 sec/batch)\n",
      "2019-03-17 17:10:39.408500: step 1170, examples 58500, loss = 1.058036327 (32.678 examples/sec; 1.530 sec/batch)\n",
      "2019-03-17 17:10:55.190466: step 1180, examples 59000, loss = 0.999974966 (31.245 examples/sec; 1.600 sec/batch)\n",
      "2019-03-17 17:11:11.051642: step 1190, examples 59500, loss = 1.110227466 (30.858 examples/sec; 1.620 sec/batch)\n",
      "2019-03-17 17:11:26.624052: step 1200, examples 60000, loss = 1.127307773 (31.925 examples/sec; 1.566 sec/batch)\n",
      "Top 1 validation accuracy: 0.5 and top 2 validation accuracy: 0.7287735939025879\n",
      "Model Saved!\n",
      "2019-03-17 17:11:48.685220: step 1210, examples 60500, loss = 1.100091100 (33.112 examples/sec; 1.510 sec/batch)\n",
      "2019-03-17 17:12:05.003612: step 1220, examples 61000, loss = 1.102299452 (31.946 examples/sec; 1.565 sec/batch)\n",
      "2019-03-17 17:12:20.438655: step 1230, examples 61500, loss = 1.002128124 (32.894 examples/sec; 1.520 sec/batch)\n",
      "2019-03-17 17:12:36.156452: step 1240, examples 62000, loss = 0.944399416 (31.905 examples/sec; 1.567 sec/batch)\n",
      "2019-03-17 17:12:51.682737: step 1250, examples 62500, loss = 1.005440593 (31.884 examples/sec; 1.568 sec/batch)\n",
      "2019-03-17 17:13:07.108756: step 1260, examples 63000, loss = 0.991346359 (31.167 examples/sec; 1.604 sec/batch)\n",
      "2019-03-17 17:13:22.665123: step 1270, examples 63500, loss = 0.997114897 (30.077 examples/sec; 1.662 sec/batch)\n",
      "2019-03-17 17:13:38.591911: step 1280, examples 64000, loss = 1.017500639 (29.316 examples/sec; 1.706 sec/batch)\n",
      "2019-03-17 17:13:54.144829: step 1290, examples 64500, loss = 1.052403808 (31.905 examples/sec; 1.567 sec/batch)\n",
      "2019-03-17 17:14:09.648054: step 1300, examples 65000, loss = 1.026740789 (32.007 examples/sec; 1.562 sec/batch)\n",
      "Top 1 validation accuracy: 0.5 and top 2 validation accuracy: 0.7570754885673523\n",
      "Model Saved!\n",
      "2019-03-17 17:14:30.423297: step 1310, examples 65500, loss = 1.018704414 (32.850 examples/sec; 1.522 sec/batch)\n",
      "2019-03-17 17:14:46.028793: step 1320, examples 66000, loss = 1.090541959 (32.636 examples/sec; 1.532 sec/batch)\n",
      "2019-03-17 17:15:01.552072: step 1330, examples 66500, loss = 1.271571755 (32.529 examples/sec; 1.537 sec/batch)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2019-03-17 17:15:16.992128: step 1340, examples 67000, loss = 0.985413969 (32.193 examples/sec; 1.553 sec/batch)\n",
      "2019-03-17 17:15:32.557519: step 1350, examples 67500, loss = 0.968541205 (32.402 examples/sec; 1.543 sec/batch)\n",
      "2019-03-17 17:15:48.049714: step 1360, examples 68000, loss = 1.053649902 (32.152 examples/sec; 1.555 sec/batch)\n",
      "2019-03-17 17:16:03.525866: step 1370, examples 68500, loss = 0.766393304 (31.206 examples/sec; 1.602 sec/batch)\n",
      "2019-03-17 17:16:18.947876: step 1380, examples 69000, loss = 1.008464217 (32.069 examples/sec; 1.559 sec/batch)\n",
      "2019-03-17 17:16:34.206451: step 1390, examples 69500, loss = 0.922006249 (30.370 examples/sec; 1.646 sec/batch)\n",
      "2019-03-17 17:16:49.728726: step 1400, examples 70000, loss = 1.195052624 (31.482 examples/sec; 1.588 sec/batch)\n",
      "Top 1 validation accuracy: 0.5 and top 2 validation accuracy: 0.7547169923782349\n",
      "Model Saved!\n",
      "2019-03-17 17:17:10.784716: step 1410, examples 70500, loss = 1.001855135 (32.110 examples/sec; 1.557 sec/batch)\n",
      "2019-03-17 17:17:26.395226: step 1420, examples 71000, loss = 1.118567228 (32.069 examples/sec; 1.559 sec/batch)\n",
      "2019-03-17 17:17:41.837288: step 1430, examples 71500, loss = 1.011694551 (33.003 examples/sec; 1.515 sec/batch)\n",
      "2019-03-17 17:17:57.425740: step 1440, examples 72000, loss = 0.949913800 (32.444 examples/sec; 1.541 sec/batch)\n",
      "2019-03-17 17:18:13.063322: step 1450, examples 72500, loss = 1.001945972 (31.541 examples/sec; 1.585 sec/batch)\n",
      "2019-03-17 17:18:28.596627: step 1460, examples 73000, loss = 1.052397132 (31.502 examples/sec; 1.587 sec/batch)\n",
      "2019-03-17 17:18:44.163019: step 1470, examples 73500, loss = 1.019923806 (33.090 examples/sec; 1.511 sec/batch)\n",
      "2019-03-17 17:18:59.675268: step 1480, examples 74000, loss = 1.006543994 (31.864 examples/sec; 1.569 sec/batch)\n",
      "2019-03-17 17:19:15.215591: step 1490, examples 74500, loss = 0.925827026 (32.764 examples/sec; 1.526 sec/batch)\n",
      "2019-03-17 17:19:30.883253: step 1500, examples 75000, loss = 0.942838132 (31.762 examples/sec; 1.574 sec/batch)\n",
      "Top 1 validation accuracy: 0.5400943160057068 and top 2 validation accuracy: 0.7712264060974121\n",
      "Model Saved!\n",
      "2019-03-17 17:19:51.945260: step 1510, examples 75500, loss = 0.846596658 (32.487 examples/sec; 1.539 sec/batch)\n",
      "2019-03-17 17:20:07.368271: step 1520, examples 76000, loss = 1.044915318 (32.152 examples/sec; 1.555 sec/batch)\n",
      "2019-03-17 17:20:22.865480: step 1530, examples 76500, loss = 0.959409118 (31.905 examples/sec; 1.567 sec/batch)\n",
      "2019-03-17 17:20:38.483009: step 1540, examples 77000, loss = 1.024816632 (33.223 examples/sec; 1.505 sec/batch)\n",
      "2019-03-17 17:20:53.917050: step 1550, examples 77500, loss = 1.039042234 (32.894 examples/sec; 1.520 sec/batch)\n",
      "2019-03-17 17:21:09.379165: step 1560, examples 78000, loss = 1.003461957 (32.508 examples/sec; 1.538 sec/batch)\n",
      "2019-03-17 17:21:24.845291: step 1570, examples 78500, loss = 1.020435572 (31.742 examples/sec; 1.575 sec/batch)\n",
      "2019-03-17 17:21:40.316430: step 1580, examples 79000, loss = 1.015839100 (32.572 examples/sec; 1.535 sec/batch)\n",
      "2019-03-17 17:21:55.833692: step 1590, examples 79500, loss = 1.056045532 (32.048 examples/sec; 1.560 sec/batch)\n",
      "2019-03-17 17:22:11.278763: step 1600, examples 80000, loss = 1.017137766 (32.028 examples/sec; 1.561 sec/batch)\n",
      "Top 1 validation accuracy: 0.5306603908538818 and top 2 validation accuracy: 0.7547169923782349\n",
      "Model Saved!\n",
      "2019-03-17 17:22:32.047991: step 1610, examples 80500, loss = 0.838789225 (31.502 examples/sec; 1.587 sec/batch)\n",
      "2019-03-17 17:22:47.580293: step 1620, examples 81000, loss = 0.836167395 (32.276 examples/sec; 1.549 sec/batch)\n",
      "2019-03-17 17:23:03.072488: step 1630, examples 81500, loss = 0.863078833 (32.339 examples/sec; 1.546 sec/batch)\n",
      "2019-03-17 17:23:18.562678: step 1640, examples 82000, loss = 0.847279370 (32.466 examples/sec; 1.540 sec/batch)\n",
      "2019-03-17 17:23:33.964634: step 1650, examples 82500, loss = 0.972000539 (32.318 examples/sec; 1.547 sec/batch)\n",
      "2019-03-17 17:23:49.657362: step 1660, examples 83000, loss = 0.920885980 (32.487 examples/sec; 1.539 sec/batch)\n",
      "2019-03-17 17:24:05.158582: step 1670, examples 83500, loss = 0.812452316 (32.572 examples/sec; 1.535 sec/batch)\n",
      "2019-03-17 17:24:20.676848: step 1680, examples 84000, loss = 1.115627170 (32.069 examples/sec; 1.559 sec/batch)\n",
      "2019-03-17 17:24:36.134951: step 1690, examples 84500, loss = 0.813955903 (32.466 examples/sec; 1.540 sec/batch)\n",
      "2019-03-17 17:24:51.579019: step 1700, examples 85000, loss = 0.990786314 (31.304 examples/sec; 1.597 sec/batch)\n",
      "Top 1 validation accuracy: 0.5424528121948242 and top 2 validation accuracy: 0.7688679099082947\n",
      "Model Saved!\n",
      "2019-03-17 17:25:12.787414: step 1710, examples 85500, loss = 0.918263018 (32.423 examples/sec; 1.542 sec/batch)\n",
      "2019-03-17 17:25:28.312698: step 1720, examples 86000, loss = 0.771598995 (32.028 examples/sec; 1.561 sec/batch)\n",
      "2019-03-17 17:25:43.864052: step 1730, examples 86500, loss = 1.036121607 (31.245 examples/sec; 1.600 sec/batch)\n",
      "2019-03-17 17:25:59.409388: step 1740, examples 87000, loss = 0.929438651 (32.614 examples/sec; 1.533 sec/batch)\n",
      "2019-03-17 17:26:14.892559: step 1750, examples 87500, loss = 0.874000192 (32.657 examples/sec; 1.531 sec/batch)\n",
      "2019-03-17 17:26:30.212296: step 1760, examples 88000, loss = 0.792172372 (32.807 examples/sec; 1.524 sec/batch)\n",
      "2019-03-17 17:26:45.804766: step 1770, examples 88500, loss = 0.756362975 (32.256 examples/sec; 1.550 sec/batch)\n",
      "2019-03-17 17:27:01.311000: step 1780, examples 89000, loss = 0.908553660 (31.884 examples/sec; 1.568 sec/batch)\n",
      "2019-03-17 17:27:16.916496: step 1790, examples 89500, loss = 0.940072000 (32.381 examples/sec; 1.544 sec/batch)\n",
      "2019-03-17 17:27:32.414707: step 1800, examples 90000, loss = 0.893453658 (32.593 examples/sec; 1.534 sec/batch)\n",
      "Top 1 validation accuracy: 0.525943398475647 and top 2 validation accuracy: 0.7877358198165894\n",
      "Model Saved!\n",
      "2019-03-17 17:27:53.479723: step 1810, examples 90500, loss = 0.877275825 (32.487 examples/sec; 1.539 sec/batch)\n",
      "2019-03-17 17:28:08.969912: step 1820, examples 91000, loss = 0.879705369 (32.593 examples/sec; 1.534 sec/batch)\n",
      "2019-03-17 17:28:24.631712: step 1830, examples 91500, loss = 0.831987441 (28.925 examples/sec; 1.729 sec/batch)\n",
      "2019-03-17 17:28:41.729871: step 1840, examples 92000, loss = 0.860464513 (31.905 examples/sec; 1.567 sec/batch)\n",
      "2019-03-17 17:28:57.260168: step 1850, examples 92500, loss = 0.936870039 (32.172 examples/sec; 1.554 sec/batch)\n",
      "2019-03-17 17:29:12.837592: step 1860, examples 93000, loss = 0.916322470 (31.304 examples/sec; 1.597 sec/batch)\n",
      "2019-03-17 17:29:28.114815: step 1870, examples 93500, loss = 0.681917548 (32.043 examples/sec; 1.560 sec/batch)\n",
      "2019-03-17 17:29:43.126221: step 1880, examples 94000, loss = 0.720130742 (34.286 examples/sec; 1.458 sec/batch)\n",
      "2019-03-17 17:29:58.136628: step 1890, examples 94500, loss = 0.808671057 (33.597 examples/sec; 1.488 sec/batch)\n",
      "2019-03-17 17:30:13.487534: step 1900, examples 95000, loss = 0.862725317 (32.529 examples/sec; 1.537 sec/batch)\n",
      "Top 1 validation accuracy: 0.5943396091461182 and top 2 validation accuracy: 0.7971698045730591\n",
      "Model Saved!\n",
      "2019-03-17 17:30:34.770127: step 1910, examples 95500, loss = 0.794902742 (31.803 examples/sec; 1.572 sec/batch)\n",
      "2019-03-17 17:30:50.475890: step 1920, examples 96000, loss = 0.962068200 (32.028 examples/sec; 1.561 sec/batch)\n",
      "2019-03-17 17:31:06.059329: step 1930, examples 96500, loss = 0.879903078 (32.402 examples/sec; 1.543 sec/batch)\n",
      "2019-03-17 17:31:21.632740: step 1940, examples 97000, loss = 0.880006611 (31.109 examples/sec; 1.607 sec/batch)\n",
      "2019-03-17 17:31:37.224200: step 1950, examples 97500, loss = 0.973120749 (32.318 examples/sec; 1.547 sec/batch)\n",
      "2019-03-17 17:31:52.739456: step 1960, examples 98000, loss = 0.776837945 (32.721 examples/sec; 1.528 sec/batch)\n",
      "2019-03-17 17:32:08.477305: step 1970, examples 98500, loss = 0.777174950 (32.872 examples/sec; 1.521 sec/batch)\n",
      "2019-03-17 17:32:23.635612: step 1980, examples 99000, loss = 0.920896351 (33.356 examples/sec; 1.499 sec/batch)\n",
      "2019-03-17 17:32:39.011498: step 1990, examples 99500, loss = 0.798579156 (31.966 examples/sec; 1.564 sec/batch)\n",
      "2019-03-17 17:32:54.638051: step 2000, examples 100000, loss = 0.840722442 (32.550 examples/sec; 1.536 sec/batch)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Top 1 validation accuracy: 0.5825471878051758 and top 2 validation accuracy: 0.801886796951294\n",
      "Model Saved!\n",
      "2019-03-17 17:33:15.607538: step 2010, examples 100500, loss = 0.835287333 (32.360 examples/sec; 1.545 sec/batch)\n",
      "2019-03-17 17:33:31.235093: step 2020, examples 101000, loss = 0.960037410 (32.318 examples/sec; 1.547 sec/batch)\n",
      "2019-03-17 17:33:46.871673: step 2030, examples 101500, loss = 0.787534177 (31.442 examples/sec; 1.590 sec/batch)\n",
      "2019-03-17 17:34:02.396956: step 2040, examples 102000, loss = 0.726289213 (32.089 examples/sec; 1.558 sec/batch)\n",
      "2019-03-17 17:34:18.056597: step 2050, examples 102500, loss = 0.820033073 (31.225 examples/sec; 1.601 sec/batch)\n",
      "2019-03-17 17:34:33.702201: step 2060, examples 103000, loss = 0.963117063 (30.782 examples/sec; 1.624 sec/batch)\n",
      "2019-03-17 17:34:49.220465: step 2070, examples 103500, loss = 0.768521369 (32.508 examples/sec; 1.538 sec/batch)\n",
      "2019-03-17 17:35:04.671551: step 2080, examples 104000, loss = 0.867734134 (32.402 examples/sec; 1.543 sec/batch)\n",
      "2019-03-17 17:35:20.360269: step 2090, examples 104500, loss = 0.811606765 (31.925 examples/sec; 1.566 sec/batch)\n",
      "2019-03-17 17:35:35.983815: step 2100, examples 105000, loss = 0.818502963 (32.235 examples/sec; 1.551 sec/batch)\n",
      "Top 1 validation accuracy: 0.5966981053352356 and top 2 validation accuracy: 0.7971698045730591\n",
      "Model Saved!\n",
      "2019-03-17 17:35:57.332582: step 2110, examples 105500, loss = 0.822862685 (32.235 examples/sec; 1.551 sec/batch)\n",
      "2019-03-17 17:36:12.857866: step 2120, examples 106000, loss = 0.777845800 (31.946 examples/sec; 1.565 sec/batch)\n",
      "2019-03-17 17:36:28.529539: step 2130, examples 106500, loss = 0.853463233 (31.363 examples/sec; 1.594 sec/batch)\n",
      "2019-03-17 17:36:44.301478: step 2140, examples 107000, loss = 0.883968413 (32.829 examples/sec; 1.523 sec/batch)\n",
      "2019-03-17 17:36:59.936053: step 2150, examples 107500, loss = 0.639179230 (31.925 examples/sec; 1.566 sec/batch)\n",
      "2019-03-17 17:37:15.653847: step 2160, examples 108000, loss = 0.689980805 (31.383 examples/sec; 1.593 sec/batch)\n",
      "2019-03-17 17:37:31.198182: step 2170, examples 108500, loss = 0.858127773 (31.502 examples/sec; 1.587 sec/batch)\n",
      "2019-03-17 17:37:46.909961: step 2180, examples 109000, loss = 0.905213356 (32.807 examples/sec; 1.524 sec/batch)\n",
      "2019-03-17 17:38:02.570605: step 2190, examples 109500, loss = 0.980427563 (32.297 examples/sec; 1.548 sec/batch)\n",
      "2019-03-17 17:38:18.145019: step 2200, examples 110000, loss = 0.863510072 (31.987 examples/sec; 1.563 sec/batch)\n",
      "Top 1 validation accuracy: 0.5754716992378235 and top 2 validation accuracy: 0.8089622855186462\n",
      "Model Saved!\n",
      "2019-03-17 17:38:39.861245: step 2210, examples 110500, loss = 0.723665774 (28.094 examples/sec; 1.780 sec/batch)\n",
      "2019-03-17 17:38:55.646218: step 2220, examples 111000, loss = 0.926620722 (32.487 examples/sec; 1.539 sec/batch)\n",
      "2019-03-17 17:39:11.260739: step 2230, examples 111500, loss = 0.959688365 (32.402 examples/sec; 1.543 sec/batch)\n",
      "2019-03-17 17:39:26.832145: step 2240, examples 112000, loss = 0.843472064 (32.172 examples/sec; 1.554 sec/batch)\n",
      "2019-03-17 17:39:42.464714: step 2250, examples 112500, loss = 0.856081069 (32.235 examples/sec; 1.551 sec/batch)\n",
      "2019-03-17 17:39:58.219608: step 2260, examples 113000, loss = 0.858249664 (31.925 examples/sec; 1.566 sec/batch)\n",
      "2019-03-17 17:40:13.990545: step 2270, examples 113500, loss = 0.892188489 (31.702 examples/sec; 1.577 sec/batch)\n",
      "2019-03-17 17:40:29.645172: step 2280, examples 114000, loss = 0.776010931 (32.069 examples/sec; 1.559 sec/batch)\n",
      "2019-03-17 17:40:45.240642: step 2290, examples 114500, loss = 0.849446356 (32.872 examples/sec; 1.521 sec/batch)\n",
      "2019-03-17 17:41:00.970470: step 2300, examples 115000, loss = 0.849315703 (31.884 examples/sec; 1.568 sec/batch)\n",
      "Top 1 validation accuracy: 0.5966981053352356 and top 2 validation accuracy: 0.8113207817077637\n",
      "Model Saved!\n",
      "2019-03-17 17:41:22.389425: step 2310, examples 115500, loss = 0.773297250 (31.581 examples/sec; 1.583 sec/batch)\n",
      "2019-03-17 17:41:38.238077: step 2320, examples 116000, loss = 0.775537670 (28.189 examples/sec; 1.774 sec/batch)\n",
      "2019-03-17 17:41:54.002997: step 2330, examples 116500, loss = 0.994576395 (31.742 examples/sec; 1.575 sec/batch)\n",
      "2019-03-17 17:42:09.531289: step 2340, examples 117000, loss = 0.655284524 (32.297 examples/sec; 1.548 sec/batch)\n",
      "2019-03-17 17:42:25.156839: step 2350, examples 117500, loss = 0.804668069 (32.048 examples/sec; 1.560 sec/batch)\n",
      "2019-03-17 17:42:40.809461: step 2360, examples 118000, loss = 0.821062028 (31.783 examples/sec; 1.573 sec/batch)\n",
      "2019-03-17 17:42:56.429997: step 2370, examples 118500, loss = 0.774618149 (33.671 examples/sec; 1.485 sec/batch)\n",
      "2019-03-17 17:43:12.104678: step 2380, examples 119000, loss = 0.776996076 (32.131 examples/sec; 1.556 sec/batch)\n",
      "2019-03-17 17:43:27.722208: step 2390, examples 119500, loss = 0.771365881 (32.550 examples/sec; 1.536 sec/batch)\n",
      "2019-03-17 17:43:43.515203: step 2400, examples 120000, loss = 0.912577450 (31.783 examples/sec; 1.573 sec/batch)\n",
      "Top 1 validation accuracy: 0.573113203048706 and top 2 validation accuracy: 0.8136792182922363\n",
      "Model Saved!\n",
      "2019-03-17 17:44:04.517048: step 2410, examples 120500, loss = 0.814319015 (31.383 examples/sec; 1.593 sec/batch)\n",
      "2019-03-17 17:44:20.305031: step 2420, examples 121000, loss = 0.774531603 (31.823 examples/sec; 1.571 sec/batch)\n",
      "2019-03-17 17:44:35.941610: step 2430, examples 121500, loss = 0.794877768 (32.959 examples/sec; 1.517 sec/batch)\n",
      "2019-03-17 17:44:51.561144: step 2440, examples 122000, loss = 0.684716105 (31.966 examples/sec; 1.564 sec/batch)\n",
      "2019-03-17 17:45:07.087431: step 2450, examples 122500, loss = 0.905641198 (31.966 examples/sec; 1.564 sec/batch)\n",
      "2019-03-17 17:45:22.828287: step 2460, examples 123000, loss = 0.750480056 (31.167 examples/sec; 1.604 sec/batch)\n",
      "2019-03-17 17:45:38.469880: step 2470, examples 123500, loss = 0.793397963 (31.702 examples/sec; 1.577 sec/batch)\n",
      "2019-03-17 17:45:54.106459: step 2480, examples 124000, loss = 0.776202619 (31.070 examples/sec; 1.609 sec/batch)\n",
      "2019-03-17 17:46:09.866282: step 2490, examples 124500, loss = 0.734327376 (30.820 examples/sec; 1.622 sec/batch)\n",
      "2019-03-17 17:46:25.676907: step 2500, examples 125000, loss = 1.077057958 (31.884 examples/sec; 1.568 sec/batch)\n",
      "Top 1 validation accuracy: 0.6202830076217651 and top 2 validation accuracy: 0.8160377144813538\n",
      "Model Saved!\n",
      "2019-03-17 17:46:46.879285: step 2510, examples 125500, loss = 0.858126223 (31.206 examples/sec; 1.602 sec/batch)\n",
      "2019-03-17 17:47:02.454702: step 2520, examples 126000, loss = 0.713342249 (32.172 examples/sec; 1.554 sec/batch)\n",
      "2019-03-17 17:47:17.998034: step 2530, examples 126500, loss = 0.828550518 (32.402 examples/sec; 1.543 sec/batch)\n",
      "2019-03-17 17:47:33.512288: step 2540, examples 127000, loss = 0.830831468 (32.423 examples/sec; 1.542 sec/batch)\n",
      "2019-03-17 17:47:49.047598: step 2550, examples 127500, loss = 0.785443902 (33.025 examples/sec; 1.514 sec/batch)\n",
      "2019-03-17 17:48:04.548817: step 2560, examples 128000, loss = 0.865472972 (32.508 examples/sec; 1.538 sec/batch)\n",
      "2019-03-17 17:48:20.050037: step 2570, examples 128500, loss = 0.794191003 (31.642 examples/sec; 1.580 sec/batch)\n",
      "2019-03-17 17:48:35.372782: step 2580, examples 129000, loss = 0.911608160 (32.214 examples/sec; 1.552 sec/batch)\n",
      "2019-03-17 17:48:50.926140: step 2590, examples 129500, loss = 0.760090590 (31.031 examples/sec; 1.611 sec/batch)\n",
      "2019-03-17 17:49:06.487519: step 2600, examples 130000, loss = 0.778669119 (30.801 examples/sec; 1.623 sec/batch)\n",
      "Top 1 validation accuracy: 0.6037735939025879 and top 2 validation accuracy: 0.8183962106704712\n",
      "Model Saved!\n",
      "2019-03-17 17:49:27.527467: step 2610, examples 130500, loss = 0.821419358 (32.089 examples/sec; 1.558 sec/batch)\n",
      "2019-03-17 17:49:42.953486: step 2620, examples 131000, loss = 0.873235762 (31.702 examples/sec; 1.577 sec/batch)\n",
      "2019-03-17 17:49:58.583047: step 2630, examples 131500, loss = 0.712846875 (31.783 examples/sec; 1.573 sec/batch)\n",
      "2019-03-17 17:50:14.134400: step 2640, examples 132000, loss = 0.842528105 (32.466 examples/sec; 1.540 sec/batch)\n",
      "2019-03-17 17:50:29.669710: step 2650, examples 132500, loss = 0.667316914 (32.402 examples/sec; 1.543 sec/batch)\n",
      "2019-03-17 17:50:45.170930: step 2660, examples 133000, loss = 0.711730063 (31.884 examples/sec; 1.568 sec/batch)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2019-03-17 17:51:00.588927: step 2670, examples 133500, loss = 0.892311871 (31.966 examples/sec; 1.564 sec/batch)\n",
      "2019-03-17 17:51:16.062073: step 2680, examples 134000, loss = 0.622710824 (31.946 examples/sec; 1.565 sec/batch)\n",
      "2019-03-17 17:51:31.969092: step 2690, examples 134500, loss = 0.688604951 (30.809 examples/sec; 1.623 sec/batch)\n",
      "2019-03-17 17:51:47.554536: step 2700, examples 135000, loss = 0.841308177 (32.172 examples/sec; 1.554 sec/batch)\n",
      "Top 1 validation accuracy: 0.6438679099082947 and top 2 validation accuracy: 0.823113203048706\n",
      "Model Saved!\n",
      "2019-03-17 17:52:08.441076: step 2710, examples 135500, loss = 0.744677126 (33.468 examples/sec; 1.494 sec/batch)\n",
      "2019-03-17 17:52:23.939287: step 2720, examples 136000, loss = 0.801290929 (32.256 examples/sec; 1.550 sec/batch)\n",
      "2019-03-17 17:52:39.595920: step 2730, examples 136500, loss = 0.767263412 (32.276 examples/sec; 1.549 sec/batch)\n",
      "2019-03-17 17:52:55.163315: step 2740, examples 137000, loss = 0.792334378 (32.466 examples/sec; 1.540 sec/batch)\n",
      "2019-03-17 17:53:10.607383: step 2750, examples 137500, loss = 0.885301352 (32.381 examples/sec; 1.544 sec/batch)\n",
      "2019-03-17 17:53:26.151716: step 2760, examples 138000, loss = 0.803255439 (32.007 examples/sec; 1.562 sec/batch)\n",
      "2019-03-17 17:53:41.671987: step 2770, examples 138500, loss = 0.654098809 (32.487 examples/sec; 1.539 sec/batch)\n",
      "2019-03-17 17:53:57.181227: step 2780, examples 139000, loss = 0.870895922 (32.235 examples/sec; 1.551 sec/batch)\n",
      "2019-03-17 17:54:12.496953: step 2790, examples 139500, loss = 0.730442047 (33.223 examples/sec; 1.505 sec/batch)\n",
      "2019-03-17 17:54:27.749512: step 2800, examples 140000, loss = 0.868782938 (33.112 examples/sec; 1.510 sec/batch)\n",
      "Top 1 validation accuracy: 0.6462264060974121 and top 2 validation accuracy: 0.8325471878051758\n",
      "Model Saved!\n",
      "2019-03-17 17:54:48.556841: step 2810, examples 140500, loss = 0.731204927 (32.256 examples/sec; 1.550 sec/batch)\n",
      "2019-03-17 17:55:04.137271: step 2820, examples 141000, loss = 0.653221607 (32.007 examples/sec; 1.562 sec/batch)\n",
      "2019-03-17 17:55:19.665563: step 2830, examples 141500, loss = 0.858169615 (32.916 examples/sec; 1.519 sec/batch)\n",
      "2019-03-17 17:55:35.027412: step 2840, examples 142000, loss = 0.704124093 (33.445 examples/sec; 1.495 sec/batch)\n",
      "2019-03-17 17:55:50.542668: step 2850, examples 142500, loss = 0.870271325 (31.422 examples/sec; 1.591 sec/batch)\n",
      "2019-03-17 17:56:06.047898: step 2860, examples 143000, loss = 0.824527681 (32.339 examples/sec; 1.546 sec/batch)\n",
      "2019-03-17 17:56:21.641363: step 2870, examples 143500, loss = 0.817841172 (32.487 examples/sec; 1.539 sec/batch)\n",
      "2019-03-17 17:56:37.321563: step 2880, examples 144000, loss = 0.603197455 (32.266 examples/sec; 1.550 sec/batch)\n",
      "2019-03-17 17:56:52.729535: step 2890, examples 144500, loss = 0.757344961 (32.572 examples/sec; 1.535 sec/batch)\n",
      "2019-03-17 17:57:08.315980: step 2900, examples 145000, loss = 0.657314539 (32.297 examples/sec; 1.548 sec/batch)\n",
      "Top 1 validation accuracy: 0.6415094137191772 and top 2 validation accuracy: 0.8254716992378235\n",
      "Model Saved!\n",
      "2019-03-17 17:57:29.481261: step 2910, examples 145500, loss = 0.764457762 (31.987 examples/sec; 1.563 sec/batch)\n",
      "2019-03-17 17:57:45.017574: step 2920, examples 146000, loss = 0.709231913 (32.069 examples/sec; 1.559 sec/batch)\n",
      "2019-03-17 17:58:00.571935: step 2930, examples 146500, loss = 0.765345633 (32.069 examples/sec; 1.559 sec/batch)\n",
      "2019-03-17 17:58:15.948824: step 2940, examples 147000, loss = 0.572418451 (33.068 examples/sec; 1.512 sec/batch)\n",
      "2019-03-17 17:58:31.491152: step 2950, examples 147500, loss = 0.822074354 (31.966 examples/sec; 1.564 sec/batch)\n",
      "2019-03-17 17:58:47.293173: step 2960, examples 148000, loss = 0.679031372 (31.966 examples/sec; 1.564 sec/batch)\n",
      "2019-03-17 17:59:02.840514: step 2970, examples 148500, loss = 0.780499876 (33.112 examples/sec; 1.510 sec/batch)\n",
      "2019-03-17 17:59:18.427963: step 2980, examples 149000, loss = 0.804200709 (32.069 examples/sec; 1.559 sec/batch)\n",
      "2019-03-17 17:59:33.961268: step 2990, examples 149500, loss = 0.580543935 (32.172 examples/sec; 1.554 sec/batch)\n",
      "2019-03-17 17:59:49.391298: step 3000, examples 150000, loss = 0.883599877 (33.513 examples/sec; 1.492 sec/batch)\n",
      "Top 1 validation accuracy: 0.6226415038108826 and top 2 validation accuracy: 0.849056601524353\n",
      "Model Saved!\n",
      "2019-03-17 18:00:10.399160: step 3010, examples 150500, loss = 0.763874471 (32.276 examples/sec; 1.549 sec/batch)\n",
      "2019-03-17 18:00:25.742961: step 3020, examples 151000, loss = 0.705869734 (32.850 examples/sec; 1.522 sec/batch)\n",
      "2019-03-17 18:00:41.332415: step 3030, examples 151500, loss = 0.766420543 (32.487 examples/sec; 1.539 sec/batch)\n",
      "2019-03-17 18:00:56.668194: step 3040, examples 152000, loss = 0.760277033 (32.256 examples/sec; 1.550 sec/batch)\n",
      "2019-03-17 18:01:12.147355: step 3050, examples 152500, loss = 0.808616996 (32.487 examples/sec; 1.539 sec/batch)\n",
      "2019-03-17 18:01:27.645567: step 3060, examples 153000, loss = 0.683020771 (31.089 examples/sec; 1.608 sec/batch)\n",
      "2019-03-17 18:01:43.247053: step 3070, examples 153500, loss = 0.937501669 (31.864 examples/sec; 1.569 sec/batch)\n",
      "2019-03-17 18:01:58.697136: step 3080, examples 154000, loss = 0.777233183 (32.297 examples/sec; 1.548 sec/batch)\n",
      "2019-03-17 18:02:14.163263: step 3090, examples 154500, loss = 0.722091138 (32.444 examples/sec; 1.541 sec/batch)\n",
      "2019-03-17 18:02:29.659469: step 3100, examples 155000, loss = 0.730754793 (32.381 examples/sec; 1.544 sec/batch)\n",
      "Top 1 validation accuracy: 0.6462264060974121 and top 2 validation accuracy: 0.8419811129570007\n",
      "Model Saved!\n",
      "2019-03-17 18:02:50.829762: step 3110, examples 155500, loss = 0.678552389 (31.621 examples/sec; 1.581 sec/batch)\n",
      "2019-03-17 18:03:06.365074: step 3120, examples 156000, loss = 0.729628384 (33.134 examples/sec; 1.509 sec/batch)\n",
      "2019-03-17 18:03:22.075850: step 3130, examples 156500, loss = 0.772747934 (32.678 examples/sec; 1.530 sec/batch)\n",
      "2019-03-17 18:03:37.592109: step 3140, examples 157000, loss = 0.668594897 (31.946 examples/sec; 1.565 sec/batch)\n",
      "2019-03-17 18:03:53.050214: step 3150, examples 157500, loss = 0.829755604 (31.561 examples/sec; 1.584 sec/batch)\n",
      "2019-03-17 18:04:08.517343: step 3160, examples 158000, loss = 0.732229769 (32.423 examples/sec; 1.542 sec/batch)\n",
      "2019-03-17 18:04:24.149912: step 3170, examples 158500, loss = 0.667159498 (32.048 examples/sec; 1.560 sec/batch)\n",
      "2019-03-17 18:04:39.407483: step 3180, examples 159000, loss = 0.754630089 (32.487 examples/sec; 1.539 sec/batch)\n",
      "2019-03-17 18:04:54.969866: step 3190, examples 159500, loss = 0.763455749 (31.561 examples/sec; 1.584 sec/batch)\n",
      "2019-03-17 18:05:10.538263: step 3200, examples 160000, loss = 0.747071445 (32.028 examples/sec; 1.561 sec/batch)\n",
      "Top 1 validation accuracy: 0.6462264060974121 and top 2 validation accuracy: 0.8537735939025879\n",
      "Model Saved!\n",
      "2019-03-17 18:05:31.305486: step 3210, examples 160500, loss = 0.735321641 (32.318 examples/sec; 1.547 sec/batch)\n",
      "2019-03-17 18:05:46.777628: step 3220, examples 161000, loss = 0.716527164 (33.200 examples/sec; 1.506 sec/batch)\n",
      "2019-03-17 18:06:02.439275: step 3230, examples 161500, loss = 0.663078547 (32.007 examples/sec; 1.562 sec/batch)\n",
      "2019-03-17 18:06:17.932472: step 3240, examples 162000, loss = 0.620959163 (32.339 examples/sec; 1.546 sec/batch)\n",
      "2019-03-17 18:06:33.608156: step 3250, examples 162500, loss = 0.670329452 (31.245 examples/sec; 1.600 sec/batch)\n",
      "2019-03-17 18:06:49.030164: step 3260, examples 163000, loss = 0.845694304 (32.700 examples/sec; 1.529 sec/batch)\n",
      "2019-03-17 18:07:04.505315: step 3270, examples 163500, loss = 0.738672495 (32.172 examples/sec; 1.554 sec/batch)\n",
      "2019-03-17 18:07:20.251185: step 3280, examples 164000, loss = 0.803878844 (32.131 examples/sec; 1.556 sec/batch)\n",
      "2019-03-17 18:07:35.842644: step 3290, examples 164500, loss = 0.627886713 (32.981 examples/sec; 1.516 sec/batch)\n",
      "2019-03-17 18:07:51.545399: step 3300, examples 165000, loss = 0.557452440 (32.829 examples/sec; 1.523 sec/batch)\n",
      "Top 1 validation accuracy: 0.6533018946647644 and top 2 validation accuracy: 0.8419811129570007\n",
      "Model Saved!\n",
      "2019-03-17 18:08:12.619438: step 3310, examples 165500, loss = 0.717323959 (32.193 examples/sec; 1.553 sec/batch)\n",
      "2019-03-17 18:08:28.094587: step 3320, examples 166000, loss = 0.608481526 (32.851 examples/sec; 1.522 sec/batch)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2019-03-17 18:08:43.699081: step 3330, examples 166500, loss = 0.889246166 (32.381 examples/sec; 1.544 sec/batch)\n",
      "2019-03-17 18:08:59.169219: step 3340, examples 167000, loss = 0.681951821 (31.884 examples/sec; 1.568 sec/batch)\n",
      "2019-03-17 18:09:14.749650: step 3350, examples 167500, loss = 0.715931654 (33.003 examples/sec; 1.515 sec/batch)\n",
      "2019-03-17 18:09:30.222794: step 3360, examples 168000, loss = 0.670045555 (32.007 examples/sec; 1.562 sec/batch)\n",
      "2019-03-17 18:09:45.705965: step 3370, examples 168500, loss = 0.656990647 (33.468 examples/sec; 1.494 sec/batch)\n",
      "2019-03-17 18:10:01.229243: step 3380, examples 169000, loss = 0.696973383 (34.109 examples/sec; 1.466 sec/batch)\n",
      "2019-03-17 18:10:16.253193: step 3390, examples 169500, loss = 0.780916810 (34.179 examples/sec; 1.463 sec/batch)\n",
      "2019-03-17 18:10:31.489709: step 3400, examples 170000, loss = 0.551340163 (31.363 examples/sec; 1.594 sec/batch)\n",
      "Top 1 validation accuracy: 0.6320754885673523 and top 2 validation accuracy: 0.8396226167678833\n",
      "Model Saved!\n",
      "2019-03-17 18:10:52.437412: step 3410, examples 170500, loss = 0.676702380 (32.678 examples/sec; 1.530 sec/batch)\n",
      "2019-03-17 18:11:08.022855: step 3420, examples 171000, loss = 0.612653852 (32.152 examples/sec; 1.555 sec/batch)\n",
      "2019-03-17 18:11:23.429824: step 3430, examples 171500, loss = 0.605803728 (33.025 examples/sec; 1.514 sec/batch)\n",
      "2019-03-17 18:11:38.942080: step 3440, examples 172000, loss = 0.691307008 (32.256 examples/sec; 1.550 sec/batch)\n",
      "2019-03-17 18:11:54.493433: step 3450, examples 172500, loss = 0.849054396 (32.829 examples/sec; 1.523 sec/batch)\n",
      "2019-03-17 18:12:10.213233: step 3460, examples 173000, loss = 0.658733368 (31.682 examples/sec; 1.578 sec/batch)\n",
      "2019-03-17 18:12:25.803690: step 3470, examples 173500, loss = 0.663457155 (31.987 examples/sec; 1.563 sec/batch)\n",
      "2019-03-17 18:12:41.305912: step 3480, examples 174000, loss = 0.805952072 (32.444 examples/sec; 1.541 sec/batch)\n",
      "2019-03-17 18:12:56.769030: step 3490, examples 174500, loss = 0.781624854 (31.946 examples/sec; 1.565 sec/batch)\n",
      "2019-03-17 18:13:12.296319: step 3500, examples 175000, loss = 0.776616514 (32.089 examples/sec; 1.558 sec/batch)\n",
      "Top 1 validation accuracy: 0.6226415038108826 and top 2 validation accuracy: 0.8136792182922363\n",
      "Model Saved!\n",
      "2019-03-17 18:13:33.500705: step 3510, examples 175500, loss = 0.648392320 (31.245 examples/sec; 1.600 sec/batch)\n",
      "2019-03-17 18:13:49.128260: step 3520, examples 176000, loss = 0.746468484 (32.110 examples/sec; 1.557 sec/batch)\n",
      "2019-03-17 18:14:04.641511: step 3530, examples 176500, loss = 0.665847063 (33.046 examples/sec; 1.513 sec/batch)\n",
      "2019-03-17 18:14:20.147744: step 3540, examples 177000, loss = 0.631497025 (32.423 examples/sec; 1.542 sec/batch)\n",
      "2019-03-17 18:14:35.671022: step 3550, examples 177500, loss = 0.668286145 (31.925 examples/sec; 1.566 sec/batch)\n",
      "2019-03-17 18:14:51.071975: step 3560, examples 178000, loss = 0.710020721 (33.178 examples/sec; 1.507 sec/batch)\n",
      "2019-03-17 18:15:06.503008: step 3570, examples 178500, loss = 0.766533911 (32.572 examples/sec; 1.535 sec/batch)\n",
      "2019-03-17 18:15:22.042329: step 3580, examples 179000, loss = 0.650503397 (32.235 examples/sec; 1.551 sec/batch)\n",
      "2019-03-17 18:15:37.544551: step 3590, examples 179500, loss = 0.542044699 (32.550 examples/sec; 1.536 sec/batch)\n",
      "2019-03-17 18:15:52.962549: step 3600, examples 180000, loss = 0.678966343 (32.572 examples/sec; 1.535 sec/batch)\n",
      "Top 1 validation accuracy: 0.6415094137191772 and top 2 validation accuracy: 0.7948113083839417\n",
      "Model Saved!\n",
      "2019-03-17 18:16:14.003500: step 3610, examples 180500, loss = 0.630705297 (32.214 examples/sec; 1.552 sec/batch)\n",
      "2019-03-17 18:16:29.534799: step 3620, examples 181000, loss = 0.596888006 (33.003 examples/sec; 1.515 sec/batch)\n",
      "2019-03-17 18:16:45.177395: step 3630, examples 181500, loss = 0.739189088 (31.946 examples/sec; 1.565 sec/batch)\n",
      "2019-03-17 18:17:00.742785: step 3640, examples 182000, loss = 0.556111872 (32.872 examples/sec; 1.521 sec/batch)\n",
      "2019-03-17 18:17:16.256036: step 3650, examples 182500, loss = 0.639029741 (32.110 examples/sec; 1.557 sec/batch)\n",
      "2019-03-17 18:17:31.728178: step 3660, examples 183000, loss = 0.729388833 (31.823 examples/sec; 1.571 sec/batch)\n",
      "2019-03-17 18:17:47.323647: step 3670, examples 183500, loss = 0.677763045 (32.850 examples/sec; 1.522 sec/batch)\n",
      "2019-03-17 18:18:02.906083: step 3680, examples 184000, loss = 0.646817982 (32.786 examples/sec; 1.525 sec/batch)\n",
      "2019-03-17 18:18:18.349148: step 3690, examples 184500, loss = 0.715227008 (32.423 examples/sec; 1.542 sec/batch)\n",
      "2019-03-17 18:18:33.820287: step 3700, examples 185000, loss = 0.658753812 (31.987 examples/sec; 1.563 sec/batch)\n",
      "Top 1 validation accuracy: 0.6485849022865295 and top 2 validation accuracy: 0.8537735939025879\n",
      "Model Saved!\n",
      "2019-03-17 18:18:54.969526: step 3710, examples 185500, loss = 0.849562466 (32.981 examples/sec; 1.516 sec/batch)\n",
      "2019-03-17 18:19:10.367471: step 3720, examples 186000, loss = 0.610099733 (33.046 examples/sec; 1.513 sec/batch)\n",
      "2019-03-17 18:19:25.830589: step 3730, examples 186500, loss = 0.575748265 (33.200 examples/sec; 1.506 sec/batch)\n",
      "2019-03-17 18:19:41.330806: step 3740, examples 187000, loss = 0.673148155 (32.256 examples/sec; 1.550 sec/batch)\n",
      "2019-03-17 18:19:56.813977: step 3750, examples 187500, loss = 0.628787279 (32.829 examples/sec; 1.523 sec/batch)\n",
      "2019-03-17 18:20:12.326226: step 3760, examples 188000, loss = 0.642596066 (33.003 examples/sec; 1.515 sec/batch)\n",
      "2019-03-17 18:20:27.372235: step 3770, examples 188500, loss = 0.689859927 (34.606 examples/sec; 1.445 sec/batch)\n",
      "2019-03-17 18:20:42.719044: step 3780, examples 189000, loss = 0.604573429 (33.245 examples/sec; 1.504 sec/batch)\n",
      "2019-03-17 18:20:58.227282: step 3790, examples 189500, loss = 0.626117826 (32.466 examples/sec; 1.540 sec/batch)\n",
      "2019-03-17 18:21:13.800693: step 3800, examples 190000, loss = 0.885560811 (32.487 examples/sec; 1.539 sec/batch)\n",
      "Top 1 validation accuracy: 0.6603773832321167 and top 2 validation accuracy: 0.8466981053352356\n",
      "Model Saved!\n",
      "2019-03-17 18:21:34.594988: step 3810, examples 190500, loss = 0.687535465 (32.381 examples/sec; 1.544 sec/batch)\n",
      "2019-03-17 18:21:50.102223: step 3820, examples 191000, loss = 0.608233213 (31.966 examples/sec; 1.564 sec/batch)\n",
      "2019-03-17 18:22:05.766878: step 3830, examples 191500, loss = 0.554955840 (32.007 examples/sec; 1.562 sec/batch)\n",
      "2019-03-17 18:22:21.321238: step 3840, examples 192000, loss = 0.692306459 (32.402 examples/sec; 1.543 sec/batch)\n",
      "2019-03-17 18:22:36.793380: step 3850, examples 192500, loss = 0.736876845 (32.466 examples/sec; 1.540 sec/batch)\n",
      "2019-03-17 18:22:52.253490: step 3860, examples 193000, loss = 0.690543234 (32.423 examples/sec; 1.542 sec/batch)\n",
      "2019-03-17 18:23:07.811862: step 3870, examples 193500, loss = 0.576805890 (32.894 examples/sec; 1.520 sec/batch)\n",
      "2019-03-17 18:23:23.396303: step 3880, examples 194000, loss = 0.551447034 (32.700 examples/sec; 1.529 sec/batch)\n",
      "2019-03-17 18:23:38.849394: step 3890, examples 194500, loss = 0.839994252 (32.721 examples/sec; 1.528 sec/batch)\n",
      "2019-03-17 18:23:54.321536: step 3900, examples 195000, loss = 0.576925337 (32.678 examples/sec; 1.530 sec/batch)\n",
      "Top 1 validation accuracy: 0.6297169923782349 and top 2 validation accuracy: 0.8537735939025879\n",
      "Model Saved!\n",
      "2019-03-17 18:24:15.324386: step 3910, examples 195500, loss = 0.634254634 (32.318 examples/sec; 1.547 sec/batch)\n",
      "2019-03-17 18:24:30.825604: step 3920, examples 196000, loss = 0.573275328 (32.256 examples/sec; 1.550 sec/batch)\n",
      "2019-03-17 18:24:46.386984: step 3930, examples 196500, loss = 0.723654568 (32.444 examples/sec; 1.541 sec/batch)\n",
      "2019-03-17 18:25:01.819019: step 3940, examples 197000, loss = 0.680428207 (33.694 examples/sec; 1.484 sec/batch)\n",
      "2019-03-17 18:25:17.303194: step 3950, examples 197500, loss = 0.640754938 (32.256 examples/sec; 1.550 sec/batch)\n",
      "2019-03-17 18:25:32.791379: step 3960, examples 198000, loss = 0.546924949 (32.110 examples/sec; 1.557 sec/batch)\n",
      "2019-03-17 18:25:48.230433: step 3970, examples 198500, loss = 0.702139795 (32.657 examples/sec; 1.531 sec/batch)\n",
      "2019-03-17 18:26:03.713604: step 3980, examples 199000, loss = 0.629159391 (33.200 examples/sec; 1.506 sec/batch)\n",
      "2019-03-17 18:26:18.950120: step 3990, examples 199500, loss = 0.594021559 (32.937 examples/sec; 1.518 sec/batch)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2019-03-17 18:26:34.410230: step 4000, examples 200000, loss = 0.703410745 (32.850 examples/sec; 1.522 sec/batch)\n",
      "Top 1 validation accuracy: 0.6580188870429993 and top 2 validation accuracy: 0.8561320900917053\n",
      "Model Saved!\n",
      "2019-03-17 18:26:55.314824: step 4010, examples 200500, loss = 0.670727849 (31.925 examples/sec; 1.566 sec/batch)\n",
      "2019-03-17 18:27:10.810026: step 4020, examples 201000, loss = 0.666491210 (32.916 examples/sec; 1.519 sec/batch)\n",
      "2019-03-17 18:27:26.388452: step 4030, examples 201500, loss = 0.631522775 (32.381 examples/sec; 1.544 sec/batch)\n",
      "2019-03-17 18:27:41.922760: step 4040, examples 202000, loss = 0.672763467 (31.722 examples/sec; 1.576 sec/batch)\n",
      "2019-03-17 18:27:57.592426: step 4050, examples 202500, loss = 0.554918110 (31.702 examples/sec; 1.577 sec/batch)\n",
      "2019-03-17 18:28:13.125732: step 4060, examples 203000, loss = 0.639123261 (33.245 examples/sec; 1.504 sec/batch)\n",
      "2019-03-17 18:28:28.633970: step 4070, examples 203500, loss = 0.580334842 (32.423 examples/sec; 1.542 sec/batch)\n",
      "2019-03-17 18:28:44.319680: step 4080, examples 204000, loss = 0.553541660 (32.466 examples/sec; 1.540 sec/batch)\n",
      "2019-03-17 18:28:59.913144: step 4090, examples 204500, loss = 0.596614301 (31.581 examples/sec; 1.583 sec/batch)\n",
      "2019-03-17 18:29:15.357212: step 4100, examples 205000, loss = 0.509513080 (33.178 examples/sec; 1.507 sec/batch)\n",
      "Top 1 validation accuracy: 0.650943398475647 and top 2 validation accuracy: 0.8325471878051758\n",
      "Model Saved!\n",
      "2019-03-17 18:29:36.518482: step 4110, examples 205500, loss = 0.634271264 (32.007 examples/sec; 1.562 sec/batch)\n",
      "2019-03-17 18:29:53.073620: step 4120, examples 206000, loss = 0.671921551 (25.851 examples/sec; 1.934 sec/batch)\n",
      "2019-03-17 18:30:09.211910: step 4130, examples 206500, loss = 0.673468173 (32.779 examples/sec; 1.525 sec/batch)\n",
      "2019-03-17 18:30:24.492899: step 4140, examples 207000, loss = 0.660402298 (32.653 examples/sec; 1.531 sec/batch)\n",
      "2019-03-17 18:30:39.803460: step 4150, examples 207500, loss = 0.743144929 (33.338 examples/sec; 1.500 sec/batch)\n",
      "2019-03-17 18:30:55.192817: step 4160, examples 208000, loss = 0.665078580 (32.322 examples/sec; 1.547 sec/batch)\n",
      "2019-03-17 18:31:10.458152: step 4170, examples 208500, loss = 0.588075876 (32.992 examples/sec; 1.516 sec/batch)\n",
      "2019-03-17 18:31:25.698848: step 4180, examples 209000, loss = 0.692135215 (33.428 examples/sec; 1.496 sec/batch)\n",
      "2019-03-17 18:31:40.910972: step 4190, examples 209500, loss = 0.687858522 (32.823 examples/sec; 1.523 sec/batch)\n",
      "2019-03-17 18:31:56.352670: step 4200, examples 210000, loss = 0.642350972 (35.456 examples/sec; 1.410 sec/batch)\n",
      "Top 1 validation accuracy: 0.6415094137191772 and top 2 validation accuracy: 0.8301886916160583\n",
      "Model Saved!\n",
      "2019-03-17 18:32:16.569970: step 4210, examples 210500, loss = 0.591412306 (33.035 examples/sec; 1.514 sec/batch)\n",
      "2019-03-17 18:32:31.850977: step 4220, examples 211000, loss = 0.555945158 (32.998 examples/sec; 1.515 sec/batch)\n",
      "2019-03-17 18:32:46.949175: step 4230, examples 211500, loss = 0.685803235 (33.103 examples/sec; 1.510 sec/batch)\n",
      "2019-03-17 18:33:02.203456: step 4240, examples 212000, loss = 0.695604384 (32.613 examples/sec; 1.533 sec/batch)\n",
      "2019-03-17 18:33:17.914819: step 4250, examples 212500, loss = 0.698487580 (33.573 examples/sec; 1.489 sec/batch)\n",
      "2019-03-17 18:33:33.008188: step 4260, examples 213000, loss = 0.559038877 (33.634 examples/sec; 1.487 sec/batch)\n",
      "2019-03-17 18:33:48.801684: step 4270, examples 213500, loss = 0.615083694 (32.477 examples/sec; 1.540 sec/batch)\n",
      "2019-03-17 18:34:04.205702: step 4280, examples 214000, loss = 0.609707236 (32.281 examples/sec; 1.549 sec/batch)\n",
      "2019-03-17 18:34:19.440641: step 4290, examples 214500, loss = 0.486668497 (33.183 examples/sec; 1.507 sec/batch)\n",
      "2019-03-17 18:34:35.417139: step 4300, examples 215000, loss = 0.587537169 (28.226 examples/sec; 1.771 sec/batch)\n",
      "Top 1 validation accuracy: 0.6273584961891174 and top 2 validation accuracy: 0.8396226167678833\n",
      "Model Saved!\n",
      "2019-03-17 18:34:57.004543: step 4310, examples 215500, loss = 0.669554651 (32.614 examples/sec; 1.533 sec/batch)\n",
      "2019-03-17 18:35:13.672739: step 4320, examples 216000, loss = 0.579650104 (28.334 examples/sec; 1.765 sec/batch)\n",
      "2019-03-17 18:35:31.237446: step 4330, examples 216500, loss = 0.566888869 (27.161 examples/sec; 1.841 sec/batch)\n",
      "2019-03-17 18:35:47.607789: step 4340, examples 217000, loss = 0.660413504 (30.782 examples/sec; 1.624 sec/batch)\n",
      "2019-03-17 18:36:03.577915: step 4350, examples 217500, loss = 0.700143456 (31.154 examples/sec; 1.605 sec/batch)\n",
      "2019-03-17 18:36:20.040691: step 4360, examples 218000, loss = 0.608527184 (29.630 examples/sec; 1.687 sec/batch)\n",
      "2019-03-17 18:36:36.441218: step 4370, examples 218500, loss = 0.570330441 (31.803 examples/sec; 1.572 sec/batch)\n",
      "2019-03-17 18:36:52.721193: step 4380, examples 219000, loss = 0.587926626 (31.742 examples/sec; 1.575 sec/batch)\n",
      "2019-03-17 18:37:08.924949: step 4390, examples 219500, loss = 0.572232723 (28.036 examples/sec; 1.783 sec/batch)\n",
      "2019-03-17 18:37:25.170283: step 4400, examples 220000, loss = 0.688128591 (32.256 examples/sec; 1.550 sec/batch)\n",
      "Top 1 validation accuracy: 0.6226415038108826 and top 2 validation accuracy: 0.8325471878051758\n",
      "Model Saved!\n",
      "2019-03-17 18:37:47.344767: step 4410, examples 220500, loss = 0.642842293 (31.294 examples/sec; 1.598 sec/batch)\n",
      "2019-03-17 18:38:03.956445: step 4420, examples 221000, loss = 0.696063221 (30.204 examples/sec; 1.655 sec/batch)\n",
      "2019-03-17 18:38:20.180056: step 4430, examples 221500, loss = 0.562579095 (31.402 examples/sec; 1.592 sec/batch)\n",
      "2019-03-17 18:38:36.009146: step 4440, examples 222000, loss = 0.543892920 (32.235 examples/sec; 1.551 sec/batch)\n",
      "2019-03-17 18:38:51.952493: step 4450, examples 222500, loss = 0.745344222 (30.124 examples/sec; 1.660 sec/batch)\n",
      "2019-03-17 18:39:08.714063: step 4460, examples 223000, loss = 0.474826217 (32.444 examples/sec; 1.541 sec/batch)\n",
      "2019-03-17 18:39:24.146112: step 4470, examples 223500, loss = 0.654078782 (32.389 examples/sec; 1.544 sec/batch)\n",
      "2019-03-17 18:39:39.867882: step 4480, examples 224000, loss = 0.505243301 (30.248 examples/sec; 1.653 sec/batch)\n",
      "2019-03-17 18:39:56.767919: step 4490, examples 224500, loss = 0.643392086 (29.351 examples/sec; 1.704 sec/batch)\n",
      "2019-03-17 18:40:12.697553: step 4500, examples 225000, loss = 0.631488264 (28.875 examples/sec; 1.732 sec/batch)\n",
      "Top 1 validation accuracy: 0.6438679099082947 and top 2 validation accuracy: 0.8325471878051758\n",
      "Model Saved!\n",
      "2019-03-17 18:40:34.901187: step 4510, examples 225500, loss = 0.750457048 (30.444 examples/sec; 1.642 sec/batch)\n",
      "2019-03-17 18:40:51.835562: step 4520, examples 226000, loss = 0.563395083 (28.242 examples/sec; 1.770 sec/batch)\n",
      "2019-03-17 18:41:08.332906: step 4530, examples 226500, loss = 0.748340428 (29.288 examples/sec; 1.707 sec/batch)\n",
      "2019-03-17 18:41:23.746944: step 4540, examples 227000, loss = 0.517306745 (33.341 examples/sec; 1.500 sec/batch)\n",
      "2019-03-17 18:41:41.198614: step 4550, examples 227500, loss = 0.568885267 (27.072 examples/sec; 1.847 sec/batch)\n",
      "2019-03-17 18:41:56.895964: step 4560, examples 228000, loss = 0.595611811 (31.835 examples/sec; 1.571 sec/batch)\n",
      "2019-03-17 18:42:12.168534: step 4570, examples 228500, loss = 0.535122812 (33.166 examples/sec; 1.508 sec/batch)\n",
      "2019-03-17 18:42:27.340285: step 4580, examples 229000, loss = 0.591346860 (33.692 examples/sec; 1.484 sec/batch)\n",
      "2019-03-17 18:42:43.035504: step 4590, examples 229500, loss = 0.496075809 (32.480 examples/sec; 1.539 sec/batch)\n",
      "2019-03-17 18:42:58.832917: step 4600, examples 230000, loss = 0.559957504 (30.961 examples/sec; 1.615 sec/batch)\n",
      "Top 1 validation accuracy: 0.6674528121948242 and top 2 validation accuracy: 0.8466981053352356\n",
      "Model Saved!\n",
      "2019-03-17 18:43:19.697738: step 4610, examples 230500, loss = 0.563350737 (32.591 examples/sec; 1.534 sec/batch)\n",
      "2019-03-17 18:43:35.129606: step 4620, examples 231000, loss = 0.508856297 (31.324 examples/sec; 1.596 sec/batch)\n",
      "2019-03-17 18:43:50.963257: step 4630, examples 231500, loss = 0.488801867 (32.951 examples/sec; 1.517 sec/batch)\n",
      "2019-03-17 18:44:06.122422: step 4640, examples 232000, loss = 0.559978664 (31.401 examples/sec; 1.592 sec/batch)\n",
      "2019-03-17 18:44:21.975044: step 4650, examples 232500, loss = 0.541001737 (32.958 examples/sec; 1.517 sec/batch)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2019-03-17 18:44:37.294314: step 4660, examples 233000, loss = 0.597392738 (32.635 examples/sec; 1.532 sec/batch)\n",
      "2019-03-17 18:44:52.733985: step 4670, examples 233500, loss = 0.593674898 (33.411 examples/sec; 1.496 sec/batch)\n",
      "2019-03-17 18:45:08.030727: step 4680, examples 234000, loss = 0.553516805 (32.536 examples/sec; 1.537 sec/batch)\n",
      "2019-03-17 18:45:23.197591: step 4690, examples 234500, loss = 0.563838303 (31.374 examples/sec; 1.594 sec/batch)\n",
      "2019-03-17 18:45:38.404740: step 4700, examples 235000, loss = 0.646329105 (31.500 examples/sec; 1.587 sec/batch)\n",
      "Top 1 validation accuracy: 0.6603773832321167 and top 2 validation accuracy: 0.8349056839942932\n",
      "Model Saved!\n",
      "2019-03-17 18:45:59.052268: step 4710, examples 235500, loss = 0.593142688 (33.382 examples/sec; 1.498 sec/batch)\n",
      "2019-03-17 18:46:14.130860: step 4720, examples 236000, loss = 0.657857180 (33.329 examples/sec; 1.500 sec/batch)\n",
      "2019-03-17 18:46:29.278029: step 4730, examples 236500, loss = 0.678813875 (32.650 examples/sec; 1.531 sec/batch)\n",
      "2019-03-17 18:46:44.385161: step 4740, examples 237000, loss = 0.586922705 (33.075 examples/sec; 1.512 sec/batch)\n",
      "2019-03-17 18:46:59.415985: step 4750, examples 237500, loss = 0.668576598 (33.104 examples/sec; 1.510 sec/batch)\n",
      "2019-03-17 18:47:14.571729: step 4760, examples 238000, loss = 0.583493173 (32.737 examples/sec; 1.527 sec/batch)\n",
      "2019-03-17 18:47:29.712873: step 4770, examples 238500, loss = 0.591056943 (32.994 examples/sec; 1.515 sec/batch)\n",
      "2019-03-17 18:47:44.834378: step 4780, examples 239000, loss = 0.601504683 (33.022 examples/sec; 1.514 sec/batch)\n",
      "2019-03-17 18:47:59.840613: step 4790, examples 239500, loss = 0.622409284 (33.732 examples/sec; 1.482 sec/batch)\n",
      "2019-03-17 18:48:15.762399: step 4800, examples 240000, loss = 0.547000945 (31.742 examples/sec; 1.575 sec/batch)\n",
      "Top 1 validation accuracy: 0.6957547068595886 and top 2 validation accuracy: 0.849056601524353\n",
      "Model Saved!\n",
      "2019-03-17 18:48:37.460756: step 4810, examples 240500, loss = 0.514478445 (31.925 examples/sec; 1.566 sec/batch)\n",
      "2019-03-17 18:48:52.850679: step 4820, examples 241000, loss = 0.532269239 (32.028 examples/sec; 1.561 sec/batch)\n",
      "2019-03-17 18:49:08.101232: step 4830, examples 241500, loss = 0.550545990 (32.572 examples/sec; 1.535 sec/batch)\n",
      "2019-03-17 18:49:23.498174: step 4840, examples 242000, loss = 0.690721571 (30.168 examples/sec; 1.657 sec/batch)\n",
      "2019-03-17 18:49:41.160140: step 4850, examples 242500, loss = 0.753120363 (32.193 examples/sec; 1.553 sec/batch)\n",
      "2019-03-17 18:49:56.941103: step 4860, examples 243000, loss = 0.668316960 (30.897 examples/sec; 1.618 sec/batch)\n",
      "2019-03-17 18:50:14.259076: step 4870, examples 243500, loss = 0.523193061 (32.172 examples/sec; 1.554 sec/batch)\n",
      "2019-03-17 18:50:29.835899: step 4880, examples 244000, loss = 0.626730561 (29.145 examples/sec; 1.716 sec/batch)\n",
      "2019-03-17 18:50:47.851804: step 4890, examples 244500, loss = 0.662358582 (27.719 examples/sec; 1.804 sec/batch)\n",
      "2019-03-17 18:51:04.730686: step 4900, examples 245000, loss = 0.524005890 (29.043 examples/sec; 1.722 sec/batch)\n",
      "Top 1 validation accuracy: 0.6839622855186462 and top 2 validation accuracy: 0.8349056839942932\n",
      "Model Saved!\n",
      "2019-03-17 18:51:27.045023: step 4910, examples 245500, loss = 0.594266355 (32.131 examples/sec; 1.556 sec/batch)\n",
      "2019-03-17 18:51:43.391490: step 4920, examples 246000, loss = 0.611594737 (26.469 examples/sec; 1.889 sec/batch)\n",
      "2019-03-17 18:51:59.981605: step 4930, examples 246500, loss = 0.521562219 (30.388 examples/sec; 1.645 sec/batch)\n",
      "2019-03-17 18:52:17.390898: step 4940, examples 247000, loss = 0.522020638 (30.877 examples/sec; 1.619 sec/batch)\n",
      "2019-03-17 18:52:33.235029: step 4950, examples 247500, loss = 0.580509007 (31.442 examples/sec; 1.590 sec/batch)\n",
      "2019-03-17 18:52:50.282362: step 4960, examples 248000, loss = 0.550541937 (25.932 examples/sec; 1.928 sec/batch)\n",
      "2019-03-17 18:53:06.934640: step 4970, examples 248500, loss = 0.529542208 (30.725 examples/sec; 1.627 sec/batch)\n",
      "2019-03-17 18:53:23.953896: step 4980, examples 249000, loss = 0.580207765 (22.802 examples/sec; 2.193 sec/batch)\n",
      "2019-03-17 18:53:43.248047: step 4990, examples 249500, loss = 0.549797714 (30.710 examples/sec; 1.628 sec/batch)\n",
      "Top 1 validation accuracy: 0.676886796951294 and top 2 validation accuracy: 0.8419811129570007\n",
      "Model Saved!\n"
     ]
    }
   ],
   "source": [
    "best_val_rnn = {}\n",
    "\n",
    "sub_id = 9\n",
    "num_cls = 4\n",
    "mstp = 5000\n",
    "lfrq = 10\n",
    "bsz = 50\n",
    "msf = 100\n",
    "tr = './trained_model_final/DCNN_RNN'\n",
    "if not os.path.exists(tr):\n",
    "    os.mkdir(tr)\n",
    "start = 0\n",
    "stop = 250\n",
    "step = 10\n",
    "time_length = 700\n",
    "time_bin = 350\n",
    "fsz = 3\n",
    "use_batchnorm = True\n",
    "use_dropout = True\n",
    "use_l2loss = True\n",
    "acc = 'Accuracy_rnn'\n",
    "path = 'Path_rnn'\n",
    "\n",
    "best_val_rnn[acc],best_val_rnn[path] = train_model_ss_subject(sub_id,tr,start,stop,step,time_length,time_bin,fsz,use_batchnorm,use_dropout,use_l2loss,num_cls,mstp,lfrq,bsz,msf)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test Accuracy for subject 0:\n",
      "Loading datasets...\n",
      "Dataset loading completes.\n",
      "INFO:tensorflow:Restoring parameters from ./trained_model_final/DCNN_RNN\\model.ckpt-4801\n",
      "[test  step 4801] loss: 1.39975; top_1_accuracy: 0.52000; top_5_accuracy: 0.820000 (0.976 sec/batch; 102.414 instances/sec)\n",
      "top_1_accuracy_test =  0.52 top_2_accuracy_test =  0.82\n",
      "Test Accuracy for subject 1:\n",
      "Loading datasets...\n",
      "Dataset loading completes.\n",
      "INFO:tensorflow:Restoring parameters from ./trained_model_final/DCNN_RNN\\model.ckpt-4801\n",
      "[test  step 4801] loss: 1.74371; top_1_accuracy: 0.50000; top_5_accuracy: 0.770000 (0.977 sec/batch; 102.332 instances/sec)\n",
      "top_1_accuracy_test =  0.5 top_2_accuracy_test =  0.77\n",
      "Test Accuracy for subject 2:\n",
      "Loading datasets...\n",
      "Dataset loading completes.\n",
      "INFO:tensorflow:Restoring parameters from ./trained_model_final/DCNN_RNN\\model.ckpt-4801\n",
      "[test  step 4801] loss: 1.15001; top_1_accuracy: 0.73000; top_5_accuracy: 0.880000 (0.998 sec/batch; 100.238 instances/sec)\n",
      "top_1_accuracy_test =  0.73 top_2_accuracy_test =  0.88\n",
      "Test Accuracy for subject 3:\n",
      "Loading datasets...\n",
      "Dataset loading completes.\n",
      "INFO:tensorflow:Restoring parameters from ./trained_model_final/DCNN_RNN\\model.ckpt-4801\n",
      "[test  step 4801] loss: 1.34297; top_1_accuracy: 0.64000; top_5_accuracy: 0.890000 (0.961 sec/batch; 104.010 instances/sec)\n",
      "top_1_accuracy_test =  0.64 top_2_accuracy_test =  0.89\n",
      "Test Accuracy for subject 4:\n",
      "Loading datasets...\n",
      "Dataset loading completes.\n",
      "INFO:tensorflow:Restoring parameters from ./trained_model_final/DCNN_RNN\\model.ckpt-4801\n",
      "[test  step 4801] loss: 1.28804; top_1_accuracy: 0.56383; top_5_accuracy: 0.861702 (0.925 sec/batch; 101.571 instances/sec)\n",
      "top_1_accuracy_test =  0.5638298 top_2_accuracy_test =  0.86170214\n",
      "Test Accuracy for subject 5:\n",
      "Loading datasets...\n",
      "Dataset loading completes.\n",
      "INFO:tensorflow:Restoring parameters from ./trained_model_final/DCNN_RNN\\model.ckpt-4801\n",
      "[test  step 4801] loss: 1.79192; top_1_accuracy: 0.45918; top_5_accuracy: 0.765306 (0.951 sec/batch; 103.007 instances/sec)\n",
      "top_1_accuracy_test =  0.45918366 top_2_accuracy_test =  0.7653061\n",
      "Test Accuracy for subject 6:\n",
      "Loading datasets...\n",
      "Dataset loading completes.\n",
      "INFO:tensorflow:Restoring parameters from ./trained_model_final/DCNN_RNN\\model.ckpt-4801\n",
      "[test  step 4801] loss: 1.26099; top_1_accuracy: 0.65000; top_5_accuracy: 0.820000 (0.977 sec/batch; 102.402 instances/sec)\n",
      "top_1_accuracy_test =  0.65 top_2_accuracy_test =  0.82\n",
      "Test Accuracy for subject 7:\n",
      "Loading datasets...\n",
      "Dataset loading completes.\n",
      "INFO:tensorflow:Restoring parameters from ./trained_model_final/DCNN_RNN\\model.ckpt-4801\n",
      "[test  step 4801] loss: 1.29373; top_1_accuracy: 0.67000; top_5_accuracy: 0.870000 (1.005 sec/batch; 99.538 instances/sec)\n",
      "top_1_accuracy_test =  0.67 top_2_accuracy_test =  0.87\n",
      "Test Accuracy for subject 8:\n",
      "Loading datasets...\n",
      "Dataset loading completes.\n",
      "INFO:tensorflow:Restoring parameters from ./trained_model_final/DCNN_RNN\\model.ckpt-4801\n",
      "[test  step 4801] loss: 1.02008; top_1_accuracy: 0.77660; top_5_accuracy: 0.914894 (0.959 sec/batch; 98.065 instances/sec)\n",
      "top_1_accuracy_test =  0.7765958 top_2_accuracy_test =  0.9148936\n",
      "Test Accuracy for all subjects:\n",
      "Loading datasets...\n",
      "Dataset loading completes.\n",
      "INFO:tensorflow:Restoring parameters from ./trained_model_final/DCNN_RNN\\model.ckpt-4801\n",
      "[test  step 4801] loss: 1.37521; top_1_accuracy: 0.61061; top_5_accuracy: 0.851016 (7.871 sec/batch; 112.566 instances/sec)\n",
      "top_1_accuracy_test =  0.6106095 top_2_accuracy_test =  0.8510158\n"
     ]
    }
   ],
   "source": [
    "# Test model accuracy on each subject\n",
    "subject_id = np.arange(10)\n",
    "start = 0\n",
    "stop = 250\n",
    "step = 10\n",
    "time_length = 700\n",
    "time_bin = 350\n",
    "#Nb = BATCH_SIZE\n",
    "fsz = 3\n",
    "use_batchnorm = True\n",
    "use_dropout = True\n",
    "use_l2loss = True\n",
    "path = 'Path_rnn' \n",
    "model_dir = best_val_rnn[path]\n",
    "\n",
    "for sub_id in subject_id:\n",
    "    if sub_id < 9:\n",
    "        print('Test Accuracy for subject {}:'.format(sub_id))\n",
    "    else:\n",
    "        print('Test Accuracy for all subjects:')\n",
    "    top_1_acc_test, top_2_acc_test = test_model_ss_subject(sub_id,model_dir,start,stop,step,time_length,time_bin,fsz,use_batchnorm,use_dropout,use_l2loss)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
